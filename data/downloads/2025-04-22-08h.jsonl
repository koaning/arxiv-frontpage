{"created":"2025-04-21 17:59:55","title":"StyleMe3D: Stylization with Disentangled Priors by Multiple Encoders on 3D Gaussians","abstract":"3D Gaussian Splatting (3DGS) excels in photorealistic scene reconstruction but struggles with stylized scenarios (e.g., cartoons, games) due to fragmented textures, semantic misalignment, and limited adaptability to abstract aesthetics. We propose StyleMe3D, a holistic framework for 3D GS style transfer that integrates multi-modal style conditioning, multi-level semantic alignment, and perceptual quality enhancement. Our key insights include: (1) optimizing only RGB attributes preserves geometric integrity during stylization; (2) disentangling low-, medium-, and high-level semantics is critical for coherent style transfer; (3) scalability across isolated objects and complex scenes is essential for practical deployment. StyleMe3D introduces four novel components: Dynamic Style Score Distillation (DSSD), leveraging Stable Diffusion's latent space for semantic alignment; Contrastive Style Descriptor (CSD) for localized, content-aware texture transfer; Simultaneously Optimized Scale (SOS) to decouple style details and structural coherence; and 3D Gaussian Quality Assessment (3DG-QA), a differentiable aesthetic prior trained on human-rated data to suppress artifacts and enhance visual harmony. Evaluated on NeRF synthetic dataset (objects) and tandt db (scenes) datasets, StyleMe3D outperforms state-of-the-art methods in preserving geometric details (e.g., carvings on sculptures) and ensuring stylistic consistency across scenes (e.g., coherent lighting in landscapes), while maintaining real-time rendering. This work bridges photorealistic 3D GS and artistic stylization, unlocking applications in gaming, virtual worlds, and digital art.","sentences":["3D Gaussian Splatting (3DGS) excels in photorealistic scene reconstruction but struggles with stylized scenarios (e.g., cartoons, games) due to fragmented textures, semantic misalignment, and limited adaptability to abstract aesthetics.","We propose StyleMe3D, a holistic framework for 3D GS style transfer that integrates multi-modal style conditioning, multi-level semantic alignment, and perceptual quality enhancement.","Our key insights include: (1) optimizing only RGB attributes preserves geometric integrity during stylization; (2) disentangling low-, medium-, and high-level semantics is critical for coherent style transfer; (3) scalability across isolated objects and complex scenes is essential for practical deployment.","StyleMe3D introduces four novel components: Dynamic Style Score Distillation (DSSD), leveraging Stable Diffusion's latent space for semantic alignment; Contrastive Style Descriptor (CSD) for localized, content-aware texture transfer; Simultaneously Optimized Scale (SOS) to decouple style details and structural coherence; and 3D Gaussian Quality Assessment (3DG-QA), a differentiable aesthetic prior trained on human-rated data to suppress artifacts and enhance visual harmony.","Evaluated on NeRF synthetic dataset (objects) and tandt db (scenes) datasets, StyleMe3D outperforms state-of-the-art methods in preserving geometric details (e.g., carvings on sculptures) and ensuring stylistic consistency across scenes (e.g., coherent lighting in landscapes), while maintaining real-time rendering.","This work bridges photorealistic 3D GS and artistic stylization, unlocking applications in gaming, virtual worlds, and digital art."],"url":"http://arxiv.org/abs/2504.15281v1"}
{"created":"2025-04-21 17:59:53","title":"VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models","abstract":"Visual reasoning is a core component of human intelligence and a critical capability for advanced multimodal models. Yet current reasoning evaluations of multimodal large language models (MLLMs) often rely on text descriptions and allow language-based reasoning shortcuts, failing to measure genuine vision-centric reasoning. To address this, we introduce VisuLogic: a benchmark of 1,000 human-verified problems across six categories (e.g., quantitative shifts, spatial relations, attribute comparisons). These various types of questions can be evaluated to assess the visual reasoning capabilities of MLLMs from multiple perspectives. We evaluate leading MLLMs on this benchmark and analyze their results to identify common failure modes. Most models score below 30% accuracy-only slightly above the 25% random baseline and far below the 51.4% achieved by humans-revealing significant gaps in visual reasoning. Furthermore, we provide a supplementary training dataset and a reinforcement-learning baseline to support further progress.","sentences":["Visual reasoning is a core component of human intelligence and a critical capability for advanced multimodal models.","Yet current reasoning evaluations of multimodal large language models (MLLMs) often rely on text descriptions and allow language-based reasoning shortcuts, failing to measure genuine vision-centric reasoning.","To address this, we introduce VisuLogic: a benchmark of 1,000 human-verified problems across six categories (e.g., quantitative shifts, spatial relations, attribute comparisons).","These various types of questions can be evaluated to assess the visual reasoning capabilities of MLLMs from multiple perspectives.","We evaluate leading MLLMs on this benchmark and analyze their results to identify common failure modes.","Most models score below 30% accuracy-only slightly above the 25% random baseline and far below the 51.4% achieved by humans-revealing significant gaps in visual reasoning.","Furthermore, we provide a supplementary training dataset and a reinforcement-learning baseline to support further progress."],"url":"http://arxiv.org/abs/2504.15279v1"}
{"created":"2025-04-21 17:59:53","title":"Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs","abstract":"Multi-view understanding, the ability to reconcile visual information across diverse viewpoints for effective navigation, manipulation, and 3D scene comprehension, is a fundamental challenge in Multi-Modal Large Language Models (MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive advances in high-level reasoning and planning, they frequently fall short when confronted with multi-view geometric consistency and cross-view correspondence. To comprehensively evaluate the challenges of MLLMs in multi-view scene reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human carefully annotated multi-view question-answer pairs across 90 diverse real-world scenes. Our six tasks (counting, attribute identification, relative distance, relative direction, object manipulation, and camera pose estimation) specifically test model's geometric correspondence and the capacity to align information consistently across views. Our extensive experiments, benchmark on 27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and GPT-4o against human evaluators reveals a substantial performance gap, indicating that current MLLMs remain far from human-level proficiency. Through in-depth analysis, we show that MLLMs are particularly underperforming under two aspects: (1) cross-view correspondence for partially occluded views and (2) establishing the coarse camera poses. These findings highlight the necessity of domain-specific refinements or modules that embed stronger multi-view awareness. We believe that our All-Angles Bench offers valuable insights and contribute to bridging the gap between MLLMs and human-level multi-view understanding. The project and benchmark are publicly available at https://danielchyeh.github.io/All-Angles-Bench/.","sentences":["Multi-view understanding, the ability to reconcile visual information across diverse viewpoints for effective navigation, manipulation, and 3D scene comprehension, is a fundamental challenge in Multi-Modal Large Language Models (MLLMs) to be used as embodied agents.","While recent MLLMs have shown impressive advances in high-level reasoning and planning, they frequently fall short when confronted with multi-view geometric consistency and cross-view correspondence.","To comprehensively evaluate the challenges of MLLMs in multi-view scene reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human carefully annotated multi-view question-answer pairs across 90 diverse real-world scenes.","Our six tasks (counting, attribute identification, relative distance, relative direction, object manipulation, and camera pose estimation) specifically test model's geometric correspondence and the capacity to align information consistently across views.","Our extensive experiments, benchmark on 27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and GPT-4o against human evaluators reveals a substantial performance gap, indicating that current MLLMs remain far from human-level proficiency.","Through in-depth analysis, we show that MLLMs are particularly underperforming under two aspects: (1) cross-view correspondence for partially occluded views and (2) establishing the coarse camera poses.","These findings highlight the necessity of domain-specific refinements or modules that embed stronger multi-view awareness.","We believe that our All-Angles Bench offers valuable insights and contribute to bridging the gap between MLLMs and human-level multi-view understanding.","The project and benchmark are publicly available at https://danielchyeh.github.io/All-Angles-Bench/."],"url":"http://arxiv.org/abs/2504.15280v1"}
{"created":"2025-04-21 17:59:49","title":"DRAWER: Digital Reconstruction and Articulation With Environment Realism","abstract":"Creating virtual digital replicas from real-world data unlocks significant potential across domains like gaming and robotics. In this paper, we present DRAWER, a novel framework that converts a video of a static indoor scene into a photorealistic and interactive digital environment. Our approach centers on two main contributions: (i) a reconstruction module based on a dual scene representation that reconstructs the scene with fine-grained geometric details, and (ii) an articulation module that identifies articulation types and hinge positions, reconstructs simulatable shapes and appearances and integrates them into the scene. The resulting virtual environment is photorealistic, interactive, and runs in real time, with compatibility for game engines and robotic simulation platforms. We demonstrate the potential of DRAWER by using it to automatically create an interactive game in Unreal Engine and to enable real-to-sim-to-real transfer for robotics applications.","sentences":["Creating virtual digital replicas from real-world data unlocks significant potential across domains like gaming and robotics.","In this paper, we present DRAWER, a novel framework that converts a video of a static indoor scene into a photorealistic and interactive digital environment.","Our approach centers on two main contributions: (i) a reconstruction module based on a dual scene representation that reconstructs the scene with fine-grained geometric details, and (ii) an articulation module that identifies articulation types and hinge positions, reconstructs simulatable shapes and appearances and integrates them into the scene.","The resulting virtual environment is photorealistic, interactive, and runs in real time, with compatibility for game engines and robotic simulation platforms.","We demonstrate the potential of DRAWER by using it to automatically create an interactive game in Unreal Engine and to enable real-to-sim-to-real transfer for robotics applications."],"url":"http://arxiv.org/abs/2504.15278v1"}
{"created":"2025-04-21 17:59:02","title":"Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning","abstract":"Process reward models (PRMs) have proven effective for test-time scaling of Large Language Models (LLMs) on challenging reasoning tasks. However, reward hacking issues with PRMs limit their successful application in reinforcement fine-tuning. In this paper, we identify the main cause of PRM-induced reward hacking: the canonical summation-form credit assignment in reinforcement learning (RL), which defines the value as cumulative gamma-decayed future rewards, easily induces LLMs to hack steps with high rewards. To address this, we propose PURE: Process sUpervised Reinforcement lEarning. The key innovation of PURE is a min-form credit assignment that formulates the value function as the minimum of future rewards. This method significantly alleviates reward hacking by limiting the value function range and distributing advantages more reasonably. Through extensive experiments on 3 base models, we show that PRM-based approaches enabling min-form credit assignment achieve comparable reasoning performance to verifiable reward-based methods within only 30% steps. In contrast, the canonical sum-form credit assignment collapses training even at the beginning! Additionally, when we supplement PRM-based fine-tuning with just 10% verifiable rewards, we further alleviate reward hacking and produce the best fine-tuned model based on Qwen2.5-Math-7B in our experiments, achieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5 benchmarks. Moreover, we summarize the observed reward hacking cases and analyze the causes of training collapse. Code and models are available at https://github.com/CJReinforce/PURE.","sentences":["Process reward models (PRMs) have proven effective for test-time scaling of Large Language Models (LLMs) on challenging reasoning tasks.","However, reward hacking issues with PRMs limit their successful application in reinforcement fine-tuning.","In this paper, we identify the main cause of PRM-induced reward hacking: the canonical summation-form credit assignment in reinforcement learning (RL), which defines the value as cumulative gamma-decayed future rewards, easily induces LLMs to hack steps with high rewards.","To address this, we propose PURE:","Process sUpervised Reinforcement lEarning.","The key innovation of PURE is a min-form credit assignment that formulates the value function as the minimum of future rewards.","This method significantly alleviates reward hacking by limiting the value function range and distributing advantages more reasonably.","Through extensive experiments on 3 base models, we show that PRM-based approaches enabling min-form credit assignment achieve comparable reasoning performance to verifiable reward-based methods within only 30% steps.","In contrast, the canonical sum-form credit assignment collapses training even at the beginning!","Additionally, when we supplement PRM-based fine-tuning with just 10% verifiable rewards, we further alleviate reward hacking and produce the best fine-tuned model based on Qwen2.5-Math-7B in our experiments, achieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5 benchmarks.","Moreover, we summarize the observed reward hacking cases and analyze the causes of training collapse.","Code and models are available at https://github.com/CJReinforce/PURE."],"url":"http://arxiv.org/abs/2504.15275v1"}
{"created":"2025-04-21 17:57:28","title":"Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models","abstract":"We introduce Eagle 2.5, a family of frontier vision-language models (VLMs) for long-context multimodal learning. Our work addresses the challenges in long video comprehension and high-resolution image understanding, introducing a generalist framework for both tasks. The proposed training framework incorporates Automatic Degrade Sampling and Image Area Preservation, two techniques that preserve contextual integrity and visual details. The framework also includes numerous efficiency optimizations in the pipeline for long-context data training. Finally, we propose Eagle-Video-110K, a novel dataset that integrates both story-level and clip-level annotations, facilitating long-video understanding. Eagle 2.5 demonstrates substantial improvements on long-context multimodal benchmarks, providing a robust solution to the limitations of existing VLMs. Notably, our best model Eagle 2.5-8B achieves 72.4% on Video-MME with 512 input frames, matching the results of top-tier commercial model such as GPT-4o and large-scale open-source models like Qwen2.5-VL-72B and InternVL2.5-78B.","sentences":["We introduce Eagle 2.5, a family of frontier vision-language models (VLMs) for long-context multimodal learning.","Our work addresses the challenges in long video comprehension and high-resolution image understanding, introducing a generalist framework for both tasks.","The proposed training framework incorporates Automatic Degrade Sampling and Image Area Preservation, two techniques that preserve contextual integrity and visual details.","The framework also includes numerous efficiency optimizations in the pipeline for long-context data training.","Finally, we propose Eagle-Video-110K, a novel dataset that integrates both story-level and clip-level annotations, facilitating long-video understanding.","Eagle 2.5 demonstrates substantial improvements on long-context multimodal benchmarks, providing a robust solution to the limitations of existing VLMs.","Notably, our best model Eagle 2.5-8B achieves 72.4% on Video-MME with 512 input frames, matching the results of top-tier commercial model such as GPT-4o and large-scale open-source models like Qwen2.5-VL-72B and InternVL2.5-78B."],"url":"http://arxiv.org/abs/2504.15271v1"}
{"created":"2025-04-21 17:57:21","title":"An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes","abstract":"Large Multimodal Models (LMMs) uniformly perceive video frames, creating computational inefficiency for videos with inherently varying temporal information density. This paper present \\textbf{Quicksviewer}, an LMM with new perceiving paradigm that partitions a video of nonuniform density into varying cubes using Gumbel Softmax, followed by a unified resampling for each cube to achieve efficient video understanding. This simple and intuitive approach dynamically compress video online based on its temporal density, significantly reducing spatiotemporal redundancy (overall 45$\\times$ compression rate), while enabling efficient training with large receptive field. We train the model from a language backbone through three progressive stages, each incorporating lengthy videos on average of 420s/1fps thanks to the perceiving efficiency. With only 0.8M total video-text samples for training, our model outperforms the direct baseline employing a fixed partitioning strategy by a maximum of 8.72 in accuracy, demonstrating the effectiveness in performance. On Video-MME, Quicksviewer achieves SOTA under modest sequence lengths using just up to 5\\% of tokens per frame required by baselines. With this paradigm, scaling up the number of input frames reveals a clear power law of the model capabilities. It is also empirically verified that the segments generated by the cubing network can help for analyzing continuous events in videos.","sentences":["Large Multimodal Models (LMMs) uniformly perceive video frames, creating computational inefficiency for videos with inherently varying temporal information density.","This paper present \\textbf{Quicksviewer}, an LMM with new perceiving paradigm that partitions a video of nonuniform density into varying cubes using Gumbel Softmax, followed by a unified resampling for each cube to achieve efficient video understanding.","This simple and intuitive approach dynamically compress video online based on its temporal density, significantly reducing spatiotemporal redundancy (overall 45$\\times$ compression rate), while enabling efficient training with large receptive field.","We train the model from a language backbone through three progressive stages, each incorporating lengthy videos on average of 420s/1fps thanks to the perceiving efficiency.","With only 0.8M total video-text samples for training, our model outperforms the direct baseline employing a fixed partitioning strategy by a maximum of 8.72 in accuracy, demonstrating the effectiveness in performance.","On Video-MME, Quicksviewer achieves SOTA under modest sequence lengths using just up to 5\\% of tokens per frame required by baselines.","With this paradigm, scaling up the number of input frames reveals a clear power law of the model capabilities.","It is also empirically verified that the segments generated by the cubing network can help for analyzing continuous events in videos."],"url":"http://arxiv.org/abs/2504.15270v1"}
{"created":"2025-04-21 17:49:06","title":"Diffusion Bridge Models for 3D Medical Image Translation","abstract":"Diffusion tensor imaging (DTI) provides crucial insights into the microstructure of the human brain, but it can be time-consuming to acquire compared to more readily available T1-weighted (T1w) magnetic resonance imaging (MRI). To address this challenge, we propose a diffusion bridge model for 3D brain image translation between T1w MRI and DTI modalities. Our model learns to generate high-quality DTI fractional anisotropy (FA) images from T1w images and vice versa, enabling cross-modality data augmentation and reducing the need for extensive DTI acquisition. We evaluate our approach using perceptual similarity, pixel-level agreement, and distributional consistency metrics, demonstrating strong performance in capturing anatomical structures and preserving information on white matter integrity. The practical utility of the synthetic data is validated through sex classification and Alzheimer's disease classification tasks, where the generated images achieve comparable performance to real data. Our diffusion bridge model offers a promising solution for improving neuroimaging datasets and supporting clinical decision-making, with the potential to significantly impact neuroimaging research and clinical practice.","sentences":["Diffusion tensor imaging (DTI) provides crucial insights into the microstructure of the human brain, but it can be time-consuming to acquire compared to more readily available T1-weighted (T1w) magnetic resonance imaging (MRI).","To address this challenge, we propose a diffusion bridge model for 3D brain image translation between T1w MRI and DTI modalities.","Our model learns to generate high-quality DTI fractional anisotropy (FA) images from T1w images and vice versa, enabling cross-modality data augmentation and reducing the need for extensive DTI acquisition.","We evaluate our approach using perceptual similarity, pixel-level agreement, and distributional consistency metrics, demonstrating strong performance in capturing anatomical structures and preserving information on white matter integrity.","The practical utility of the synthetic data is validated through sex classification and Alzheimer's disease classification tasks, where the generated images achieve comparable performance to real data.","Our diffusion bridge model offers a promising solution for improving neuroimaging datasets and supporting clinical decision-making, with the potential to significantly impact neuroimaging research and clinical practice."],"url":"http://arxiv.org/abs/2504.15267v1"}
{"created":"2025-04-21 17:47:46","title":"Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction","abstract":"We design a suite of minimal algorithmic tasks that are a loose abstraction of open-ended real-world tasks. This allows us to cleanly and controllably quantify the creative limits of the present-day language model. Much like real-world tasks that require a creative, far-sighted leap of thought, our tasks require an implicit, open-ended stochastic planning step that either (a) discovers new connections in an abstract knowledge graph (like in wordplay, drawing analogies, or research) or (b) constructs new patterns (like in designing math problems or new proteins). In these tasks, we empirically and conceptually argue how next-token learning is myopic and memorizes excessively; comparatively, multi-token approaches, namely teacherless training and diffusion models, excel in producing diverse and original output. Secondly, in our tasks, we find that to elicit randomness from the Transformer without hurting coherence, it is better to inject noise right at the input layer (via a method we dub hash-conditioning) rather than defer to temperature sampling from the output layer. Thus, our work offers a principled, minimal test-bed for analyzing open-ended creative skills, and offers new arguments for going beyond next-token learning and softmax-based sampling. We make part of the code available under https://github.com/chenwu98/algorithmic-creativity","sentences":["We design a suite of minimal algorithmic tasks that are a loose abstraction of open-ended real-world tasks.","This allows us to cleanly and controllably quantify the creative limits of the present-day language model.","Much like real-world tasks that require a creative, far-sighted leap of thought, our tasks require an implicit, open-ended stochastic planning step that either (a) discovers new connections in an abstract knowledge graph (like in wordplay, drawing analogies, or research) or (b) constructs new patterns (like in designing math problems or new proteins).","In these tasks, we empirically and conceptually argue how next-token learning is myopic and memorizes excessively; comparatively, multi-token approaches, namely teacherless training and diffusion models, excel in producing diverse and original output.","Secondly, in our tasks, we find that to elicit randomness from the Transformer without hurting coherence, it is better to inject noise right at the input layer (via a method we dub hash-conditioning) rather than defer to temperature sampling from the output layer.","Thus, our work offers a principled, minimal test-bed for analyzing open-ended creative skills, and offers new arguments for going beyond next-token learning and softmax-based sampling.","We make part of the code available under https://github.com/chenwu98/algorithmic-creativity"],"url":"http://arxiv.org/abs/2504.15266v1"}
{"created":"2025-04-21 17:45:21","title":"Interpretable Locomotion Prediction in Construction Using a Memory-Driven LLM Agent With Chain-of-Thought Reasoning","abstract":"Construction tasks are inherently unpredictable, with dynamic environments and safety-critical demands posing significant risks to workers. Exoskeletons offer potential assistance but falter without accurate intent recognition across diverse locomotion modes. This paper presents a locomotion prediction agent leveraging Large Language Models (LLMs) augmented with memory systems, aimed at improving exoskeleton assistance in such settings. Using multimodal inputs - spoken commands and visual data from smart glasses - the agent integrates a Perception Module, Short-Term Memory (STM), Long-Term Memory (LTM), and Refinement Module to predict locomotion modes effectively. Evaluation reveals a baseline weighted F1-score of 0.73 without memory, rising to 0.81 with STM, and reaching 0.90 with both STM and LTM, excelling with vague and safety-critical commands. Calibration metrics, including a Brier Score drop from 0.244 to 0.090 and ECE from 0.222 to 0.044, affirm improved reliability. This framework supports safer, high-level human-exoskeleton collaboration, with promise for adaptive assistive systems in dynamic industries.","sentences":["Construction tasks are inherently unpredictable, with dynamic environments and safety-critical demands posing significant risks to workers.","Exoskeletons offer potential assistance but falter without accurate intent recognition across diverse locomotion modes.","This paper presents a locomotion prediction agent leveraging Large Language Models (LLMs) augmented with memory systems, aimed at improving exoskeleton assistance in such settings.","Using multimodal inputs - spoken commands and visual data from smart glasses - the agent integrates a Perception Module, Short-Term Memory (STM), Long-Term Memory (LTM), and Refinement Module to predict locomotion modes effectively.","Evaluation reveals a baseline weighted F1-score of 0.73 without memory, rising to 0.81 with STM, and reaching 0.90 with both STM and LTM, excelling with vague and safety-critical commands.","Calibration metrics, including a Brier Score drop from 0.244 to 0.090 and ECE from 0.222 to 0.044, affirm improved reliability.","This framework supports safer, high-level human-exoskeleton collaboration, with promise for adaptive assistive systems in dynamic industries."],"url":"http://arxiv.org/abs/2504.15263v1"}
{"created":"2025-04-21 17:41:15","title":"Leveraging Language Models for Automated Patient Record Linkage","abstract":"Objective: Healthcare data fragmentation presents a major challenge for linking patient data, necessitating robust record linkage to integrate patient records from diverse sources. This study investigates the feasibility of leveraging language models for automated patient record linkage, focusing on two key tasks: blocking and matching. Materials and Methods: We utilized real-world healthcare data from the Missouri Cancer Registry and Research Center, linking patient records from two independent sources using probabilistic linkage as a baseline. A transformer-based model, RoBERTa, was fine-tuned for blocking using sentence embeddings. For matching, several language models were experimented under fine-tuned and zero-shot settings, assessing their performance against ground truth labels. Results: The fine-tuned blocking model achieved a 92% reduction in the number of candidate pairs while maintaining near-perfect recall. In the matching task, fine-tuned Mistral-7B achieved the best performance with only 6 incorrect predictions. Among zero-shot models, Mistral-Small-24B performed best, with a total of 55 incorrect predictions. Discussion: Fine-tuned language models achieved strong performance in patient record blocking and matching with minimal errors. However, they remain less accurate and efficient than a hybrid rule-based and probabilistic approach for blocking. Additionally, reasoning models like DeepSeek-R1 are impractical for large-scale record linkage due to high computational costs. Conclusion: This study highlights the potential of language models for automating patient record linkage, offering improved efficiency by eliminating the manual efforts required to perform patient record linkage. Overall, language models offer a scalable solution that can enhance data integration, reduce manual effort, and support disease surveillance and research.","sentences":["Objective: Healthcare data fragmentation presents a major challenge for linking patient data, necessitating robust record linkage to integrate patient records from diverse sources.","This study investigates the feasibility of leveraging language models for automated patient record linkage, focusing on two key tasks: blocking and matching.","Materials and Methods: We utilized real-world healthcare data from the Missouri Cancer Registry and Research Center, linking patient records from two independent sources using probabilistic linkage as a baseline.","A transformer-based model, RoBERTa, was fine-tuned for blocking using sentence embeddings.","For matching, several language models were experimented under fine-tuned and zero-shot settings, assessing their performance against ground truth labels.","Results:","The fine-tuned blocking model achieved a 92% reduction in the number of candidate pairs while maintaining near-perfect recall.","In the matching task, fine-tuned Mistral-7B achieved the best performance with only 6 incorrect predictions.","Among zero-shot models, Mistral-Small-24B performed best, with a total of 55 incorrect predictions.","Discussion: Fine-tuned language models achieved strong performance in patient record blocking and matching with minimal errors.","However, they remain less accurate and efficient than a hybrid rule-based and probabilistic approach for blocking.","Additionally, reasoning models like DeepSeek-R1 are impractical for large-scale record linkage due to high computational costs.","Conclusion:","This study highlights the potential of language models for automating patient record linkage, offering improved efficiency by eliminating the manual efforts required to perform patient record linkage.","Overall, language models offer a scalable solution that can enhance data integration, reduce manual effort, and support disease surveillance and research."],"url":"http://arxiv.org/abs/2504.15261v1"}
{"created":"2025-04-21 17:38:50","title":"Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation","abstract":"Digital modeling and reconstruction of human faces serve various applications. However, its availability is often hindered by the requirements of data capturing devices, manual labor, and suitable actors. This situation restricts the diversity, expressiveness, and control over the resulting models. This work aims to demonstrate that a semantically controllable generative network can provide enhanced control over the digital face modeling process. To enhance diversity beyond the limited human faces scanned in a controlled setting, we introduce a novel data generation pipeline that creates a high-quality 3D face database using a pre-trained diffusion model. Our proposed normalization module converts synthesized data from the diffusion model into high-quality scanned data. Using the 44,000 face models we obtained, we further developed an efficient GAN-based generator. This generator accepts semantic attributes as input, and generates geometry and albedo. It also allows continuous post-editing of attributes in the latent space. Our asset refinement component subsequently creates physically-based facial assets. We introduce a comprehensive system designed for creating and editing high-quality face assets. Our proposed model has undergone extensive experiment, comparison and evaluation. We also integrate everything into a web-based interactive tool. We aim to make this tool publicly available with the release of the paper.","sentences":["Digital modeling and reconstruction of human faces serve various applications.","However, its availability is often hindered by the requirements of data capturing devices, manual labor, and suitable actors.","This situation restricts the diversity, expressiveness, and control over the resulting models.","This work aims to demonstrate that a semantically controllable generative network can provide enhanced control over the digital face modeling process.","To enhance diversity beyond the limited human faces scanned in a controlled setting, we introduce a novel data generation pipeline that creates a high-quality 3D face database using a pre-trained diffusion model.","Our proposed normalization module converts synthesized data from the diffusion model into high-quality scanned data.","Using the 44,000 face models we obtained, we further developed an efficient GAN-based generator.","This generator accepts semantic attributes as input, and generates geometry and albedo.","It also allows continuous post-editing of attributes in the latent space.","Our asset refinement component subsequently creates physically-based facial assets.","We introduce a comprehensive system designed for creating and editing high-quality face assets.","Our proposed model has undergone extensive experiment, comparison and evaluation.","We also integrate everything into a web-based interactive tool.","We aim to make this tool publicly available with the release of the paper."],"url":"http://arxiv.org/abs/2504.15259v1"}
{"created":"2025-04-21 17:35:42","title":"FlowReasoner: Reinforcing Query-Level Meta-Agents","abstract":"This paper proposes a query-level meta-agent named FlowReasoner to automate the design of query-level multi-agent systems, i.e., one system per user query. Our core idea is to incentivize a reasoning-based meta-agent via external execution feedback. Concretely, by distilling DeepSeek R1, we first endow the basic reasoning ability regarding the generation of multi-agent systems to FlowReasoner. Then, we further enhance it via reinforcement learning (RL) with external execution feedback. A multi-purpose reward is designed to guide the RL training from aspects of performance, complexity, and efficiency. In this manner, FlowReasoner is enabled to generate a personalized multi-agent system for each user query via deliberative reasoning. Experiments on both engineering and competition code benchmarks demonstrate the superiority of FlowReasoner. Remarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks. The code is available at https://github.com/sail-sg/FlowReasoner.","sentences":["This paper proposes a query-level meta-agent named FlowReasoner to automate the design of query-level multi-agent systems, i.e., one system per user query.","Our core idea is to incentivize a reasoning-based meta-agent via external execution feedback.","Concretely, by distilling DeepSeek R1, we first endow the basic reasoning ability regarding the generation of multi-agent systems to FlowReasoner.","Then, we further enhance it via reinforcement learning (RL) with external execution feedback.","A multi-purpose reward is designed to guide the RL training from aspects of performance, complexity, and efficiency.","In this manner, FlowReasoner is enabled to generate a personalized multi-agent system for each user query via deliberative reasoning.","Experiments on both engineering and competition code benchmarks demonstrate the superiority of FlowReasoner.","Remarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks.","The code is available at https://github.com/sail-sg/FlowReasoner."],"url":"http://arxiv.org/abs/2504.15257v1"}
{"created":"2025-04-21 17:33:33","title":"CRUST-Bench: A Comprehensive Benchmark for C-to-safe-Rust Transpilation","abstract":"C-to-Rust transpilation is essential for modernizing legacy C code while enhancing safety and interoperability with modern Rust ecosystems. However, no dataset currently exists for evaluating whether a system can transpile C into safe Rust that passes a set of test cases. We introduce CRUST-Bench, a dataset of 100 C repositories, each paired with manually-written interfaces in safe Rust as well as test cases that can be used to validate correctness of the transpilation. By considering entire repositories rather than isolated functions, CRUST-Bench captures the challenges of translating complex projects with dependencies across multiple files. The provided Rust interfaces provide explicit specifications that ensure adherence to idiomatic, memory-safe Rust patterns, while the accompanying test cases enforce functional correctness. We evaluate state-of-the-art large language models (LLMs) on this task and find that safe and idiomatic Rust generation is still a challenging problem for various state-of-the-art methods and techniques. We also provide insights into the errors LLMs usually make in transpiling code from C to safe Rust. The best performing model, OpenAI o1, is able to solve only 15 tasks in a single-shot setting. Improvements on CRUST-Bench would lead to improved transpilation systems that can reason about complex scenarios and help in migrating legacy codebases from C into languages like Rust that ensure memory safety. You can find the dataset and code at https://github.com/anirudhkhatry/CRUST-bench.","sentences":["C-to-Rust transpilation is essential for modernizing legacy C code while enhancing safety and interoperability with modern Rust ecosystems.","However, no dataset currently exists for evaluating whether a system can transpile C into safe Rust that passes a set of test cases.","We introduce CRUST-Bench, a dataset of 100 C repositories, each paired with manually-written interfaces in safe Rust as well as test cases that can be used to validate correctness of the transpilation.","By considering entire repositories rather than isolated functions, CRUST-Bench captures the challenges of translating complex projects with dependencies across multiple files.","The provided Rust interfaces provide explicit specifications that ensure adherence to idiomatic, memory-safe Rust patterns, while the accompanying test cases enforce functional correctness.","We evaluate state-of-the-art large language models (LLMs) on this task and find that safe and idiomatic Rust generation is still a challenging problem for various state-of-the-art methods and techniques.","We also provide insights into the errors LLMs usually make in transpiling code from C to safe Rust.","The best performing model, OpenAI o1, is able to solve only 15 tasks in a single-shot setting.","Improvements on CRUST-Bench would lead to improved transpilation systems that can reason about complex scenarios and help in migrating legacy codebases from C into languages like Rust that ensure memory safety.","You can find the dataset and code at https://github.com/anirudhkhatry/CRUST-bench."],"url":"http://arxiv.org/abs/2504.15254v1"}
{"created":"2025-04-21 17:33:23","title":"Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators","abstract":"Scaling test-time computation, or affording a generator large language model (LLM) extra compute during inference, typically employs the help of external non-generative evaluators (i.e., reward models). Concurrently, LLM-judges, models trained to generate evaluations and critiques (explanations) in natural language, are becoming increasingly popular in automatic evaluation. Despite judge empirical successes, their effectiveness as evaluators in test-time scaling settings is largely unknown. In this paper, we introduce the Judge Evaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge performance in three domains (math reasoning, code generation, and instruction following) under three task settings: response reranking, step-level beam search, and critique-based response refinement. We evaluate 10 different judge models (7B-70B parameters) for 8 different base generator models (6.7B-72B parameters). Our benchmark shows that while judges are competitive with outcome reward models in reranking, they are consistently worse than process reward models in beam search procedures. Furthermore, though unique to LLM-judges, their natural language critiques are currently ineffective in guiding the generator towards better responses.","sentences":["Scaling test-time computation, or affording a generator large language model (LLM) extra compute during inference, typically employs the help of external non-generative evaluators (i.e., reward models).","Concurrently, LLM-judges, models trained to generate evaluations and critiques (explanations) in natural language, are becoming increasingly popular in automatic evaluation.","Despite judge empirical successes, their effectiveness as evaluators in test-time scaling settings is largely unknown.","In this paper, we introduce the Judge Evaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge performance in three domains (math reasoning, code generation, and instruction following) under three task settings: response reranking, step-level beam search, and critique-based response refinement.","We evaluate 10 different judge models (7B-70B parameters) for 8 different base generator models (6.7B-72B parameters).","Our benchmark shows that while judges are competitive with outcome reward models in reranking, they are consistently worse than process reward models in beam search procedures.","Furthermore, though unique to LLM-judges, their natural language critiques are currently ineffective in guiding the generator towards better responses."],"url":"http://arxiv.org/abs/2504.15253v1"}
{"created":"2025-04-21 17:33:02","title":"SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam","abstract":"Understanding and monitoring aquatic biodiversity is critical for ecological health and conservation efforts. This paper proposes SuoiAI, an end-to-end pipeline for building a dataset of aquatic invertebrates in Vietnam and employing machine learning (ML) techniques for species classification. We outline the methods for data collection, annotation, and model training, focusing on reducing annotation effort through semi-supervised learning and leveraging state-of-the-art object detection and classification models. Our approach aims to overcome challenges such as data scarcity, fine-grained classification, and deployment in diverse environmental conditions.","sentences":["Understanding and monitoring aquatic biodiversity is critical for ecological health and conservation efforts.","This paper proposes SuoiAI, an end-to-end pipeline for building a dataset of aquatic invertebrates in Vietnam and employing machine learning (ML) techniques for species classification.","We outline the methods for data collection, annotation, and model training, focusing on reducing annotation effort through semi-supervised learning and leveraging state-of-the-art object detection and classification models.","Our approach aims to overcome challenges such as data scarcity, fine-grained classification, and deployment in diverse environmental conditions."],"url":"http://arxiv.org/abs/2504.15252v1"}
{"created":"2025-04-21 17:31:55","title":"On Learning Parallel Pancakes with Mostly Uniform Weights","abstract":"We study the complexity of learning $k$-mixtures of Gaussians ($k$-GMMs) on $\\mathbb{R}^d$. This task is known to have complexity $d^{\\Omega(k)}$ in full generality. To circumvent this exponential lower bound on the number of components, research has focused on learning families of GMMs satisfying additional structural properties. A natural assumption posits that the component weights are not exponentially small and that the components have the same unknown covariance. Recent work gave a $d^{O(\\log(1/w_{\\min}))}$-time algorithm for this class of GMMs, where $w_{\\min}$ is the minimum weight. Our first main result is a Statistical Query (SQ) lower bound showing that this quasi-polynomial upper bound is essentially best possible, even for the special case of uniform weights. Specifically, we show that it is SQ-hard to distinguish between such a mixture and the standard Gaussian. We further explore how the distribution of weights affects the complexity of this task. Our second main result is a quasi-polynomial upper bound for the aforementioned testing task when most of the weights are uniform while a small fraction of the weights are potentially arbitrary.","sentences":["We study the complexity of learning $k$-mixtures of Gaussians ($k$-GMMs) on $\\mathbb{R}^d$. This task is known to have complexity $d^{\\Omega(k)}$ in full generality.","To circumvent this exponential lower bound on the number of components, research has focused on learning families of GMMs satisfying additional structural properties.","A natural assumption posits that the component weights are not exponentially small and that the components have the same unknown covariance.","Recent work gave a $d^{O(\\log(1/w_{\\min}))}$-time algorithm for this class of GMMs, where $w_{\\min}$ is the minimum weight.","Our first main result is a Statistical Query (SQ) lower bound showing that this quasi-polynomial upper bound is essentially best possible, even for the special case of uniform weights.","Specifically, we show that it is SQ-hard to distinguish between such a mixture and the standard Gaussian.","We further explore how the distribution of weights affects the complexity of this task.","Our second main result is a quasi-polynomial upper bound for the aforementioned testing task when most of the weights are uniform while a small fraction of the weights are potentially arbitrary."],"url":"http://arxiv.org/abs/2504.15251v1"}
{"created":"2025-04-21 17:22:18","title":"Lance: Efficient Random Access in Columnar Storage through Adaptive Structural Encodings","abstract":"The growing interest in artificial intelligence has created workloads that require both sequential and random access. At the same time, NVMe-backed storage solutions have emerged, providing caching capability for large columnar datasets in cloud storage. Current columnar storage libraries fall short of effectively utilizing an NVMe device's capabilities, especially when it comes to random access. Historically, this has been assumed an implicit weakness in columnar storage formats, but this has not been sufficiently explored. In this paper, we examine the effectiveness of popular columnar formats such as Apache Arrow, Apache Parquet, and Lance in both random access and full scan tasks against NVMe storage.   We argue that effective encoding of a column's structure, such as the repetition and validity information, is the key to unlocking the disk's performance. We show that Parquet, when configured correctly, can achieve over 60x better random access performance than default settings. We also show that this high random access performance requires making minor trade-offs in scan performance and RAM utilization. We then describe the Lance structural encoding scheme, which alternates between two different structural encodings based on data width, and achieves better random access performance without making trade-offs in scan performance or RAM utilization.","sentences":["The growing interest in artificial intelligence has created workloads that require both sequential and random access.","At the same time, NVMe-backed storage solutions have emerged, providing caching capability for large columnar datasets in cloud storage.","Current columnar storage libraries fall short of effectively utilizing an NVMe device's capabilities, especially when it comes to random access.","Historically, this has been assumed an implicit weakness in columnar storage formats, but this has not been sufficiently explored.","In this paper, we examine the effectiveness of popular columnar formats such as Apache Arrow, Apache Parquet, and Lance in both random access and full scan tasks against NVMe storage.   ","We argue that effective encoding of a column's structure, such as the repetition and validity information, is the key to unlocking the disk's performance.","We show that Parquet, when configured correctly, can achieve over 60x better random access performance than default settings.","We also show that this high random access performance requires making minor trade-offs in scan performance and RAM utilization.","We then describe the Lance structural encoding scheme, which alternates between two different structural encodings based on data width, and achieves better random access performance without making trade-offs in scan performance or RAM utilization."],"url":"http://arxiv.org/abs/2504.15247v1"}
{"created":"2025-04-21 17:19:57","title":"A Refreshment Stirred, Not Shaken (III): Can Swapping Be Differentially Private?","abstract":"The quest for a precise and contextually grounded answer to the question in the present paper's title resulted in this stirred-not-shaken triptych, a phrase that reflects our desire to deepen the theoretical basis, broaden the practical applicability, and reduce the misperception of differential privacy (DP)$\\unicode{x2014}$all without shaking its core foundations. Indeed, given the existence of more than 200 formulations of DP (and counting), before even attempting to answer the titular question one must first precisely specify what it actually means to be DP. Motivated by this observation, a theoretical investigation into DP's fundamental essence resulted in Part I of this trio, which introduces a five-building-block system explicating the who, where, what, how and how much aspects of DP. Instantiating this system in the context of the United States Decennial Census, Part II then demonstrates the broader applicability and relevance of DP by comparing a swapping strategy like that used in 2010 with the TopDown Algorithm$\\unicode{x2014}$a DP method adopted in the 2020 Census. This paper provides nontechnical summaries of the preceding two parts as well as new discussion$\\unicode{x2014}$for example, on how greater awareness of the five building blocks can thwart privacy theatrics; how our results bridging traditional SDC and DP allow a data custodian to reap the benefits of both these fields; how invariants impact disclosure risk; and how removing the implicit reliance on aleatoric uncertainty could lead to new generalizations of DP.","sentences":["The quest for a precise and contextually grounded answer to the question in the present paper's title resulted in this stirred-not-shaken triptych, a phrase that reflects our desire to deepen the theoretical basis, broaden the practical applicability, and reduce the misperception of differential privacy (DP)$\\unicode{x2014}$all without shaking its core foundations.","Indeed, given the existence of more than 200 formulations of DP (and counting), before even attempting to answer the titular question one must first precisely specify what it actually means to be DP.","Motivated by this observation, a theoretical investigation into DP's fundamental essence resulted in Part I of this trio, which introduces a five-building-block system explicating the who, where, what, how and how much aspects of DP.","Instantiating this system in the context of the United States Decennial Census, Part II then demonstrates the broader applicability and relevance of DP by comparing a swapping strategy like that used in 2010 with the TopDown Algorithm$\\unicode{x2014}$a DP method adopted in the 2020 Census.","This paper provides nontechnical summaries of the preceding two parts as well as new discussion$\\unicode{x2014}$for example, on how greater awareness of the five building blocks can thwart privacy theatrics; how our results bridging traditional SDC and DP allow a data custodian to reap the benefits of both these fields; how invariants impact disclosure risk; and how removing the implicit reliance on aleatoric uncertainty could lead to new generalizations of DP."],"url":"http://arxiv.org/abs/2504.15246v1"}
{"created":"2025-04-21 17:16:14","title":"Faster Algorithms for Agnostically Learning Disjunctions and their Implications","abstract":"We study the algorithmic task of learning Boolean disjunctions in the distribution-free agnostic PAC model. The best known agnostic learner for the class of disjunctions over $\\{0, 1\\}^n$ is the $L_1$-polynomial regression algorithm, achieving complexity $2^{\\tilde{O}(n^{1/2})}$. This complexity bound is known to be nearly best possible within the class of Correlational Statistical Query (CSQ) algorithms. In this work, we develop an agnostic learner for this concept class with complexity $2^{\\tilde{O}(n^{1/3})}$. Our algorithm can be implemented in the Statistical Query (SQ) model, providing the first separation between the SQ and CSQ models in distribution-free agnostic learning.","sentences":["We study the algorithmic task of learning Boolean disjunctions in the distribution-free agnostic PAC model.","The best known agnostic learner for the class of disjunctions over $\\{0, 1\\}^n$ is the $L_1$-polynomial regression algorithm, achieving complexity $2^{\\tilde{O}(n^{1/2})}$. This complexity bound is known to be nearly best possible within the class of Correlational Statistical Query (CSQ) algorithms.","In this work, we develop an agnostic learner for this concept class with complexity $2^{\\tilde{O}(n^{1/3})}$. Our algorithm can be implemented in the Statistical Query (SQ) model, providing the first separation between the SQ and CSQ models in distribution-free agnostic learning."],"url":"http://arxiv.org/abs/2504.15244v1"}
{"created":"2025-04-21 17:15:48","title":"Single-loop Algorithms for Stochastic Non-convex Optimization with Weakly-Convex Constraints","abstract":"Constrained optimization with multiple functional inequality constraints has significant applications in machine learning. This paper examines a crucial subset of such problems where both the objective and constraint functions are weakly convex. Existing methods often face limitations, including slow convergence rates or reliance on double-loop algorithmic designs. To overcome these challenges, we introduce a novel single-loop penalty-based stochastic algorithm. Following the classical exact penalty method, our approach employs a {\\bf hinge-based penalty}, which permits the use of a constant penalty parameter, enabling us to achieve a {\\bf state-of-the-art complexity} for finding an approximate Karush-Kuhn-Tucker (KKT) solution. We further extend our algorithm to address finite-sum coupled compositional objectives, which are prevalent in artificial intelligence applications, establishing improved complexity over existing approaches. Finally, we validate our method through experiments on fair learning with receiver operating characteristic (ROC) fairness constraints and continual learning with non-forgetting constraints.","sentences":["Constrained optimization with multiple functional inequality constraints has significant applications in machine learning.","This paper examines a crucial subset of such problems where both the objective and constraint functions are weakly convex.","Existing methods often face limitations, including slow convergence rates or reliance on double-loop algorithmic designs.","To overcome these challenges, we introduce a novel single-loop penalty-based stochastic algorithm.","Following the classical exact penalty method, our approach employs a {\\bf hinge-based penalty}, which permits the use of a constant penalty parameter, enabling us to achieve a {\\bf state-of-the-art complexity} for finding an approximate Karush-Kuhn-Tucker (KKT) solution.","We further extend our algorithm to address finite-sum coupled compositional objectives, which are prevalent in artificial intelligence applications, establishing improved complexity over existing approaches.","Finally, we validate our method through experiments on fair learning with receiver operating characteristic (ROC) fairness constraints and continual learning with non-forgetting constraints."],"url":"http://arxiv.org/abs/2504.15243v1"}
{"created":"2025-04-21 17:15:06","title":"MR. Guard: Multilingual Reasoning Guardrail using Curriculum Learning","abstract":"Large Language Models (LLMs) are susceptible to adversarial attacks such as jailbreaking, which can elicit harmful or unsafe behaviors. This vulnerability is exacerbated in multilingual setting, where multilingual safety-aligned data are often limited. Thus, developing a guardrail capable of detecting and filtering unsafe content across diverse languages is critical for deploying LLMs in real-world applications. In this work, we propose an approach to build a multilingual guardrail with reasoning. Our method consists of: (1) synthetic multilingual data generation incorporating culturally and linguistically nuanced variants, (2) supervised fine-tuning, and (3) a curriculum-guided Group Relative Policy Optimization (GRPO) framework that further improves performance. Experimental results demonstrate that our multilingual guardrail consistently outperforms recent baselines across both in-domain and out-of-domain languages. The multilingual reasoning capability of our guardrail enables it to generate multilingual explanations, which are particularly useful for understanding language-specific risks and ambiguities in multilingual content moderation.","sentences":["Large Language Models (LLMs) are susceptible to adversarial attacks such as jailbreaking, which can elicit harmful or unsafe behaviors.","This vulnerability is exacerbated in multilingual setting, where multilingual safety-aligned data are often limited.","Thus, developing a guardrail capable of detecting and filtering unsafe content across diverse languages is critical for deploying LLMs in real-world applications.","In this work, we propose an approach to build a multilingual guardrail with reasoning.","Our method consists of: (1) synthetic multilingual data generation incorporating culturally and linguistically nuanced variants, (2) supervised fine-tuning, and (3) a curriculum-guided Group Relative Policy Optimization (GRPO) framework that further improves performance.","Experimental results demonstrate that our multilingual guardrail consistently outperforms recent baselines across both in-domain and out-of-domain languages.","The multilingual reasoning capability of our guardrail enables it to generate multilingual explanations, which are particularly useful for understanding language-specific risks and ambiguities in multilingual content moderation."],"url":"http://arxiv.org/abs/2504.15241v1"}
{"created":"2025-04-21 17:14:05","title":"Conformalized-KANs: Uncertainty Quantification with Coverage Guarantees for Kolmogorov-Arnold Networks (KANs) in Scientific Machine Learning","abstract":"This paper explores uncertainty quantification (UQ) methods in the context of Kolmogorov-Arnold Networks (KANs). We apply an ensemble approach to KANs to obtain a heuristic measure of UQ, enhancing interpretability and robustness in modeling complex functions. Building on this, we introduce Conformalized-KANs, which integrate conformal prediction, a distribution-free UQ technique, with KAN ensembles to generate calibrated prediction intervals with guaranteed coverage. Extensive numerical experiments are conducted to evaluate the effectiveness of these methods, focusing particularly on the robustness and accuracy of the prediction intervals under various hyperparameter settings. We show that the conformal KAN predictions can be applied to recent extensions of KANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs). The results demonstrate the potential of our approaches to improve the reliability and applicability of KANs in scientific machine learning.","sentences":["This paper explores uncertainty quantification (UQ) methods in the context of Kolmogorov-Arnold Networks (KANs).","We apply an ensemble approach to KANs to obtain a heuristic measure of UQ, enhancing interpretability and robustness in modeling complex functions.","Building on this, we introduce Conformalized-KANs, which integrate conformal prediction, a distribution-free UQ technique, with KAN ensembles to generate calibrated prediction intervals with guaranteed coverage.","Extensive numerical experiments are conducted to evaluate the effectiveness of these methods, focusing particularly on the robustness and accuracy of the prediction intervals under various hyperparameter settings.","We show that the conformal KAN predictions can be applied to recent extensions of KANs, including Finite Basis KANs (FBKANs) and multifideilty KANs (MFKANs).","The results demonstrate the potential of our approaches to improve the reliability and applicability of KANs in scientific machine learning."],"url":"http://arxiv.org/abs/2504.15240v1"}
{"created":"2025-04-21 17:13:16","title":"Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions","abstract":"AI assistants can impart value judgments that shape people's decisions and worldviews, yet little is known empirically about what values these systems rely on in practice. To address this, we develop a bottom-up, privacy-preserving method to extract the values (normative considerations stated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit in hundreds of thousands of real-world interactions. We empirically discover and taxonomize 3,307 AI values and study how they vary by context. We find that Claude expresses many practical and epistemic values, and typically supports prosocial human values while resisting values like \"moral nihilism\". While some values appear consistently across contexts (e.g. \"transparency\"), many are more specialized and context-dependent, reflecting the diversity of human interlocutors and their varied contexts. For example, \"harm prevention\" emerges when Claude resists users, \"historical accuracy\" when responding to queries about controversial events, \"healthy boundaries\" when asked for relationship advice, and \"human agency\" in technology ethics discussions. By providing the first large-scale empirical mapping of AI values in deployment, our work creates a foundation for more grounded evaluation and design of values in AI systems.","sentences":["AI assistants can impart value judgments that shape people's decisions and worldviews, yet little is known empirically about what values these systems rely on in practice.","To address this, we develop a bottom-up, privacy-preserving method to extract the values (normative considerations stated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit in hundreds of thousands of real-world interactions.","We empirically discover and taxonomize 3,307 AI values and study how they vary by context.","We find that Claude expresses many practical and epistemic values, and typically supports prosocial human values while resisting values like \"moral nihilism\".","While some values appear consistently across contexts (e.g. \"transparency\"), many are more specialized and context-dependent, reflecting the diversity of human interlocutors and their varied contexts.","For example, \"harm prevention\" emerges when Claude resists users, \"historical accuracy\" when responding to queries about controversial events, \"healthy boundaries\" when asked for relationship advice, and \"human agency\" in technology ethics discussions.","By providing the first large-scale empirical mapping of AI values in deployment, our work creates a foundation for more grounded evaluation and design of values in AI systems."],"url":"http://arxiv.org/abs/2504.15236v1"}
{"created":"2025-04-21 17:10:10","title":"Cascade IPG Observer for Underwater Robot State Estimation","abstract":"This paper presents a novel cascade nonlinear observer framework for inertial state estimation. It tackles the problem of intermediate state estimation when external localization is unavailable or in the event of a sensor outage. The proposed observer comprises two nonlinear observers based on a recently developed iteratively preconditioned gradient descent (IPG) algorithm. It takes the inputs via an IMU preintegration model where the first observer is a quaternion-based IPG. The output for the first observer is the input for the second observer, estimating the velocity and, consequently, the position. The proposed observer is validated on a public underwater dataset and a real-world experiment using our robot platform. The estimation is compared with an extended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF). Results demonstrate that our method outperforms these methods regarding better positional accuracy and lower variance.","sentences":["This paper presents a novel cascade nonlinear observer framework for inertial state estimation.","It tackles the problem of intermediate state estimation when external localization is unavailable or in the event of a sensor outage.","The proposed observer comprises two nonlinear observers based on a recently developed iteratively preconditioned gradient descent (IPG) algorithm.","It takes the inputs via an IMU preintegration model where the first observer is a quaternion-based IPG.","The output for the first observer is the input for the second observer, estimating the velocity and, consequently, the position.","The proposed observer is validated on a public underwater dataset and a real-world experiment using our robot platform.","The estimation is compared with an extended Kalman filter (EKF) and an invariant extended Kalman filter (InEKF).","Results demonstrate that our method outperforms these methods regarding better positional accuracy and lower variance."],"url":"http://arxiv.org/abs/2504.15235v1"}
{"created":"2025-04-21 17:08:45","title":"A Review on Privacy in DAG-Based DLTs","abstract":"Directed Acyclic Graph (DAG)-based Distributed Ledger Technologies (DLTs) have emerged as a promising solution to the scalability issues inherent in traditional blockchains. However, amidst the focus on scalability, the crucial aspect of privacy within DAG-based DLTs has been largely overlooked. This paper seeks to address this gap by providing a comprehensive examination of privacy notions and challenges within DAG-based DLTs. We delve into potential methodologies to enhance privacy within these systems, while also analyzing the associated hurdles and real-world implementations within state-of-the-art DAG-based DLTs. By exploring these methodologies, we not only illuminate the current landscape of privacy in DAG-based DLTs but also outline future research directions in this evolving field.","sentences":["Directed Acyclic Graph (DAG)-based Distributed Ledger Technologies (DLTs) have emerged as a promising solution to the scalability issues inherent in traditional blockchains.","However, amidst the focus on scalability, the crucial aspect of privacy within DAG-based DLTs has been largely overlooked.","This paper seeks to address this gap by providing a comprehensive examination of privacy notions and challenges within DAG-based DLTs.","We delve into potential methodologies to enhance privacy within these systems, while also analyzing the associated hurdles and real-world implementations within state-of-the-art DAG-based DLTs.","By exploring these methodologies, we not only illuminate the current landscape of privacy in DAG-based DLTs but also outline future research directions in this evolving field."],"url":"http://arxiv.org/abs/2504.15233v1"}
{"created":"2025-04-21 17:08:36","title":"Shape-Guided Clothing Warping for Virtual Try-On","abstract":"Image-based virtual try-on aims to seamlessly fit in-shop clothing to a person image while maintaining pose consistency. Existing methods commonly employ the thin plate spline (TPS) transformation or appearance flow to deform in-shop clothing for aligning with the person's body. Despite their promising performance, these methods often lack precise control over fine details, leading to inconsistencies in shape between clothing and the person's body as well as distortions in exposed limb regions. To tackle these challenges, we propose a novel shape-guided clothing warping method for virtual try-on, dubbed SCW-VTON, which incorporates global shape constraints and additional limb textures to enhance the realism and consistency of the warped clothing and try-on results. To integrate global shape constraints for clothing warping, we devise a dual-path clothing warping module comprising a shape path and a flow path. The former path captures the clothing shape aligned with the person's body, while the latter path leverages the mapping between the pre- and post-deformation of the clothing shape to guide the estimation of appearance flow. Furthermore, to alleviate distortions in limb regions of try-on results, we integrate detailed limb guidance by developing a limb reconstruction network based on masked image modeling. Through the utilization of SCW-VTON, we are able to generate try-on results with enhanced clothing shape consistency and precise control over details. Extensive experiments demonstrate the superiority of our approach over state-of-the-art methods both qualitatively and quantitatively. The code is available at https://github.com/xyhanHIT/SCW-VTON.","sentences":["Image-based virtual try-on aims to seamlessly fit in-shop clothing to a person image while maintaining pose consistency.","Existing methods commonly employ the thin plate spline (TPS) transformation or appearance flow to deform in-shop clothing for aligning with the person's body.","Despite their promising performance, these methods often lack precise control over fine details, leading to inconsistencies in shape between clothing and the person's body as well as distortions in exposed limb regions.","To tackle these challenges, we propose a novel shape-guided clothing warping method for virtual try-on, dubbed SCW-VTON, which incorporates global shape constraints and additional limb textures to enhance the realism and consistency of the warped clothing and try-on results.","To integrate global shape constraints for clothing warping, we devise a dual-path clothing warping module comprising a shape path and a flow path.","The former path captures the clothing shape aligned with the person's body, while the latter path leverages the mapping between the pre- and post-deformation of the clothing shape to guide the estimation of appearance flow.","Furthermore, to alleviate distortions in limb regions of try-on results, we integrate detailed limb guidance by developing a limb reconstruction network based on masked image modeling.","Through the utilization of SCW-VTON, we are able to generate try-on results with enhanced clothing shape consistency and precise control over details.","Extensive experiments demonstrate the superiority of our approach over state-of-the-art methods both qualitatively and quantitatively.","The code is available at https://github.com/xyhanHIT/SCW-VTON."],"url":"http://arxiv.org/abs/2504.15232v1"}
{"created":"2025-04-21 17:08:28","title":"Linear Complementary Pairs of Quasi-Cyclic and Quasi-Twisted Codes","abstract":"In this paper, we provide a polynomial characterization of linear complementary pairs of quasi-cyclic and quasi-twisted codes of index 2. We also give several examples of linear complementary pairs of quasi-cyclic and quasi-twisted codes with (almost) optimal security parameters.","sentences":["In this paper, we provide a polynomial characterization of linear complementary pairs of quasi-cyclic and quasi-twisted codes of index 2.","We also give several examples of linear complementary pairs of quasi-cyclic and quasi-twisted codes with (almost) optimal security parameters."],"url":"http://arxiv.org/abs/2504.15231v1"}
{"created":"2025-04-21 17:00:31","title":"Immersive Teleoperation Framework for Locomanipulation Tasks","abstract":"Recent advancements in robotic loco-manipulation have leveraged Virtual Reality (VR) to enhance the precision and immersiveness of teleoperation systems, significantly outperforming traditional methods reliant on 2D camera feeds and joystick controls. Despite these advancements, challenges remain, particularly concerning user experience across different setups. This paper introduces a novel VR-based teleoperation framework designed for a robotic manipulator integrated onto a mobile platform. Central to our approach is the application of Gaussian splatting, a technique that abstracts the manipulable scene into a VR environment, thereby enabling more intuitive and immersive interactions. Users can navigate and manipulate within the virtual scene as if interacting with a real robot, enhancing both the engagement and efficacy of teleoperation tasks. An extensive user study validates our approach, demonstrating significant usability and efficiency improvements. Two-thirds (66%) of participants completed tasks faster, achieving an average time reduction of 43%. Additionally, 93% preferred the Gaussian Splat interface overall, with unanimous (100%) recommendations for future use, highlighting improvements in precision, responsiveness, and situational awareness. Finally, we demonstrate the effectiveness of our framework through real-world experiments in two distinct application scenarios, showcasing the practical capabilities and versatility of the Splat-based VR interface.","sentences":["Recent advancements in robotic loco-manipulation have leveraged Virtual Reality (VR) to enhance the precision and immersiveness of teleoperation systems, significantly outperforming traditional methods reliant on 2D camera feeds and joystick controls.","Despite these advancements, challenges remain, particularly concerning user experience across different setups.","This paper introduces a novel VR-based teleoperation framework designed for a robotic manipulator integrated onto a mobile platform.","Central to our approach is the application of Gaussian splatting, a technique that abstracts the manipulable scene into a VR environment, thereby enabling more intuitive and immersive interactions.","Users can navigate and manipulate within the virtual scene as if interacting with a real robot, enhancing both the engagement and efficacy of teleoperation tasks.","An extensive user study validates our approach, demonstrating significant usability and efficiency improvements.","Two-thirds (66%) of participants completed tasks faster, achieving an average time reduction of 43%.","Additionally, 93% preferred the Gaussian Splat interface overall, with unanimous (100%) recommendations for future use, highlighting improvements in precision, responsiveness, and situational awareness.","Finally, we demonstrate the effectiveness of our framework through real-world experiments in two distinct application scenarios, showcasing the practical capabilities and versatility of the Splat-based VR interface."],"url":"http://arxiv.org/abs/2504.15229v1"}
{"created":"2025-04-21 16:58:18","title":"A Self-Improving Coding Agent","abstract":"We demonstrate that an LLM coding agent, equipped with basic coding tools, can autonomously edit itself, and thereby improve its performance on benchmark tasks. We find performance gains from 17% to 53% on a random subset of SWE Bench Verified, with additional performance gains on LiveCodeBench, as well as synthetically generated agent benchmarks. Our work represents an advancement in the automated and open-ended design of agentic systems, and provides a reference agent framework for those seeking to post-train LLMs on tool use and other agentic tasks.","sentences":["We demonstrate that an LLM coding agent, equipped with basic coding tools, can autonomously edit itself, and thereby improve its performance on benchmark tasks.","We find performance gains from 17% to 53% on a random subset of SWE Bench Verified, with additional performance gains on LiveCodeBench, as well as synthetically generated agent benchmarks.","Our work represents an advancement in the automated and open-ended design of agentic systems, and provides a reference agent framework for those seeking to post-train LLMs on tool use and other agentic tasks."],"url":"http://arxiv.org/abs/2504.15228v1"}
{"created":"2025-04-21 16:57:56","title":"A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing","abstract":"Automation of robotic systems for servicing in cislunar space is becoming extremely important as the number of satellites in orbit increases. Safety is critical in performing satellite maintenance, so the control techniques utilized must be trusted in addition to being highly efficient. In this work, Genetic Fuzzy Trees are combined with the widely used LQR control scheme via Thales' TrUE AI Toolkit to create a trusted and efficient controller for a two-degree-of-freedom planar robotic manipulator that would theoretically be used to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is 18.5% more performant than optimal LQR on average, and that it is incredibly robust to uncertainty.","sentences":["Automation of robotic systems for servicing in cislunar space is becoming extremely important as the number of satellites in orbit increases.","Safety is critical in performing satellite maintenance, so the control techniques utilized must be trusted in addition to being highly efficient.","In this work, Genetic Fuzzy Trees are combined with the widely used LQR control scheme via Thales' TrUE AI Toolkit to create a trusted and efficient controller for a two-degree-of-freedom planar robotic manipulator that would theoretically be used to perform satellite maintenance.","It was found that Genetic Fuzzy-LQR is 18.5% more performant than optimal LQR on average, and that it is incredibly robust to uncertainty."],"url":"http://arxiv.org/abs/2504.15226v1"}
{"created":"2025-04-21 16:57:46","title":"M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding","abstract":"With the widespread availability of sensor data across industrial and operational systems, we frequently encounter heterogeneous time series from multiple systems. Anomaly detection is crucial for such systems to facilitate predictive maintenance. However, most existing anomaly detection methods are designed for either univariate or single-system multivariate data, making them insufficient for these complex scenarios. To address this, we introduce M$^2$AD, a framework for unsupervised anomaly detection in multivariate time series data from multiple systems. M$^2$AD employs deep models to capture expected behavior under normal conditions, using the residuals as indicators of potential anomalies. These residuals are then aggregated into a global anomaly score through a Gaussian Mixture Model and Gamma calibration. We theoretically demonstrate that this framework can effectively address heterogeneity and dependencies across sensors and systems. Empirically, M$^2$AD outperforms existing methods in extensive evaluations by 21% on average, and its effectiveness is demonstrated on a large-scale real-world case study on 130 assets in Amazon Fulfillment Centers. Our code and results are available at https://github.com/sarahmish/M2AD.","sentences":["With the widespread availability of sensor data across industrial and operational systems, we frequently encounter heterogeneous time series from multiple systems.","Anomaly detection is crucial for such systems to facilitate predictive maintenance.","However, most existing anomaly detection methods are designed for either univariate or single-system multivariate data, making them insufficient for these complex scenarios.","To address this, we introduce M$^2$AD, a framework for unsupervised anomaly detection in multivariate time series data from multiple systems.","M$^2$AD employs deep models to capture expected behavior under normal conditions, using the residuals as indicators of potential anomalies.","These residuals are then aggregated into a global anomaly score through a Gaussian Mixture Model and Gamma calibration.","We theoretically demonstrate that this framework can effectively address heterogeneity and dependencies across sensors and systems.","Empirically, M$^2$AD outperforms existing methods in extensive evaluations by 21% on average, and its effectiveness is demonstrated on a large-scale real-world case study on 130 assets in Amazon Fulfillment Centers.","Our code and results are available at https://github.com/sarahmish/M2AD."],"url":"http://arxiv.org/abs/2504.15225v1"}
{"created":"2025-04-21 16:53:02","title":"A Deep Learning Framework for Sequence Mining with Bidirectional LSTM and Multi-Scale Attention","abstract":"This paper addresses the challenges of mining latent patterns and modeling contextual dependencies in complex sequence data. A sequence pattern mining algorithm is proposed by integrating Bidirectional Long Short-Term Memory (BiLSTM) with a multi-scale attention mechanism. The BiLSTM captures both forward and backward dependencies in sequences, enhancing the model's ability to perceive global contextual structures. At the same time, the multi-scale attention module assigns adaptive weights to key feature regions under different window sizes. This improves the model's responsiveness to both local and global important information. Extensive experiments are conducted on a publicly available multivariate time series dataset. The proposed model is compared with several mainstream sequence modeling methods. Results show that it outperforms existing models in terms of accuracy, precision, and recall. This confirms the effectiveness and robustness of the proposed architecture in complex pattern recognition tasks. Further ablation studies and sensitivity analyses are carried out to investigate the effects of attention scale and input sequence length on model performance. These results provide empirical support for structural optimization of the model.","sentences":["This paper addresses the challenges of mining latent patterns and modeling contextual dependencies in complex sequence data.","A sequence pattern mining algorithm is proposed by integrating Bidirectional Long Short-Term Memory (BiLSTM) with a multi-scale attention mechanism.","The BiLSTM captures both forward and backward dependencies in sequences, enhancing the model's ability to perceive global contextual structures.","At the same time, the multi-scale attention module assigns adaptive weights to key feature regions under different window sizes.","This improves the model's responsiveness to both local and global important information.","Extensive experiments are conducted on a publicly available multivariate time series dataset.","The proposed model is compared with several mainstream sequence modeling methods.","Results show that it outperforms existing models in terms of accuracy, precision, and recall.","This confirms the effectiveness and robustness of the proposed architecture in complex pattern recognition tasks.","Further ablation studies and sensitivity analyses are carried out to investigate the effects of attention scale and input sequence length on model performance.","These results provide empirical support for structural optimization of the model."],"url":"http://arxiv.org/abs/2504.15223v1"}
{"created":"2025-04-21 16:46:07","title":"Fully Bayesian Approaches to Topics over Time","abstract":"The Topics over Time (ToT) model captures thematic changes in timestamped datasets by explicitly modeling publication dates jointly with word co-occurrence patterns. However, ToT was not approached in a fully Bayesian fashion, a flaw that makes it susceptible to stability problems. To address this issue, we propose a fully Bayesian Topics over Time (BToT) model via the introduction of a conjugate prior to the Beta distribution. This prior acts as a regularization that prevents the online version of the algorithm from unstable updates when a topic is poorly represented in a mini-batch. The characteristics of this prior to the Beta distribution are studied here for the first time. Still, this model suffers from a difference in scale between the single-time observations and the multiplicity of words per document. A variation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a solution. In WBToT, publication dates are repeated a certain number of times per document, which balances the relative influence of words and timestamps along the inference process. We have tested our models on two datasets: a collection of over 200 years of US state-of-the-union (SOTU) addresses and a large-scale COVID-19 Twitter corpus of 10 million tweets. The results show that WBToT captures events better than Latent Dirichlet Allocation and other SOTA topic models like BERTopic: the median absolute deviation of the topic presence over time is reduced by $51\\%$ and $34\\%$, respectively. Our experiments also demonstrate the superior coherence of WBToT over BToT, which highlights the importance of balancing the time and word modalities. Finally, we illustrate the stability of the online optimization algorithm in WBToT, which allows the application of WBToT to problems that are intractable for standard ToT.","sentences":["The Topics over Time (ToT) model captures thematic changes in timestamped datasets by explicitly modeling publication dates jointly with word co-occurrence patterns.","However, ToT was not approached in a fully Bayesian fashion, a flaw that makes it susceptible to stability problems.","To address this issue, we propose a fully Bayesian Topics over Time (BToT) model via the introduction of a conjugate prior to the Beta distribution.","This prior acts as a regularization that prevents the online version of the algorithm from unstable updates when a topic is poorly represented in a mini-batch.","The characteristics of this prior to the Beta distribution are studied here for the first time.","Still, this model suffers from a difference in scale between the single-time observations and the multiplicity of words per document.","A variation of BToT, Weighted Bayesian Topics over Time (WBToT), is proposed as a solution.","In WBToT, publication dates are repeated a certain number of times per document, which balances the relative influence of words and timestamps along the inference process.","We have tested our models on two datasets: a collection of over 200 years of US state-of-the-union (SOTU) addresses and a large-scale COVID-19 Twitter corpus of 10 million tweets.","The results show that WBToT captures events better than Latent Dirichlet Allocation and other SOTA topic models like BERTopic: the median absolute deviation of the topic presence over time is reduced by $51\\%$ and $34\\%$, respectively.","Our experiments also demonstrate the superior coherence of WBToT over BToT, which highlights the importance of balancing the time and word modalities.","Finally, we illustrate the stability of the online optimization algorithm in WBToT, which allows the application of WBToT to problems that are intractable for standard ToT."],"url":"http://arxiv.org/abs/2504.15220v1"}
{"created":"2025-04-21 16:43:50","title":"EvalAgent: Discovering Implicit Evaluation Criteria from the Web","abstract":"Evaluation of language model outputs on structured writing tasks is typically conducted with a number of desirable criteria presented to human evaluators or large language models (LLMs). For instance, on a prompt like \"Help me draft an academic talk on coffee intake vs research productivity\", a model response may be evaluated for criteria like accuracy and coherence. However, high-quality responses should do more than just satisfy basic task requirements. An effective response to this query should include quintessential features of an academic talk, such as a compelling opening, clear research questions, and a takeaway. To help identify these implicit criteria, we introduce EvalAgent, a novel framework designed to automatically uncover nuanced and task-specific criteria. EvalAgent first mines expert-authored online guidance. It then uses this evidence to propose diverse, long-tail evaluation criteria that are grounded in reliable external sources. Our experiments demonstrate that the grounded criteria produced by EvalAgent are often implicit (not directly stated in the user's prompt), yet specific (high degree of lexical precision). Further, EvalAgent criteria are often not satisfied by initial responses but they are actionable, such that responses can be refined to satisfy them. Finally, we show that combining LLM-generated and EvalAgent criteria uncovers more human-valued criteria than using LLMs alone.","sentences":["Evaluation of language model outputs on structured writing tasks is typically conducted with a number of desirable criteria presented to human evaluators or large language models (LLMs).","For instance, on a prompt like \"Help me draft an academic talk on coffee intake vs research productivity\", a model response may be evaluated for criteria like accuracy and coherence.","However, high-quality responses should do more than just satisfy basic task requirements.","An effective response to this query should include quintessential features of an academic talk, such as a compelling opening, clear research questions, and a takeaway.","To help identify these implicit criteria, we introduce EvalAgent, a novel framework designed to automatically uncover nuanced and task-specific criteria.","EvalAgent first mines expert-authored online guidance.","It then uses this evidence to propose diverse, long-tail evaluation criteria that are grounded in reliable external sources.","Our experiments demonstrate that the grounded criteria produced by EvalAgent are often implicit (not directly stated in the user's prompt), yet specific (high degree of lexical precision).","Further, EvalAgent criteria are often not satisfied by initial responses but they are actionable, such that responses can be refined to satisfy them.","Finally, we show that combining LLM-generated and EvalAgent criteria uncovers more human-valued criteria than using LLMs alone."],"url":"http://arxiv.org/abs/2504.15219v1"}
{"created":"2025-04-21 16:41:40","title":"DRAGON: Distributional Rewards Optimize Diffusion Generative Models","abstract":"We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome. Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible. It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards. Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution. When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio). Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward. For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD). We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an 81.45% average win rate. Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards. With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations. As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality. Sound examples at https://ml-dragon.github.io/web.","sentences":["We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome.","Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible.","It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards.","Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution.","When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio).","Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward.","For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD).","We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets.","Over all 20 target rewards, DRAGON achieves an 81.45% average win rate.","Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards.","With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations.","As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality.","Sound examples at https://ml-dragon.github.io/web."],"url":"http://arxiv.org/abs/2504.15217v1"}
{"created":"2025-04-21 16:39:17","title":"An experimental study of the influence of anonymous information on social media users","abstract":"Increasingly, people use social media for their day-to-day interactions and as a source of information, even though much of this information is practically anonymous. This raises the question: does anonymous information influence its recipients? We conducted an online, two-phase, preregistered experiment using a nationally representative sample of participants from the U.S. to find the answer. To avoid biases of opinions among participants, in the first phase, each participant examines ten Rorschach inkblots and chooses one of four opinions assigned to each inkblot. In the second phase, the participants are randomly assigned to one of four distinct information conditions and are asked to revisit their opinions for the same ten inkblots. Conditions ranged from repeating phase one to receiving anonymous comments about certain opinions. Results were consistent with the preregistration. Importantly, anonymous comments shown in phase two influence up to half of the participants' opinion selections. To better understand the role of anonymous comments in influencing the selections of opinions, we implemented agent-based modeling (ABM). ABM results suggest that a straightforward mechanism can explain the impact of such information. Overall, our results indicate that even anonymous information can have a significant impact on its recipients, potentially altering their popularity rankings. However, the strength of such influence weakens when recipients' confidence in their selections increases. Additionally, we found that participants' confidence in the first phase is inversely related to the number of change opinions.","sentences":["Increasingly, people use social media for their day-to-day interactions and as a source of information, even though much of this information is practically anonymous.","This raises the question: does anonymous information influence its recipients?","We conducted an online, two-phase, preregistered experiment using a nationally representative sample of participants from the U.S. to find the answer.","To avoid biases of opinions among participants, in the first phase, each participant examines ten Rorschach inkblots and chooses one of four opinions assigned to each inkblot.","In the second phase, the participants are randomly assigned to one of four distinct information conditions and are asked to revisit their opinions for the same ten inkblots.","Conditions ranged from repeating phase one to receiving anonymous comments about certain opinions.","Results were consistent with the preregistration.","Importantly, anonymous comments shown in phase two influence up to half of the participants' opinion selections.","To better understand the role of anonymous comments in influencing the selections of opinions, we implemented agent-based modeling (ABM).","ABM results suggest that a straightforward mechanism can explain the impact of such information.","Overall, our results indicate that even anonymous information can have a significant impact on its recipients, potentially altering their popularity rankings.","However, the strength of such influence weakens when recipients' confidence in their selections increases.","Additionally, we found that participants' confidence in the first phase is inversely related to the number of change opinions."],"url":"http://arxiv.org/abs/2504.15215v1"}
{"created":"2025-04-21 16:36:38","title":"Histogram-based Parameter-efficient Tuning for Passive Sonar Classification","abstract":"Parameter-efficient transfer learning (PETL) methods adapt large artificial neural networks to downstream tasks without fine-tuning the entire model. However, existing additive methods, such as adapters, sometimes struggle to capture distributional shifts in intermediate feature embeddings. We propose a novel histogram-based parameter-efficient tuning (HPT) technique that captures the statistics of the target domain and modulates the embeddings. Experimental results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD) demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves 91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields feature representations closer to those of fully fine-tuned models. Overall, HPT balances parameter savings and performance, providing a distribution-aware alternative to existing adapters and shows a promising direction for scalable transfer learning in resource-constrained environments. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.","sentences":["Parameter-efficient transfer learning (PETL) methods adapt large artificial neural networks to downstream tasks without fine-tuning the entire model.","However, existing additive methods, such as adapters, sometimes struggle to capture distributional shifts in intermediate feature embeddings.","We propose a novel histogram-based parameter-efficient tuning (HPT) technique that captures the statistics of the target domain and modulates the embeddings.","Experimental results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD) demonstrate that HPT outperforms conventional adapters.","Notably, HPT achieves 91.8% vs. 89.8% accuracy on VTUAD.","Furthermore, HPT trains faster and yields feature representations closer to those of fully fine-tuned models.","Overall, HPT balances parameter savings and performance, providing a distribution-aware alternative to existing adapters and shows a promising direction for scalable transfer learning in resource-constrained environments.","The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient."],"url":"http://arxiv.org/abs/2504.15214v1"}
{"created":"2025-04-21 16:31:15","title":"Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI","abstract":"The evaluation of Generative AI (GenAI) systems plays a critical role in public policy and decision-making, yet existing methods are often limited by reliance on benchmark-driven, point-estimate comparisons that fail to capture uncertainty and broader societal impacts. This paper argues for the use of Bayesian statistics as a principled framework to address these challenges. Bayesian methods enable the integration of domain expertise through prior elicitation, allow for continuous learning from new data, and provide robust uncertainty quantification via posterior inference. We demonstrate how Bayesian inference can be applied to GenAI evaluation, particularly in incorporating stakeholder perspectives to enhance fairness, transparency, and reliability. Furthermore, we discuss Bayesian workflows as an iterative process for model validation and refinement, ensuring robust assessments of GenAI systems in dynamic, real-world contexts.","sentences":["The evaluation of Generative AI (GenAI) systems plays a critical role in public policy and decision-making, yet existing methods are often limited by reliance on benchmark-driven, point-estimate comparisons that fail to capture uncertainty and broader societal impacts.","This paper argues for the use of Bayesian statistics as a principled framework to address these challenges.","Bayesian methods enable the integration of domain expertise through prior elicitation, allow for continuous learning from new data, and provide robust uncertainty quantification via posterior inference.","We demonstrate how Bayesian inference can be applied to GenAI evaluation, particularly in incorporating stakeholder perspectives to enhance fairness, transparency, and reliability.","Furthermore, we discuss Bayesian workflows as an iterative process for model validation and refinement, ensuring robust assessments of GenAI systems in dynamic, real-world contexts."],"url":"http://arxiv.org/abs/2504.15211v1"}
{"created":"2025-04-21 16:29:07","title":"Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs","abstract":"Code-generating Large Language Models (LLMs) have become essential tools in modern software development, enhancing productivity and accelerating development. This paper aims to investigate the fine-tuning of code-generating LLMs using Reinforcement Learning and Direct Preference Optimization, further improving their performance. To achieve this, we enhance the training data for the reward model with the help of symbolic execution techniques, ensuring more comprehensive and objective data. With symbolic execution, we create a custom dataset that better captures the nuances in code evaluation. Our reward models, fine-tuned on this dataset, demonstrate significant improvements over the baseline, CodeRL, in estimating the quality of generated code. Our code-generating LLMs, trained with the help of reward model feedback, achieve similar results compared to the CodeRL benchmark.","sentences":["Code-generating Large Language Models (LLMs) have become essential tools in modern software development, enhancing productivity and accelerating development.","This paper aims to investigate the fine-tuning of code-generating LLMs using Reinforcement Learning and Direct Preference Optimization, further improving their performance.","To achieve this, we enhance the training data for the reward model with the help of symbolic execution techniques, ensuring more comprehensive and objective data.","With symbolic execution, we create a custom dataset that better captures the nuances in code evaluation.","Our reward models, fine-tuned on this dataset, demonstrate significant improvements over the baseline, CodeRL, in estimating the quality of generated code.","Our code-generating LLMs, trained with the help of reward model feedback, achieve similar results compared to the CodeRL benchmark."],"url":"http://arxiv.org/abs/2504.15210v1"}
{"created":"2025-04-21 16:27:16","title":"A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data","abstract":"The monitoring of water quality is a crucial part of environmental protection, and a large number of monitors are widely deployed to monitor water quality. Due to unavoidable factors such as data acquisition breakdowns, sensors and communication failures, water quality monitoring data suffers from missing values over time, resulting in High-Dimensional and Sparse (HDS) Water Quality Data (WQD). The simple and rough filling of the missing values leads to inaccurate results and affects the implementation of relevant measures. Therefore, this paper proposes a Causal convolutional Low-rank Representation (CLR) model for imputing missing WQD to improve the completeness of the WQD, which employs a two-fold idea: a) applying causal convolutional operation to consider the temporal dependence of the low-rank representation, thus incorporating temporal information to improve the imputation accuracy; and b) implementing a hyperparameters adaptation scheme to automatically adjust the best hyperparameters during model training, thereby reducing the tedious manual adjustment of hyper-parameters. Experimental studies on three real-world water quality datasets demonstrate that the proposed CLR model is superior to some of the existing state-of-the-art imputation models in terms of imputation accuracy and time cost, as well as indicating that the proposed model provides more reliable decision support for environmental monitoring.","sentences":["The monitoring of water quality is a crucial part of environmental protection, and a large number of monitors are widely deployed to monitor water quality.","Due to unavoidable factors such as data acquisition breakdowns, sensors and communication failures, water quality monitoring data suffers from missing values over time, resulting in High-Dimensional and Sparse (HDS)","Water Quality Data (WQD).","The simple and rough filling of the missing values leads to inaccurate results and affects the implementation of relevant measures.","Therefore, this paper proposes a Causal convolutional Low-rank Representation (CLR) model for imputing missing WQD to improve the completeness of the WQD, which employs a two-fold idea: a) applying causal convolutional operation to consider the temporal dependence of the low-rank representation, thus incorporating temporal information to improve the imputation accuracy; and b) implementing a hyperparameters adaptation scheme to automatically adjust the best hyperparameters during model training, thereby reducing the tedious manual adjustment of hyper-parameters.","Experimental studies on three real-world water quality datasets demonstrate that the proposed CLR model is superior to some of the existing state-of-the-art imputation models in terms of imputation accuracy and time cost, as well as indicating that the proposed model provides more reliable decision support for environmental monitoring."],"url":"http://arxiv.org/abs/2504.15209v1"}
{"created":"2025-04-21 16:26:56","title":"Compute-Optimal LLMs Provably Generalize Better With Scale","abstract":"Why do larger language models generalize better? To investigate this question, we develop generalization bounds on the pretraining objective of large language models (LLMs) in the compute-optimal regime, as described by the Chinchilla scaling laws. We introduce a novel, fully empirical Freedman-type martingale concentration inequality that tightens existing bounds by accounting for the variance of the loss function. This generalization bound can be decomposed into three interpretable components: the number of parameters per token, the loss variance, and the quantization error at a fixed bitrate. As compute-optimal language models are scaled up, the number of parameters per data point remains constant; however, both the loss variance and the quantization error decrease, implying that larger models should have smaller generalization gaps. We examine why larger models tend to be more quantizable from an information theoretic perspective, showing that the rate at which they can integrate new information grows more slowly than their capacity on the compute-optimal frontier. From these findings we produce a scaling law for the generalization gap, with bounds that become predictably stronger with scale.","sentences":["Why do larger language models generalize better?","To investigate this question, we develop generalization bounds on the pretraining objective of large language models (LLMs) in the compute-optimal regime, as described by the Chinchilla scaling laws.","We introduce a novel, fully empirical Freedman-type martingale concentration inequality that tightens existing bounds by accounting for the variance of the loss function.","This generalization bound can be decomposed into three interpretable components: the number of parameters per token, the loss variance, and the quantization error at a fixed bitrate.","As compute-optimal language models are scaled up, the number of parameters per data point remains constant; however, both the loss variance and the quantization error decrease, implying that larger models should have smaller generalization gaps.","We examine why larger models tend to be more quantizable from an information theoretic perspective, showing that the rate at which they can integrate new information grows more slowly than their capacity on the compute-optimal frontier.","From these findings we produce a scaling law for the generalization gap, with bounds that become predictably stronger with scale."],"url":"http://arxiv.org/abs/2504.15208v1"}
{"created":"2025-04-21 16:22:44","title":"How Global Calibration Strengthens Multiaccuracy","abstract":"Multiaccuracy and multicalibration are multigroup fairness notions for prediction that have found numerous applications in learning and computational complexity. They can be achieved from a single learning primitive: weak agnostic learning. Here we investigate the power of multiaccuracy as a learning primitive, both with and without the additional assumption of calibration. We find that multiaccuracy in itself is rather weak, but that the addition of global calibration (this notion is called calibrated multiaccuracy) boosts its power substantially, enough to recover implications that were previously known only assuming the stronger notion of multicalibration.   We give evidence that multiaccuracy might not be as powerful as standard weak agnostic learning, by showing that there is no way to post-process a multiaccurate predictor to get a weak learner, even assuming the best hypothesis has correlation $1/2$. Rather, we show that it yields a restricted form of weak agnostic learning, which requires some concept in the class to have correlation greater than $1/2$ with the labels. However, by also requiring the predictor to be calibrated, we recover not just weak, but strong agnostic learning.   A similar picture emerges when we consider the derivation of hardcore measures from predictors satisfying multigroup fairness notions. On the one hand, while multiaccuracy only yields hardcore measures of density half the optimal, we show that (a weighted version of) calibrated multiaccuracy achieves optimal density.   Our results yield new insights into the complementary roles played by multiaccuracy and calibration in each setting. They shed light on why multiaccuracy and global calibration, although not particularly powerful by themselves, together yield considerably stronger notions.","sentences":["Multiaccuracy and multicalibration are multigroup fairness notions for prediction that have found numerous applications in learning and computational complexity.","They can be achieved from a single learning primitive: weak agnostic learning.","Here we investigate the power of multiaccuracy as a learning primitive, both with and without the additional assumption of calibration.","We find that multiaccuracy in itself is rather weak, but that the addition of global calibration (this notion is called calibrated multiaccuracy) boosts its power substantially, enough to recover implications that were previously known only assuming the stronger notion of multicalibration.   ","We give evidence that multiaccuracy might not be as powerful as standard weak agnostic learning, by showing that there is no way to post-process a multiaccurate predictor to get a weak learner, even assuming the best hypothesis has correlation $1/2$. Rather, we show that it yields a restricted form of weak agnostic learning, which requires some concept in the class to have correlation greater than $1/2$ with the labels.","However, by also requiring the predictor to be calibrated, we recover not just weak, but strong agnostic learning.   ","A similar picture emerges when we consider the derivation of hardcore measures from predictors satisfying multigroup fairness notions.","On the one hand, while multiaccuracy only yields hardcore measures of density half the optimal, we show that (a weighted version of) calibrated multiaccuracy achieves optimal density.   ","Our results yield new insights into the complementary roles played by multiaccuracy and calibration in each setting.","They shed light on why multiaccuracy and global calibration, although not particularly powerful by themselves, together yield considerably stronger notions."],"url":"http://arxiv.org/abs/2504.15206v1"}
{"created":"2025-04-21 16:20:43","title":"Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges","abstract":"Retrieval-augmented generation (RAG) enables large language models (LLMs) to generate answers with citations from source documents containing \"ground truth\", thereby reducing system hallucinations. A crucial factor in RAG evaluation is \"support\", whether the information in the cited documents supports the answer. To this end, we conducted a large-scale comparative study of 45 participant submissions on 36 topics to the TREC 2024 RAG Track, comparing an automatic LLM judge (GPT-4o) against human judges for support assessment. We considered two conditions: (1) fully manual assessments from scratch and (2) manual assessments with post-editing of LLM predictions. Our results indicate that for 56% of the manual from-scratch assessments, human and GPT-4o predictions match perfectly (on a three-level scale), increasing to 72% in the manual with post-editing condition. Furthermore, by carefully analyzing the disagreements in an unbiased study, we found that an independent human judge correlates better with GPT-4o than a human judge, suggesting that LLM judges can be a reliable alternative for support assessment. To conclude, we provide a qualitative analysis of human and GPT-4o errors to help guide future iterations of support assessment.","sentences":["Retrieval-augmented generation (RAG) enables large language models (LLMs) to generate answers with citations from source documents containing \"ground truth\", thereby reducing system hallucinations.","A crucial factor in RAG evaluation is \"support\", whether the information in the cited documents supports the answer.","To this end, we conducted a large-scale comparative study of 45 participant submissions on 36 topics to the TREC 2024 RAG Track, comparing an automatic LLM judge (GPT-4o) against human judges for support assessment.","We considered two conditions: (1) fully manual assessments from scratch and (2) manual assessments with post-editing of LLM predictions.","Our results indicate that for 56% of the manual from-scratch assessments, human and GPT-4o predictions match perfectly (on a three-level scale), increasing to 72% in the manual with post-editing condition.","Furthermore, by carefully analyzing the disagreements in an unbiased study, we found that an independent human judge correlates better with GPT-4o than a human judge, suggesting that LLM judges can be a reliable alternative for support assessment.","To conclude, we provide a qualitative analysis of human and GPT-4o errors to help guide future iterations of support assessment."],"url":"http://arxiv.org/abs/2504.15205v1"}
{"created":"2025-04-21 16:20:13","title":"Soft-Output from Covered Space Decoding of Product Codes","abstract":"In this work, we propose a new soft-in soft-out decoder called soft-output from covered space (SOCS) decoder. It estimates the a posteriori reliability based on the space explored by a list decoder, i.e., the set of vectors for which the list decoder knows whether they are codewords. This approach enables a more accurate calculation of the a posteriori reliability and results in gains of up to 0.25$\\,$dB for turbo product decoding with SOCS decoding compared to Chase-Pyndiah decoding.","sentences":["In this work, we propose a new soft-in soft-out decoder called soft-output from covered space (SOCS) decoder.","It estimates the a posteriori reliability based on the space explored by a list decoder, i.e., the set of vectors for which the list decoder knows whether they are codewords.","This approach enables a more accurate calculation of the a posteriori reliability and results in gains of up to 0.25$\\,$dB for turbo product decoding with SOCS decoding compared to Chase-Pyndiah decoding."],"url":"http://arxiv.org/abs/2504.15204v1"}
{"created":"2025-04-21 16:17:53","title":"Extending the ElGamal Cryptosystem to the Third Group of Units of $\\Z_{n}$","abstract":"In this paper, we extend the ElGamal cryptosystem to the third group of units of the ring $\\Z_{n}$, which we prove to be more secure than the previous extensions. We describe the arithmetic needed in the new setting. We also provide some numerical simulations that shows the security and efficiency of our proposed cryptosystem.","sentences":["In this paper, we extend the ElGamal cryptosystem to the third group of units of the ring $\\Z_{n}$, which we prove to be more secure than the previous extensions.","We describe the arithmetic needed in the new setting.","We also provide some numerical simulations that shows the security and efficiency of our proposed cryptosystem."],"url":"http://arxiv.org/abs/2504.15202v1"}
{"created":"2025-04-21 16:16:19","title":"Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning","abstract":"MILS (Multimodal Iterative LLM Solver) is a recently published framework that claims \"LLMs can see and hear without any training\" by leveraging an iterative, LLM-CLIP based approach for zero-shot image captioning. While this MILS approach demonstrates good performance, our investigation reveals that this success comes at a hidden, substantial computational cost due to its expensive multi-step refinement process. In contrast, alternative models such as BLIP-2 and GPT-4V achieve competitive results through a streamlined, single-pass approach. We hypothesize that the significant overhead inherent in MILS's iterative process may undermine its practical benefits, thereby challenging the narrative that zero-shot performance can be attained without incurring heavy resource demands. This work is the first to expose and quantify the trade-offs between output quality and computational cost in MILS, providing critical insights for the design of more efficient multimodal models.","sentences":["MILS (Multimodal Iterative LLM Solver) is a recently published framework that claims \"LLMs can see and hear without any training\" by leveraging an iterative, LLM-CLIP based approach for zero-shot image captioning.","While this MILS approach demonstrates good performance, our investigation reveals that this success comes at a hidden, substantial computational cost due to its expensive multi-step refinement process.","In contrast, alternative models such as BLIP-2 and GPT-4V achieve competitive results through a streamlined, single-pass approach.","We hypothesize that the significant overhead inherent in MILS's iterative process may undermine its practical benefits, thereby challenging the narrative that zero-shot performance can be attained without incurring heavy resource demands.","This work is the first to expose and quantify the trade-offs between output quality and computational cost in MILS, providing critical insights for the design of more efficient multimodal models."],"url":"http://arxiv.org/abs/2504.15199v1"}
{"created":"2025-04-21 16:02:26","title":"Automated Measurement of Eczema Severity with Self-Supervised Learning","abstract":"Automated diagnosis of eczema using images acquired from digital camera can enable individuals to self-monitor their recovery. The process entails first segmenting out the eczema region from the image and then measuring the severity of eczema in the segmented region. The state-of-the-art methods for automated eczema diagnosis rely on deep neural networks such as convolutional neural network (CNN) and have shown impressive performance in accurately measuring the severity of eczema. However, these methods require massive volume of annotated data to train which can be hard to obtain. In this paper, we propose a self-supervised learning framework for automated eczema diagnosis under limited training data regime. Our framework consists of two stages: i) Segmentation, where we use an in-context learning based algorithm called SegGPT for few-shot segmentation of eczema region from the image; ii) Feature extraction and classification, where we extract DINO features from the segmented regions and feed it to a multi-layered perceptron (MLP) for 4-class classification of eczema severity. When evaluated on a dataset of annotated \"in-the-wild\" eczema images, we show that our method outperforms (Weighted F1: 0.67 $\\pm$ 0.01) the state-of-the-art deep learning methods such as finetuned Resnet-18 (Weighted F1: 0.44 $\\pm$ 0.16) and Vision Transformer (Weighted F1: 0.40 $\\pm$ 0.22). Our results show that self-supervised learning can be a viable solution for automated skin diagnosis where labeled data is scarce.","sentences":["Automated diagnosis of eczema using images acquired from digital camera can enable individuals to self-monitor their recovery.","The process entails first segmenting out the eczema region from the image and then measuring the severity of eczema in the segmented region.","The state-of-the-art methods for automated eczema diagnosis rely on deep neural networks such as convolutional neural network (CNN) and have shown impressive performance in accurately measuring the severity of eczema.","However, these methods require massive volume of annotated data to train which can be hard to obtain.","In this paper, we propose a self-supervised learning framework for automated eczema diagnosis under limited training data regime.","Our framework consists of two stages: i) Segmentation, where we use an in-context learning based algorithm called SegGPT for few-shot segmentation of eczema region from the image; ii) Feature extraction and classification, where we extract DINO features from the segmented regions and feed it to a multi-layered perceptron (MLP) for 4-class classification of eczema severity.","When evaluated on a dataset of annotated \"in-the-wild\" eczema images, we show that our method outperforms (Weighted F1: 0.67 $\\pm$ 0.01) the state-of-the-art deep learning methods such as finetuned Resnet-18 (Weighted F1: 0.44 $\\pm$ 0.16) and Vision Transformer (Weighted F1: 0.40 $\\pm$ 0.22).","Our results show that self-supervised learning can be a viable solution for automated skin diagnosis where labeled data is scarce."],"url":"http://arxiv.org/abs/2504.15193v1"}
{"created":"2025-04-21 16:01:51","title":"Breast density in MRI: an AI-based quantification and relationship to assessment in mammography","abstract":"Mammographic breast density is a well-established risk factor for breast cancer. Recently there has been interest in breast MRI as an adjunct to mammography, as this modality provides an orthogonal and highly quantitative assessment of breast tissue. However, its 3D nature poses analytic challenges related to delineating and aggregating complex structures across slices. Here, we applied an in-house machine-learning algorithm to assess breast density on normal breasts in three MRI datasets. Breast density was consistent across different datasets (0.104 - 0.114). Analysis across different age groups also demonstrated strong consistency across datasets and confirmed a trend of decreasing density with age as reported in previous studies. MR breast density was correlated with mammographic breast density, although some notable differences suggest that certain breast density components are captured only on MRI. Future work will determine how to integrate MR breast density with current tools to improve future breast cancer risk prediction.","sentences":["Mammographic breast density is a well-established risk factor for breast cancer.","Recently there has been interest in breast MRI as an adjunct to mammography, as this modality provides an orthogonal and highly quantitative assessment of breast tissue.","However, its 3D nature poses analytic challenges related to delineating and aggregating complex structures across slices.","Here, we applied an in-house machine-learning algorithm to assess breast density on normal breasts in three MRI datasets.","Breast density was consistent across different datasets (0.104 - 0.114).","Analysis across different age groups also demonstrated strong consistency across datasets and confirmed a trend of decreasing density with age as reported in previous studies.","MR breast density was correlated with mammographic breast density, although some notable differences suggest that certain breast density components are captured only on MRI.","Future work will determine how to integrate MR breast density with current tools to improve future breast cancer risk prediction."],"url":"http://arxiv.org/abs/2504.15192v1"}
{"created":"2025-04-21 15:57:33","title":"Synergistic Weak-Strong Collaboration by Aligning Preferences","abstract":"Current Large Language Models (LLMs) excel in general reasoning yet struggle with specialized tasks requiring proprietary or domain-specific knowledge. Fine-tuning large models for every niche application is often infeasible due to black-box constraints and high computational overhead. To address this, we propose a collaborative framework that pairs a specialized weak model with a general strong model. The weak model, tailored to specific domains, produces initial drafts and background information, while the strong model leverages its advanced reasoning to refine these drafts, extending LLMs' capabilities to critical yet specialized tasks. To optimize this collaboration, we introduce a collaborative feedback to fine-tunes the weak model, which quantifies the influence of the weak model's contributions in the collaboration procedure and establishes preference pairs to guide preference tuning of the weak model. We validate our framework through experiments on three domains. We find that the collaboration significantly outperforms each model alone by leveraging complementary strengths. Moreover, aligning the weak model with the collaborative preference further enhances overall performance.","sentences":["Current Large Language Models (LLMs) excel in general reasoning yet struggle with specialized tasks requiring proprietary or domain-specific knowledge.","Fine-tuning large models for every niche application is often infeasible due to black-box constraints and high computational overhead.","To address this, we propose a collaborative framework that pairs a specialized weak model with a general strong model.","The weak model, tailored to specific domains, produces initial drafts and background information, while the strong model leverages its advanced reasoning to refine these drafts, extending LLMs' capabilities to critical yet specialized tasks.","To optimize this collaboration, we introduce a collaborative feedback to fine-tunes the weak model, which quantifies the influence of the weak model's contributions in the collaboration procedure and establishes preference pairs to guide preference tuning of the weak model.","We validate our framework through experiments on three domains.","We find that the collaboration significantly outperforms each model alone by leveraging complementary strengths.","Moreover, aligning the weak model with the collaborative preference further enhances overall performance."],"url":"http://arxiv.org/abs/2504.15188v1"}
{"created":"2025-04-21 15:57:33","title":"LACE: Controlled Image Prompting and Iterative Refinement with GenAI for Professional Visual Art Creators","abstract":"We present LACE, a hybrid Human-AI co-creative system integrated into Adobe Photoshop supporting turn-taking and parallel interaction modes for iterative image generation. Through a study with 21 participants across representational, abstract, and design tasks, we found turn-taking preferred in early stages for idea generation, and parallel modes suited for detailed refinement. While this shorter workshop paper provides key insights and highlights, the comprehensive findings and detailed analysis are presented in a longer version available separately on arXiv.","sentences":["We present LACE, a hybrid Human-AI co-creative system integrated into Adobe Photoshop supporting turn-taking and parallel interaction modes for iterative image generation.","Through a study with 21 participants across representational, abstract, and design tasks, we found turn-taking preferred in early stages for idea generation, and parallel modes suited for detailed refinement.","While this shorter workshop paper provides key insights and highlights, the comprehensive findings and detailed analysis are presented in a longer version available separately on arXiv."],"url":"http://arxiv.org/abs/2504.15189v1"}
{"created":"2025-04-21 15:49:27","title":"ForgeBench: A Machine Learning Benchmark Suite and Auto-Generation Framework for Next-Generation HLS Tools","abstract":"Although High-Level Synthesis (HLS) has attracted considerable interest in hardware design, it has not yet become mainstream due to two primary challenges. First, current HLS hardware design benchmarks are outdated as they do not cover modern machine learning (ML) applications, preventing the rigorous development of HLS tools on ML-focused hardware design. Second, existing HLS tools are outdated because they predominantly target individual accelerator designs and lack an architecture-oriented perspective to support common hardware module extraction and reuse, limiting their adaptability and broader applicability. Motivated by these two limitations, we propose ForgeBench, an ML-focused benchmark suite with a hardware design auto-generation framework for next-generation HLS tools. In addition to the auto-generation framework, we provide two ready-to-use benchmark suites. The first contains over 6,000 representative ML HLS designs. We envision future HLS tools being architecture-oriented, capable of automatically identifying common computational modules across designs, and supporting flexible dataflow and control. Accordingly, the second benchmark suite includes ML HLS designs with possible resource sharing manually implemented to highlight the necessity of architecture-oriented design, ensuring it is future-HLS ready. ForgeBench is open-sourced at https://github.com/hchen799/ForgeBench .","sentences":["Although High-Level Synthesis (HLS) has attracted considerable interest in hardware design, it has not yet become mainstream due to two primary challenges.","First, current HLS hardware design benchmarks are outdated as they do not cover modern machine learning (ML) applications, preventing the rigorous development of HLS tools on ML-focused hardware design.","Second, existing HLS tools are outdated because they predominantly target individual accelerator designs and lack an architecture-oriented perspective to support common hardware module extraction and reuse, limiting their adaptability and broader applicability.","Motivated by these two limitations, we propose ForgeBench, an ML-focused benchmark suite with a hardware design auto-generation framework for next-generation HLS tools.","In addition to the auto-generation framework, we provide two ready-to-use benchmark suites.","The first contains over 6,000 representative ML HLS designs.","We envision future HLS tools being architecture-oriented, capable of automatically identifying common computational modules across designs, and supporting flexible dataflow and control.","Accordingly, the second benchmark suite includes ML HLS designs with possible resource sharing manually implemented to highlight the necessity of architecture-oriented design, ensuring it is future-HLS ready.","ForgeBench is open-sourced at https://github.com/hchen799/ForgeBench ."],"url":"http://arxiv.org/abs/2504.15185v1"}
{"created":"2025-04-21 15:44:06","title":"Tiger200K: Manually Curated High Visual Quality Video Dataset from UGC Platform","abstract":"The recent surge in open-source text-to-video generation models has significantly energized the research community, yet their dependence on proprietary training datasets remains a key constraint. While existing open datasets like Koala-36M employ algorithmic filtering of web-scraped videos from early platforms, they still lack the quality required for fine-tuning advanced video generation models. We present Tiger200K, a manually curated high visual quality video dataset sourced from User-Generated Content (UGC) platforms. By prioritizing visual fidelity and aesthetic quality, Tiger200K underscores the critical role of human expertise in data curation, and providing high-quality, temporally consistent video-text pairs for fine-tuning and optimizing video generation architectures through a simple but effective pipeline including shot boundary detection, OCR, border detecting, motion filter and fine bilingual caption. The dataset will undergo ongoing expansion and be released as an open-source initiative to advance research and applications in video generative models. Project page: https://tinytigerpan.github.io/tiger200k/","sentences":["The recent surge in open-source text-to-video generation models has significantly energized the research community, yet their dependence on proprietary training datasets remains a key constraint.","While existing open datasets like Koala-36M employ algorithmic filtering of web-scraped videos from early platforms, they still lack the quality required for fine-tuning advanced video generation models.","We present Tiger200K, a manually curated high visual quality video dataset sourced from User-Generated Content (UGC) platforms.","By prioritizing visual fidelity and aesthetic quality, Tiger200K underscores the critical role of human expertise in data curation, and providing high-quality, temporally consistent video-text pairs for fine-tuning and optimizing video generation architectures through a simple but effective pipeline including shot boundary detection, OCR, border detecting, motion filter and fine bilingual caption.","The dataset will undergo ongoing expansion and be released as an open-source initiative to advance research and applications in video generative models.","Project page: https://tinytigerpan.github.io/tiger200k/"],"url":"http://arxiv.org/abs/2504.15182v1"}
{"created":"2025-04-21 15:44:01","title":"Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures","abstract":"This report provides a detailed comparison between the measures proposed in the EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and current practices adopted by leading AI companies. As the EU moves toward enforcing binding obligations for GPAI model providers, the Code of Practice will be key to bridging legal requirements with concrete technical commitments. Our analysis focuses on the draft's Safety and Security section which is only relevant for the providers of the most advanced models (Commitments II.1-II.16) and excerpts from current public-facing documents quotes that are relevant to each individual measure.   We systematically reviewed different document types - including companies' frontier safety frameworks and model cards - from over a dozen companies, including OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and others. This report is not meant to be an indication of legal compliance nor does it take any prescriptive viewpoint about the Code of Practice or companies' policies. Instead, it aims to inform the ongoing dialogue between regulators and GPAI model providers by surfacing evidence of precedent.","sentences":["This report provides a detailed comparison between the measures proposed in the EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and current practices adopted by leading AI companies.","As the EU moves toward enforcing binding obligations for GPAI model providers, the Code of Practice will be key to bridging legal requirements with concrete technical commitments.","Our analysis focuses on the draft's Safety and Security section which is only relevant for the providers of the most advanced models (Commitments II.1-II.16) and excerpts from current public-facing documents quotes that are relevant to each individual measure.   ","We systematically reviewed different document types - including companies' frontier safety frameworks and model cards - from over a dozen companies, including OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and others.","This report is not meant to be an indication of legal compliance nor does it take any prescriptive viewpoint about the Code of Practice or companies' policies.","Instead, it aims to inform the ongoing dialogue between regulators and GPAI model providers by surfacing evidence of precedent."],"url":"http://arxiv.org/abs/2504.15181v1"}
{"created":"2025-04-21 15:40:14","title":"FaceCraft4D: Animated 3D Facial Avatar Generation from a Single Image","abstract":"We present a novel framework for generating high-quality, animatable 4D avatar from a single image. While recent advances have shown promising results in 4D avatar creation, existing methods either require extensive multiview data or struggle with shape accuracy and identity consistency. To address these limitations, we propose a comprehensive system that leverages shape, image, and video priors to create full-view, animatable avatars. Our approach first obtains initial coarse shape through 3D-GAN inversion. Then, it enhances multiview textures using depth-guided warping signals for cross-view consistency with the help of the image diffusion model. To handle expression animation, we incorporate a video prior with synchronized driving signals across viewpoints. We further introduce a Consistent-Inconsistent training to effectively handle data inconsistencies during 4D reconstruction. Experimental results demonstrate that our method achieves superior quality compared to the prior art, while maintaining consistency across different viewpoints and expressions.","sentences":["We present a novel framework for generating high-quality, animatable 4D avatar from a single image.","While recent advances have shown promising results in 4D avatar creation, existing methods either require extensive multiview data or struggle with shape accuracy and identity consistency.","To address these limitations, we propose a comprehensive system that leverages shape, image, and video priors to create full-view, animatable avatars.","Our approach first obtains initial coarse shape through 3D-GAN inversion.","Then, it enhances multiview textures using depth-guided warping signals for cross-view consistency with the help of the image diffusion model.","To handle expression animation, we incorporate a video prior with synchronized driving signals across viewpoints.","We further introduce a Consistent-Inconsistent training to effectively handle data inconsistencies during 4D reconstruction.","Experimental results demonstrate that our method achieves superior quality compared to the prior art, while maintaining consistency across different viewpoints and expressions."],"url":"http://arxiv.org/abs/2504.15179v1"}
{"created":"2025-04-21 15:35:48","title":"DSPO: Direct Semantic Preference Optimization for Real-World Image Super-Resolution","abstract":"Recent advances in diffusion models have improved Real-World Image Super-Resolution (Real-ISR), but existing methods lack human feedback integration, risking misalignment with human preference and may leading to artifacts, hallucinations and harmful content generation. To this end, we are the first to introduce human preference alignment into Real-ISR, a technique that has been successfully applied in Large Language Models and Text-to-Image tasks to effectively enhance the alignment of generated outputs with human preferences. Specifically, we introduce Direct Preference Optimization (DPO) into Real-ISR to achieve alignment, where DPO serves as a general alignment technique that directly learns from the human preference dataset. Nevertheless, unlike high-level tasks, the pixel-level reconstruction objectives of Real-ISR are difficult to reconcile with the image-level preferences of DPO, which can lead to the DPO being overly sensitive to local anomalies, leading to reduced generation quality. To resolve this dichotomy, we propose Direct Semantic Preference Optimization (DSPO) to align instance-level human preferences by incorporating semantic guidance, which is through two strategies: (a) semantic instance alignment strategy, implementing instance-level alignment to ensure fine-grained perceptual consistency, and (b) user description feedback strategy, mitigating hallucinations through semantic textual feedback on instance-level images. As a plug-and-play solution, DSPO proves highly effective in both one-step and multi-step SR frameworks.","sentences":["Recent advances in diffusion models have improved Real-World Image Super-Resolution (Real-ISR), but existing methods lack human feedback integration, risking misalignment with human preference and may leading to artifacts, hallucinations and harmful content generation.","To this end, we are the first to introduce human preference alignment into Real-ISR, a technique that has been successfully applied in Large Language Models and Text-to-Image tasks to effectively enhance the alignment of generated outputs with human preferences.","Specifically, we introduce Direct Preference Optimization (DPO) into Real-ISR to achieve alignment, where DPO serves as a general alignment technique that directly learns from the human preference dataset.","Nevertheless, unlike high-level tasks, the pixel-level reconstruction objectives of Real-ISR are difficult to reconcile with the image-level preferences of DPO, which can lead to the DPO being overly sensitive to local anomalies, leading to reduced generation quality.","To resolve this dichotomy, we propose Direct Semantic Preference Optimization (DSPO) to align instance-level human preferences by incorporating semantic guidance, which is through two strategies: (a) semantic instance alignment strategy, implementing instance-level alignment to ensure fine-grained perceptual consistency, and (b) user description feedback strategy, mitigating hallucinations through semantic textual feedback on instance-level images.","As a plug-and-play solution, DSPO proves highly effective in both one-step and multi-step SR frameworks."],"url":"http://arxiv.org/abs/2504.15176v1"}
{"created":"2025-04-21 15:24:34","title":"Audio-Visual Class-Incremental Learning for Fish Feeding intensity Assessment in Aquaculture","abstract":"Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture management. Recent multi-modal approaches have shown promise in improving FFIA robustness and efficiency. However, these methods face significant challenges when adapting to new fish species or environments due to catastrophic forgetting and the lack of suitable datasets. To address these limitations, we first introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled audio-visual clips capturing feeding intensities across six different fish species in real aquaculture environments. Then, we pioneer audio-visual class incremental learning (CIL) for FFIA and demonstrate through benchmarking on AV-CIL-FFIA that it significantly outperforms single-modality methods. Existing CIL methods rely heavily on historical data. Exemplar-based approaches store raw samples, creating storage challenges, while exemplar-free methods avoid data storage but struggle to distinguish subtle feeding intensity variations across different fish species. To overcome these limitations, we introduce HAIL-FFIA, a novel audio-visual class-incremental learning framework that bridges this gap with a prototype-based approach that achieves exemplar-free efficiency while preserving essential knowledge through compact feature representations. Specifically, HAIL-FFIA employs hierarchical representation learning with a dual-path knowledge preservation mechanism that separates general intensity knowledge from fish-specific characteristics. Additionally, it features a dynamic modality balancing system that adaptively adjusts the importance of audio versus visual information based on feeding behaviour stages. Experimental results show that HAIL-FFIA is superior to SOTA methods on AV-CIL-FFIA, achieving higher accuracy with lower storage needs while effectively mitigating catastrophic forgetting in incremental fish species learning.","sentences":["Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture management.","Recent multi-modal approaches have shown promise in improving FFIA robustness and efficiency.","However, these methods face significant challenges when adapting to new fish species or environments due to catastrophic forgetting and the lack of suitable datasets.","To address these limitations, we first introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled audio-visual clips capturing feeding intensities across six different fish species in real aquaculture environments.","Then, we pioneer audio-visual class incremental learning (CIL) for FFIA and demonstrate through benchmarking on AV-CIL-FFIA that it significantly outperforms single-modality methods.","Existing CIL methods rely heavily on historical data.","Exemplar-based approaches store raw samples, creating storage challenges, while exemplar-free methods avoid data storage but struggle to distinguish subtle feeding intensity variations across different fish species.","To overcome these limitations, we introduce HAIL-FFIA, a novel audio-visual class-incremental learning framework that bridges this gap with a prototype-based approach that achieves exemplar-free efficiency while preserving essential knowledge through compact feature representations.","Specifically, HAIL-FFIA employs hierarchical representation learning with a dual-path knowledge preservation mechanism that separates general intensity knowledge from fish-specific characteristics.","Additionally, it features a dynamic modality balancing system that adaptively adjusts the importance of audio versus visual information based on feeding behaviour stages.","Experimental results show that HAIL-FFIA is superior to SOTA methods on AV-CIL-FFIA, achieving higher accuracy with lower storage needs while effectively mitigating catastrophic forgetting in incremental fish species learning."],"url":"http://arxiv.org/abs/2504.15171v1"}
{"created":"2025-04-21 15:23:59","title":"HSANET: A Hybrid Self-Cross Attention Network For Remote Sensing Change Detection","abstract":"The remote sensing image change detection task is an essential method for large-scale monitoring. We propose HSANet, a network that uses hierarchical convolution to extract multi-scale features. It incorporates hybrid self-attention and cross-attention mechanisms to learn and fuse global and cross-scale information. This enables HSANet to capture global context at different scales and integrate cross-scale features, refining edge details and improving detection performance. We will also open-source our model code: https://github.com/ChengxiHAN/HSANet.","sentences":["The remote sensing image change detection task is an essential method for large-scale monitoring.","We propose HSANet, a network that uses hierarchical convolution to extract multi-scale features.","It incorporates hybrid self-attention and cross-attention mechanisms to learn and fuse global and cross-scale information.","This enables HSANet to capture global context at different scales and integrate cross-scale features, refining edge details and improving detection performance.","We will also open-source our model code: https://github.com/ChengxiHAN/HSANet."],"url":"http://arxiv.org/abs/2504.15170v1"}
{"created":"2025-04-21 15:22:21","title":"On true empty category","abstract":"According to Chomsky (1981, 1986), empty categories consist of PRO, pro, trace, and variable. However, some empty object positions seem to be incompatible with extant empty categories. Given this, Li (2007a, 2007b, 2014) and Li & Wei (2014) raise the true empty category hypothesis, which holds that true empty category is only an empty position with category and Case features. As a last resort option, it is used mainly to meet the subcatgorization of a verb. This assumption is ingenious, and if proved to be true, it will exert a great impact on the study of UG. In this paper, we evaluate their evidence from topicalization and demonstrate that it can be accounted for without invoking true empty category.","sentences":["According to Chomsky (1981, 1986), empty categories consist of PRO, pro, trace, and variable.","However, some empty object positions seem to be incompatible with extant empty categories.","Given this, Li (2007a, 2007b, 2014) and Li & Wei (2014) raise the true empty category hypothesis, which holds that true empty category is only an empty position with category and Case features.","As a last resort option, it is used mainly to meet the subcatgorization of a verb.","This assumption is ingenious, and if proved to be true, it will exert a great impact on the study of UG.","In this paper, we evaluate their evidence from topicalization and demonstrate that it can be accounted for without invoking true empty category."],"url":"http://arxiv.org/abs/2504.15168v1"}
{"created":"2025-04-21 15:16:13","title":"An Efficient Aerial Image Detection with Variable Receptive Fields","abstract":"Aerial object detection using unmanned aerial vehicles (UAVs) faces critical challenges including sub-10px targets, dense occlusions, and stringent computational constraints. Existing detectors struggle to balance accuracy and efficiency due to rigid receptive fields and redundant architectures. To address these limitations, we propose Variable Receptive Field DETR (VRF-DETR), a transformer-based detector incorporating three key components: 1) Multi-Scale Context Fusion (MSCF) module that dynamically recalibrates features through adaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution (GConv) layer enabling parameter-efficient local-context modeling via depthwise separable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF) Bottleneck that hierarchically disentangles occluded objects through cascaded global-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR achieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with only 13.5M parameters. This work establishes a new efficiency-accuracy Pareto frontier for UAV-based detection tasks.","sentences":["Aerial object detection using unmanned aerial vehicles (UAVs) faces critical challenges including sub-10px targets, dense occlusions, and stringent computational constraints.","Existing detectors struggle to balance accuracy and efficiency due to rigid receptive fields and redundant architectures.","To address these limitations, we propose Variable Receptive Field DETR (VRF-DETR), a transformer-based detector incorporating three key components: 1) Multi-Scale Context Fusion (MSCF) module that dynamically recalibrates features through adaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution (GConv) layer enabling parameter-efficient local-context modeling via depthwise separable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF) Bottleneck that hierarchically disentangles occluded objects through cascaded global-local interactions.","Experiments on VisDrone2019 demonstrate VRF-DETR achieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with only 13.5M parameters.","This work establishes a new efficiency-accuracy Pareto frontier for UAV-based detection tasks."],"url":"http://arxiv.org/abs/2504.15165v1"}
{"created":"2025-04-21 15:09:40","title":"Survey of Loss Augmented Knowledge Tracing","abstract":"The training of artificial neural networks is heavily dependent on the careful selection of an appropriate loss function. While commonly used loss functions, such as cross-entropy and mean squared error (MSE), generally suffice for a broad range of tasks, challenges often emerge due to limitations in data quality or inefficiencies within the learning process. In such circumstances, the integration of supplementary terms into the loss function can serve to address these challenges, enhancing both model performance and robustness. Two prominent techniques, loss regularization and contrastive learning, have been identified as effective strategies for augmenting the capacity of loss functions in artificial neural networks.   Knowledge tracing is a compelling area of research that leverages predictive artificial intelligence to facilitate the automation of personalized and efficient educational experiences for students. In this paper, we provide a comprehensive review of the deep learning-based knowledge tracing (DKT) algorithms trained using advanced loss functions and discuss their improvements over prior techniques. We discuss contrastive knowledge tracing algorithms, such as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT, providing performance benchmarks and insights into real-world deployment challenges. The survey concludes with future research directions, including hybrid loss strategies and context-aware modeling.","sentences":["The training of artificial neural networks is heavily dependent on the careful selection of an appropriate loss function.","While commonly used loss functions, such as cross-entropy and mean squared error (MSE), generally suffice for a broad range of tasks, challenges often emerge due to limitations in data quality or inefficiencies within the learning process.","In such circumstances, the integration of supplementary terms into the loss function can serve to address these challenges, enhancing both model performance and robustness.","Two prominent techniques, loss regularization and contrastive learning, have been identified as effective strategies for augmenting the capacity of loss functions in artificial neural networks.   ","Knowledge tracing is a compelling area of research that leverages predictive artificial intelligence to facilitate the automation of personalized and efficient educational experiences for students.","In this paper, we provide a comprehensive review of the deep learning-based knowledge tracing (DKT) algorithms trained using advanced loss functions and discuss their improvements over prior techniques.","We discuss contrastive knowledge tracing algorithms, such as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT, providing performance benchmarks and insights into real-world deployment challenges.","The survey concludes with future research directions, including hybrid loss strategies and context-aware modeling."],"url":"http://arxiv.org/abs/2504.15163v1"}
{"created":"2025-04-21 15:08:01","title":"To Offload or Not To Offload: Model-driven Comparison of Edge-native and On-device Processing","abstract":"Computational offloading is a promising approach for overcoming resource constraints on client devices by moving some or all of an application's computations to remote servers. With the advent of specialized hardware accelerators, client devices are now able to perform fast local processing of specific tasks, such as machine learning inference, reducing the need for offloading computations. However, edge servers with accelerators also offer faster processing for offloaded tasks than was previously possible. In this paper, we present an analytic and experimental comparison of on-device processing and edge offloading for a range of accelerator, network, and application workload scenarios, with the goal of understanding when to use local on-device processing and when to offload computations. We present models that leverage analytical queuing results to capture the effects of dynamic factors such as the performance gap between the device and edge server, network variability, server load, and multi-tenancy on the edge server. We experimentally demonstrate the accuracy of our models for a range of hardware and application scenarios and show that our models achieve a mean absolute percentage error of 2.2% compared to observed latencies. We use our models to develop an adaptive resource manager for intelligent offloading and show its efficacy in the presence of variable network conditions and dynamic multi-tenant edge settings.","sentences":["Computational offloading is a promising approach for overcoming resource constraints on client devices by moving some or all of an application's computations to remote servers.","With the advent of specialized hardware accelerators, client devices are now able to perform fast local processing of specific tasks, such as machine learning inference, reducing the need for offloading computations.","However, edge servers with accelerators also offer faster processing for offloaded tasks than was previously possible.","In this paper, we present an analytic and experimental comparison of on-device processing and edge offloading for a range of accelerator, network, and application workload scenarios, with the goal of understanding when to use local on-device processing and when to offload computations.","We present models that leverage analytical queuing results to capture the effects of dynamic factors such as the performance gap between the device and edge server, network variability, server load, and multi-tenancy on the edge server.","We experimentally demonstrate the accuracy of our models for a range of hardware and application scenarios and show that our models achieve a mean absolute percentage error of 2.2% compared to observed latencies.","We use our models to develop an adaptive resource manager for intelligent offloading and show its efficacy in the presence of variable network conditions and dynamic multi-tenant edge settings."],"url":"http://arxiv.org/abs/2504.15162v1"}
{"created":"2025-04-21 15:07:26","title":"The Synthetic Imputation Approach: Generating Optimal Synthetic Texts For Underrepresented Categories In Supervised Classification Tasks","abstract":"Encoder-decoder Large Language Models (LLMs), such as BERT and RoBERTa, require that all categories in an annotation task be sufficiently represented in the training data for optimal performance. However, it is often difficult to find sufficient examples for all categories in a task when building a high-quality training set. In this article, I describe this problem and propose a solution, the synthetic imputation approach. Leveraging a generative LLM (GPT-4o), this approach generates synthetic texts based on careful prompting and five original examples drawn randomly with replacement from the sample. This approach ensures that new synthetic texts are sufficiently different from the original texts to reduce overfitting, but retain the underlying substantive meaning of the examples to maximize out-of-sample performance. With 75 original examples or more, synthetic imputation's performance is on par with a full sample of original texts, and overfitting remains low, predictable and correctable with 50 original samples. The synthetic imputation approach provides a novel role for generative LLMs in research and allows applied researchers to balance their datasets for best performance.","sentences":["Encoder-decoder Large Language Models (LLMs), such as BERT and RoBERTa, require that all categories in an annotation task be sufficiently represented in the training data for optimal performance.","However, it is often difficult to find sufficient examples for all categories in a task when building a high-quality training set.","In this article, I describe this problem and propose a solution, the synthetic imputation approach.","Leveraging a generative LLM (GPT-4o), this approach generates synthetic texts based on careful prompting and five original examples drawn randomly with replacement from the sample.","This approach ensures that new synthetic texts are sufficiently different from the original texts to reduce overfitting, but retain the underlying substantive meaning of the examples to maximize out-of-sample performance.","With 75 original examples or more, synthetic imputation's performance is on par with a full sample of original texts, and overfitting remains low, predictable and correctable with 50 original samples.","The synthetic imputation approach provides a novel role for generative LLMs in research and allows applied researchers to balance their datasets for best performance."],"url":"http://arxiv.org/abs/2504.15160v1"}
{"created":"2025-04-21 15:05:22","title":"Acquire and then Adapt: Squeezing out Text-to-Image Model for Image Restoration","abstract":"Recently, pre-trained text-to-image (T2I) models have been extensively adopted for real-world image restoration because of their powerful generative prior. However, controlling these large models for image restoration usually requires a large number of high-quality images and immense computational resources for training, which is costly and not privacy-friendly. In this paper, we find that the well-trained large T2I model (i.e., Flux) is able to produce a variety of high-quality images aligned with real-world distributions, offering an unlimited supply of training samples to mitigate the above issue. Specifically, we proposed a training data construction pipeline for image restoration, namely FluxGen, which includes unconditional image generation, image selection, and degraded image simulation. A novel light-weighted adapter (FluxIR) with squeeze-and-excitation layers is also carefully designed to control the large Diffusion Transformer (DiT)-based T2I model so that reasonable details can be restored. Experiments demonstrate that our proposed method enables the Flux model to adapt effectively to real-world image restoration tasks, achieving superior scores and visual quality on both synthetic and real-world degradation datasets - at only about 8.5\\% of the training cost compared to current approaches.","sentences":["Recently, pre-trained text-to-image (T2I) models have been extensively adopted for real-world image restoration because of their powerful generative prior.","However, controlling these large models for image restoration usually requires a large number of high-quality images and immense computational resources for training, which is costly and not privacy-friendly.","In this paper, we find that the well-trained large T2I model (i.e., Flux) is able to produce a variety of high-quality images aligned with real-world distributions, offering an unlimited supply of training samples to mitigate the above issue.","Specifically, we proposed a training data construction pipeline for image restoration, namely FluxGen, which includes unconditional image generation, image selection, and degraded image simulation.","A novel light-weighted adapter (FluxIR) with squeeze-and-excitation layers is also carefully designed to control the large Diffusion Transformer (DiT)-based T2I model so that reasonable details can be restored.","Experiments demonstrate that our proposed method enables the Flux model to adapt effectively to real-world image restoration tasks, achieving superior scores and visual quality on both synthetic and real-world degradation datasets - at only about 8.5\\% of the training cost compared to current approaches."],"url":"http://arxiv.org/abs/2504.15159v1"}
{"created":"2025-04-21 15:03:19","title":"Reconfiguring Proportional Committees","abstract":"An important desideratum in approval-based multiwinner voting is proportionality. We study the problem of reconfiguring proportional committees: given two proportional committees, is there a transition path that consists only of proportional committees, where each transition involves replacing one candidate with another candidate? We show that the set of committees satisfying the proportionality axiom of justified representation (JR) is not always connected, and it is PSPACE-complete to decide whether two such committees are connected. On the other hand, we prove that any two JR committees can be connected by committees satisfying a $2$-approximation of JR. We also obtain similar results for the stronger axiom of extended justified representation (EJR). In addition, we demonstrate that the committees produced by several well-known voting rules are connected or at least not isolated, and investigate the reconfiguration problem in restricted preference domains.","sentences":["An important desideratum in approval-based multiwinner voting is proportionality.","We study the problem of reconfiguring proportional committees: given two proportional committees, is there a transition path that consists only of proportional committees, where each transition involves replacing one candidate with another candidate?","We show that the set of committees satisfying the proportionality axiom of justified representation (JR) is not always connected, and it is PSPACE-complete to decide whether two such committees are connected.","On the other hand, we prove that any two JR committees can be connected by committees satisfying a $2$-approximation of JR.","We also obtain similar results for the stronger axiom of extended justified representation (EJR).","In addition, we demonstrate that the committees produced by several well-known voting rules are connected or at least not isolated, and investigate the reconfiguration problem in restricted preference domains."],"url":"http://arxiv.org/abs/2504.15157v1"}
{"created":"2025-04-21 14:57:48","title":"Dynamic 3D KAN Convolution with Adaptive Grid Optimization for Hyperspectral Image Classification","abstract":"Deep neural networks face several challenges in hyperspectral image classification, including high-dimensional data, sparse distribution of ground objects, and spectral redundancy, which often lead to classification overfitting and limited generalization capability. To more efficiently adapt to ground object distributions while extracting image features without introducing excessive parameters and skipping redundant information, this paper proposes KANet based on an improved 3D-DenseNet model, consisting of 3D KAN Conv and an adaptive grid update mechanism. By introducing learnable univariate B-spline functions on network edges, specifically by flattening three-dimensional neighborhoods into vectors and applying B-spline-parameterized nonlinear activation functions to replace the fixed linear weights of traditional 3D convolutional kernels, we precisely capture complex spectral-spatial nonlinear relationships in hyperspectral data. Simultaneously, through a dynamic grid adjustment mechanism, we adaptively update the grid point positions of B-splines based on the statistical characteristics of input data, optimizing the resolution of spline functions to match the non-uniform distribution of spectral features, significantly improving the model's accuracy in high-dimensional data modeling and parameter efficiency, effectively alleviating the curse of dimensionality. This characteristic demonstrates superior neural scaling laws compared to traditional convolutional neural networks and reduces overfitting risks in small-sample and high-noise scenarios. KANet enhances model representation capability through a 3D dynamic expert convolution system without increasing network depth or width. The proposed method demonstrates superior performance on IN, UP, and KSC datasets, outperforming mainstream hyperspectral image classification approaches.","sentences":["Deep neural networks face several challenges in hyperspectral image classification, including high-dimensional data, sparse distribution of ground objects, and spectral redundancy, which often lead to classification overfitting and limited generalization capability.","To more efficiently adapt to ground object distributions while extracting image features without introducing excessive parameters and skipping redundant information, this paper proposes KANet based on an improved 3D-DenseNet model, consisting of 3D KAN Conv and an adaptive grid update mechanism.","By introducing learnable univariate B-spline functions on network edges, specifically by flattening three-dimensional neighborhoods into vectors and applying B-spline-parameterized nonlinear activation functions to replace the fixed linear weights of traditional 3D convolutional kernels, we precisely capture complex spectral-spatial nonlinear relationships in hyperspectral data.","Simultaneously, through a dynamic grid adjustment mechanism, we adaptively update the grid point positions of B-splines based on the statistical characteristics of input data, optimizing the resolution of spline functions to match the non-uniform distribution of spectral features, significantly improving the model's accuracy in high-dimensional data modeling and parameter efficiency, effectively alleviating the curse of dimensionality.","This characteristic demonstrates superior neural scaling laws compared to traditional convolutional neural networks and reduces overfitting risks in small-sample and high-noise scenarios.","KANet enhances model representation capability through a 3D dynamic expert convolution system without increasing network depth or width.","The proposed method demonstrates superior performance on IN, UP, and KSC datasets, outperforming mainstream hyperspectral image classification approaches."],"url":"http://arxiv.org/abs/2504.15155v1"}
{"created":"2025-04-21 14:56:29","title":"Distribution Testing Meets Sum Estimation","abstract":"We study the problem of estimating the sum of $n$ elements, each with weight $w(i)$, in a structured universe. Our goal is to estimate $W = \\sum_{i=1}^n w(i)$ within a $(1 \\pm \\epsilon)$ factor using a sublinear number of samples, assuming weights are non-increasing, i.e., $w(1) \\geq w(2) \\geq \\dots \\geq w(n)$. The sum estimation problem is well-studied under different access models to the universe $U$. However, to the best of our knowledge, nothing is known about the sum estimation problem using non-adaptive conditional sampling. In this work, we explore the sum estimation problem using non-adaptive conditional weighted and non-adaptive conditional uniform samples, assuming that the underlying distribution ($D(i)=w(i)/W$) is monotone. We also extend our approach to to the case where the underlying distribution of $U$ is unimodal. Additionally, we consider support size estimation when $w(i) = 0$ or $w(i) \\geq W/n$, using hybrid sampling (both weighted and uniform) to access $U$. We propose an algorithm to estimate $W$ under the non-increasing weight assumption, using $O(\\frac{1}{\\epsilon^3} \\log{n} + \\frac{1}{\\epsilon^6})$ non-adaptive weighted conditional samples and $O(\\frac{1}{\\epsilon^3} \\log{n})$ uniform conditional samples. Our algorithm matches the $\\Omega(\\log{n})$ lower bound by \\cite{ACK15}. For unimodal distributions, the sample complexity remains similar, with an additional $O(\\log{n})$ evaluation queries to locate the minimum weighted point in the domain. For estimating the support size $k$ of $U$, where weights are either $0$ or at least $W/n$, our algorithm uses $O\\big( \\frac{\\log^3(n/\\epsilon)}{\\epsilon^8} \\cdot \\log^4 \\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ uniform samples and $O\\big( \\frac{\\log(n/\\epsilon)}{\\epsilon^2} \\cdot \\log \\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ weighted samples to output $\\hat{k}$ satisfying $k - 2\\epsilon n \\leq \\hat{k} \\leq k + \\epsilon n$.","sentences":["We study the problem of estimating the sum of $n$ elements, each with weight $w(i)$, in a structured universe.","Our goal is to estimate $W = \\sum_{i=1}^n w(i)$ within a $(1 \\pm \\epsilon)$ factor using a sublinear number of samples, assuming weights are non-increasing, i.e., $w(1) \\geq w(2)","\\geq \\dots \\geq w(n)$.","The sum estimation problem is well-studied under different access models to the universe $U$. However, to the best of our knowledge, nothing is known about the sum estimation problem using non-adaptive conditional sampling.","In this work, we explore the sum estimation problem using non-adaptive conditional weighted and non-adaptive conditional uniform samples, assuming that the underlying distribution ($D(i)=w(i)/W$) is monotone.","We also extend our approach to to the case where the underlying distribution of $U$ is unimodal.","Additionally, we consider support size estimation when $w(i) = 0$ or $w(i)","\\geq W/n$, using hybrid sampling (both weighted and uniform) to access $U$.","We propose an algorithm to estimate $W$ under the non-increasing weight assumption, using $O(\\frac{1}{\\epsilon^3} \\log{n} + \\frac{1}{\\epsilon^6})$ non-adaptive weighted conditional samples and $O(\\frac{1}{\\epsilon^3} \\log{n})$ uniform conditional samples.","Our algorithm matches the $\\Omega(\\log{n})$ lower bound by \\cite{ACK15}.","For unimodal distributions, the sample complexity remains similar, with an additional $O(\\log{n})$ evaluation queries to locate the minimum weighted point in the domain.","For estimating the support size $k$ of $U$, where weights are either $0$ or at least $W/n$, our algorithm uses $O\\big( \\frac{\\log^3(n/\\epsilon)}{\\epsilon^8} \\cdot \\log^4 \\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ uniform samples and $O\\big( \\frac{\\log(n/\\epsilon)}{\\epsilon^2} \\cdot \\log \\frac{\\log(n/\\epsilon)}{\\epsilon} \\big)$ weighted samples to output $\\hat{k}$ satisfying $k - 2\\epsilon n \\leq \\hat{k} \\leq k + \\epsilon n$."],"url":"http://arxiv.org/abs/2504.15153v1"}
{"created":"2025-04-21 14:55:57","title":"Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection","abstract":"Liver registration by overlaying preoperative 3D models onto intraoperative 2D frames can assist surgeons in perceiving the spatial anatomy of the liver clearly for a higher surgical success rate. Existing registration methods rely heavily on anatomical landmark-based workflows, which encounter two major limitations: 1) ambiguous landmark definitions fail to provide efficient markers for registration; 2) insufficient integration of intraoperative liver visual information in shape deformation modeling. To address these challenges, in this paper, we propose a landmark-free preoperative-to-intraoperative registration framework utilizing effective self-supervised learning, termed \\ourmodel. This framework transforms the conventional 3D-2D workflow into a 3D-3D registration pipeline, which is then decoupled into rigid and non-rigid registration subtasks. \\ourmodel~first introduces a feature-disentangled transformer to learn robust correspondences for recovering rigid transformations. Further, a structure-regularized deformation network is designed to adjust the preoperative model to align with the intraoperative liver surface. This network captures structural correlations through geometry similarity modeling in a low-rank transformer network. To facilitate the validation of the registration performance, we also construct an in-vivo registration dataset containing liver resection videos of 21 patients, called \\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the liver together with liver mask annotations and calibrated camera intrinsic parameters. Extensive experiments and user studies on both synthetic and in-vivo datasets demonstrate the superiority and potential clinical applicability of our method.","sentences":["Liver registration by overlaying preoperative 3D models onto intraoperative 2D frames can assist surgeons in perceiving the spatial anatomy of the liver clearly for a higher surgical success rate.","Existing registration methods rely heavily on anatomical landmark-based workflows, which encounter two major limitations: 1) ambiguous landmark definitions fail to provide efficient markers for registration; 2) insufficient integration of intraoperative liver visual information in shape deformation modeling.","To address these challenges, in this paper, we propose a landmark-free preoperative-to-intraoperative registration framework utilizing effective self-supervised learning, termed \\ourmodel.","This framework transforms the conventional 3D-2D workflow into a 3D-3D registration pipeline, which is then decoupled into rigid and non-rigid registration subtasks.","\\ourmodel~first introduces a feature-disentangled transformer to learn robust correspondences for recovering rigid transformations.","Further, a structure-regularized deformation network is designed to adjust the preoperative model to align with the intraoperative liver surface.","This network captures structural correlations through geometry similarity modeling in a low-rank transformer network.","To facilitate the validation of the registration performance, we also construct an in-vivo registration dataset containing liver resection videos of 21 patients, called \\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the liver together with liver mask annotations and calibrated camera intrinsic parameters.","Extensive experiments and user studies on both synthetic and in-vivo datasets demonstrate the superiority and potential clinical applicability of our method."],"url":"http://arxiv.org/abs/2504.15152v1"}
{"created":"2025-04-21 14:51:15","title":"The Iterative Chainlet Partitioning Algorithm for the Traveling Salesman Problem with Drone and Neural Acceleration","abstract":"This study introduces the Iterative Chainlet Partitioning (ICP) algorithm and its neural acceleration for solving the Traveling Salesman Problem with Drone (TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smaller segments called chainlets, each optimized individually by a dynamic programming subroutine. The chainlet with the highest improvement is updated and the procedure is repeated until no further improvement is possible. The number of subroutine calls is bounded linearly in problem size for the first iteration and remains constant in subsequent iterations, ensuring algorithmic scalability. Empirical results show that ICP outperforms existing algorithms in both solution quality and computational time. Tested over 1,059 benchmark instances, ICP yields an average improvement of 2.75% in solution quality over the previous state-of-the-art algorithm while reducing computational time by 79.8%. The procedure is deterministic, ensuring reliability without requiring multiple runs. The subroutine is the computational bottleneck in the already efficient ICP algorithm. To reduce the necessity of subroutine calls, we integrate a graph neural network (GNN) to predict incremental improvements. We demonstrate that the resulting Neuro ICP (NICP) achieves substantial acceleration while maintaining solution quality. Compared to ICP, NICP reduces the total computational time by 49.7%, while the objective function value increase is limited to 0.12%. The framework's adaptability to various operational constraints makes it a valuable foundation for developing efficient algorithms for truck-drone synchronized routing problems.","sentences":["This study introduces the Iterative Chainlet Partitioning (ICP) algorithm and its neural acceleration for solving the Traveling Salesman Problem with Drone (TSP-D).","The proposed ICP algorithm decomposes a TSP-D solution into smaller segments called chainlets, each optimized individually by a dynamic programming subroutine.","The chainlet with the highest improvement is updated and the procedure is repeated until no further improvement is possible.","The number of subroutine calls is bounded linearly in problem size for the first iteration and remains constant in subsequent iterations, ensuring algorithmic scalability.","Empirical results show that ICP outperforms existing algorithms in both solution quality and computational time.","Tested over 1,059 benchmark instances, ICP yields an average improvement of 2.75% in solution quality over the previous state-of-the-art algorithm while reducing computational time by 79.8%.","The procedure is deterministic, ensuring reliability without requiring multiple runs.","The subroutine is the computational bottleneck in the already efficient ICP algorithm.","To reduce the necessity of subroutine calls, we integrate a graph neural network (GNN) to predict incremental improvements.","We demonstrate that the resulting Neuro ICP (NICP) achieves substantial acceleration while maintaining solution quality.","Compared to ICP, NICP reduces the total computational time by 49.7%, while the objective function value increase is limited to 0.12%.","The framework's adaptability to various operational constraints makes it a valuable foundation for developing efficient algorithms for truck-drone synchronized routing problems."],"url":"http://arxiv.org/abs/2504.15147v1"}
{"created":"2025-04-21 14:50:28","title":"Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems","abstract":"Modern digital ecosystems feature complex, dynamic interactions among autonomous entities across diverse domains. Traditional models often separate agents and objects, lacking a unified foundation to capture their interactive behaviors. This paper introduces the Behavioral Universe Network (BUN), a theoretical framework grounded in the Agent-Interaction-Behavior (AIB) formalism. BUN treats subjects (active agents), objects (resources), and behaviors (operations) as first-class entities, all governed by a shared Behavioral Information Base (BIB). We detail the AIB core concepts and demonstrate how BUN leverages information-driven triggers, semantic enrichment, and adaptive rules to coordinate multi-agent systems. We highlight key benefits: enhanced behavior analysis, strong adaptability, and cross-domain interoperability. We conclude by positioning BUN as a promising foundation for next-generation digital governance and intelligent applications.","sentences":["Modern digital ecosystems feature complex, dynamic interactions among autonomous entities across diverse domains.","Traditional models often separate agents and objects, lacking a unified foundation to capture their interactive behaviors.","This paper introduces the Behavioral Universe Network (BUN), a theoretical framework grounded in the Agent-Interaction-Behavior (AIB) formalism.","BUN treats subjects (active agents), objects (resources), and behaviors (operations) as first-class entities, all governed by a shared Behavioral Information Base (BIB).","We detail the AIB core concepts and demonstrate how BUN leverages information-driven triggers, semantic enrichment, and adaptive rules to coordinate multi-agent systems.","We highlight key benefits: enhanced behavior analysis, strong adaptability, and cross-domain interoperability.","We conclude by positioning BUN as a promising foundation for next-generation digital governance and intelligent applications."],"url":"http://arxiv.org/abs/2504.15146v1"}
{"created":"2025-04-21 14:49:15","title":"\"I Know It When I See It\": Mood Spaces for Connecting and Expressing Visual Concepts","abstract":"Expressing complex concepts is easy when they can be labeled or quantified, but many ideas are hard to define yet instantly recognizable. We propose a Mood Board, where users convey abstract concepts with examples that hint at the intended direction of attribute changes. We compute an underlying Mood Space that 1) factors out irrelevant features and 2) finds the connections between images, thus bringing relevant concepts closer. We invent a fibration computation to compress/decompress pre-trained features into/from a compact space, 50-100x smaller. The main innovation is learning to mimic the pairwise affinity relationship of the image tokens across exemplars. To focus on the coarse-to-fine hierarchical structures in the Mood Space, we compute the top eigenvector structure from the affinity matrix and define a loss in the eigenvector space. The resulting Mood Space is locally linear and compact, allowing image-level operations, such as object averaging, visual analogy, and pose transfer, to be performed as a simple vector operation in Mood Space. Our learning is efficient in computation without any fine-tuning, needs only a few (2-20) exemplars, and takes less than a minute to learn.","sentences":["Expressing complex concepts is easy when they can be labeled or quantified, but many ideas are hard to define yet instantly recognizable.","We propose a Mood Board, where users convey abstract concepts with examples that hint at the intended direction of attribute changes.","We compute an underlying Mood Space that 1) factors out irrelevant features and 2) finds the connections between images, thus bringing relevant concepts closer.","We invent a fibration computation to compress/decompress pre-trained features into/from a compact space, 50-100x smaller.","The main innovation is learning to mimic the pairwise affinity relationship of the image tokens across exemplars.","To focus on the coarse-to-fine hierarchical structures in the Mood Space, we compute the top eigenvector structure from the affinity matrix and define a loss in the eigenvector space.","The resulting Mood Space is locally linear and compact, allowing image-level operations, such as object averaging, visual analogy, and pose transfer, to be performed as a simple vector operation in Mood Space.","Our learning is efficient in computation without any fine-tuning, needs only a few (2-20) exemplars, and takes less than a minute to learn."],"url":"http://arxiv.org/abs/2504.15145v1"}
{"created":"2025-04-21 14:48:45","title":"C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation","abstract":"Despite the effort in vulnerability detection over the last two decades, memory safety vulnerabilities continue to be a critical problem. Recent reports suggest that the key solution is to migrate to memory-safe languages. To this end, C-to-Rust transpilation becomes popular to resolve memory-safety issues in C programs. Recent works propose C-to-Rust transpilation frameworks; however, a comprehensive evaluation dataset is missing. Although one solution is to put together a large enough dataset, this increases the analysis time in automated frameworks as well as in manual efforts for some cases. In this work, we build a method to select functions from a large set to construct a minimized yet representative dataset to evaluate the C-to-Rust transpilation. We propose C2RUST-BENCH that contains 2,905 functions, which are representative of C-to-Rust transpilation, selected from 15,503 functions of real-world programs.","sentences":["Despite the effort in vulnerability detection over the last two decades, memory safety vulnerabilities continue to be a critical problem.","Recent reports suggest that the key solution is to migrate to memory-safe languages.","To this end, C-to-Rust transpilation becomes popular to resolve memory-safety issues in C programs.","Recent works propose C-to-Rust transpilation frameworks; however, a comprehensive evaluation dataset is missing.","Although one solution is to put together a large enough dataset, this increases the analysis time in automated frameworks as well as in manual efforts for some cases.","In this work, we build a method to select functions from a large set to construct a minimized yet representative dataset to evaluate the C-to-Rust transpilation.","We propose C2RUST-BENCH that contains 2,905 functions, which are representative of C-to-Rust transpilation, selected from 15,503 functions of real-world programs."],"url":"http://arxiv.org/abs/2504.15144v1"}
{"created":"2025-04-21 14:46:31","title":"Deterministic Depth-4 PIT and Normalization","abstract":"In this paper, we initiate the study of deterministic PIT for $\\Sigma^{[k]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits over fields of any characteristic, where $k$ and $\\delta$ are bounded. Our main result is a deterministic polynomial-time black-box PIT algorithm for $\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits, under the additional condition that one of the summands at the top $\\Sigma$ gate is squarefree.   Our techniques are purely algebro-geometric: they do not rely on Sylvester--Gallai-type theorems, and our PIT result holds over arbitrary fields.   The core of our proof is based on the normalization of algebraic varieties. Specifically, we carry out the analysis in the integral closure of a coordinate ring, which enjoys better algebraic properties than the original ring.","sentences":["In this paper, we initiate the study of deterministic PIT for $\\Sigma^{[k]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits over fields of any characteristic, where $k$ and $\\delta$ are bounded.","Our main result is a deterministic polynomial-time black-box PIT algorithm for $\\Sigma^{[3]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuits, under the additional condition that one of the summands at the top $\\Sigma$ gate is squarefree.   ","Our techniques are purely algebro-geometric: they do not rely on Sylvester--Gallai-type theorems, and our PIT result holds over arbitrary fields.   ","The core of our proof is based on the normalization of algebraic varieties.","Specifically, we carry out the analysis in the integral closure of a coordinate ring, which enjoys better algebraic properties than the original ring."],"url":"http://arxiv.org/abs/2504.15143v1"}
{"created":"2025-04-21 14:43:00","title":"GIFDL: Generated Image Fluctuation Distortion Learning for Enhancing Steganographic Security","abstract":"Minimum distortion steganography is currently the mainstream method for modification-based steganography. A key issue in this method is how to define steganographic distortion. With the rapid development of deep learning technology, the definition of distortion has evolved from manual design to deep learning design. Concurrently, rapid advancements in image generation have made generated images viable as cover media. However, existing distortion design methods based on machine learning do not fully leverage the advantages of generated cover media, resulting in suboptimal security performance. To address this issue, we propose GIFDL (Generated Image Fluctuation Distortion Learning), a steganographic distortion learning method based on the fluctuations in generated images. Inspired by the idea of natural steganography, we take a series of highly similar fluctuation images as the input to the steganographic distortion generator and introduce a new GAN training strategy to disguise stego images as fluctuation images. Experimental results demonstrate that GIFDL, compared with state-of-the-art GAN-based distortion learning methods, exhibits superior resistance to steganalysis, increasing the detection error rates by an average of 3.30% across three steganalyzers.","sentences":["Minimum distortion steganography is currently the mainstream method for modification-based steganography.","A key issue in this method is how to define steganographic distortion.","With the rapid development of deep learning technology, the definition of distortion has evolved from manual design to deep learning design.","Concurrently, rapid advancements in image generation have made generated images viable as cover media.","However, existing distortion design methods based on machine learning do not fully leverage the advantages of generated cover media, resulting in suboptimal security performance.","To address this issue, we propose GIFDL (Generated Image Fluctuation Distortion Learning), a steganographic distortion learning method based on the fluctuations in generated images.","Inspired by the idea of natural steganography, we take a series of highly similar fluctuation images as the input to the steganographic distortion generator and introduce a new GAN training strategy to disguise stego images as fluctuation images.","Experimental results demonstrate that GIFDL, compared with state-of-the-art GAN-based distortion learning methods, exhibits superior resistance to steganalysis, increasing the detection error rates by an average of 3.30% across three steganalyzers."],"url":"http://arxiv.org/abs/2504.15139v1"}
{"created":"2025-04-21 14:40:55","title":"Automatic Generation of Aerobatic Flight in Complex Environments via Diffusion Models","abstract":"Performing striking aerobatic flight in complex environments demands manual designs of key maneuvers in advance, which is intricate and time-consuming as the horizon of the trajectory performed becomes long. This paper presents a novel framework that leverages diffusion models to automate and scale up aerobatic trajectory generation. Our key innovation is the decomposition of complex maneuvers into aerobatic primitives, which are short frame sequences that act as building blocks, featuring critical aerobatic behaviors for tractable trajectory synthesis. The model learns aerobatic primitives using historical trajectory observations as dynamic priors to ensure motion continuity, with additional conditional inputs (target waypoints and optional action constraints) integrated to enable user-editable trajectory generation. During model inference, classifier guidance is incorporated with batch sampling to achieve obstacle avoidance. Additionally, the generated outcomes are refined through post-processing with spatial-temporal trajectory optimization to ensure dynamical feasibility. Extensive simulations and real-world experiments have validated the key component designs of our method, demonstrating its feasibility for deploying on real drones to achieve long-horizon aerobatic flight.","sentences":["Performing striking aerobatic flight in complex environments demands manual designs of key maneuvers in advance, which is intricate and time-consuming as the horizon of the trajectory performed becomes long.","This paper presents a novel framework that leverages diffusion models to automate and scale up aerobatic trajectory generation.","Our key innovation is the decomposition of complex maneuvers into aerobatic primitives, which are short frame sequences that act as building blocks, featuring critical aerobatic behaviors for tractable trajectory synthesis.","The model learns aerobatic primitives using historical trajectory observations as dynamic priors to ensure motion continuity, with additional conditional inputs (target waypoints and optional action constraints) integrated to enable user-editable trajectory generation.","During model inference, classifier guidance is incorporated with batch sampling to achieve obstacle avoidance.","Additionally, the generated outcomes are refined through post-processing with spatial-temporal trajectory optimization to ensure dynamical feasibility.","Extensive simulations and real-world experiments have validated the key component designs of our method, demonstrating its feasibility for deploying on real drones to achieve long-horizon aerobatic flight."],"url":"http://arxiv.org/abs/2504.15138v1"}
{"created":"2025-04-21 14:38:44","title":"KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking","abstract":"Entity linking (EL) aligns textual mentions with their corresponding entities in a knowledge base, facilitating various applications such as semantic search and question answering. Recent advances in multimodal entity linking (MEL) have shown that combining text and images can reduce ambiguity and improve alignment accuracy. However, most existing MEL methods overlook the rich structural information available in the form of knowledge-graph (KG) triples. In this paper, we propose KGMEL, a novel framework that leverages KG triples to enhance MEL. Specifically, it operates in three stages: (1) Generation: Produces high-quality triples for each mention by employing vision-language models based on its text and images. (2) Retrieval: Learns joint mention-entity representations, via contrastive learning, that integrate text, images, and (generated or KG) triples to retrieve candidate entities for each mention. (3) Reranking: Refines the KG triples of the candidate entities and employs large language models to identify the best-matching entity for the mention. Extensive experiments on benchmark datasets demonstrate that KGMEL outperforms existing methods. Our code and datasets are available at: https://github.com/juyeonnn/KGMEL.","sentences":["Entity linking (EL) aligns textual mentions with their corresponding entities in a knowledge base, facilitating various applications such as semantic search and question answering.","Recent advances in multimodal entity linking (MEL) have shown that combining text and images can reduce ambiguity and improve alignment accuracy.","However, most existing MEL methods overlook the rich structural information available in the form of knowledge-graph (KG) triples.","In this paper, we propose KGMEL, a novel framework that leverages KG triples to enhance MEL.","Specifically, it operates in three stages: (1) Generation: Produces high-quality triples for each mention by employing vision-language models based on its text and images.","(2) Retrieval:","Learns joint mention-entity representations, via contrastive learning, that integrate text, images, and (generated or KG) triples to retrieve candidate entities for each mention.","(3) Reranking: Refines the KG triples of the candidate entities and employs large language models to identify the best-matching entity for the mention.","Extensive experiments on benchmark datasets demonstrate that KGMEL outperforms existing methods.","Our code and datasets are available at: https://github.com/juyeonnn/KGMEL."],"url":"http://arxiv.org/abs/2504.15135v1"}
{"created":"2025-04-21 14:37:37","title":"Instance-Adaptive Keypoint Learning with Local-to-Global Geometric Aggregation for Category-Level Object Pose Estimation","abstract":"Category-level object pose estimation aims to predict the 6D pose and size of previously unseen instances from predefined categories, requiring strong generalization across diverse object instances. Although many previous methods attempt to mitigate intra-class variations, they often struggle with instances exhibiting complex geometries or significant deviations from canonical shapes. To address this challenge, we propose INKL-Pose, a novel category-level object pose estimation framework that enables INstance-adaptive Keypoint Learning with local-to-global geometric aggregation. Specifically, our approach first predicts semantically consistent and geometric informative keypoints through an Instance-Adaptive Keypoint Generator, then refines them with: (1) a Local Keypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global Keypoint Feature Aggregator using bidirectional Mamba for structural consistency. To enable bidirectional modeling in Mamba, we introduce a Feature Sequence Flipping strategy that preserves spatial coherence while constructing backward feature sequences. Additionally, we design a surface loss and a separation loss to enforce uniform coverage and spatial diversity in keypoint distribution. The generated keypoints are finally mapped to a canonical space for regressing the object's 6D pose and size. Extensive experiments on CAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves state-of-the-art performance and significantly outperforms existing methods.","sentences":["Category-level object pose estimation aims to predict the 6D pose and size of previously unseen instances from predefined categories, requiring strong generalization across diverse object instances.","Although many previous methods attempt to mitigate intra-class variations, they often struggle with instances exhibiting complex geometries or significant deviations from canonical shapes.","To address this challenge, we propose INKL-Pose, a novel category-level object pose estimation framework that enables INstance-adaptive Keypoint Learning with local-to-global geometric aggregation.","Specifically, our approach first predicts semantically consistent and geometric informative keypoints through an Instance-Adaptive Keypoint Generator, then refines them with: (1) a Local Keypoint Feature Aggregator capturing fine-grained geometries, and (2) a Global Keypoint Feature Aggregator using bidirectional Mamba for structural consistency.","To enable bidirectional modeling in Mamba, we introduce a Feature Sequence Flipping strategy that preserves spatial coherence while constructing backward feature sequences.","Additionally, we design a surface loss and a separation loss to enforce uniform coverage and spatial diversity in keypoint distribution.","The generated keypoints are finally mapped to a canonical space for regressing the object's 6D pose and size.","Extensive experiments on CAMERA25, REAL275, and HouseCat6D demonstrate that INKL-Pose achieves state-of-the-art performance and significantly outperforms existing methods."],"url":"http://arxiv.org/abs/2504.15134v1"}
{"created":"2025-04-21 14:33:55","title":"EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models","abstract":"In this paper, we introduce EasyEdit2, a framework designed to enable plug-and-play adjustability for controlling Large Language Model (LLM) behaviors. EasyEdit2 supports a wide range of test-time interventions, including safety, sentiment, personality, reasoning patterns, factuality, and language features. Unlike its predecessor, EasyEdit2 features a new architecture specifically designed for seamless model steering. It comprises key modules such as the steering vector generator and the steering vector applier, which enable automatic generation and application of steering vectors to influence the model's behavior without modifying its parameters. One of the main advantages of EasyEdit2 is its ease of use-users do not need extensive technical knowledge. With just a single example, they can effectively guide and adjust the model's responses, making precise control both accessible and efficient. Empirically, we report model steering performance across different LLMs, demonstrating the effectiveness of these techniques. We have released the source code on GitHub at https://github.com/zjunlp/EasyEdit along with a demonstration notebook. In addition, we provide a demo video at https://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.","sentences":["In this paper, we introduce EasyEdit2, a framework designed to enable plug-and-play adjustability for controlling Large Language Model (LLM) behaviors.","EasyEdit2 supports a wide range of test-time interventions, including safety, sentiment, personality, reasoning patterns, factuality, and language features.","Unlike its predecessor, EasyEdit2 features a new architecture specifically designed for seamless model steering.","It comprises key modules such as the steering vector generator and the steering vector applier, which enable automatic generation and application of steering vectors to influence the model's behavior without modifying its parameters.","One of the main advantages of EasyEdit2 is its ease of use-users do not need extensive technical knowledge.","With just a single example, they can effectively guide and adjust the model's responses, making precise control both accessible and efficient.","Empirically, we report model steering performance across different LLMs, demonstrating the effectiveness of these techniques.","We have released the source code on GitHub at https://github.com/zjunlp/EasyEdit along with a demonstration notebook.","In addition, we provide a demo video at https://zjunlp.github.io/project/EasyEdit2/video for a quick introduction."],"url":"http://arxiv.org/abs/2504.15133v1"}
{"created":"2025-04-21 14:30:16","title":"Investigating Youth's Technical and Ethical Understanding of Generative Language Models When Engaging in Construction and Deconstruction Activities","abstract":"The widespread adoption of generative artificial intelligence/machine learning (AI/ML) technologies has increased the need to support youth in developing AI/ML literacies. However, most work has centered on preparing young people to use these systems, with less attention to how they can participate in designing and evaluating them. This study investigates how engaging young people in the design and auditing of generative language models (GLMs) may foster the development of their understanding of how these systems work from both technical and ethical perspectives. The study takes an in-pieces approach to investigate novices' conceptions of GLMs. Such an approach supports the analysis of how technical and ethical conceptions evolve and relate to each other. I am currently conducting a series of participatory design workshops with sixteen ninth graders (ages 14-15) in which they will (a) build GLMs from a data-driven perspective that glassboxes how data shapes model performance and (b) audit commercial GLMs by repeatedly and systematically querying them to draw inferences about their behaviors. I will analyze participants' interactions to identify ethical and technical conceptions they may exhibit while designing and auditing GLMs. I will also conduct clinical interviews and use microgenetic knowledge analysis and ordered network analysis to investigate how participants' ethical and technical conceptions of GLMs relate to each other and change after the workshop. The study will contribute (a) evidence of how engaging youth in design and auditing activities may support the development of ethical and technical understanding of GLMs and (b) an inventory of novice design and auditing practices that may support youth's technical and ethical understanding of GLMs.","sentences":["The widespread adoption of generative artificial intelligence/machine learning (AI/ML) technologies has increased the need to support youth in developing AI/ML literacies.","However, most work has centered on preparing young people to use these systems, with less attention to how they can participate in designing and evaluating them.","This study investigates how engaging young people in the design and auditing of generative language models (GLMs) may foster the development of their understanding of how these systems work from both technical and ethical perspectives.","The study takes an in-pieces approach to investigate novices' conceptions of GLMs.","Such an approach supports the analysis of how technical and ethical conceptions evolve and relate to each other.","I am currently conducting a series of participatory design workshops with sixteen ninth graders (ages 14-15) in which they will (a) build GLMs from a data-driven perspective that glassboxes how data shapes model performance and (b) audit commercial GLMs by repeatedly and systematically querying them to draw inferences about their behaviors.","I will analyze participants' interactions to identify ethical and technical conceptions they may exhibit while designing and auditing GLMs.","I will also conduct clinical interviews and use microgenetic knowledge analysis and ordered network analysis to investigate how participants' ethical and technical conceptions of GLMs relate to each other and change after the workshop.","The study will contribute (a) evidence of how engaging youth in design and auditing activities may support the development of ethical and technical understanding of GLMs and (b) an inventory of novice design and auditing practices that may support youth's technical and ethical understanding of GLMs."],"url":"http://arxiv.org/abs/2504.15132v1"}
{"created":"2025-04-21 14:26:04","title":"Beyond Binary Opinions: A Deep Reinforcement Learning-Based Approach to Uncertainty-Aware Competitive Influence Maximization","abstract":"The Competitive Influence Maximization (CIM) problem involves multiple entities competing for influence in online social networks (OSNs). While Deep Reinforcement Learning (DRL) has shown promise, existing methods often assume users' opinions are binary and ignore their behavior and prior knowledge. We propose DRIM, a multi-dimensional uncertainty-aware DRL-based CIM framework that leverages Subjective Logic (SL) to model uncertainty in user opinions, preferences, and DRL decision-making. DRIM introduces an Uncertainty-based Opinion Model (UOM) for a more realistic representation of user uncertainty and optimizes seed selection for propagating true information while countering false information. In addition, it quantifies uncertainty in balancing exploration and exploitation. Results show that UOM significantly enhances true information spread and maintains influence against advanced false information strategies. DRIM-based CIM schemes outperform state-of-the-art methods by up to 57% and 88% in influence while being up to 48% and 77% faster. Sensitivity analysis indicates that higher network observability and greater information propagation boost performance, while high network activity mitigates the effect of users' initial biases.","sentences":["The Competitive Influence Maximization (CIM) problem involves multiple entities competing for influence in online social networks (OSNs).","While Deep Reinforcement Learning (DRL) has shown promise, existing methods often assume users' opinions are binary and ignore their behavior and prior knowledge.","We propose DRIM, a multi-dimensional uncertainty-aware DRL-based CIM framework that leverages Subjective Logic (SL) to model uncertainty in user opinions, preferences, and DRL decision-making.","DRIM introduces an Uncertainty-based Opinion Model (UOM) for a more realistic representation of user uncertainty and optimizes seed selection for propagating true information while countering false information.","In addition, it quantifies uncertainty in balancing exploration and exploitation.","Results show that UOM significantly enhances true information spread and maintains influence against advanced false information strategies.","DRIM-based CIM schemes outperform state-of-the-art methods by up to 57% and 88% in influence while being up to 48% and 77% faster.","Sensitivity analysis indicates that higher network observability and greater information propagation boost performance, while high network activity mitigates the effect of users' initial biases."],"url":"http://arxiv.org/abs/2504.15131v1"}
{"created":"2025-04-21 14:25:32","title":"Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning","abstract":"Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics, particularly in applications such as warehouse automation and logistics. Existing solutions often face challenges in scalability, adaptability, and efficiency, limiting their applicability in dynamic environments with real-time planning requirements. This paper presents Neural ATTF (Adaptive Task Token Framework), a new algorithm that combines a Priority Guided Task Matching (PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning method. Neural STA* enhances path planning by enabling rapid exploration of the search space through guided learned heuristics and ensures collision avoidance under dynamic constraints. PGTM prioritizes delayed agents and dynamically assigns tasks by prioritizing agents nearest to these tasks, optimizing both continuity and system throughput. Experimental evaluations against state-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and LNS-wPBS, demonstrate the superior scalability, solution quality, and computational efficiency of Neural ATTF. These results highlight the framework's potential for addressing the critical demands of complex, real-world multi-agent systems operating in high-demand, unpredictable settings.","sentences":["Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics, particularly in applications such as warehouse automation and logistics.","Existing solutions often face challenges in scalability, adaptability, and efficiency, limiting their applicability in dynamic environments with real-time planning requirements.","This paper presents Neural ATTF (Adaptive Task Token Framework), a new algorithm that combines a Priority Guided Task Matching (PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning method.","Neural STA* enhances path planning by enabling rapid exploration of the search space through guided learned heuristics and ensures collision avoidance under dynamic constraints.","PGTM prioritizes delayed agents and dynamically assigns tasks by prioritizing agents nearest to these tasks, optimizing both continuity and system throughput.","Experimental evaluations against state-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and LNS-wPBS, demonstrate the superior scalability, solution quality, and computational efficiency of Neural ATTF.","These results highlight the framework's potential for addressing the critical demands of complex, real-world multi-agent systems operating in high-demand, unpredictable settings."],"url":"http://arxiv.org/abs/2504.15130v1"}
{"created":"2025-04-21 14:25:23","title":"A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment","abstract":"Deploying robot learning methods to a quadrotor in unstructured outdoor environments is an exciting task. Quadrotors operating in real-world environments by learning-based methods encounter several challenges: a large amount of simulator generated data required for training, strict demands for real-time processing onboard, and the sim-to-real gap caused by dynamic and noisy conditions. Current works have made a great breakthrough in applying learning-based methods to end-to-end control of quadrotors, but rarely mention the infrastructure system training from scratch and deploying to reality, which makes it difficult to reproduce methods and applications. To bridge this gap, we propose a platform that enables the seamless transfer of end-to-end deep reinforcement learning (DRL) policies. We integrate the training environment, flight dynamics control, DRL algorithms, the MAVROS middleware stack, and hardware into a comprehensive workflow and architecture that enables quadrotors' policies to be trained from scratch to real-world deployment in several minutes. Our platform provides rich types of environments including hovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and planning in unknown environments, as a physical experiment benchmark. Through extensive empirical validation, we demonstrate the efficiency of proposed sim-to-real platform, and robust outdoor flight performance under real-world perturbations. Details can be found from our website https://emnavi.tech/AirGym/.","sentences":["Deploying robot learning methods to a quadrotor in unstructured outdoor environments is an exciting task.","Quadrotors operating in real-world environments by learning-based methods encounter several challenges: a large amount of simulator generated data required for training, strict demands for real-time processing onboard, and the sim-to-real gap caused by dynamic and noisy conditions.","Current works have made a great breakthrough in applying learning-based methods to end-to-end control of quadrotors, but rarely mention the infrastructure system training from scratch and deploying to reality, which makes it difficult to reproduce methods and applications.","To bridge this gap, we propose a platform that enables the seamless transfer of end-to-end deep reinforcement learning (DRL) policies.","We integrate the training environment, flight dynamics control, DRL algorithms, the MAVROS middleware stack, and hardware into a comprehensive workflow and architecture that enables quadrotors' policies to be trained from scratch to real-world deployment in several minutes.","Our platform provides rich types of environments including hovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and planning in unknown environments, as a physical experiment benchmark.","Through extensive empirical validation, we demonstrate the efficiency of proposed sim-to-real platform, and robust outdoor flight performance under real-world perturbations.","Details can be found from our website https://emnavi.tech/AirGym/."],"url":"http://arxiv.org/abs/2504.15129v1"}
{"created":"2025-04-21 14:20:49","title":"Contemplative Wisdom for Superalignment","abstract":"As artificial intelligence (AI) improves, traditional alignment strategies may falter in the face of unpredictable self-improvement, hidden subgoals, and the sheer complexity of intelligent systems. Rather than externally constraining behavior, we advocate designing AI with intrinsic morality built into its cognitive architecture and world model. Inspired by contemplative wisdom traditions, we show how four axiomatic principles can instil a resilient Wise World Model in AI systems. First, mindfulness enables self-monitoring and recalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal fixation and relaxes rigid priors. Third, non-duality dissolves adversarial self-other boundaries. Fourth, boundless care motivates the universal reduction of suffering. We find that prompting AI to reflect on these principles improves performance on the AILuminate Benchmark using GPT-4o, particularly when combined. We offer detailed implementation strategies for state-of-the-art models, including contemplative architectures, constitutions, and reinforcement of chain-of-thought. For future systems, the active inference framework may offer the self-organizing and dynamic coupling capabilities needed to enact these insights in embodied agents. This interdisciplinary approach offers a self-correcting and resilient alternative to prevailing brittle control schemes.","sentences":["As artificial intelligence (AI) improves, traditional alignment strategies may falter in the face of unpredictable self-improvement, hidden subgoals, and the sheer complexity of intelligent systems.","Rather than externally constraining behavior, we advocate designing AI with intrinsic morality built into its cognitive architecture and world model.","Inspired by contemplative wisdom traditions, we show how four axiomatic principles can instil a resilient Wise World Model in AI systems.","First, mindfulness enables self-monitoring and recalibration of emergent subgoals.","Second, emptiness forestalls dogmatic goal fixation and relaxes rigid priors.","Third, non-duality dissolves adversarial self-other boundaries.","Fourth, boundless care motivates the universal reduction of suffering.","We find that prompting AI to reflect on these principles improves performance on the AILuminate Benchmark using GPT-4o, particularly when combined.","We offer detailed implementation strategies for state-of-the-art models, including contemplative architectures, constitutions, and reinforcement of chain-of-thought.","For future systems, the active inference framework may offer the self-organizing and dynamic coupling capabilities needed to enact these insights in embodied agents.","This interdisciplinary approach offers a self-correcting and resilient alternative to prevailing brittle control schemes."],"url":"http://arxiv.org/abs/2504.15125v1"}
{"created":"2025-04-21 14:19:19","title":"MoBGS: Motion Deblurring Dynamic 3D Gaussian Splatting for Blurry Monocular Video","abstract":"We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS) framework capable of reconstructing sharp and high-quality novel spatio-temporal views from blurry monocular videos in an end-to-end manner. Existing dynamic novel view synthesis (NVS) methods are highly sensitive to motion blur in casually captured videos, resulting in significant degradation of rendering quality. While recent approaches address motion-blurred inputs for NVS, they primarily focus on static scene reconstruction and lack dedicated motion modeling for dynamic objects. To overcome these limitations, our MoBGS introduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for effective latent camera trajectory estimation, improving global camera motion deblurring. In addition, we propose a physically-inspired Latent Camera-induced Exposure Estimation (LCEE) method to ensure consistent deblurring of both global camera and local object motion. Our MoBGS framework ensures the temporal consistency of unseen latent timestamps and robust motion decomposition of static and dynamic regions. Extensive experiments on the Stereo Blur dataset and real-world blurry videos show that our MoBGS significantly outperforms the very recent advanced methods (DyBluRF and Deblur4DGS), achieving state-of-the-art performance for dynamic NVS under motion blur.","sentences":["We present MoBGS, a novel deblurring dynamic 3D Gaussian Splatting (3DGS) framework capable of reconstructing sharp and high-quality novel spatio-temporal views from blurry monocular videos in an end-to-end manner.","Existing dynamic novel view synthesis (NVS) methods are highly sensitive to motion blur in casually captured videos, resulting in significant degradation of rendering quality.","While recent approaches address motion-blurred inputs for NVS, they primarily focus on static scene reconstruction and lack dedicated motion modeling for dynamic objects.","To overcome these limitations, our MoBGS introduces a novel Blur-adaptive Latent Camera Estimation (BLCE) method for effective latent camera trajectory estimation, improving global camera motion deblurring.","In addition, we propose a physically-inspired Latent Camera-induced Exposure Estimation (LCEE) method to ensure consistent deblurring of both global camera and local object motion.","Our MoBGS framework ensures the temporal consistency of unseen latent timestamps and robust motion decomposition of static and dynamic regions.","Extensive experiments on the Stereo Blur dataset and real-world blurry videos show that our MoBGS significantly outperforms the very recent advanced methods (DyBluRF and Deblur4DGS), achieving state-of-the-art performance for dynamic NVS under motion blur."],"url":"http://arxiv.org/abs/2504.15122v1"}
{"created":"2025-04-21 14:19:00","title":"Robust and Real-time Surface Normal Estimation from Stereo Disparities using Affine Transformations","abstract":"This work introduces a novel method for surface normal estimation from rectified stereo image pairs, leveraging affine transformations derived from disparity values to achieve fast and accurate results. We demonstrate how the rectification of stereo image pairs simplifies the process of surface normal estimation by reducing computational complexity. To address noise reduction, we develop a custom algorithm inspired by convolutional operations, tailored to process disparity data efficiently. We also introduce adaptive heuristic techniques for efficiently detecting connected surface components within the images, further improving the robustness of the method. By integrating these methods, we construct a surface normal estimator that is both fast and accurate, producing a dense, oriented point cloud as the final output. Our method is validated using both simulated environments and real-world stereo images from the Middlebury and Cityscapes datasets, demonstrating significant improvements in real-time performance and accuracy when implemented on a GPU. Upon acceptance, the shader source code will be made publicly available to facilitate further research and reproducibility.","sentences":["This work introduces a novel method for surface normal estimation from rectified stereo image pairs, leveraging affine transformations derived from disparity values to achieve fast and accurate results.","We demonstrate how the rectification of stereo image pairs simplifies the process of surface normal estimation by reducing computational complexity.","To address noise reduction, we develop a custom algorithm inspired by convolutional operations, tailored to process disparity data efficiently.","We also introduce adaptive heuristic techniques for efficiently detecting connected surface components within the images, further improving the robustness of the method.","By integrating these methods, we construct a surface normal estimator that is both fast and accurate, producing a dense, oriented point cloud as the final output.","Our method is validated using both simulated environments and real-world stereo images from the Middlebury and Cityscapes datasets, demonstrating significant improvements in real-time performance and accuracy when implemented on a GPU.","Upon acceptance, the shader source code will be made publicly available to facilitate further research and reproducibility."],"url":"http://arxiv.org/abs/2504.15121v1"}
{"created":"2025-04-21 14:17:25","title":"Kuwain 1.5B: An Arabic SLM via Language Injection","abstract":"Enhancing existing models with new knowledge is a crucial aspect of AI development. This paper introduces a novel method for integrating a new language into a large language model (LLM). Our approach successfully incorporates a previously unseen target language into an existing LLM without compromising its prior knowledge. We trained a tiny model with 1.5 billion parameters named Kuwain by injecting the Arabic language into a small open-source model mainly trained in English. Our method demonstrates significant improvements in Arabic language performance, with an average 8% improvement across various benchmarks, while retaining the model's existing knowledge with a minimum amount of the original model's data. This offers a cost-effective alternative to training a comprehensive model in both English and Arabic. The results highlight the potential for efficient, targeted language model expansion without extensive retraining or resource-intensive processes.","sentences":["Enhancing existing models with new knowledge is a crucial aspect of AI development.","This paper introduces a novel method for integrating a new language into a large language model (LLM).","Our approach successfully incorporates a previously unseen target language into an existing LLM without compromising its prior knowledge.","We trained a tiny model with 1.5 billion parameters named Kuwain by injecting the Arabic language into a small open-source model mainly trained in English.","Our method demonstrates significant improvements in Arabic language performance, with an average 8% improvement across various benchmarks, while retaining the model's existing knowledge with a minimum amount of the original model's data.","This offers a cost-effective alternative to training a comprehensive model in both English and Arabic.","The results highlight the potential for efficient, targeted language model expansion without extensive retraining or resource-intensive processes."],"url":"http://arxiv.org/abs/2504.15120v1"}
{"created":"2025-04-21 14:16:46","title":"Improving Sound Source Localization with Joint Slot Attention on Image and Audio","abstract":"Sound source localization (SSL) is the task of locating the source of sound within an image. Due to the lack of localization labels, the de facto standard in SSL has been to represent an image and audio as a single embedding vector each, and use them to learn SSL via contrastive learning. To this end, previous work samples one of local image features as the image embedding and aggregates all local audio features to obtain the audio embedding, which is far from optimal due to the presence of noise and background irrelevant to the actual target in the input. We present a novel SSL method that addresses this chronic issue by joint slot attention on image and audio. To be specific, two slots competitively attend image and audio features to decompose them into target and off-target representations, and only target representations of image and audio are used for contrastive learning. Also, we introduce cross-modal attention matching to further align local features of image and audio. Our method achieved the best in almost all settings on three public benchmarks for SSL, and substantially outperformed all the prior work in cross-modal retrieval.","sentences":["Sound source localization (SSL) is the task of locating the source of sound within an image.","Due to the lack of localization labels, the de facto standard in SSL has been to represent an image and audio as a single embedding vector each, and use them to learn SSL via contrastive learning.","To this end, previous work samples one of local image features as the image embedding and aggregates all local audio features to obtain the audio embedding, which is far from optimal due to the presence of noise and background irrelevant to the actual target in the input.","We present a novel SSL method that addresses this chronic issue by joint slot attention on image and audio.","To be specific, two slots competitively attend image and audio features to decompose them into target and off-target representations, and only target representations of image and audio are used for contrastive learning.","Also, we introduce cross-modal attention matching to further align local features of image and audio.","Our method achieved the best in almost all settings on three public benchmarks for SSL, and substantially outperformed all the prior work in cross-modal retrieval."],"url":"http://arxiv.org/abs/2504.15118v1"}
{"created":"2025-04-21 14:10:20","title":"Deterministic $k$-Median Clustering in Near-Optimal Time","abstract":"The metric $k$-median problem is a textbook clustering problem. As input, we are given a metric space $V$ of size $n$ and an integer $k$, and our task is to find a subset $S \\subseteq V$ of at most $k$ `centers' that minimizes the total distance from each point in $V$ to its nearest center in $S$.   Mettu and Plaxton [UAI'02] gave a randomized algorithm for $k$-median that computes a $O(1)$-approximation in $\\tilde O(nk)$ time. They also showed that any algorithm for this problem with a bounded approximation ratio must have a running time of $\\Omega(nk)$. Thus, the running time of their algorithm is optimal up to polylogarithmic factors.   For deterministic $k$-median, Guha et al.~[FOCS'00] gave an algorithm that computes a $\\text{poly}(\\log (n/k))$-approximation in $\\tilde O(nk)$ time, where the degree of the polynomial in the approximation is unspecified. To the best of our knowledge, this remains the state-of-the-art approximation of any deterministic $k$-median algorithm with this running time.   This leads us to the following natural question: What is the best approximation of a deterministic $k$-median algorithm with near-optimal running time? We make progress in answering this question by giving a deterministic algorithm that computes a $O(\\log(n/k))$-approximation in $\\tilde O(nk)$ time. We also provide a lower bound showing that any deterministic algorithm with this running time must have an approximation ratio of $\\Omega(\\log n/(\\log k + \\log \\log n))$, establishing a gap between the randomized and deterministic settings for $k$-median.","sentences":["The metric $k$-median problem is a textbook clustering problem.","As input, we are given a metric space $V$ of size $n$ and an integer $k$, and our task is to find a subset $S \\subseteq V$ of at most $k$ `centers' that minimizes the total distance from each point in $V$ to its nearest center in $S$.   Mettu and Plaxton [UAI'02] gave a randomized algorithm for $k$-median that computes a $O(1)$-approximation in $\\tilde O(nk)$ time.","They also showed that any algorithm for this problem with a bounded approximation ratio must have a running time of $\\Omega(nk)$. Thus, the running time of their algorithm is optimal up to polylogarithmic factors.   ","For deterministic $k$-median, Guha et al.~[FOCS'00] gave an algorithm that computes a $\\text{poly}(\\log (n/k))$-approximation in $\\tilde O(nk)$ time, where the degree of the polynomial in the approximation is unspecified.","To the best of our knowledge, this remains the state-of-the-art approximation of any deterministic $k$-median algorithm with this running time.   ","This leads us to the following natural question: What is the best approximation of a deterministic $k$-median algorithm with near-optimal running time?","We make progress in answering this question by giving a deterministic algorithm that computes a $O(\\log(n/k))$-approximation in $\\tilde O(nk)$ time.","We also provide a lower bound showing that any deterministic algorithm with this running time must have an approximation ratio of $\\Omega(\\log n/(\\log k + \\log \\log n))$, establishing a gap between the randomized and deterministic settings for $k$-median."],"url":"http://arxiv.org/abs/2504.15115v1"}
{"created":"2025-04-21 14:02:59","title":"Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for Functions and their Derivatives","abstract":"Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold Networks (KANs) have recently emerged as an improved backbone for most deep learning frameworks, promising more adaptivity than their multilayer perception (MLP) predecessor by allowing for trainable spline-based activation functions. In this paper, we probe the theoretical foundations of the KAN architecture by showing that it can optimally approximate any Besov function in $B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain $\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect to any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$. We complement our approximation guarantee with a dimension-free estimate on the sample complexity of a residual KAN model when learning a function of Besov regularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates contemporary deep learning wisdom by leveraging residual/skip connections between layers.","sentences":["Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold Networks (KANs) have recently emerged as an improved backbone for most deep learning frameworks, promising more adaptivity than their multilayer perception (MLP) predecessor by allowing for trainable spline-based activation functions.","In this paper, we probe the theoretical foundations of the KAN architecture by showing that it can optimally approximate any Besov function in $B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain $\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect to any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$. We complement our approximation guarantee with a dimension-free estimate on the sample complexity of a residual KAN model when learning a function of Besov regularity from $N$ i.i.d. noiseless samples.","Our KAN architecture incorporates contemporary deep learning wisdom by leveraging residual/skip connections between layers."],"url":"http://arxiv.org/abs/2504.15110v1"}
{"created":"2025-04-21 13:59:44","title":"Unwarping Screen Content Images via Structure-texture Enhancement Network and Transformation Self-estimation","abstract":"While existing implicit neural network-based image unwarping methods perform well on natural images, they struggle to handle screen content images (SCIs), which often contain large geometric distortions, text, symbols, and sharp edges. To address this, we propose a structure-texture enhancement network (STEN) with transformation self-estimation for SCI warping. STEN integrates a B-spline implicit neural representation module and a transformation error estimation and self-correction algorithm. It comprises two branches: the structure estimation branch (SEB), which enhances local aggregation and global dependency modeling, and the texture estimation branch (TEB), which improves texture detail synthesis using B-spline implicit neural representation. Additionally, the transformation self-estimation module autonomously estimates the transformation error and corrects the coordinate transformation matrix, effectively handling real-world image distortions. Extensive experiments on public SCI datasets demonstrate that our approach significantly outperforms state-of-the-art methods. Comparisons on well-known natural image datasets also show the potential of our approach for natural image distortion.","sentences":["While existing implicit neural network-based image unwarping methods perform well on natural images, they struggle to handle screen content images (SCIs), which often contain large geometric distortions, text, symbols, and sharp edges.","To address this, we propose a structure-texture enhancement network (STEN) with transformation self-estimation for SCI warping.","STEN integrates a B-spline implicit neural representation module and a transformation error estimation and self-correction algorithm.","It comprises two branches: the structure estimation branch (SEB), which enhances local aggregation and global dependency modeling, and the texture estimation branch (TEB), which improves texture detail synthesis using B-spline implicit neural representation.","Additionally, the transformation self-estimation module autonomously estimates the transformation error and corrects the coordinate transformation matrix, effectively handling real-world image distortions.","Extensive experiments on public SCI datasets demonstrate that our approach significantly outperforms state-of-the-art methods.","Comparisons on well-known natural image datasets also show the potential of our approach for natural image distortion."],"url":"http://arxiv.org/abs/2504.15108v1"}
{"created":"2025-04-21 13:54:33","title":"A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae","abstract":"Latent fingerprint enhancement is a critical step in the process of latent fingerprint identification. Existing deep learning-based enhancement methods still fall short of practical application requirements, particularly in restoring low-quality fingerprint regions. Recognizing that different regions of latent fingerprints require distinct enhancement strategies, we propose a Triple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances different regions of the image using tailored strategies. Furthermore, to improve the generalization capability of the network, we integrate orientation field and minutiae-related modules into TBSFNet and introduce a Multi-Level Feature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST datasets demonstrate that MLFGNet outperforms existing enhancement algorithms.","sentences":["Latent fingerprint enhancement is a critical step in the process of latent fingerprint identification.","Existing deep learning-based enhancement methods still fall short of practical application requirements, particularly in restoring low-quality fingerprint regions.","Recognizing that different regions of latent fingerprints require distinct enhancement strategies, we propose a Triple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances different regions of the image using tailored strategies.","Furthermore, to improve the generalization capability of the network, we integrate orientation field and minutiae-related modules into TBSFNet and introduce a Multi-Level Feature Guidance Network (MLFGNet).","Experimental results on the MOLF and MUST datasets demonstrate that MLFGNet outperforms existing enhancement algorithms."],"url":"http://arxiv.org/abs/2504.15105v1"}
{"created":"2025-04-21 13:49:17","title":"NeuGaze: Reshaping the future BCI","abstract":"Traditional brain-computer interfaces (BCIs), reliant on costly electroencephalography or invasive implants, struggle with complex human-computer interactions due to setup complexity and limited precision. We present NeuGaze, a novel webcam-based system that leverages eye gaze, head movements, and facial expressions to enable intuitive, real-time control using only a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal calibration, NeuGaze achieves performance comparable to conventional inputs, supporting precise cursor navigation, key triggering via an efficient skill wheel, and dynamic gaming interactions, such as defeating formidable opponents in first-person games. By harnessing preserved neck-up functionalities in motor-impaired individuals, NeuGaze eliminates the need for specialized hardware, offering a low-cost, accessible alternative to BCIs. This paradigm empowers diverse applications, from assistive technology to entertainment, redefining human-computer interaction for motor-impaired users. Project is at \\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.","sentences":["Traditional brain-computer interfaces (BCIs), reliant on costly electroencephalography or invasive implants, struggle with complex human-computer interactions due to setup complexity and limited precision.","We present NeuGaze, a novel webcam-based system that leverages eye gaze, head movements, and facial expressions to enable intuitive, real-time control using only a standard 30 Hz webcam, often pre-installed in laptops.","Requiring minimal calibration, NeuGaze achieves performance comparable to conventional inputs, supporting precise cursor navigation, key triggering via an efficient skill wheel, and dynamic gaming interactions, such as defeating formidable opponents in first-person games.","By harnessing preserved neck-up functionalities in motor-impaired individuals, NeuGaze eliminates the need for specialized hardware, offering a low-cost, accessible alternative to BCIs.","This paradigm empowers diverse applications, from assistive technology to entertainment, redefining human-computer interaction for motor-impaired users.","Project is at \\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}."],"url":"http://arxiv.org/abs/2504.15101v1"}
{"created":"2025-04-21 13:41:09","title":"Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN","abstract":"Up to now, the training processes of typical Generative Adversarial Networks (GANs) are still particularly sensitive to data properties and hyperparameters, which may lead to severe oscillations, difficulties in convergence, or even failures to converge, especially when the overall variances of the training sets are large. These phenomena are often attributed to the training characteristics of such networks. Aiming at the problem, this paper develops a new intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which employs reinforcement learning in the training process of GANs to make training easier. Specifically, this paper allows the training step size to be controlled by an agent to improve training stability, and makes the training process more intelligent with variable learning rates, making GANs less sensitive to step size. Experiments have been conducted on three benchmark datasets to verify the effectiveness of the developed FSCO.","sentences":["Up to now, the training processes of typical Generative Adversarial Networks (GANs) are still particularly sensitive to data properties and hyperparameters, which may lead to severe oscillations, difficulties in convergence, or even failures to converge, especially when the overall variances of the training sets are large.","These phenomena are often attributed to the training characteristics of such networks.","Aiming at the problem, this paper develops a new intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which employs reinforcement learning in the training process of GANs to make training easier.","Specifically, this paper allows the training step size to be controlled by an agent to improve training stability, and makes the training process more intelligent with variable learning rates, making GANs less sensitive to step size.","Experiments have been conducted on three benchmark datasets to verify the effectiveness of the developed FSCO."],"url":"http://arxiv.org/abs/2504.15099v1"}
{"created":"2025-04-21 13:38:37","title":"Optimal Behavior Planning for Implicit Communication using a Probabilistic Vehicle-Pedestrian Interaction Model","abstract":"In interactions between automated vehicles (AVs) and crossing pedestrians, modeling implicit vehicle communication is crucial. In this work, we present a combined prediction and planning approach that allows to consider the influence of the planned vehicle behavior on a pedestrian and predict a pedestrian's reaction. We plan the behavior by solving two consecutive optimal control problems (OCPs) analytically, using variational calculus. We perform a validation step that assesses whether the planned vehicle behavior is adequate to trigger a certain pedestrian reaction, which accounts for the closed-loop characteristics of prediction and planning influencing each other. In this step, we model the influence of the planned vehicle behavior on the pedestrian using a probabilistic behavior acceptance model that returns an estimate for the crossing probability. The probabilistic modeling of the pedestrian reaction facilitates considering the pedestrian's costs, thereby improving cooperative behavior planning. We demonstrate the performance of the proposed approach in simulated vehicle-pedestrian interactions with varying initial settings and highlight the decision making capabilities of the planning approach.","sentences":["In interactions between automated vehicles (AVs) and crossing pedestrians, modeling implicit vehicle communication is crucial.","In this work, we present a combined prediction and planning approach that allows to consider the influence of the planned vehicle behavior on a pedestrian and predict a pedestrian's reaction.","We plan the behavior by solving two consecutive optimal control problems (OCPs) analytically, using variational calculus.","We perform a validation step that assesses whether the planned vehicle behavior is adequate to trigger a certain pedestrian reaction, which accounts for the closed-loop characteristics of prediction and planning influencing each other.","In this step, we model the influence of the planned vehicle behavior on the pedestrian using a probabilistic behavior acceptance model that returns an estimate for the crossing probability.","The probabilistic modeling of the pedestrian reaction facilitates considering the pedestrian's costs, thereby improving cooperative behavior planning.","We demonstrate the performance of the proposed approach in simulated vehicle-pedestrian interactions with varying initial settings and highlight the decision making capabilities of the planning approach."],"url":"http://arxiv.org/abs/2504.15098v1"}
{"created":"2025-04-21 13:30:51","title":"VistaDepth: Frequency Modulation With Bias Reweighting For Enhanced Long-Range Depth Estimation","abstract":"Monocular depth estimation (MDE) aims to predict per-pixel depth values from a single RGB image. Recent advancements have positioned diffusion models as effective MDE tools by framing the challenge as a conditional image generation task. Despite their progress, these methods often struggle with accurately reconstructing distant depths, due largely to the imbalanced distribution of depth values and an over-reliance on spatial-domain features. To overcome these limitations, we introduce VistaDepth, a novel framework that integrates adaptive frequency-domain feature enhancements with an adaptive weight-balancing mechanism into the diffusion process. Central to our approach is the Latent Frequency Modulation (LFM) module, which dynamically refines spectral responses in the latent feature space, thereby improving the preservation of structural details and reducing noisy artifacts. Furthermore, we implement an adaptive weighting strategy that modulates the diffusion loss in real-time, enhancing the model's sensitivity towards distant depth reconstruction. These innovations collectively result in superior depth perception performance across both distance and detail. Experimental evaluations confirm that VistaDepth achieves state-of-the-art performance among diffusion-based MDE techniques, particularly excelling in the accurate reconstruction of distant regions.","sentences":["Monocular depth estimation (MDE) aims to predict per-pixel depth values from a single RGB image.","Recent advancements have positioned diffusion models as effective MDE tools by framing the challenge as a conditional image generation task.","Despite their progress, these methods often struggle with accurately reconstructing distant depths, due largely to the imbalanced distribution of depth values and an over-reliance on spatial-domain features.","To overcome these limitations, we introduce VistaDepth, a novel framework that integrates adaptive frequency-domain feature enhancements with an adaptive weight-balancing mechanism into the diffusion process.","Central to our approach is the Latent Frequency Modulation (LFM) module, which dynamically refines spectral responses in the latent feature space, thereby improving the preservation of structural details and reducing noisy artifacts.","Furthermore, we implement an adaptive weighting strategy that modulates the diffusion loss in real-time, enhancing the model's sensitivity towards distant depth reconstruction.","These innovations collectively result in superior depth perception performance across both distance and detail.","Experimental evaluations confirm that VistaDepth achieves state-of-the-art performance among diffusion-based MDE techniques, particularly excelling in the accurate reconstruction of distant regions."],"url":"http://arxiv.org/abs/2504.15095v1"}
{"created":"2025-04-21 13:25:55","title":"Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models","abstract":"Detecting collaborative and problem-solving behaviours from digital traces to interpret students' collaborative problem solving (CPS) competency is a long-term goal in the Artificial Intelligence in Education (AIEd) field. Although multimodal data and advanced models are argued to have the potential to detect complex CPS behaviours, empirical evidence on their value remains limited with some contrasting evidence. In this study, we investigated the potential of multimodal data to improve model performance in diagnosing 78 secondary school students' CPS subskills and indicators in authentic educational settings. In particular, text embeddings from verbal data and acoustic embeddings from audio data were used in a multimodal classification model for CPS diagnosis. Both unimodal and multimodal transformer-based models outperformed traditional models in detecting CPS classes. Although the inclusion of multimodality did not improve the performance of traditional unimodal models, its integration into transformer-based models demonstrated improved performance for diagnosing social-cognitive CPS classes compared to unimodal transformer-based models. Based on the results, the paper argues that multimodality and the selection of a particular modelling technique should not be taken for granted to achieve the best performance in the automated detection of every CPS subskill and indicator. Rather, their value is limited to certain types of CPS indicators, affected by the complexity of the labels, and dependent on the composition of indicators in the dataset. We conclude the paper by discussing the required nuance when considering the value of LLMs and multimodality in automated CPS diagnosis, highlighting the need for human-AI complementarity, and proposing the exploration of relevant model architectures and techniques to improve CPS diagnosis in authentic educational contexts.","sentences":["Detecting collaborative and problem-solving behaviours from digital traces to interpret students' collaborative problem solving (CPS) competency is a long-term goal in the Artificial Intelligence in Education (AIEd) field.","Although multimodal data and advanced models are argued to have the potential to detect complex CPS behaviours, empirical evidence on their value remains limited with some contrasting evidence.","In this study, we investigated the potential of multimodal data to improve model performance in diagnosing 78 secondary school students' CPS subskills and indicators in authentic educational settings.","In particular, text embeddings from verbal data and acoustic embeddings from audio data were used in a multimodal classification model for CPS diagnosis.","Both unimodal and multimodal transformer-based models outperformed traditional models in detecting CPS classes.","Although the inclusion of multimodality did not improve the performance of traditional unimodal models, its integration into transformer-based models demonstrated improved performance for diagnosing social-cognitive CPS classes compared to unimodal transformer-based models.","Based on the results, the paper argues that multimodality and the selection of a particular modelling technique should not be taken for granted to achieve the best performance in the automated detection of every CPS subskill and indicator.","Rather, their value is limited to certain types of CPS indicators, affected by the complexity of the labels, and dependent on the composition of indicators in the dataset.","We conclude the paper by discussing the required nuance when considering the value of LLMs and multimodality in automated CPS diagnosis, highlighting the need for human-AI complementarity, and proposing the exploration of relevant model architectures and techniques to improve CPS diagnosis in authentic educational contexts."],"url":"http://arxiv.org/abs/2504.15093v1"}
{"created":"2025-04-21 13:24:30","title":"Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving","abstract":"A recommender system (RS) aims to provide users with personalized item recommendations, enhancing their overall experience. Traditional RSs collect and process all user data on a central server. However, this centralized approach raises significant privacy concerns, as it increases the risk of data breaches and privacy leakages, which are becoming increasingly unacceptable to privacy-sensitive users. To address these privacy challenges, federated learning has been integrated into RSs, ensuring that user data remains secure. In centralized RSs, the issue of rating bias is effectively addressed by jointly analyzing all users' raw interaction data. However, this becomes a significant challenge in federated RSs, as raw data is no longer accessible due to privacy-preserving constraints. To overcome this problem, we propose a Federated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is explicitly incorporated into every local model's loss function, allowing for the effective elimination of rating bias without compromising data privacy. Extensive experiments conducted on three real-world datasets demonstrate that FBALF achieves significantly higher recommendation accuracy compared to other state-of-the-art federated RSs.","sentences":["A recommender system (RS) aims to provide users with personalized item recommendations, enhancing their overall experience.","Traditional RSs collect and process all user data on a central server.","However, this centralized approach raises significant privacy concerns, as it increases the risk of data breaches and privacy leakages, which are becoming increasingly unacceptable to privacy-sensitive users.","To address these privacy challenges, federated learning has been integrated into RSs, ensuring that user data remains secure.","In centralized RSs, the issue of rating bias is effectively addressed by jointly analyzing all users' raw interaction data.","However, this becomes a significant challenge in federated RSs, as raw data is no longer accessible due to privacy-preserving constraints.","To overcome this problem, we propose a Federated Bias-Aware Latent Factor (FBALF) model.","In FBALF, training bias is explicitly incorporated into every local model's loss function, allowing for the effective elimination of rating bias without compromising data privacy.","Extensive experiments conducted on three real-world datasets demonstrate that FBALF achieves significantly higher recommendation accuracy compared to other state-of-the-art federated RSs."],"url":"http://arxiv.org/abs/2504.15090v1"}
{"created":"2025-04-21 13:23:48","title":"Robust Planning and Control of Omnidirectional MRAVs for Aerial Communications in Wireless Networks","abstract":"A new class of Multi-Rotor Aerial Vehicles (MRAVs), known as omnidirectional MRAVs (o-MRAVs), has gained attention for their ability to independently control 3D position and orientation. This capability enhances robust planning and control in aerial communication networks, enabling more adaptive trajectory planning and precise antenna alignment without additional mechanical components. These features are particularly valuable in uncertain environments, where disturbances such as wind and interference affect communication stability. This paper examines o-MRAVs in the context of robust aerial network planning, comparing them with the more common under-actuated MRAVs (u-MRAVs). Key applications, including physical layer security, optical communications, and network densification, are highlighted, demonstrating the potential of o-MRAVs to improve reliability and efficiency in dynamic communication scenarios.","sentences":["A new class of Multi-Rotor Aerial Vehicles (MRAVs), known as omnidirectional MRAVs (o-MRAVs), has gained attention for their ability to independently control 3D position and orientation.","This capability enhances robust planning and control in aerial communication networks, enabling more adaptive trajectory planning and precise antenna alignment without additional mechanical components.","These features are particularly valuable in uncertain environments, where disturbances such as wind and interference affect communication stability.","This paper examines o-MRAVs in the context of robust aerial network planning, comparing them with the more common under-actuated MRAVs (u-MRAVs).","Key applications, including physical layer security, optical communications, and network densification, are highlighted, demonstrating the potential of o-MRAVs to improve reliability and efficiency in dynamic communication scenarios."],"url":"http://arxiv.org/abs/2504.15089v1"}
{"created":"2025-04-21 13:20:56","title":"Safety Co-Option and Compromised National Security: The Self-Fulfilling Prophecy of Weakened AI Risk Thresholds","abstract":"Risk thresholds provide a measure of the level of risk exposure that a society or individual is willing to withstand, ultimately shaping how we determine the safety of technological systems. Against the backdrop of the Cold War, the first risk analyses, such as those devised for nuclear systems, cemented societally accepted risk thresholds against which safety-critical and defense systems are now evaluated. But today, the appropriate risk tolerances for AI systems have yet to be agreed on by global governing efforts, despite the need for democratic deliberation regarding the acceptable levels of harm to human life. Absent such AI risk thresholds, AI technologists-primarily industry labs, as well as \"AI safety\" focused organizations-have instead advocated for risk tolerances skewed by a purported AI arms race and speculative \"existential\" risks, taking over the arbitration of risk determinations with life-or-death consequences, subverting democratic processes.   In this paper, we demonstrate how such approaches have allowed AI technologists to engage in \"safety revisionism,\" substituting traditional safety methods and terminology with ill-defined alternatives that vie for the accelerated adoption of military AI uses at the cost of lowered safety and security thresholds. We explore how the current trajectory for AI risk determination and evaluation for foundation model use within national security is poised for a race to the bottom, to the detriment of the US's national security interests. Safety-critical and defense systems must comply with assurance frameworks that are aligned with established risk thresholds, and foundation models are no exception. As such, development of evaluation frameworks for AI-based military systems must preserve the safety and security of US critical and defense infrastructure, and remain in alignment with international humanitarian law.","sentences":["Risk thresholds provide a measure of the level of risk exposure that a society or individual is willing to withstand, ultimately shaping how we determine the safety of technological systems.","Against the backdrop of the Cold War, the first risk analyses, such as those devised for nuclear systems, cemented societally accepted risk thresholds against which safety-critical and defense systems are now evaluated.","But today, the appropriate risk tolerances for AI systems have yet to be agreed on by global governing efforts, despite the need for democratic deliberation regarding the acceptable levels of harm to human life.","Absent such AI risk thresholds, AI technologists-primarily industry labs, as well as \"AI safety\" focused organizations-have instead advocated for risk tolerances skewed by a purported AI arms race and speculative \"existential\" risks, taking over the arbitration of risk determinations with life-or-death consequences, subverting democratic processes.   ","In this paper, we demonstrate how such approaches have allowed AI technologists to engage in \"safety revisionism,\" substituting traditional safety methods and terminology with ill-defined alternatives that vie for the accelerated adoption of military AI uses at the cost of lowered safety and security thresholds.","We explore how the current trajectory for AI risk determination and evaluation for foundation model use within national security is poised for a race to the bottom, to the detriment of the US's national security interests.","Safety-critical and defense systems must comply with assurance frameworks that are aligned with established risk thresholds, and foundation models are no exception.","As such, development of evaluation frameworks for AI-based military systems must preserve the safety and security of US critical and defense infrastructure, and remain in alignment with international humanitarian law."],"url":"http://arxiv.org/abs/2504.15088v1"}
{"created":"2025-04-21 13:18:54","title":"Hierarchical Attention Fusion of Visual and Textual Representations for Cross-Domain Sequential Recommendation","abstract":"Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by leveraging historical interactions across multiple domains, focusing on modeling cross-domain preferences through intra- and inter-sequence item relationships. Inspired by human cognitive processes, we propose Hierarchical Attention Fusion of Visual and Textual Representations (HAF-VT), a novel approach integrating visual and textual data to enhance cognitive modeling. Using the frozen CLIP model, we generate image and text embeddings, enriching item representations with multimodal data. A hierarchical attention mechanism jointly learns single-domain and cross-domain preferences, mimicking human information integration. Evaluated on four e-commerce datasets, HAF-VT outperforms existing methods in capturing cross-domain user interests, bridging cognitive principles with computational models and highlighting the role of multimodal data in sequential decision-making.","sentences":["Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by leveraging historical interactions across multiple domains, focusing on modeling cross-domain preferences through intra- and inter-sequence item relationships.","Inspired by human cognitive processes, we propose Hierarchical Attention Fusion of Visual and Textual Representations (HAF-VT), a novel approach integrating visual and textual data to enhance cognitive modeling.","Using the frozen CLIP model, we generate image and text embeddings, enriching item representations with multimodal data.","A hierarchical attention mechanism jointly learns single-domain and cross-domain preferences, mimicking human information integration.","Evaluated on four e-commerce datasets, HAF-VT outperforms existing methods in capturing cross-domain user interests, bridging cognitive principles with computational models and highlighting the role of multimodal data in sequential decision-making."],"url":"http://arxiv.org/abs/2504.15085v1"}
{"created":"2025-04-21 13:15:23","title":"An island-parallel ensemble metaheuristic algorithm for large graph coloring problems","abstract":"Graph Coloring Problem (GCP) is an NP-Hard vertex labeling problem in graphs such that no two adjacent vertices can have the same color. Large instances of GCP cannot be solved in reasonable execution times by exact algorithms. Therefore, soft computing approaches, such as metaheuristics, have proven to be very efficient for solving large instances of GCP. In this study, we propose a new island-parallel ensemble metaheuristic algorithm (PEM-Color) to solve large GCP instances. Ensemble learning is a new machine learning approach based on combining the output of multiple models instead of using a single one. We use Message Passing Interface (MPI) parallel computation libraries to combine recent state-of-the-art metaheuristics: Harris Hawk Optimization (HHO), Artificial Bee Colony (ABC), and Teaching Learning Based (TLBO) to improve the quality of their solutions further. To the best of our knowledge, this is the first study that combines metaheuristics and applies to the GCP using an ensemble approach. We conducted experiments on large graph instances from the well-known DIMACS benchmark using 64 processors and achieved significant improvements in execution times. The experiments also indicate an almost linear speed-up with a strong scalability potential. The solution quality of the instances is promising, as our algorithm outperforms 13 state-of-the-art algorithms.","sentences":["Graph Coloring Problem (GCP) is an NP-Hard vertex labeling problem in graphs such that no two adjacent vertices can have the same color.","Large instances of GCP cannot be solved in reasonable execution times by exact algorithms.","Therefore, soft computing approaches, such as metaheuristics, have proven to be very efficient for solving large instances of GCP.","In this study, we propose a new island-parallel ensemble metaheuristic algorithm (PEM-Color) to solve large GCP instances.","Ensemble learning is a new machine learning approach based on combining the output of multiple models instead of using a single one.","We use Message Passing Interface (MPI) parallel computation libraries to combine recent state-of-the-art metaheuristics: Harris Hawk Optimization (HHO), Artificial Bee Colony (ABC), and Teaching Learning Based (TLBO) to improve the quality of their solutions further.","To the best of our knowledge, this is the first study that combines metaheuristics and applies to the GCP using an ensemble approach.","We conducted experiments on large graph instances from the well-known DIMACS benchmark using 64 processors and achieved significant improvements in execution times.","The experiments also indicate an almost linear speed-up with a strong scalability potential.","The solution quality of the instances is promising, as our algorithm outperforms 13 state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2504.15082v1"}

{"created":"2025-04-30 17:59:56","title":"ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction","abstract":"In recent years, video generation has seen significant advancements. However, challenges still persist in generating complex motions and interactions. To address these challenges, we introduce ReVision, a plug-and-play framework that explicitly integrates parameterized 3D physical knowledge into a pretrained conditional video generation model, significantly enhancing its ability to generate high-quality videos with complex motion and interactions. Specifically, ReVision consists of three stages. First, a video diffusion model is used to generate a coarse video. Next, we extract a set of 2D and 3D features from the coarse video to construct a 3D object-centric representation, which is then refined by our proposed parameterized physical prior model to produce an accurate 3D motion sequence. Finally, this refined motion sequence is fed back into the same video diffusion model as additional conditioning, enabling the generation of motion-consistent videos, even in scenarios involving complex actions and interactions. We validate the effectiveness of our approach on Stable Video Diffusion, where ReVision significantly improves motion fidelity and coherence. Remarkably, with only 1.5B parameters, it even outperforms a state-of-the-art video generation model with over 13B parameters on complex video generation by a substantial margin. Our results suggest that, by incorporating 3D physical knowledge, even a relatively small video diffusion model can generate complex motions and interactions with greater realism and controllability, offering a promising solution for physically plausible video generation.","sentences":["In recent years, video generation has seen significant advancements.","However, challenges still persist in generating complex motions and interactions.","To address these challenges, we introduce ReVision, a plug-and-play framework that explicitly integrates parameterized 3D physical knowledge into a pretrained conditional video generation model, significantly enhancing its ability to generate high-quality videos with complex motion and interactions.","Specifically, ReVision consists of three stages.","First, a video diffusion model is used to generate a coarse video.","Next, we extract a set of 2D and 3D features from the coarse video to construct a 3D object-centric representation, which is then refined by our proposed parameterized physical prior model to produce an accurate 3D motion sequence.","Finally, this refined motion sequence is fed back into the same video diffusion model as additional conditioning, enabling the generation of motion-consistent videos, even in scenarios involving complex actions and interactions.","We validate the effectiveness of our approach on Stable Video Diffusion, where ReVision significantly improves motion fidelity and coherence.","Remarkably, with only 1.5B parameters, it even outperforms a state-of-the-art video generation model with over 13B parameters on complex video generation by a substantial margin.","Our results suggest that, by incorporating 3D physical knowledge, even a relatively small video diffusion model can generate complex motions and interactions with greater realism and controllability, offering a promising solution for physically plausible video generation."],"url":"http://arxiv.org/abs/2504.21855v1"}
{"created":"2025-04-30 17:59:02","title":"A Survey of Interactive Generative Video","abstract":"Interactive Generative Video (IGV) has emerged as a crucial technology in response to the growing demand for high-quality, interactive video content across various domains. In this paper, we define IGV as a technology that combines generative capabilities to produce diverse high-quality video content with interactive features that enable user engagement through control signals and responsive feedback. We survey the current landscape of IGV applications, focusing on three major domains: 1) gaming, where IGV enables infinite exploration in virtual worlds; 2) embodied AI, where IGV serves as a physics-aware environment synthesizer for training agents in multimodal interaction with dynamically evolving scenes; and 3) autonomous driving, where IGV provides closed-loop simulation capabilities for safety-critical testing and validation. To guide future development, we propose a comprehensive framework that decomposes an ideal IGV system into five essential modules: Generation, Control, Memory, Dynamics, and Intelligence. Furthermore, we systematically analyze the technical challenges and future directions in realizing each component for an ideal IGV system, such as achieving real-time generation, enabling open-domain control, maintaining long-term coherence, simulating accurate physics, and integrating causal reasoning. We believe that this systematic analysis will facilitate future research and development in the field of IGV, ultimately advancing the technology toward more sophisticated and practical applications.","sentences":["Interactive Generative Video (IGV) has emerged as a crucial technology in response to the growing demand for high-quality, interactive video content across various domains.","In this paper, we define IGV as a technology that combines generative capabilities to produce diverse high-quality video content with interactive features that enable user engagement through control signals and responsive feedback.","We survey the current landscape of IGV applications, focusing on three major domains: 1) gaming, where IGV enables infinite exploration in virtual worlds; 2) embodied AI, where IGV serves as a physics-aware environment synthesizer for training agents in multimodal interaction with dynamically evolving scenes; and 3) autonomous driving, where IGV provides closed-loop simulation capabilities for safety-critical testing and validation.","To guide future development, we propose a comprehensive framework that decomposes an ideal IGV system into five essential modules: Generation, Control, Memory, Dynamics, and Intelligence.","Furthermore, we systematically analyze the technical challenges and future directions in realizing each component for an ideal IGV system, such as achieving real-time generation, enabling open-domain control, maintaining long-term coherence, simulating accurate physics, and integrating causal reasoning.","We believe that this systematic analysis will facilitate future research and development in the field of IGV, ultimately advancing the technology toward more sophisticated and practical applications."],"url":"http://arxiv.org/abs/2504.21853v1"}
{"created":"2025-04-30 17:58:06","title":"TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments","abstract":"Objectives: While Large Language Models (LLMs) have been widely used to assist clinicians and support patients, no existing work has explored dialogue systems for standard diagnostic interviews and assessments. This study aims to bridge the gap in mental healthcare accessibility by developing an LLM-powered dialogue system that replicates clinician behavior. Materials and Methods: We introduce TRUST, a framework of cooperative LLM modules capable of conducting formal diagnostic interviews and assessments for Post-Traumatic Stress Disorder (PTSD). To guide the generation of appropriate clinical responses, we propose a Dialogue Acts schema specifically designed for clinical interviews. Additionally, we develop a patient simulation approach based on real-life interview transcripts to replace time-consuming and costly manual testing by clinicians. Results: A comprehensive set of evaluation metrics is designed to assess the dialogue system from both the agent and patient simulation perspectives. Expert evaluations by conversation and clinical specialists show that TRUST performs comparably to real-life clinical interviews. Discussion: Our system performs at the level of average clinicians, with room for future enhancements in communication styles and response appropriateness. Conclusions: Our TRUST framework shows its potential to facilitate mental healthcare availability.","sentences":["Objectives: While Large Language Models (LLMs) have been widely used to assist clinicians and support patients, no existing work has explored dialogue systems for standard diagnostic interviews and assessments.","This study aims to bridge the gap in mental healthcare accessibility by developing an LLM-powered dialogue system that replicates clinician behavior.","Materials and Methods: We introduce TRUST, a framework of cooperative LLM modules capable of conducting formal diagnostic interviews and assessments for Post-Traumatic Stress Disorder (PTSD).","To guide the generation of appropriate clinical responses, we propose a Dialogue Acts schema specifically designed for clinical interviews.","Additionally, we develop a patient simulation approach based on real-life interview transcripts to replace time-consuming and costly manual testing by clinicians.","Results: A comprehensive set of evaluation metrics is designed to assess the dialogue system from both the agent and patient simulation perspectives.","Expert evaluations by conversation and clinical specialists show that TRUST performs comparably to real-life clinical interviews.","Discussion:","Our system performs at the level of average clinicians, with room for future enhancements in communication styles and response appropriateness.","Conclusions: Our TRUST framework shows its potential to facilitate mental healthcare availability."],"url":"http://arxiv.org/abs/2504.21851v1"}
{"created":"2025-04-30 17:57:22","title":"COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning","abstract":"Multimodal Large Language Models (MLLMs) excel at simple vision-language tasks but struggle when faced with complex tasks that require multiple capabilities, such as simultaneously recognizing objects, counting them, and understanding their spatial relationships. This might be partially the result of the fact that Visual Instruction Tuning (VIT), a critical training step for MLLMs, has traditionally focused on scaling data volume, but not the compositional complexity of training examples. We propose COMPACT (COMPositional Atomic-to-complex visual Capability Tuning), which generates a training dataset explicitly controlling for the compositional complexity of the training examples. The data from COMPACT allows MLLMs to train on combinations of atomic capabilities to learn complex capabilities more efficiently. Across all benchmarks, COMPACT achieves comparable performance to the LLaVA-665k VIT while using less than 10% of its data budget, and even outperforms it on several, especially those involving complex multi-capability tasks. For example, COMPACT achieves substantial 83.3% improvement on MMStar and 94.0% improvement on MM-Vet compared to the full-scale VIT on particularly complex questions that require four or more atomic capabilities. COMPACT offers a scalable, data-efficient, visual compositional tuning recipe to improve on complex visual-language tasks.","sentences":["Multimodal Large Language Models (MLLMs) excel at simple vision-language tasks but struggle when faced with complex tasks that require multiple capabilities, such as simultaneously recognizing objects, counting them, and understanding their spatial relationships.","This might be partially the result of the fact that Visual Instruction Tuning (VIT), a critical training step for MLLMs, has traditionally focused on scaling data volume, but not the compositional complexity of training examples.","We propose COMPACT (COMPositional Atomic-to-complex visual Capability Tuning), which generates a training dataset explicitly controlling for the compositional complexity of the training examples.","The data from COMPACT allows MLLMs to train on combinations of atomic capabilities to learn complex capabilities more efficiently.","Across all benchmarks, COMPACT achieves comparable performance to the LLaVA-665k VIT while using less than 10% of its data budget, and even outperforms it on several, especially those involving complex multi-capability tasks.","For example, COMPACT achieves substantial 83.3% improvement on MMStar and 94.0% improvement on MM-Vet compared to the full-scale VIT on particularly complex questions that require four or more atomic capabilities.","COMPACT offers a scalable, data-efficient, visual compositional tuning recipe to improve on complex visual-language tasks."],"url":"http://arxiv.org/abs/2504.21850v1"}
{"created":"2025-04-30 17:56:23","title":"Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support","abstract":"Governance institutions must respond to societal risks, including those posed by generative AI. This study empirically examines how public trust in institutions and AI technologies, along with perceived risks, shape preferences for AI regulation. Using the nationally representative 2023 Artificial Intelligence, Morality, and Sentience (AIMS) survey, we assess trust in government, AI companies, and AI technologies, as well as public support for regulatory measures such as slowing AI development or outright bans on advanced AI. Our findings reveal broad public support for AI regulation, with risk perception playing a significant role in shaping policy preferences. Individuals with higher trust in government favor regulation, while those with greater trust in AI companies and AI technologies are less inclined to support restrictions. Trust in government and perceived risks significantly predict preferences for both soft (e.g., slowing development) and strong (e.g., banning AI systems) regulatory interventions. These results highlight the importance of public opinion in AI governance. As AI capabilities advance, effective regulation will require balancing public concerns about risks with trust in institutions. This study provides a foundational empirical baseline for policymakers navigating AI governance and underscores the need for further research into public trust, risk perception, and regulatory strategies in the evolving AI landscape.","sentences":["Governance institutions must respond to societal risks, including those posed by generative AI.","This study empirically examines how public trust in institutions and AI technologies, along with perceived risks, shape preferences for AI regulation.","Using the nationally representative 2023 Artificial Intelligence, Morality, and Sentience (AIMS) survey, we assess trust in government, AI companies, and AI technologies, as well as public support for regulatory measures such as slowing AI development or outright bans on advanced AI.","Our findings reveal broad public support for AI regulation, with risk perception playing a significant role in shaping policy preferences.","Individuals with higher trust in government favor regulation, while those with greater trust in AI companies and AI technologies are less inclined to support restrictions.","Trust in government and perceived risks significantly predict preferences for both soft (e.g., slowing development) and strong (e.g., banning AI systems) regulatory interventions.","These results highlight the importance of public opinion in AI governance.","As AI capabilities advance, effective regulation will require balancing public concerns about risks with trust in institutions.","This study provides a foundational empirical baseline for policymakers navigating AI governance and underscores the need for further research into public trust, risk perception, and regulatory strategies in the evolving AI landscape."],"url":"http://arxiv.org/abs/2504.21849v1"}
{"created":"2025-04-30 17:55:48","title":"Characterizing AI Agents for Alignment and Governance","abstract":"The creation of effective governance mechanisms for AI agents requires a deeper understanding of their core properties and how these properties relate to questions surrounding the deployment and operation of agents in the world. This paper provides a characterization of AI agents that focuses on four dimensions: autonomy, efficacy, goal complexity, and generality. We propose different gradations for each dimension, and argue that each dimension raises unique questions about the design, operation, and governance of these systems. Moreover, we draw upon this framework to construct \"agentic profiles\" for different kinds of AI agents. These profiles help to illuminate cross-cutting technical and non-technical governance challenges posed by different classes of AI agents, ranging from narrow task-specific assistants to highly autonomous general-purpose systems. By mapping out key axes of variation and continuity, this framework provides developers, policymakers, and members of the public with the opportunity to develop governance approaches that better align with collective societal goals.","sentences":["The creation of effective governance mechanisms for AI agents requires a deeper understanding of their core properties and how these properties relate to questions surrounding the deployment and operation of agents in the world.","This paper provides a characterization of AI agents that focuses on four dimensions: autonomy, efficacy, goal complexity, and generality.","We propose different gradations for each dimension, and argue that each dimension raises unique questions about the design, operation, and governance of these systems.","Moreover, we draw upon this framework to construct \"agentic profiles\" for different kinds of AI agents.","These profiles help to illuminate cross-cutting technical and non-technical governance challenges posed by different classes of AI agents, ranging from narrow task-specific assistants to highly autonomous general-purpose systems.","By mapping out key axes of variation and continuity, this framework provides developers, policymakers, and members of the public with the opportunity to develop governance approaches that better align with collective societal goals."],"url":"http://arxiv.org/abs/2504.21848v1"}
{"created":"2025-04-30 17:55:29","title":"Differentiable Room Acoustic Rendering with Multi-View Vision Priors","abstract":"An immersive acoustic experience enabled by spatial audio is just as crucial as the visual aspect in creating realistic virtual environments. However, existing methods for room impulse response estimation rely either on data-demanding learning-based models or computationally expensive physics-based modeling. In this work, we introduce Audio-Visual Differentiable Room Acoustic Rendering (AV-DAR), a framework that leverages visual cues extracted from multi-view images and acoustic beam tracing for physics-based room acoustic rendering. Experiments across six real-world environments from two datasets demonstrate that our multimodal, physics-based approach is efficient, interpretable, and accurate, significantly outperforming a series of prior methods. Notably, on the Real Acoustic Field dataset, AV-DAR achieves comparable performance to models trained on 10 times more data while delivering relative gains ranging from 16.6% to 50.9% when trained at the same scale.","sentences":["An immersive acoustic experience enabled by spatial audio is just as crucial as the visual aspect in creating realistic virtual environments.","However, existing methods for room impulse response estimation rely either on data-demanding learning-based models or computationally expensive physics-based modeling.","In this work, we introduce Audio-Visual Differentiable Room Acoustic Rendering (AV-DAR), a framework that leverages visual cues extracted from multi-view images and acoustic beam tracing for physics-based room acoustic rendering.","Experiments across six real-world environments from two datasets demonstrate that our multimodal, physics-based approach is efficient, interpretable, and accurate, significantly outperforming a series of prior methods.","Notably, on the Real Acoustic Field dataset, AV-DAR achieves comparable performance to models trained on 10 times more data while delivering relative gains ranging from 16.6% to 50.9% when trained at the same scale."],"url":"http://arxiv.org/abs/2504.21847v1"}
{"created":"2025-04-30 17:55:24","title":"Active Light Modulation to Counter Manipulation of Speech Visual Content","abstract":"High-profile speech videos are prime targets for falsification, owing to their accessibility and influence. This work proposes Spotlight, a low-overhead and unobtrusive system for protecting live speech videos from visual falsification of speaker identity and lip and facial motion. Unlike predominant falsification detection methods operating in the digital domain, Spotlight creates dynamic physical signatures at the event site and embeds them into all video recordings via imperceptible modulated light. These physical signatures encode semantically-meaningful features unique to the speech event, including the speaker's identity and facial motion, and are cryptographically-secured to prevent spoofing. The signatures can be extracted from any video downstream and validated against the portrayed speech content to check its integrity. Key elements of Spotlight include (1) a framework for generating extremely compact (i.e., 150-bit), pose-invariant speech video features, based on locality-sensitive hashing; and (2) an optical modulation scheme that embeds >200 bps into video while remaining imperceptible both in video and live. Prototype experiments on extensive video datasets show Spotlight achieves AUCs $\\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified videos. Further, Spotlight is highly robust across recording conditions, video post-processing techniques, and white-box adversarial attacks on its video feature extraction methodologies.","sentences":["High-profile speech videos are prime targets for falsification, owing to their accessibility and influence.","This work proposes Spotlight, a low-overhead and unobtrusive system for protecting live speech videos from visual falsification of speaker identity and lip and facial motion.","Unlike predominant falsification detection methods operating in the digital domain, Spotlight creates dynamic physical signatures at the event site and embeds them into all video recordings via imperceptible modulated light.","These physical signatures encode semantically-meaningful features unique to the speech event, including the speaker's identity and facial motion, and are cryptographically-secured to prevent spoofing.","The signatures can be extracted from any video downstream and validated against the portrayed speech content to check its integrity.","Key elements of Spotlight include (1) a framework for generating extremely compact (i.e., 150-bit), pose-invariant speech video features, based on locality-sensitive hashing; and (2) an optical modulation scheme that embeds >200 bps into video while remaining imperceptible both in video and live.","Prototype experiments on extensive video datasets show Spotlight achieves AUCs $\\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified videos.","Further, Spotlight is highly robust across recording conditions, video post-processing techniques, and white-box adversarial attacks on its video feature extraction methodologies."],"url":"http://arxiv.org/abs/2504.21846v1"}
{"created":"2025-04-30 17:51:20","title":"Neuro-Symbolic Generation of Explanations for Robot Policies with Weighted Signal Temporal Logic","abstract":"Neural network-based policies have demonstrated success in many robotic applications, but often lack human-explanability, which poses challenges in safety-critical deployments. To address this, we propose a neuro-symbolic explanation framework that generates a weighted signal temporal logic (wSTL) specification to describe a robot policy in a interpretable form. Existing methods typically produce explanations that are verbose and inconsistent, which hinders explainability, and loose, which do not give meaningful insights into the underlying policy. We address these issues by introducing a simplification process consisting of predicate filtering, regularization, and iterative pruning. We also introduce three novel explainability evaluation metrics -- conciseness, consistency, and strictness -- to assess explanation quality beyond conventional classification metrics. Our method is validated in three simulated robotic environments, where it outperforms baselines in generating concise, consistent, and strict wSTL explanations without sacrificing classification accuracy. This work bridges policy learning with formal methods, contributing to safer and more transparent decision-making in robotics.","sentences":["Neural network-based policies have demonstrated success in many robotic applications, but often lack human-explanability, which poses challenges in safety-critical deployments.","To address this, we propose a neuro-symbolic explanation framework that generates a weighted signal temporal logic (wSTL) specification to describe a robot policy in a interpretable form.","Existing methods typically produce explanations that are verbose and inconsistent, which hinders explainability, and loose, which do not give meaningful insights into the underlying policy.","We address these issues by introducing a simplification process consisting of predicate filtering, regularization, and iterative pruning.","We also introduce three novel explainability evaluation metrics -- conciseness, consistency, and strictness -- to assess explanation quality beyond conventional classification metrics.","Our method is validated in three simulated robotic environments, where it outperforms baselines in generating concise, consistent, and strict wSTL explanations without sacrificing classification accuracy.","This work bridges policy learning with formal methods, contributing to safer and more transparent decision-making in robotics."],"url":"http://arxiv.org/abs/2504.21841v1"}
{"created":"2025-04-30 17:48:43","title":"Learning Universal User Representations Leveraging Cross-domain User Intent at Snapchat","abstract":"The development of powerful user representations is a key factor in the success of recommender systems (RecSys). Online platforms employ a range of RecSys techniques to personalize user experience across diverse in-app surfaces. User representations are often learned individually through user's historical interactions within each surface and user representations across different surfaces can be shared post-hoc as auxiliary features or additional retrieval sources. While effective, such schemes cannot directly encode collaborative filtering signals across different surfaces, hindering its capacity to discover complex relationships between user behaviors and preferences across the whole platform. To bridge this gap at Snapchat, we seek to conduct universal user modeling (UUM) across different in-app surfaces, learning general-purpose user representations which encode behaviors across surfaces. Instead of replacing domain-specific representations, UUM representations capture cross-domain trends, enriching existing representations with complementary information. This work discusses our efforts in developing initial UUM versions, practical challenges, technical choices and modeling and research directions with promising offline performance. Following successful A/B testing, UUM representations have been launched in production, powering multiple use cases and demonstrating their value. UUM embedding has been incorporated into (i) Long-form Video embedding-based retrieval, leading to 2.78% increase in Long-form Video Open Rate, (ii) Long-form Video L2 ranking, with 19.2% increase in Long-form Video View Time sum, (iii) Lens L2 ranking, leading to 1.76% increase in Lens play time, and (iv) Notification L2 ranking, with 0.87% increase in Notification Open Rate.","sentences":["The development of powerful user representations is a key factor in the success of recommender systems (RecSys).","Online platforms employ a range of RecSys techniques to personalize user experience across diverse in-app surfaces.","User representations are often learned individually through user's historical interactions within each surface and user representations across different surfaces can be shared post-hoc as auxiliary features or additional retrieval sources.","While effective, such schemes cannot directly encode collaborative filtering signals across different surfaces, hindering its capacity to discover complex relationships between user behaviors and preferences across the whole platform.","To bridge this gap at Snapchat, we seek to conduct universal user modeling (UUM) across different in-app surfaces, learning general-purpose user representations which encode behaviors across surfaces.","Instead of replacing domain-specific representations, UUM representations capture cross-domain trends, enriching existing representations with complementary information.","This work discusses our efforts in developing initial UUM versions, practical challenges, technical choices and modeling and research directions with promising offline performance.","Following successful A/B testing, UUM representations have been launched in production, powering multiple use cases and demonstrating their value.","UUM embedding has been incorporated into (i) Long-form Video embedding-based retrieval, leading to 2.78% increase in Long-form Video Open Rate, (ii) Long-form Video L2 ranking, with 19.2% increase in Long-form Video View Time sum, (iii) Lens L2 ranking, leading to 1.76% increase in Lens play time, and (iv) Notification L2 ranking, with 0.87% increase in Notification Open Rate."],"url":"http://arxiv.org/abs/2504.21838v1"}
{"created":"2025-04-30 17:46:32","title":"3D Stylization via Large Reconstruction Model","abstract":"With the growing success of text or image guided 3D generators, users demand more control over the generation process, appearance stylization being one of them. Given a reference image, this requires adapting the appearance of a generated 3D asset to reflect the visual style of the reference while maintaining visual consistency from multiple viewpoints. To tackle this problem, we draw inspiration from the success of 2D stylization methods that leverage the attention mechanisms in large image generation models to capture and transfer visual style. In particular, we probe if large reconstruction models, commonly used in the context of 3D generation, has a similar capability. We discover that the certain attention blocks in these models capture the appearance specific features. By injecting features from a visual style image to such blocks, we develop a simple yet effective 3D appearance stylization method. Our method does not require training or test time optimization. Through both quantitative and qualitative evaluations, we demonstrate that our approach achieves superior results in terms of 3D appearance stylization, significantly improving efficiency while maintaining high-quality visual outcomes.","sentences":["With the growing success of text or image guided 3D generators, users demand more control over the generation process, appearance stylization being one of them.","Given a reference image, this requires adapting the appearance of a generated 3D asset to reflect the visual style of the reference while maintaining visual consistency from multiple viewpoints.","To tackle this problem, we draw inspiration from the success of 2D stylization methods that leverage the attention mechanisms in large image generation models to capture and transfer visual style.","In particular, we probe if large reconstruction models, commonly used in the context of 3D generation, has a similar capability.","We discover that the certain attention blocks in these models capture the appearance specific features.","By injecting features from a visual style image to such blocks, we develop a simple yet effective 3D appearance stylization method.","Our method does not require training or test time optimization.","Through both quantitative and qualitative evaluations, we demonstrate that our approach achieves superior results in terms of 3D appearance stylization, significantly improving efficiency while maintaining high-quality visual outcomes."],"url":"http://arxiv.org/abs/2504.21836v1"}
{"created":"2025-04-30 17:37:55","title":"Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization","abstract":"We introduce DEEVISum (Distilled Early Exit Vision language model for Summarization), a lightweight, efficient, and scalable vision language model designed for segment wise video summarization. Leveraging multi modal prompts that combine textual and audio derived signals, DEEVISum incorporates Multi Stage Knowledge Distillation (MSKD) and Early Exit (EE) to strike a balance between performance and efficiency. MSKD offers a 1.33% absolute F1 improvement over baseline distillation (0.5%), while EE reduces inference time by approximately 21% with a 1.3 point drop in F1. Evaluated on the TVSum dataset, our best model PaLI Gemma2 3B + MSKD achieves an F1 score of 61.1, competing the performance of significantly larger models, all while maintaining a lower computational footprint. We publicly release our code and processed dataset to support further research.","sentences":["We introduce DEEVISum (Distilled Early Exit Vision language model for Summarization), a lightweight, efficient, and scalable vision language model designed for segment wise video summarization.","Leveraging multi modal prompts that combine textual and audio derived signals, DEEVISum incorporates Multi Stage Knowledge Distillation (MSKD) and Early Exit (EE) to strike a balance between performance and efficiency.","MSKD offers a 1.33% absolute F1 improvement over baseline distillation (0.5%), while EE reduces inference time by approximately 21% with a 1.3 point drop in F1.","Evaluated on the TVSum dataset, our best model PaLI Gemma2 3B + MSKD achieves an F1 score of 61.1, competing the performance of significantly larger models, all while maintaining a lower computational footprint.","We publicly release our code and processed dataset to support further research."],"url":"http://arxiv.org/abs/2504.21831v1"}
{"created":"2025-04-30 17:30:13","title":"An Underwater, Fault-Tolerant, Laser-Aided Robotic Multi-Modal Dense SLAM System for Continuous Underwater In-Situ Observation","abstract":"Existing underwater SLAM systems are difficult to work effectively in texture-sparse and geometrically degraded underwater environments, resulting in intermittent tracking and sparse mapping. Therefore, we present Water-DSLAM, a novel laser-aided multi-sensor fusion system that can achieve uninterrupted, fault-tolerant dense SLAM capable of continuous in-situ observation in diverse complex underwater scenarios through three key innovations: Firstly, we develop Water-Scanner, a multi-sensor fusion robotic platform featuring a self-designed Underwater Binocular Structured Light (UBSL) module that enables high-precision 3D perception. Secondly, we propose a fault-tolerant triple-subsystem architecture combining: 1) DP-INS (DVL- and Pressure-aided Inertial Navigation System): fusing inertial measurement unit, doppler velocity log, and pressure sensor based Error-State Kalman Filter (ESKF) to provide high-frequency absolute odometry 2) Water-UBSL: a novel Iterated ESKF (IESKF)-based tight coupling between UBSL and DP-INS to mitigate UBSL's degeneration issues 3) Water-Stereo: a fusion of DP-INS and stereo camera for accurate initialization and tracking. Thirdly, we introduce a multi-modal factor graph back-end that dynamically fuses heterogeneous sensor data. The proposed multi-sensor factor graph maintenance strategy efficiently addresses issues caused by asynchronous sensor frequencies and partial data loss. Experimental results demonstrate Water-DSLAM achieves superior robustness (0.039 m trajectory RMSE and 100\\% continuity ratio during partial sensor dropout) and dense mapping (6922.4 points/m^3 in 750 m^3 water volume, approximately 10 times denser than existing methods) in various challenging environments, including pools, dark underwater scenes, 16-meter-deep sinkholes, and field rivers. Our project is available at https://water-scanner.github.io/.","sentences":["Existing underwater SLAM systems are difficult to work effectively in texture-sparse and geometrically degraded underwater environments, resulting in intermittent tracking and sparse mapping.","Therefore, we present Water-DSLAM, a novel laser-aided multi-sensor fusion system that can achieve uninterrupted, fault-tolerant dense SLAM capable of continuous in-situ observation in diverse complex underwater scenarios through three key innovations: Firstly, we develop Water-Scanner, a multi-sensor fusion robotic platform featuring a self-designed Underwater Binocular Structured Light (UBSL) module that enables high-precision 3D perception.","Secondly, we propose a fault-tolerant triple-subsystem architecture combining: 1) DP-INS (DVL- and Pressure-aided Inertial Navigation System): fusing inertial measurement unit, doppler velocity log, and pressure sensor based Error-State Kalman Filter (ESKF) to provide high-frequency absolute odometry 2) Water-UBSL: a novel Iterated ESKF (IESKF)-based tight coupling between UBSL and DP-INS to mitigate UBSL's degeneration issues 3) Water-Stereo: a fusion of DP-INS and stereo camera for accurate initialization and tracking.","Thirdly, we introduce a multi-modal factor graph back-end that dynamically fuses heterogeneous sensor data.","The proposed multi-sensor factor graph maintenance strategy efficiently addresses issues caused by asynchronous sensor frequencies and partial data loss.","Experimental results demonstrate Water-DSLAM achieves superior robustness (0.039 m trajectory RMSE and 100\\% continuity ratio during partial sensor dropout) and dense mapping (6922.4 points/m^3 in 750 m^3 water volume, approximately 10 times denser than existing methods) in various challenging environments, including pools, dark underwater scenes, 16-meter-deep sinkholes, and field rivers.","Our project is available at https://water-scanner.github.io/."],"url":"http://arxiv.org/abs/2504.21826v1"}
{"created":"2025-04-30 17:21:30","title":"Enumeration of minimum weight codewords of affine Cartesian codes","abstract":"Affine Cartesian codes were first discussed by Geil and Thomsen in 2013 in a broader framework and were formally introduced by L\\'opez, Renter\\'ia-M\\'arquez and Villarreal in 2014. These are linear error-correcting codes obtained by evaluating polynomials at points of a Cartesian product of subsets of the given finite field. They can be viewed as a vast generalization of Reed-Muller codes. In 1970, Delsarte, Goethals and MacWilliams gave a %characterization of minimum weight codewords of Reed-Muller codes and also formula for the minimum weight codewords of Reed-Muller codes. Carvalho and Neumann in 2020 considered affine Cartesian codes in a special setting where the subsets in the Cartesian product are nested subfields of the given finite field, and gave a characterization of their minimum weight codewords. We use this to give an explicit formula for the number of minimum weight codewords of affine Cartesian codes in the case of nested subfields. This is seen to unify the known formulas for the number of minimum weight codewords of Reed-Solomon codes and Reed-Muller codes.","sentences":["Affine Cartesian codes were first discussed by Geil and Thomsen in 2013 in a broader framework and were formally introduced by L\\'opez, Renter\\'ia-M\\'arquez and Villarreal in 2014.","These are linear error-correcting codes obtained by evaluating polynomials at points of a Cartesian product of subsets of the given finite field.","They can be viewed as a vast generalization of Reed-Muller codes.","In 1970, Delsarte, Goethals and MacWilliams gave a %characterization of minimum weight codewords of Reed-Muller codes and also formula for the minimum weight codewords of Reed-Muller codes.","Carvalho and Neumann in 2020 considered affine Cartesian codes in a special setting where the subsets in the Cartesian product are nested subfields of the given finite field, and gave a characterization of their minimum weight codewords.","We use this to give an explicit formula for the number of minimum weight codewords of affine Cartesian codes in the case of nested subfields.","This is seen to unify the known formulas for the number of minimum weight codewords of Reed-Solomon codes and Reed-Muller codes."],"url":"http://arxiv.org/abs/2504.21816v1"}
{"created":"2025-04-30 17:20:14","title":"Why Compress What You Can Generate? When GPT-4o Generation Ushers in Image Compression Fields","abstract":"The rapid development of AIGC foundation models has revolutionized the paradigm of image compression, which paves the way for the abandonment of most pixel-level transform and coding, compelling us to ask: why compress what you can generate if the AIGC foundation model is powerful enough to faithfully generate intricate structure and fine-grained details from nothing more than some compact descriptors, i.e., texts, or cues. Fortunately, recent GPT-4o image generation of OpenAI has achieved impressive cross-modality generation, editing, and design capabilities, which motivates us to answer the above question by exploring its potential in image compression fields. In this work, we investigate two typical compression paradigms: textual coding and multimodal coding (i.e., text + extremely low-resolution image), where all/most pixel-level information is generated instead of compressing via the advanced GPT-4o image generation function. The essential challenge lies in how to maintain semantic and structure consistency during the decoding process. To overcome this, we propose a structure raster-scan prompt engineering mechanism to transform the image into textual space, which is compressed as the condition of GPT-4o image generation. Extensive experiments have shown that the combination of our designed structural raster-scan prompts and GPT-4o's image generation function achieved the impressive performance compared with recent multimodal/generative image compression at ultra-low bitrate, further indicating the potential of AIGC generation in image compression fields.","sentences":["The rapid development of AIGC foundation models has revolutionized the paradigm of image compression, which paves the way for the abandonment of most pixel-level transform and coding, compelling us to ask: why compress what you can generate if the AIGC foundation model is powerful enough to faithfully generate intricate structure and fine-grained details from nothing more than some compact descriptors, i.e., texts, or cues.","Fortunately, recent GPT-4o image generation of OpenAI has achieved impressive cross-modality generation, editing, and design capabilities, which motivates us to answer the above question by exploring its potential in image compression fields.","In this work, we investigate two typical compression paradigms: textual coding and multimodal coding (i.e., text + extremely low-resolution image), where all/most pixel-level information is generated instead of compressing via the advanced GPT-4o image generation function.","The essential challenge lies in how to maintain semantic and structure consistency during the decoding process.","To overcome this, we propose a structure raster-scan prompt engineering mechanism to transform the image into textual space, which is compressed as the condition of GPT-4o image generation.","Extensive experiments have shown that the combination of our designed structural raster-scan prompts and GPT-4o's image generation function achieved the impressive performance compared with recent multimodal/generative image compression at ultra-low bitrate, further indicating the potential of AIGC generation in image compression fields."],"url":"http://arxiv.org/abs/2504.21814v1"}
{"created":"2025-04-30 17:13:44","title":"A simple and effective approach for body part recognition on CT scans based on projection estimation","abstract":"It is well known that machine learning models require a high amount of annotated data to obtain optimal performance. Labelling Computed Tomography (CT) data can be a particularly challenging task due to its volumetric nature and often missing and$/$or incomplete associated meta-data. Even inspecting one CT scan requires additional computer software, or in the case of programming languages $-$ additional programming libraries. This study proposes a simple, yet effective approach based on 2D X-ray-like estimation of 3D CT scans for body region identification. Although body region is commonly associated with the CT scan, it often describes only the focused major body region neglecting other anatomical regions present in the observed CT. In the proposed approach, estimated 2D images were utilized to identify 14 distinct body regions, providing valuable information for constructing a high-quality medical dataset. To evaluate the effectiveness of the proposed method, it was compared against 2.5D, 3D and foundation model (MI2) based approaches. Our approach outperformed the others, where it came on top with statistical significance and F1-Score for the best-performing model EffNet-B0 of 0.980 $\\pm$ 0.016 in comparison to the 0.840 $\\pm$ 0.114 (2.5D DenseNet-161), 0.854 $\\pm$ 0.096 (3D VoxCNN), and 0.852 $\\pm$ 0.104 (MI2 foundation model). The utilized dataset comprised three different clinical centers and counted 15,622 CT scans (44,135 labels).","sentences":["It is well known that machine learning models require a high amount of annotated data to obtain optimal performance.","Labelling Computed Tomography (CT) data can be a particularly challenging task due to its volumetric nature and often missing and$/$or incomplete associated meta-data.","Even inspecting one CT scan requires additional computer software, or in the case of programming languages $-$ additional programming libraries.","This study proposes a simple, yet effective approach based on 2D X-ray-like estimation of 3D CT scans for body region identification.","Although body region is commonly associated with the CT scan, it often describes only the focused major body region neglecting other anatomical regions present in the observed CT.","In the proposed approach, estimated 2D images were utilized to identify 14 distinct body regions, providing valuable information for constructing a high-quality medical dataset.","To evaluate the effectiveness of the proposed method, it was compared against 2.5D, 3D and foundation model (MI2) based approaches.","Our approach outperformed the others, where it came on top with statistical significance and F1-Score for the best-performing model EffNet-B0 of 0.980 $\\pm$ 0.016 in comparison to the 0.840 $\\pm$ 0.114 (2.5D DenseNet-161), 0.854 $\\pm$ 0.096 (3D VoxCNN), and 0.852 $\\pm$ 0.104 (MI2 foundation model).","The utilized dataset comprised three different clinical centers and counted 15,622 CT scans (44,135 labels)."],"url":"http://arxiv.org/abs/2504.21810v1"}
{"created":"2025-04-30 17:11:36","title":"Stable Trajectory Clustering: An Efficient Split and Merge Algorithm","abstract":"Clustering algorithms group data points by characteristics to identify patterns. Over the past two decades, researchers have extended these methods to analyze trajectories of humans, animals, and vehicles, studying their behavior and movement across applications. This paper presents whole-trajectory clustering and sub-trajectory clustering algorithms based on DBSCAN line segment clustering, which encompasses two key events: split and merge of line segments. The events are employed by object movement history and the average Euclidean distance between line segments. In this framework, whole-trajectory clustering considers entire entities' trajectories, whereas sub-trajectory clustering employs a sliding window model to identify similar sub-trajectories. Many existing trajectory clustering algorithms respond to temporary anomalies in data by splitting trajectories, which often obscures otherwise consistent clustering patterns and leads to less reliable insights. We introduce the stable trajectory clustering algorithm, which leverages the mean absolute deviation concept to demonstrate that selective omission of transient deviations not only preserves the integrity of clusters but also improves their stability and interpretability. We run all proposed algorithms on real trajectory datasets to illustrate their effectiveness and sensitivity to parameter variations.","sentences":["Clustering algorithms group data points by characteristics to identify patterns.","Over the past two decades, researchers have extended these methods to analyze trajectories of humans, animals, and vehicles, studying their behavior and movement across applications.","This paper presents whole-trajectory clustering and sub-trajectory clustering algorithms based on DBSCAN line segment clustering, which encompasses two key events: split and merge of line segments.","The events are employed by object movement history and the average Euclidean distance between line segments.","In this framework, whole-trajectory clustering considers entire entities' trajectories, whereas sub-trajectory clustering employs a sliding window model to identify similar sub-trajectories.","Many existing trajectory clustering algorithms respond to temporary anomalies in data by splitting trajectories, which often obscures otherwise consistent clustering patterns and leads to less reliable insights.","We introduce the stable trajectory clustering algorithm, which leverages the mean absolute deviation concept to demonstrate that selective omission of transient deviations not only preserves the integrity of clusters but also improves their stability and interpretability.","We run all proposed algorithms on real trajectory datasets to illustrate their effectiveness and sensitivity to parameter variations."],"url":"http://arxiv.org/abs/2504.21808v1"}
{"created":"2025-04-30 17:02:06","title":"An Empirical Study on the Effectiveness of Large Language Models for Binary Code Understanding","abstract":"Binary code analysis plays a pivotal role in the field of software security and is widely used in tasks such as software maintenance, malware detection, software vulnerability discovery, patch analysis, etc. However, unlike source code, reverse engineers face significant challenges in understanding binary code due to the lack of intuitive semantic information. Although traditional reverse tools can convert binary code into C-like pseudo code, the lack of code comments and symbolic information such as function names still makes code understanding difficult. In recent years, two groups of techniques have shown promising prospects: (1) Deep learning-based techniques have demonstrated competitive results in tasks related to binary code understanding, furthermore, (2) Large Language Models (LLMs) have been extensively pre-trained at the source-code level for tasks such as code understanding and generation. This has left participants wondering about the capabilities of LLMs in binary code understanding. To this end, this work proposes a benchmark to evaluate the effectiveness of LLMs in real-world reverse engineering scenarios, which covers two key binary code understanding tasks, i.e., function name recovery and binary code summarization. To more comprehensively evaluate, we include binaries with multiple target architectures as well as different optimization options. We gain valuable insights into the capabilities and limitations through extensive empirical studies of popular LLMs using our benchmark. Our evaluations reveal that existing LLMs can understand binary code to a certain extent, thereby improving the efficiency of binary code analysis. Our results highlight the great potential of the LLMs in advancing the field of binary code understanding, and provide new directions for binary code analysis techniques.","sentences":["Binary code analysis plays a pivotal role in the field of software security and is widely used in tasks such as software maintenance, malware detection, software vulnerability discovery, patch analysis, etc.","However, unlike source code, reverse engineers face significant challenges in understanding binary code due to the lack of intuitive semantic information.","Although traditional reverse tools can convert binary code into C-like pseudo code, the lack of code comments and symbolic information such as function names still makes code understanding difficult.","In recent years, two groups of techniques have shown promising prospects: (1) Deep learning-based techniques have demonstrated competitive results in tasks related to binary code understanding, furthermore, (2) Large Language Models (LLMs) have been extensively pre-trained at the source-code level for tasks such as code understanding and generation.","This has left participants wondering about the capabilities of LLMs in binary code understanding.","To this end, this work proposes a benchmark to evaluate the effectiveness of LLMs in real-world reverse engineering scenarios, which covers two key binary code understanding tasks, i.e., function name recovery and binary code summarization.","To more comprehensively evaluate, we include binaries with multiple target architectures as well as different optimization options.","We gain valuable insights into the capabilities and limitations through extensive empirical studies of popular LLMs using our benchmark.","Our evaluations reveal that existing LLMs can understand binary code to a certain extent, thereby improving the efficiency of binary code analysis.","Our results highlight the great potential of the LLMs in advancing the field of binary code understanding, and provide new directions for binary code analysis techniques."],"url":"http://arxiv.org/abs/2504.21803v1"}
{"created":"2025-04-30 16:57:48","title":"DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition","abstract":"We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3. The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals. The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3's step-by-step reasoning, to create an initial cold start for reinforcement learning. This process enables us to integrate both informal and formal mathematical reasoning into a unified model. The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench. In addition to standard benchmarks, we introduce ProverBench, a collection of 325 formalized problems, to enrich our evaluation, including 15 selected problems from the recent AIME competitions (years 24-25). Further evaluation on these 15 AIME problems shows that the model successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of these problems using majority voting, highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing.","sentences":["We introduce DeepSeek-Prover-V2, an open-source large language model designed for formal theorem proving in Lean 4, with initialization data collected through a recursive theorem proving pipeline powered by DeepSeek-V3.","The cold-start training procedure begins by prompting DeepSeek-V3 to decompose complex problems into a series of subgoals.","The proofs of resolved subgoals are synthesized into a chain-of-thought process, combined with DeepSeek-V3's step-by-step reasoning, to create an initial cold start for reinforcement learning.","This process enables us to integrate both informal and formal mathematical reasoning into a unified model.","The resulting model, DeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural theorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49 out of 658 problems from PutnamBench.","In addition to standard benchmarks, we introduce ProverBench, a collection of 325 formalized problems, to enrich our evaluation, including 15 selected problems from the recent AIME competitions (years 24-25).","Further evaluation on these 15 AIME problems shows that the model successfully solves 6 of them.","In comparison, DeepSeek-V3 solves 8 of these problems using majority voting, highlighting that the gap between formal and informal mathematical reasoning in large language models is substantially narrowing."],"url":"http://arxiv.org/abs/2504.21801v1"}
{"created":"2025-04-30 16:56:56","title":"How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues","abstract":"The growing adoption of synthetic data in healthcare is driven by privacy concerns, limited access to real-world data, and the high cost of annotation. This work explores the use of synthetic Prolonged Exposure (PE) therapeutic conversations for Post-Traumatic Stress Disorder (PTSD) as a scalable alternative for training and evaluating clinical models. We systematically compare real and synthetic dialogues using linguistic, structural, and protocol-specific metrics, including turn-taking patterns and treatment fidelity. We also introduce and evaluate PE-specific metrics derived from linguistic analysis and semantic modeling, offering a novel framework for assessing clinical fidelity beyond surface fluency. Our findings show that although synthetic data holds promise for mitigating data scarcity and protecting patient privacy, it can struggle to capture the subtle dynamics of therapeutic interactions. In our dataset, synthetic dialogues match structural features of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99), however, synthetic interactions do not adequately reflect key fidelity markers (e.g., distress monitoring). We highlight gaps in existing evaluation frameworks and advocate for fidelity-aware metrics that go beyond surface fluency to uncover clinically significant failures. Our findings clarify where synthetic data can effectively complement real-world datasets -- and where critical limitations remain.","sentences":["The growing adoption of synthetic data in healthcare is driven by privacy concerns, limited access to real-world data, and the high cost of annotation.","This work explores the use of synthetic Prolonged Exposure (PE) therapeutic conversations for Post-Traumatic Stress Disorder (PTSD) as a scalable alternative for training and evaluating clinical models.","We systematically compare real and synthetic dialogues using linguistic, structural, and protocol-specific metrics, including turn-taking patterns and treatment fidelity.","We also introduce and evaluate PE-specific metrics derived from linguistic analysis and semantic modeling, offering a novel framework for assessing clinical fidelity beyond surface fluency.","Our findings show that although synthetic data holds promise for mitigating data scarcity and protecting patient privacy, it can struggle to capture the subtle dynamics of therapeutic interactions.","In our dataset, synthetic dialogues match structural features of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99), however, synthetic interactions do not adequately reflect key fidelity markers (e.g., distress monitoring).","We highlight gaps in existing evaluation frameworks and advocate for fidelity-aware metrics that go beyond surface fluency to uncover clinically significant failures.","Our findings clarify where synthetic data can effectively complement real-world datasets -- and where critical limitations remain."],"url":"http://arxiv.org/abs/2504.21800v1"}
{"created":"2025-04-30 16:56:06","title":"SWE-smith: Scaling Data for Software Engineering Agents","abstract":"Despite recent progress in Language Models (LMs) for software engineering, collecting training data remains a significant pain point. Existing datasets are small, with at most 1,000s of training instances from 11 or fewer GitHub repositories. The procedures to curate such datasets are often complex, necessitating hundreds of hours of human labor; companion execution environments also take up several terabytes of storage, severely limiting their scalability and usability. To address this pain point, we introduce SWE-smith, a novel pipeline for generating software engineering training data at scale. Given any Python codebase, SWE-smith constructs a corresponding execution environment, then automatically synthesizes 100s to 1,000s of task instances that break existing test(s) in the codebase. Using SWE-smith, we create a dataset of 50k instances sourced from 128 GitHub repositories, an order of magnitude larger than all previous works. We train SWE-agent-LM-32B, achieving 40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art among open source models. We open source SWE-smith (collection procedure, task instances, trajectories, models) to lower the barrier of entry for research in LM systems for automated software engineering. All assets available at https://swesmith.com.","sentences":["Despite recent progress in Language Models (LMs) for software engineering, collecting training data remains a significant pain point.","Existing datasets are small, with at most 1,000s of training instances from 11 or fewer","GitHub repositories.","The procedures to curate such datasets are often complex, necessitating hundreds of hours of human labor; companion execution environments also take up several terabytes of storage, severely limiting their scalability and usability.","To address this pain point, we introduce SWE-smith, a novel pipeline for generating software engineering training data at scale.","Given any Python codebase, SWE-smith constructs a corresponding execution environment, then automatically synthesizes 100s to 1,000s of task instances that break existing test(s) in the codebase.","Using SWE-smith, we create a dataset of 50k instances sourced from 128 GitHub repositories, an order of magnitude larger than all previous works.","We train SWE-agent-LM-32B, achieving 40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art among open source models.","We open source SWE-smith (collection procedure, task instances, trajectories, models) to lower the barrier of entry for research in LM systems for automated software engineering.","All assets available at https://swesmith.com."],"url":"http://arxiv.org/abs/2504.21798v1"}
{"created":"2025-04-30 16:48:00","title":"Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation","abstract":"Magnetic Resonance Imaging (MRI) plays an important role in identifying clinically significant prostate cancer (csPCa), yet automated methods face challenges such as data imbalance, variable tumor sizes, and a lack of annotated data. This study introduces Anomaly-Driven U-Net (adU-Net), which incorporates anomaly maps derived from biparametric MRI sequences into a deep learning-based segmentation framework to improve csPCa identification. We conduct a comparative analysis of anomaly detection methods and evaluate the integration of anomaly maps into the segmentation pipeline. Anomaly maps, generated using Fixed-Point GAN reconstruction, highlight deviations from normal prostate tissue, guiding the segmentation model to potential cancerous regions. We compare the performance by using the average score, computed as the mean of the AUROC and Average Precision (AP). On the external test set, adU-Net achieves the best average score of 0.618, outperforming the baseline nnU-Net model (0.605). The results demonstrate that incorporating anomaly detection into segmentation improves generalization and performance, particularly with ADC-based anomaly maps, offering a promising direction for automated csPCa identification.","sentences":["Magnetic Resonance Imaging (MRI) plays an important role in identifying clinically significant prostate cancer (csPCa), yet automated methods face challenges such as data imbalance, variable tumor sizes, and a lack of annotated data.","This study introduces Anomaly-Driven U-Net (adU-Net), which incorporates anomaly maps derived from biparametric MRI sequences into a deep learning-based segmentation framework to improve csPCa identification.","We conduct a comparative analysis of anomaly detection methods and evaluate the integration of anomaly maps into the segmentation pipeline.","Anomaly maps, generated using Fixed-Point GAN reconstruction, highlight deviations from normal prostate tissue, guiding the segmentation model to potential cancerous regions.","We compare the performance by using the average score, computed as the mean of the AUROC and Average Precision (AP).","On the external test set, adU-Net achieves the best average score of 0.618, outperforming the baseline nnU-Net model (0.605).","The results demonstrate that incorporating anomaly detection into segmentation improves generalization and performance, particularly with ADC-based anomaly maps, offering a promising direction for automated csPCa identification."],"url":"http://arxiv.org/abs/2504.21789v1"}
{"created":"2025-04-30 16:34:53","title":"Message Optimality and Message-Time Trade-offs for APSP and Beyond","abstract":"Round complexity is an extensively studied metric of distributed algorithms. In contrast, our knowledge of the \\emph{message complexity} of distributed computing problems and its relationship (if any) with round complexity is still quite limited. To illustrate, for many fundamental distributed graph optimization problems such as (exact) diameter computation, All-Pairs Shortest Paths (APSP), Maximum Matching etc., while (near) round-optimal algorithms are known, message-optimal algorithms are hitherto unknown. More importantly, the existing round-optimal algorithms are not message-optimal. This raises two important questions: (1) Can we design message-optimal algorithms for these problems? (2) Can we give message-time tradeoffs for these problems in case the message-optimal algorithms are not round-optimal?   In this work, we focus on a fundamental graph optimization problem, \\emph{All Pairs Shortest Path (APSP)}, whose message complexity is still unresolved. We present two main results in the CONGEST model: (1) We give a message-optimal (up to logarithmic factors) algorithm that solves weighted APSP, using $\\tilde{O}(n^2)$ messages. This algorithm takes $\\tilde{O}(n^2)$ rounds. (2) For any $0 \\leq \\varepsilon \\le 1$, we show how to solve unweighted APSP in $\\tilde{O}(n^{2-\\varepsilon })$ rounds and $\\tilde{O}(n^{2+\\varepsilon })$ messages. At one end of this smooth trade-off, we obtain a (nearly) message-optimal algorithm using $\\tilde{O}(n^2)$ messages (for $\\varepsilon = 0$), whereas at the other end we get a (nearly) round-optimal algorithm using $\\tilde{O}(n)$ rounds (for $\\varepsilon = 1$). This is the first such message-time trade-off result known.","sentences":["Round complexity is an extensively studied metric of distributed algorithms.","In contrast, our knowledge of the \\emph{message complexity} of distributed computing problems and its relationship (if any) with round complexity is still quite limited.","To illustrate, for many fundamental distributed graph optimization problems such as (exact) diameter computation, All-Pairs Shortest Paths (APSP), Maximum Matching etc., while (near) round-optimal algorithms are known, message-optimal algorithms are hitherto unknown.","More importantly, the existing round-optimal algorithms are not message-optimal.","This raises two important questions: (1) Can we design message-optimal algorithms for these problems?","(2) Can we give message-time tradeoffs for these problems in case the message-optimal algorithms are not round-optimal?   ","In this work, we focus on a fundamental graph optimization problem, \\emph{All Pairs Shortest Path (APSP)}, whose message complexity is still unresolved.","We present two main results in the CONGEST model: (1) We give a message-optimal (up to logarithmic factors)","algorithm that solves weighted APSP, using $\\tilde{O}(n^2)$ messages.","This algorithm takes $\\tilde{O}(n^2)$ rounds.","(2) For any $0 \\leq \\varepsilon \\le 1$, we show how to solve unweighted APSP in $\\tilde{O}(n^{2-\\varepsilon })$ rounds and $\\tilde{O}(n^{2+\\varepsilon })$ messages.","At one end of this smooth trade-off, we obtain a (nearly) message-optimal algorithm using $\\tilde{O}(n^2)$ messages (for $\\varepsilon = 0$), whereas at the other end we get a (nearly) round-optimal algorithm using $\\tilde{O}(n)$ rounds (for $\\varepsilon = 1$).","This is the first such message-time trade-off result known."],"url":"http://arxiv.org/abs/2504.21781v1"}
{"created":"2025-04-30 16:33:00","title":"Normality of 8-Bit Bent Function","abstract":"Bent functions are Boolean functions in an even number of variables that are indicators of Hadamard difference sets in elementary abelian 2-groups. A bent function in m variables is said to be normal if it is constant on an affine space of dimension m/2. In this paper, we demonstrate that all bent functions in m = 8 variables -- whose exact count, determined by Langevin and Leander (Des. Codes Cryptogr. 59(1--3): 193--205, 2011), is approximately $2^106$ share a common algebraic property: every 8-variable bent function is normal, up to the addition of a linear function. With this result, we complete the analysis of the normality of bent functions for the last unresolvedcase, m= 8. It is already known that all bent functions in m variables are normal for m <= 6, while for m > = 10, there exist bent functions that cannot be made normal by adding linear functions. Consequently, we provide a complete solution to an open problem by Charpin (J. Complex. 20(2-3): 245-265, 2004)","sentences":["Bent functions are Boolean functions in an even number of variables that are indicators of Hadamard difference sets in elementary abelian 2-groups.","A bent function in m variables is said to be normal if it is constant on an affine space of dimension m/2.","In this paper, we demonstrate that all bent functions in m = 8 variables -- whose exact count, determined by Langevin and Leander (Des. Codes Cryptogr.","59(1--3): 193--205, 2011), is approximately $2^106$ share a common algebraic property: every 8-variable bent function is normal, up to the addition of a linear function.","With this result, we complete the analysis of the normality of bent functions for the last unresolvedcase, m= 8.","It is already known that all bent functions in m variables are normal for m <= 6, while for m >","= 10, there exist bent functions that cannot be made normal by adding linear functions.","Consequently, we provide a complete solution to an open problem by Charpin (J. Complex.","20(2-3): 245-265, 2004)"],"url":"http://arxiv.org/abs/2504.21779v1"}
{"created":"2025-04-30 16:29:14","title":"Near-Optimal Distributed Ruling Sets for Trees and High-Girth Graphs","abstract":"Given a graph $G=(V,E)$, a $\\beta$-ruling set is a subset $S\\subseteq V$ that is i) independent, and ii) every node $v\\in V$ has a node of $S$ within distance $\\beta$. In this paper we present almost optimal distributed algorithms for finding ruling sets in trees and high girth graphs in the classic LOCAL model. As our first contribution we present an $O(\\log\\log n)$-round randomized algorithm for computing $2$-ruling sets on trees, almost matching the $\\Omega(\\log\\log n/\\log\\log\\log n)$ lower bound given by Balliu et al. [FOCS'20]. Second, we show that $2$-ruling sets can be solved in $\\widetilde{O}(\\log^{5/3}\\log n)$ rounds in high-girth graphs. Lastly, we show that $O(\\log\\log\\log n)$-ruling sets can be computed in $\\widetilde{O}(\\log\\log n)$ rounds in high-girth graphs matching the lower bound up to triple-log factors. All of these results either improve polynomially or exponentially on the previously best algorithms and use a smaller domination distance $\\beta$.","sentences":["Given a graph $G=(V,E)$, a $\\beta$-ruling set is a subset $S\\subseteq V$ that is i) independent, and ii) every node $v\\in V$ has a node of $S$ within distance $\\beta$. In this paper we present almost optimal distributed algorithms for finding ruling sets in trees and high girth graphs in the classic LOCAL model.","As our first contribution we present an $O(\\log\\log n)$-round randomized algorithm for computing $2$-ruling sets on trees, almost matching the $\\Omega(\\log\\log n/\\log\\log\\log n)$ lower bound given by Balliu et al.","[FOCS'20].","Second, we show that $2$-ruling sets can be solved in $\\widetilde{O}(\\log^{5/3}\\log n)$ rounds in high-girth graphs.","Lastly, we show that $O(\\log\\log\\log n)$-ruling sets can be computed in $\\widetilde{O}(\\log\\log n)$ rounds in high-girth graphs matching the lower bound up to triple-log factors.","All of these results either improve polynomially or exponentially on the previously best algorithms and use a smaller domination distance $\\beta$."],"url":"http://arxiv.org/abs/2504.21777v1"}
{"created":"2025-04-30 16:25:25","title":"WebThinker: Empowering Large Reasoning Models with Deep Research Capability","abstract":"Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate impressive long-horizon reasoning capabilities. However, their reliance on static internal knowledge limits their performance on complex, knowledge-intensive tasks and hinders their ability to produce comprehensive research reports requiring synthesis of diverse web information. To address this, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs to autonomously search the web, navigate web pages, and draft research reports during the reasoning process. WebThinker integrates a \\textbf{Deep Web Explorer} module, enabling LRMs to dynamically search, navigate, and extract information from the web when encountering knowledge gaps. It also employs an \\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to seamlessly interleave reasoning, information gathering, and report writing in real time. To further enhance research tool utilization, we introduce an \\textbf{RL-based training strategy} via iterative online Direct Preference Optimization (DPO). Extensive experiments on complex reasoning benchmarks (GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive) demonstrate that WebThinker significantly outperforms existing methods and strong proprietary systems. Our approach enhances LRM reliability and applicability in complex scenarios, paving the way for more capable and versatile deep research systems. The code is available at https://github.com/RUC-NLPIR/WebThinker.","sentences":["Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate impressive long-horizon reasoning capabilities.","However, their reliance on static internal knowledge limits their performance on complex, knowledge-intensive tasks and hinders their ability to produce comprehensive research reports requiring synthesis of diverse web information.","To address this, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs to autonomously search the web, navigate web pages, and draft research reports during the reasoning process.","WebThinker integrates a \\textbf{Deep Web Explorer} module, enabling LRMs to dynamically search, navigate, and extract information from the web when encountering knowledge gaps.","It also employs an \\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to seamlessly interleave reasoning, information gathering, and report writing in real time.","To further enhance research tool utilization, we introduce an \\textbf{RL-based training strategy} via iterative online Direct Preference Optimization (DPO).","Extensive experiments on complex reasoning benchmarks (GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive) demonstrate that WebThinker significantly outperforms existing methods and strong proprietary systems.","Our approach enhances LRM reliability and applicability in complex scenarios, paving the way for more capable and versatile deep research systems.","The code is available at https://github.com/RUC-NLPIR/WebThinker."],"url":"http://arxiv.org/abs/2504.21776v1"}
{"created":"2025-04-30 16:25:02","title":"Learning Heterogeneous Performance-Fairness Trade-offs in Federated Learning","abstract":"Recent methods leverage a hypernet to handle the performance-fairness trade-offs in federated learning. This hypernet maps the clients' preferences between model performance and fairness to preference-specifc models on the trade-off curve, known as local Pareto front. However, existing methods typically adopt a uniform preference sampling distribution to train the hypernet across clients, neglecting the inherent heterogeneity of their local Pareto fronts. Meanwhile, from the perspective of generalization, they do not consider the gap between local and global Pareto fronts on the global dataset. To address these limitations, we propose HetPFL to effectively learn both local and global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA) and Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the optimal preference sampling distribution for each client to accommodate heterogeneous local Pareto fronts. While PHF performs preference-aware fusion of clients' hypernets to ensure the performance of the global Pareto front. We prove that HetPFL converges linearly with respect to the number of rounds, under weaker assumptions than existing methods. Extensive experiments on four datasets show that HetPFL significantly outperforms seven baselines in terms of the quality of learned local and global Pareto fronts.","sentences":["Recent methods leverage a hypernet to handle the performance-fairness trade-offs in federated learning.","This hypernet maps the clients' preferences between model performance and fairness to preference-specifc models on the trade-off curve, known as local Pareto front.","However, existing methods typically adopt a uniform preference sampling distribution to train the hypernet across clients, neglecting the inherent heterogeneity of their local Pareto fronts.","Meanwhile, from the perspective of generalization, they do not consider the gap between local and global Pareto fronts on the global dataset.","To address these limitations, we propose HetPFL to effectively learn both local and global Pareto fronts.","HetPFL comprises Preference Sampling Adaptation (PSA) and Preference-aware Hypernet Fusion (PHF).","PSA adaptively determines the optimal preference sampling distribution for each client to accommodate heterogeneous local Pareto fronts.","While PHF performs preference-aware fusion of clients' hypernets to ensure the performance of the global Pareto front.","We prove that HetPFL converges linearly with respect to the number of rounds, under weaker assumptions than existing methods.","Extensive experiments on four datasets show that HetPFL significantly outperforms seven baselines in terms of the quality of learned local and global Pareto fronts."],"url":"http://arxiv.org/abs/2504.21775v1"}
{"created":"2025-04-30 16:22:14","title":"Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?","abstract":"Collaborative perception enhances environmental awareness through inter-agent communication and is regarded as a promising solution to intelligent transportation systems. However, existing collaborative methods for Unmanned Aerial Vehicles (UAVs) overlook the unique characteristics of the UAV perspective, resulting in substantial communication overhead. To address this issue, we propose a novel communication-efficient collaborative perception framework based on late-intermediate fusion, dubbed LIF. The core concept is to exchange informative and compact detection results and shift the fusion stage to the feature representation level. In particular, we leverage vision-guided positional embedding (VPE) and box-based virtual augmented feature (BoBEV) to effectively integrate complementary information from various agents. Additionally, we innovatively introduce an uncertainty-driven communication mechanism that uses uncertainty evaluation to select high-quality and reliable shared areas. Experimental results demonstrate that our LIF achieves superior performance with minimal communication bandwidth, proving its effectiveness and practicality. Code and models are available at https://github.com/uestchjw/LIF.","sentences":["Collaborative perception enhances environmental awareness through inter-agent communication and is regarded as a promising solution to intelligent transportation systems.","However, existing collaborative methods for Unmanned Aerial Vehicles (UAVs) overlook the unique characteristics of the UAV perspective, resulting in substantial communication overhead.","To address this issue, we propose a novel communication-efficient collaborative perception framework based on late-intermediate fusion, dubbed LIF.","The core concept is to exchange informative and compact detection results and shift the fusion stage to the feature representation level.","In particular, we leverage vision-guided positional embedding (VPE) and box-based virtual augmented feature (BoBEV) to effectively integrate complementary information from various agents.","Additionally, we innovatively introduce an uncertainty-driven communication mechanism that uses uncertainty evaluation to select high-quality and reliable shared areas.","Experimental results demonstrate that our LIF achieves superior performance with minimal communication bandwidth, proving its effectiveness and practicality.","Code and models are available at https://github.com/uestchjw/LIF."],"url":"http://arxiv.org/abs/2504.21774v1"}
{"created":"2025-04-30 16:17:53","title":"MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness","abstract":"With the widespread application of large language models (LLMs), the issue of generating non-existing facts, known as hallucination, has garnered increasing attention. Previous research in enhancing LLM confidence estimation mainly focuses on the single problem setting. However, LLM awareness of its internal parameterized knowledge boundary under the more challenging multi-problem setting, which requires answering multiple problems accurately simultaneously, remains underexplored. To bridge this gap, we introduce a novel method, Multiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates the learning of answer prediction and confidence estimation during fine-tuning on instruction data. Extensive experiments demonstrate that our method outperforms baselines by up to 25% in average precision.","sentences":["With the widespread application of large language models (LLMs), the issue of generating non-existing facts, known as hallucination, has garnered increasing attention.","Previous research in enhancing LLM confidence estimation mainly focuses on the single problem setting.","However, LLM awareness of its internal parameterized knowledge boundary under the more challenging multi-problem setting, which requires answering multiple problems accurately simultaneously, remains underexplored.","To bridge this gap, we introduce a novel method, Multiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates the learning of answer prediction and confidence estimation during fine-tuning on instruction data.","Extensive experiments demonstrate that our method outperforms baselines by up to 25% in average precision."],"url":"http://arxiv.org/abs/2504.21773v1"}
{"created":"2025-04-30 16:17:05","title":"Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline","abstract":"Short video platforms like YouTube Shorts and TikTok face significant copyright compliance challenges, as infringers frequently embed arbitrary background music (BGM) to obscure original soundtracks (OST) and evade content originality detection. To tackle this issue, we propose a novel pipeline that integrates Music Source Separation (MSS) and cross-modal video-music retrieval (CMVMR). Our approach effectively separates arbitrary BGM from the original OST, enabling the restoration of authentic video audio tracks. To support this work, we introduce two domain-specific datasets: OASD-20K for audio separation and OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips featuring mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset comprising 1,121 video and mixed-audio pairs, specifically designed for short video restoration tasks. Experimental results demonstrate that our pipeline not only removes arbitrary BGM with high accuracy but also restores OSTs, ensuring content integrity. This approach provides an ethical and scalable solution to copyright challenges in user-generated content on short video platforms.","sentences":["Short video platforms like YouTube Shorts and TikTok face significant copyright compliance challenges, as infringers frequently embed arbitrary background music (BGM) to obscure original soundtracks (OST) and evade content originality detection.","To tackle this issue, we propose a novel pipeline that integrates Music Source Separation (MSS) and cross-modal video-music retrieval (CMVMR).","Our approach effectively separates arbitrary BGM from the original OST, enabling the restoration of authentic video audio tracks.","To support this work, we introduce two domain-specific datasets: OASD-20K for audio separation and OSVAR-160 for pipeline evaluation.","OASD-20K contains 20,000 audio clips featuring mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset comprising 1,121 video and mixed-audio pairs, specifically designed for short video restoration tasks.","Experimental results demonstrate that our pipeline not only removes arbitrary BGM with high accuracy but also restores OSTs, ensuring content integrity.","This approach provides an ethical and scalable solution to copyright challenges in user-generated content on short video platforms."],"url":"http://arxiv.org/abs/2504.21772v1"}
{"created":"2025-04-30 16:16:14","title":"Anatomical Similarity as a New Metric to Evaluate Brain Generative Models","abstract":"Generative models enhance neuroimaging through data augmentation, quality improvement, and rare condition studies. Despite advances in realistic synthetic MRIs, evaluations focus on texture and perception, lacking sensitivity to crucial anatomical fidelity. This study proposes a new metric, called WASABI (Wasserstein-Based Anatomical Brain Index), to assess the anatomical realism of synthetic brain MRIs. WASABI leverages \\textit{SynthSeg}, a deep learning-based brain parcellation tool, to derive volumetric measures of brain regions in each MRI and uses the multivariate Wasserstein distance to compare distributions between real and synthetic anatomies. Based on controlled experiments on two real datasets and synthetic MRIs from five generative models, WASABI demonstrates higher sensitivity in quantifying anatomical discrepancies compared to traditional image-level metrics, even when synthetic images achieve near-perfect visual quality. Our findings advocate for shifting the evaluation paradigm beyond visual inspection and conventional metrics, emphasizing anatomical fidelity as a crucial benchmark for clinically meaningful brain MRI synthesis. Our code is available at https://github.com/BahramJafrasteh/wasabi-mri.","sentences":["Generative models enhance neuroimaging through data augmentation, quality improvement, and rare condition studies.","Despite advances in realistic synthetic MRIs, evaluations focus on texture and perception, lacking sensitivity to crucial anatomical fidelity.","This study proposes a new metric, called WASABI (Wasserstein-Based Anatomical Brain Index), to assess the anatomical realism of synthetic brain MRIs.","WASABI leverages \\textit{SynthSeg}, a deep learning-based brain parcellation tool, to derive volumetric measures of brain regions in each MRI and uses the multivariate Wasserstein distance to compare distributions between real and synthetic anatomies.","Based on controlled experiments on two real datasets and synthetic MRIs from five generative models, WASABI demonstrates higher sensitivity in quantifying anatomical discrepancies compared to traditional image-level metrics, even when synthetic images achieve near-perfect visual quality.","Our findings advocate for shifting the evaluation paradigm beyond visual inspection and conventional metrics, emphasizing anatomical fidelity as a crucial benchmark for clinically meaningful brain MRI synthesis.","Our code is available at https://github.com/BahramJafrasteh/wasabi-mri."],"url":"http://arxiv.org/abs/2504.21771v1"}
{"created":"2025-04-30 16:15:53","title":"LASHED: LLMs And Static Hardware Analysis for Early Detection of RTL Bugs","abstract":"While static analysis is useful in detecting early-stage hardware security bugs, its efficacy is limited because it requires information to form checks and is often unable to explain the security impact of a detected vulnerability. Large Language Models can be useful in filling these gaps by identifying relevant assets, removing false violations flagged by static analysis tools, and explaining the reported violations. LASHED combines the two approaches (LLMs and Static Analysis) to overcome each other's limitations for hardware security bug detection. We investigate our approach on four open-source SoCs for five Common Weakness Enumerations (CWEs) and present strategies for improvement with better prompt engineering. We find that 87.5% of instances flagged by our recommended scheme are plausible CWEs. In-context learning and asking the model to 'think again' improves LASHED's precision.","sentences":["While static analysis is useful in detecting early-stage hardware security bugs, its efficacy is limited because it requires information to form checks and is often unable to explain the security impact of a detected vulnerability.","Large Language Models can be useful in filling these gaps by identifying relevant assets, removing false violations flagged by static analysis tools, and explaining the reported violations.","LASHED combines the two approaches (LLMs and Static Analysis) to overcome each other's limitations for hardware security bug detection.","We investigate our approach on four open-source SoCs for five Common Weakness Enumerations (CWEs) and present strategies for improvement with better prompt engineering.","We find that 87.5% of instances flagged by our recommended scheme are plausible CWEs.","In-context learning and asking the model to 'think again' improves LASHED's precision."],"url":"http://arxiv.org/abs/2504.21770v1"}
{"created":"2025-04-30 16:14:25","title":"LLM-based Interactive Imitation Learning for Robotic Manipulation","abstract":"Recent advancements in machine learning provide methods to train autonomous agents capable of handling the increasing complexity of sequential decision-making in robotics. Imitation Learning (IL) is a prominent approach, where agents learn to control robots based on human demonstrations. However, IL commonly suffers from violating the independent and identically distributed (i.i.d) assumption in robotic tasks. Interactive Imitation Learning (IIL) achieves improved performance by allowing agents to learn from interactive feedback from human teachers. Despite these improvements, both approaches come with significant costs due to the necessity of human involvement. Leveraging the emergent capabilities of Large Language Models (LLMs) in reasoning and generating human-like responses, we introduce LLM-iTeach -- a novel IIL framework that utilizes an LLM as an interactive teacher to enhance agent performance while alleviating the dependence on human resources. Firstly, LLM-iTeach uses a hierarchical prompting strategy that guides the LLM in generating a policy in Python code. Then, with a designed similarity-based feedback mechanism, LLM-iTeach provides corrective and evaluative feedback interactively during the agent's training. We evaluate LLM-iTeach against baseline methods such as Behavior Cloning (BC), an IL method, and CEILing, a state-of-the-art IIL method using a human teacher, on various robotic manipulation tasks. Our results demonstrate that LLM-iTeach surpasses BC in the success rate and achieves or even outscores that of CEILing, highlighting the potential of LLMs as cost-effective, human-like teachers in interactive learning environments. We further demonstrate the method's potential for generalization by evaluating it on additional tasks. The code and prompts are provided at: https://github.com/Tubicor/LLM-iTeach.","sentences":["Recent advancements in machine learning provide methods to train autonomous agents capable of handling the increasing complexity of sequential decision-making in robotics.","Imitation Learning (IL) is a prominent approach, where agents learn to control robots based on human demonstrations.","However, IL commonly suffers from violating the independent and identically distributed (i.i.d) assumption in robotic tasks.","Interactive Imitation Learning (IIL) achieves improved performance by allowing agents to learn from interactive feedback from human teachers.","Despite these improvements, both approaches come with significant costs due to the necessity of human involvement.","Leveraging the emergent capabilities of Large Language Models (LLMs) in reasoning and generating human-like responses, we introduce LLM-iTeach -- a novel IIL framework that utilizes an LLM as an interactive teacher to enhance agent performance while alleviating the dependence on human resources.","Firstly, LLM-iTeach uses a hierarchical prompting strategy that guides the LLM in generating a policy in Python code.","Then, with a designed similarity-based feedback mechanism, LLM-iTeach provides corrective and evaluative feedback interactively during the agent's training.","We evaluate LLM-iTeach against baseline methods such as Behavior Cloning (BC), an IL method, and CEILing, a state-of-the-art IIL method using a human teacher, on various robotic manipulation tasks.","Our results demonstrate that LLM-iTeach surpasses BC in the success rate and achieves or even outscores that of CEILing, highlighting the potential of LLMs as cost-effective, human-like teachers in interactive learning environments.","We further demonstrate the method's potential for generalization by evaluating it on additional tasks.","The code and prompts are provided at: https://github.com/Tubicor/LLM-iTeach."],"url":"http://arxiv.org/abs/2504.21769v1"}
{"created":"2025-04-30 16:07:44","title":"Whleaper: A 10-DOF Flexible Bipedal Wheeled Robot","abstract":"Wheel-legged robots combine the advantages of both wheeled robots and legged robots, offering versatile locomotion capabilities with excellent stability on challenging terrains and high efficiency on flat surfaces. However, existing wheel-legged robots typically have limited hip joint mobility compared to humans, while hip joint plays a crucial role in locomotion. In this paper, we introduce Whleaper, a novel 10-degree-of-freedom (DOF) bipedal wheeled robot, with 3 DOFs at the hip of each leg. Its humanoid joint design enables adaptable motion in complex scenarios, ensuring stability and flexibility. This paper introduces the details of Whleaper, with a focus on innovative mechanical design, control algorithms and system implementation. Firstly, stability stems from the increased DOFs at the hip, which expand the range of possible postures and improve the robot's foot-ground contact. Secondly, the extra DOFs also augment its mobility. During walking or sliding, more complex movements can be adopted to execute obstacle avoidance tasks. Thirdly, we utilize two control algorithms to implement multimodal motion for walking and sliding. By controlling specific DOFs of the robot, we conducted a series of simulations and practical experiments, demonstrating that a high-DOF hip joint design can effectively enhance the stability and flexibility of wheel-legged robots. Whleaper shows its capability to perform actions such as squatting, obstacle avoidance sliding, and rapid turning in real-world scenarios.","sentences":["Wheel-legged robots combine the advantages of both wheeled robots and legged robots, offering versatile locomotion capabilities with excellent stability on challenging terrains and high efficiency on flat surfaces.","However, existing wheel-legged robots typically have limited hip joint mobility compared to humans, while hip joint plays a crucial role in locomotion.","In this paper, we introduce Whleaper, a novel 10-degree-of-freedom (DOF) bipedal wheeled robot, with 3 DOFs at the hip of each leg.","Its humanoid joint design enables adaptable motion in complex scenarios, ensuring stability and flexibility.","This paper introduces the details of Whleaper, with a focus on innovative mechanical design, control algorithms and system implementation.","Firstly, stability stems from the increased DOFs at the hip, which expand the range of possible postures and improve the robot's foot-ground contact.","Secondly, the extra DOFs also augment its mobility.","During walking or sliding, more complex movements can be adopted to execute obstacle avoidance tasks.","Thirdly, we utilize two control algorithms to implement multimodal motion for walking and sliding.","By controlling specific DOFs of the robot, we conducted a series of simulations and practical experiments, demonstrating that a high-DOF hip joint design can effectively enhance the stability and flexibility of wheel-legged robots.","Whleaper shows its capability to perform actions such as squatting, obstacle avoidance sliding, and rapid turning in real-world scenarios."],"url":"http://arxiv.org/abs/2504.21767v1"}
{"created":"2025-04-30 15:46:55","title":"VDDP: Verifiable Distributed Differential Privacy under the Client-Server-Verifier Setup","abstract":"Despite differential privacy (DP) often being considered the de facto standard for data privacy, its realization is vulnerable to unfaithful execution of its mechanisms by servers, especially in distributed settings. Specifically, servers may sample noise from incorrect distributions or generate correlated noise while appearing to follow established protocols. This work analyzes these malicious behaviors in a general differential privacy framework within a distributed client-server-verifier setup. To address these adversarial problems, we propose a novel definition called Verifiable Distributed Differential Privacy (VDDP) by incorporating additional verification mechanisms. We also explore the relationship between zero-knowledge proofs (ZKP) and DP, demonstrating that while ZKPs are sufficient for achieving DP under verifiability requirements, they are not necessary. Furthermore, we develop two novel and efficient mechanisms that satisfy VDDP: (1) the Verifiable Distributed Discrete Laplacian Mechanism (VDDLM), which offers up to a $4 \\times 10^5$x improvement in proof generation efficiency with only 0.1-0.2x error compared to the previous state-of-the-art verifiable differentially private mechanism; (2) an improved solution to Verifiable Randomized Response (VRR) under local DP, a special case of VDDP, achieving up a reduction of up to 5000x in communication costs and the verifier's overhead.","sentences":["Despite differential privacy (DP) often being considered the de facto standard for data privacy, its realization is vulnerable to unfaithful execution of its mechanisms by servers, especially in distributed settings.","Specifically, servers may sample noise from incorrect distributions or generate correlated noise while appearing to follow established protocols.","This work analyzes these malicious behaviors in a general differential privacy framework within a distributed client-server-verifier setup.","To address these adversarial problems, we propose a novel definition called Verifiable Distributed Differential Privacy (VDDP) by incorporating additional verification mechanisms.","We also explore the relationship between zero-knowledge proofs (ZKP) and DP, demonstrating that while ZKPs are sufficient for achieving DP under verifiability requirements, they are not necessary.","Furthermore, we develop two novel and efficient mechanisms that satisfy VDDP: (1) the Verifiable Distributed Discrete Laplacian Mechanism (VDDLM), which offers up to a $4 \\times 10^5$x improvement in proof generation efficiency with only 0.1-0.2x error compared to the previous state-of-the-art verifiable differentially private mechanism; (2) an improved solution to Verifiable Randomized Response (VRR) under local DP, a special case of VDDP, achieving up a reduction of up to 5000x in communication costs and the verifier's overhead."],"url":"http://arxiv.org/abs/2504.21752v1"}
{"created":"2025-04-30 15:45:28","title":"CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation","abstract":"Real world development demands code that is readable, extensible, and testable by organizing the implementation into modular components and iteratively reuse pre-implemented code. We term this iterative, multi-turn process codeflow and introduce CodeFlowBench, the first benchmark designed for comprehensively evaluating LLMs' ability to perform codeflow, namely to implement new functionality by reusing existing functions over multiple turns. CodeFlowBench comprises 5258 problems drawn from Codeforces and is continuously updated via an automated pipeline that decomposes each problem into a series of function-level subproblems based on its dependency tree and each subproblem is paired with unit tests. We further propose a novel evaluation framework with tasks and metrics tailored to multi-turn code reuse to assess model performance. In experiments across various LLMs under both multi-turn and single-turn patterns. We observe models' poor performance on CodeFlowBench, with a substantial performance drop in the iterative codeflow scenario. For instance, o1-mini achieves a pass@1 of 20.8% in multi-turn pattern versus 37.8% in single-turn pattern. Further analysis shows that different models excel at different dependency depths, yet all struggle to correctly solve structurally complex problems, highlighting challenges for current LLMs to serve as code generation tools when performing codeflow. Overall, CodeFlowBench offers a comprehensive benchmark and new insights into LLM capabilities for multi-turn, iterative code generation, guiding future advances in code generation tasks.","sentences":["Real world development demands code that is readable, extensible, and testable by organizing the implementation into modular components and iteratively reuse pre-implemented code.","We term this iterative, multi-turn process codeflow and introduce CodeFlowBench, the first benchmark designed for comprehensively evaluating LLMs' ability to perform codeflow, namely to implement new functionality by reusing existing functions over multiple turns.","CodeFlowBench comprises 5258 problems drawn from Codeforces and is continuously updated via an automated pipeline that decomposes each problem into a series of function-level subproblems based on its dependency tree and each subproblem is paired with unit tests.","We further propose a novel evaluation framework with tasks and metrics tailored to multi-turn code reuse to assess model performance.","In experiments across various LLMs under both multi-turn and single-turn patterns.","We observe models' poor performance on CodeFlowBench, with a substantial performance drop in the iterative codeflow scenario.","For instance, o1-mini achieves a pass@1 of 20.8% in multi-turn pattern versus 37.8% in single-turn pattern.","Further analysis shows that different models excel at different dependency depths, yet all struggle to correctly solve structurally complex problems, highlighting challenges for current LLMs to serve as code generation tools when performing codeflow.","Overall, CodeFlowBench offers a comprehensive benchmark and new insights into LLM capabilities for multi-turn, iterative code generation, guiding future advances in code generation tasks."],"url":"http://arxiv.org/abs/2504.21751v1"}
{"created":"2025-04-30 15:42:43","title":"Online Knapsack Problems with Estimates","abstract":"Imagine you are a computer scientist who enjoys attending conferences or workshops within the year. Sadly, your travel budget is limited, so you must select a subset of events you can travel to.   When you are aware of all possible events and their costs at the beginning of the year, you can select the subset of the possible events that maximizes your happiness and is within your budget.   On the other hand, if you are blind about the options, you will likely have a hard time when trying to decide if you want to register somewhere or not, and will likely regret decisions you made in the future.   These scenarios can be modeled by knapsack variants, either by an offline or an online problem. However, both scenarios are somewhat unrealistic:   Usually, you will not know the exact costs of each workshop at the beginning of the year. The online version, however, is too pessimistic, as you might already know which options there are and how much they cost roughly. At some point, you have to decide whether to register for some workshop, but then you are aware of the conference fee and the flight and hotel prices.   We model this problem within the setting of online knapsack problems with estimates: in the beginning, you receive a list of potential items with their estimated size as well as the accuracy of the estimates. Then, the items are revealed one by one in an online fashion with their actual size, and you need to decide whether to take one or not. In this article, we show a best-possible algorithm for each estimate accuracy $\\delta$ (i.e., when each actual item size can deviate by $\\pm \\delta$ from the announced size) for both the simple knapsack and the simple knapsack with removability.","sentences":["Imagine you are a computer scientist who enjoys attending conferences or workshops within the year.","Sadly, your travel budget is limited, so you must select a subset of events you can travel to.   ","When you are aware of all possible events and their costs at the beginning of the year, you can select the subset of the possible events that maximizes your happiness and is within your budget.   ","On the other hand, if you are blind about the options, you will likely have a hard time when trying to decide if you want to register somewhere or not, and will likely regret decisions you made in the future.   ","These scenarios can be modeled by knapsack variants, either by an offline or an online problem.","However, both scenarios are somewhat unrealistic:   Usually, you will not know the exact costs of each workshop at the beginning of the year.","The online version, however, is too pessimistic, as you might already know which options there are and how much they cost roughly.","At some point, you have to decide whether to register for some workshop, but then you are aware of the conference fee and the flight and hotel prices.   ","We model this problem within the setting of online knapsack problems with estimates: in the beginning, you receive a list of potential items with their estimated size as well as the accuracy of the estimates.","Then, the items are revealed one by one in an online fashion with their actual size, and you need to decide whether to take one or not.","In this article, we show a best-possible algorithm for each estimate accuracy $\\delta$ (i.e., when each actual item size can deviate by $\\pm \\delta$ from the announced size) for both the simple knapsack and the simple knapsack with removability."],"url":"http://arxiv.org/abs/2504.21750v1"}
{"created":"2025-04-30 15:42:23","title":"Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space","abstract":"3D morphable models (3DMMs) are a powerful tool to represent the possible shapes and appearances of an object category. Given a single test image, 3DMMs can be used to solve various tasks, such as predicting the 3D shape, pose, semantic correspondence, and instance segmentation of an object. Unfortunately, 3DMMs are only available for very few object categories that are of particular interest, like faces or human bodies, as they require a demanding 3D data acquisition and category-specific training process. In contrast, we introduce a new method, Common3D, that learns 3DMMs of common objects in a fully self-supervised manner from a collection of object-centric videos. For this purpose, our model represents objects as a learned 3D template mesh and a deformation field that is parameterized as an image-conditioned neural network. Different from prior works, Common3D represents the object appearance with neural features instead of RGB colors, which enables the learning of more generalizable representations through an abstraction from pixel intensities. Importantly, we train the appearance features using a contrastive objective by exploiting the correspondences defined through the deformable template mesh. This leads to higher quality correspondence features compared to related works and a significantly improved model performance at estimating 3D object pose and semantic correspondence. Common3D is the first completely self-supervised method that can solve various vision tasks in a zero-shot manner.","sentences":["3D morphable models (3DMMs) are a powerful tool to represent the possible shapes and appearances of an object category.","Given a single test image, 3DMMs can be used to solve various tasks, such as predicting the 3D shape, pose, semantic correspondence, and instance segmentation of an object.","Unfortunately, 3DMMs are only available for very few object categories that are of particular interest, like faces or human bodies, as they require a demanding 3D data acquisition and category-specific training process.","In contrast, we introduce a new method, Common3D, that learns 3DMMs of common objects in a fully self-supervised manner from a collection of object-centric videos.","For this purpose, our model represents objects as a learned 3D template mesh and a deformation field that is parameterized as an image-conditioned neural network.","Different from prior works, Common3D represents the object appearance with neural features instead of RGB colors, which enables the learning of more generalizable representations through an abstraction from pixel intensities.","Importantly, we train the appearance features using a contrastive objective by exploiting the correspondences defined through the deformable template mesh.","This leads to higher quality correspondence features compared to related works and a significantly improved model performance at estimating 3D object pose and semantic correspondence.","Common3D is the first completely self-supervised method that can solve various vision tasks in a zero-shot manner."],"url":"http://arxiv.org/abs/2504.21749v1"}
{"created":"2025-04-30 15:41:03","title":"Improving Retrieval-Augmented Neural Machine Translation with Monolingual Data","abstract":"Conventional retrieval-augmented neural machine translation (RANMT) systems leverage bilingual corpora, e.g., translation memories (TMs). Yet, in many settings, in-domain monolingual target-side corpora are often available. This work explores ways to take advantage of such resources by retrieving relevant segments directly in the target language, based on a source-side query. For this, we design improved cross-lingual retrieval systems, trained with both sentence level and word-level matching objectives. In our experiments with two RANMT architectures, we first demonstrate the benefits of such cross-lingual objectives in a controlled setting, obtaining translation performances that surpass standard TM-based models. We then showcase our method on a real-world set-up, where the target monolingual resources far exceed the amount of parallel data and observe large improvements of our new techniques, which outperform both the baseline setting, and general-purpose cross-lingual retrievers.","sentences":["Conventional retrieval-augmented neural machine translation (RANMT) systems leverage bilingual corpora, e.g., translation memories (TMs).","Yet, in many settings, in-domain monolingual target-side corpora are often available.","This work explores ways to take advantage of such resources by retrieving relevant segments directly in the target language, based on a source-side query.","For this, we design improved cross-lingual retrieval systems, trained with both sentence level and word-level matching objectives.","In our experiments with two RANMT architectures, we first demonstrate the benefits of such cross-lingual objectives in a controlled setting, obtaining translation performances that surpass standard TM-based models.","We then showcase our method on a real-world set-up, where the target monolingual resources far exceed the amount of parallel data and observe large improvements of our new techniques, which outperform both the baseline setting, and general-purpose cross-lingual retrievers."],"url":"http://arxiv.org/abs/2504.21747v1"}
{"created":"2025-04-30 15:39:06","title":"Investigating Literary Motifs in Ancient and Medieval Novels with Large Language Models","abstract":"The Greek fictional narratives often termed love novels or romances, ranging from the first century CE to the middle of the 15th century, have long been considered as similar in many ways, not least in the use of particular literary motifs. By applying the use of fine-tuned large language models, this study aims to investigate which motifs exactly that the texts in this corpus have in common, and in which ways they differ from each other. The results show that while some motifs persist throughout the corpus, others fluctuate in frequency, indicating certain trends or external influences. Conclusively, the method proves to adequately extract literary motifs according to a set definition, providing data for both quantitative and qualitative analyses.","sentences":["The Greek fictional narratives often termed love novels or romances, ranging from the first century CE to the middle of the 15th century, have long been considered as similar in many ways, not least in the use of particular literary motifs.","By applying the use of fine-tuned large language models, this study aims to investigate which motifs exactly that the texts in this corpus have in common, and in which ways they differ from each other.","The results show that while some motifs persist throughout the corpus, others fluctuate in frequency, indicating certain trends or external influences.","Conclusively, the method proves to adequately extract literary motifs according to a set definition, providing data for both quantitative and qualitative analyses."],"url":"http://arxiv.org/abs/2504.21742v1"}
{"created":"2025-04-30 15:37:44","title":"Bilateral Differentially Private Vertical Federated Boosted Decision Trees","abstract":"Federated learning is a distributed machine learning paradigm that enables collaborative training across multiple parties while ensuring data privacy. Gradient Boosting Decision Trees (GBDT), such as XGBoost, have gained popularity due to their high performance and strong interpretability. Therefore, there has been a growing interest in adapting XGBoost for use in federated settings via cryptographic techniques. However, it should be noted that these approaches may not always provide rigorous theoretical privacy guarantees, and they often come with a high computational cost in terms of time and space requirements. In this paper, we propose a variant of vertical federated XGBoost with bilateral differential privacy guarantee: MaskedXGBoost. We build well-calibrated noise to perturb the intermediate information to protect privacy. The noise is structured with part of its ingredients in the null space of the arithmetical operation for splitting score evaluation in XGBoost, helping us achieve consistently better utility than other perturbation methods and relatively lower overhead than encryption-based techniques. We provide theoretical utility analysis and empirically verify privacy preservation. Compared with other algorithms, our algorithm's superiority in both utility and efficiency has been validated on multiple datasets.","sentences":["Federated learning is a distributed machine learning paradigm that enables collaborative training across multiple parties while ensuring data privacy.","Gradient Boosting Decision Trees (GBDT), such as XGBoost, have gained popularity due to their high performance and strong interpretability.","Therefore, there has been a growing interest in adapting XGBoost for use in federated settings via cryptographic techniques.","However, it should be noted that these approaches may not always provide rigorous theoretical privacy guarantees, and they often come with a high computational cost in terms of time and space requirements.","In this paper, we propose a variant of vertical federated XGBoost with bilateral differential privacy guarantee: MaskedXGBoost.","We build well-calibrated noise to perturb the intermediate information to protect privacy.","The noise is structured with part of its ingredients in the null space of the arithmetical operation for splitting score evaluation in XGBoost, helping us achieve consistently better utility than other perturbation methods and relatively lower overhead than encryption-based techniques.","We provide theoretical utility analysis and empirically verify privacy preservation.","Compared with other algorithms, our algorithm's superiority in both utility and efficiency has been validated on multiple datasets."],"url":"http://arxiv.org/abs/2504.21739v1"}
{"created":"2025-04-30 15:37:23","title":"LangWBC: Language-directed Humanoid Whole-Body Control via End-to-end Learning","abstract":"General-purpose humanoid robots are expected to interact intuitively with humans, enabling seamless integration into daily life. Natural language provides the most accessible medium for this purpose. However, translating language into humanoid whole-body motion remains a significant challenge, primarily due to the gap between linguistic understanding and physical actions. In this work, we present an end-to-end, language-directed policy for real-world humanoid whole-body control. Our approach combines reinforcement learning with policy distillation, allowing a single neural network to interpret language commands and execute corresponding physical actions directly. To enhance motion diversity and compositionality, we incorporate a Conditional Variational Autoencoder (CVAE) structure. The resulting policy achieves agile and versatile whole-body behaviors conditioned on language inputs, with smooth transitions between various motions, enabling adaptation to linguistic variations and the emergence of novel motions. We validate the efficacy and generalizability of our method through extensive simulations and real-world experiments, demonstrating robust whole-body control. Please see our website at LangWBC.github.io for more information.","sentences":["General-purpose humanoid robots are expected to interact intuitively with humans, enabling seamless integration into daily life.","Natural language provides the most accessible medium for this purpose.","However, translating language into humanoid whole-body motion remains a significant challenge, primarily due to the gap between linguistic understanding and physical actions.","In this work, we present an end-to-end, language-directed policy for real-world humanoid whole-body control.","Our approach combines reinforcement learning with policy distillation, allowing a single neural network to interpret language commands and execute corresponding physical actions directly.","To enhance motion diversity and compositionality, we incorporate a Conditional Variational Autoencoder (CVAE) structure.","The resulting policy achieves agile and versatile whole-body behaviors conditioned on language inputs, with smooth transitions between various motions, enabling adaptation to linguistic variations and the emergence of novel motions.","We validate the efficacy and generalizability of our method through extensive simulations and real-world experiments, demonstrating robust whole-body control.","Please see our website at LangWBC.github.io for more information."],"url":"http://arxiv.org/abs/2504.21738v1"}
{"created":"2025-04-30 15:31:52","title":"TheraQuest: A Gamified, LLM-Powered Simulation for Massage Therapy Training","abstract":"Massage therapy training emphasizes hands-on techniques and effective therapist--patient communication. However, many educational programs struggle to provide realistic practice scenarios. To address this problem, we propose TheraQuest, a gamified, web-based simulation platform that employs large language models (LLMs) to generate diverse virtual patients with varying symptoms and cultural backgrounds. Through interactive dialogue, anatomical decision-making, and immediate assessment, trainees develop both diagnostic reasoning and empathetic communication skills in a low-risk environment. Unlike exclusively VR-based solutions, TheraQuest remains accessible via standard web browsers, mitigating the cost and discomfort associated with extended headset use. Preliminary testing suggests that integrating LLM-driven virtual patients with real-time skill metrics can enhance trainee engagement and help bridge the gap between theoretical knowledge and clinical proficiency.","sentences":["Massage therapy training emphasizes hands-on techniques and effective therapist--patient communication.","However, many educational programs struggle to provide realistic practice scenarios.","To address this problem, we propose TheraQuest, a gamified, web-based simulation platform that employs large language models (LLMs) to generate diverse virtual patients with varying symptoms and cultural backgrounds.","Through interactive dialogue, anatomical decision-making, and immediate assessment, trainees develop both diagnostic reasoning and empathetic communication skills in a low-risk environment.","Unlike exclusively VR-based solutions, TheraQuest remains accessible via standard web browsers, mitigating the cost and discomfort associated with extended headset use.","Preliminary testing suggests that integrating LLM-driven virtual patients with real-time skill metrics can enhance trainee engagement and help bridge the gap between theoretical knowledge and clinical proficiency."],"url":"http://arxiv.org/abs/2504.21735v1"}
{"created":"2025-04-30 15:21:36","title":"Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement Learning","abstract":"Mixed Reality (MR) could assist users' tasks by continuously integrating virtual content with their view of the physical environment. However, where and how to place these content to best support the users has been a challenging problem due to the dynamic nature of MR experiences. In contrast to prior work that investigates optimization-based methods, we are exploring how reinforcement learning (RL) could assist with continuous 3D content placement that is aware of users' poses and their surrounding environments. Through an initial exploration and preliminary evaluation, our results demonstrate the potential of RL to position content that maximizes the reward for users on the go. We further identify future directions for research that could harness the power of RL for personalized and optimized UI and content placement in MR.","sentences":["Mixed Reality (MR) could assist users' tasks by continuously integrating virtual content with their view of the physical environment.","However, where and how to place these content to best support the users has been a challenging problem due to the dynamic nature of MR experiences.","In contrast to prior work that investigates optimization-based methods, we are exploring how reinforcement learning (RL) could assist with continuous 3D content placement that is aware of users' poses and their surrounding environments.","Through an initial exploration and preliminary evaluation, our results demonstrate the potential of RL to position content that maximizes the reward for users on the go.","We further identify future directions for research that could harness the power of RL for personalized and optimized UI and content placement in MR."],"url":"http://arxiv.org/abs/2504.21731v1"}
{"created":"2025-04-30 15:21:25","title":"Cert-SSB: Toward Certified Sample-Specific Backdoor Defense","abstract":"Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an attacker manipulates a small portion of the training data to implant hidden backdoors into the model. The compromised model behaves normally on clean samples but misclassifies backdoored samples into the attacker-specified target class, posing a significant threat to real-world DNN applications. Currently, several empirical defense methods have been proposed to mitigate backdoor attacks, but they are often bypassed by more advanced backdoor techniques. In contrast, certified defenses based on randomized smoothing have shown promise by adding random noise to training and testing samples to counteract backdoor attacks. In this paper, we reveal that existing randomized smoothing defenses implicitly assume that all samples are equidistant from the decision boundary. However, it may not hold in practice, leading to suboptimal certification performance. To address this issue, we propose a sample-specific certified backdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic gradient ascent to optimize the noise magnitude for each sample, ensuring a sample-specific noise level that is then applied to multiple poisoned training sets to retrain several smoothed models. After that, Cert-SSB aggregates the predictions of multiple smoothed models to generate the final robust prediction. In particular, in this case, existing certification methods become inapplicable since the optimized noise varies across different samples. To conquer this challenge, we introduce a storage-update-based certification method, which dynamically adjusts each sample's certification region to improve certification performance. We conduct extensive experiments on multiple benchmark datasets, demonstrating the effectiveness of our proposed method. Our code is available at https://github.com/NcepuQiaoTing/Cert-SSB.","sentences":["Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an attacker manipulates a small portion of the training data to implant hidden backdoors into the model.","The compromised model behaves normally on clean samples but misclassifies backdoored samples into the attacker-specified target class, posing a significant threat to real-world DNN applications.","Currently, several empirical defense methods have been proposed to mitigate backdoor attacks, but they are often bypassed by more advanced backdoor techniques.","In contrast, certified defenses based on randomized smoothing have shown promise by adding random noise to training and testing samples to counteract backdoor attacks.","In this paper, we reveal that existing randomized smoothing defenses implicitly assume that all samples are equidistant from the decision boundary.","However, it may not hold in practice, leading to suboptimal certification performance.","To address this issue, we propose a sample-specific certified backdoor defense method, termed Cert-SSB.","Cert-SSB first employs stochastic gradient ascent to optimize the noise magnitude for each sample, ensuring a sample-specific noise level that is then applied to multiple poisoned training sets to retrain several smoothed models.","After that, Cert-SSB aggregates the predictions of multiple smoothed models to generate the final robust prediction.","In particular, in this case, existing certification methods become inapplicable since the optimized noise varies across different samples.","To conquer this challenge, we introduce a storage-update-based certification method, which dynamically adjusts each sample's certification region to improve certification performance.","We conduct extensive experiments on multiple benchmark datasets, demonstrating the effectiveness of our proposed method.","Our code is available at https://github.com/NcepuQiaoTing/Cert-SSB."],"url":"http://arxiv.org/abs/2504.21730v1"}
{"created":"2025-04-30 15:20:10","title":"Asymptotic Analysis of Weighted Fair Division","abstract":"Several resource allocation settings involve agents with unequal entitlements represented by weights. We analyze weighted fair division from an asymptotic perspective: if $m$ items are divided among $n$ agents whose utilities are independently sampled from a probability distribution, when is it likely that a fair allocation exist? We show that if the ratio between the weights is bounded, a weighted envy-free allocation exists with high probability provided that $m = \\Omega(n\\log n/\\log\\log n)$, generalizing a prior unweighted result. For weighted proportionality, we establish a sharp threshold of $m = n/(1-\\mu)$ for the transition from non-existence to existence, where $\\mu\\in (0,1)$ denotes the mean of the distribution. In addition, we prove that for two agents, a weighted envy-free (and weighted proportional) allocation is likely to exist if $m = \\omega(\\sqrt{r})$, where $r$ denotes the ratio between the two weights.","sentences":["Several resource allocation settings involve agents with unequal entitlements represented by weights.","We analyze weighted fair division from an asymptotic perspective: if $m$ items are divided among $n$ agents whose utilities are independently sampled from a probability distribution, when is it likely that a fair allocation exist?","We show that if the ratio between the weights is bounded, a weighted envy-free allocation exists with high probability provided that $m = \\Omega(n\\log n/\\log\\log n)$, generalizing a prior unweighted result.","For weighted proportionality, we establish a sharp threshold of $m = n/(1-\\mu)$ for the transition from non-existence to existence, where $\\mu\\in (0,1)$ denotes the mean of the distribution.","In addition, we prove that for two agents, a weighted envy-free (and weighted proportional) allocation is likely to exist if $m = \\omega(\\sqrt{r})$, where $r$ denotes the ratio between the two weights."],"url":"http://arxiv.org/abs/2504.21728v1"}
{"created":"2025-04-30 15:06:44","title":"Generalizing Biased Backpressure Routing and Scheduling to Wireless Multi-hop Networks with Advanced Air-interfaces","abstract":"Backpressure (BP) routing and scheduling is a well-established resource allocation method for wireless multi-hop networks, known for its fully distributed operations and proven maximum queue stability. Recent advances in shortest path-biased BP routing (SP-BP) mitigate shortcomings such as slow startup and random walk, but exclusive link-level commodity selection still suffers from the last-packet problem and bandwidth underutilization. Moreover, classic BP routing implicitly assumes single-input-single-output (SISO) transceivers, which can lead to the same packets being scheduled on multiple outgoing links for multiple-input-multiple-output (MIMO) transceivers, causing detouring and looping in MIMO networks. In this paper, we revisit the foundational Lyapunov drift theory underlying BP routing and demonstrate that exclusive commodity selection is unnecessary, and instead propose a Max-Utility link-sharing method. Additionally, we generalize MaxWeight scheduling to MIMO networks by introducing attributed capacity hypergraphs (ACH), an extension of traditional conflict graphs for SISO networks, and by incorporating backlog reassignment into scheduling iterations to prevent redundant packet routing. Numerical evaluations show that our approach substantially mitigates the last-packet problem in state-of-the-art (SOTA) SP-BP under lightweight traffic, and slightly expands the network capacity region for heavier traffic.","sentences":["Backpressure (BP) routing and scheduling is a well-established resource allocation method for wireless multi-hop networks, known for its fully distributed operations and proven maximum queue stability.","Recent advances in shortest path-biased BP routing (SP-BP) mitigate shortcomings such as slow startup and random walk, but exclusive link-level commodity selection still suffers from the last-packet problem and bandwidth underutilization.","Moreover, classic BP routing implicitly assumes single-input-single-output (SISO) transceivers, which can lead to the same packets being scheduled on multiple outgoing links for multiple-input-multiple-output (MIMO) transceivers, causing detouring and looping in MIMO networks.","In this paper, we revisit the foundational Lyapunov drift theory underlying BP routing and demonstrate that exclusive commodity selection is unnecessary, and instead propose a Max-Utility link-sharing method.","Additionally, we generalize MaxWeight scheduling to MIMO networks by introducing attributed capacity hypergraphs (ACH), an extension of traditional conflict graphs for SISO networks, and by incorporating backlog reassignment into scheduling iterations to prevent redundant packet routing.","Numerical evaluations show that our approach substantially mitigates the last-packet problem in state-of-the-art (SOTA) SP-BP under lightweight traffic, and slightly expands the network capacity region for heavier traffic."],"url":"http://arxiv.org/abs/2504.21721v1"}
{"created":"2025-04-30 15:05:20","title":"Sionna RT: Technical Report","abstract":"Sionna is an open-source, GPU-accelerated library that, as of version 0.14, incorporates a ray tracer for simulating radio wave propagation. A unique feature of Sionna RT is differentiability, enabling the calculation of gradients for the channel impulse responses (CIRs), radio maps, and other related metrics with respect to system and environmental parameters, such as material properties, antenna patterns, and array geometries. The release of Sionna 1.0 provides a complete overhaul of the ray tracer, significantly improving its speed, memory efficiency, and extensibility. This document details the algorithms employed by Sionna RT to simulate radio wave propagation efficiently, while also addressing their current limitations. Given that the computation of CIRs and radio maps requires distinct algorithms, these are detailed in separate sections. For CIRs, Sionna RT integrates shooting and bouncing of rays (SBR) with the image method and uses a hashing-based mechanism to efficiently eliminate duplicate paths. Radio maps are computed using a purely SBR-based approach.","sentences":["Sionna is an open-source, GPU-accelerated library that, as of version 0.14, incorporates a ray tracer for simulating radio wave propagation.","A unique feature of Sionna RT is differentiability, enabling the calculation of gradients for the channel impulse responses (CIRs), radio maps, and other related metrics with respect to system and environmental parameters, such as material properties, antenna patterns, and array geometries.","The release of Sionna 1.0 provides a complete overhaul of the ray tracer, significantly improving its speed, memory efficiency, and extensibility.","This document details the algorithms employed by Sionna RT to simulate radio wave propagation efficiently, while also addressing their current limitations.","Given that the computation of CIRs and radio maps requires distinct algorithms, these are detailed in separate sections.","For CIRs, Sionna RT integrates shooting and bouncing of rays (SBR) with the image method and uses a hashing-based mechanism to efficiently eliminate duplicate paths.","Radio maps are computed using a purely SBR-based approach."],"url":"http://arxiv.org/abs/2504.21719v1"}
{"created":"2025-04-30 15:05:12","title":"VividListener: Expressive and Controllable Listener Dynamics Modeling for Multi-Modal Responsive Interaction","abstract":"Generating responsive listener head dynamics with nuanced emotions and expressive reactions is crucial for practical dialogue modeling in various virtual avatar animations. Previous studies mainly focus on the direct short-term production of listener behavior. They overlook the fine-grained control over motion variations and emotional intensity, especially in long-sequence modeling. Moreover, the lack of long-term and large-scale paired speaker-listener corpora including head dynamics and fine-grained multi-modality annotations (e.g., text-based expression descriptions, emotional intensity) also limits the application of dialogue modeling.Therefore, we first newly collect a large-scale multi-turn dataset of 3D dyadic conversation containing more than 1.4M valid frames for multi-modal responsive interaction, dubbed ListenerX. Additionally, we propose VividListener, a novel framework enabling fine-grained, expressive and controllable listener dynamics modeling. This framework leverages multi-modal conditions as guiding principles for fostering coherent interactions between speakers and listeners.Specifically, we design the Responsive Interaction Module (RIM) to adaptively represent the multi-modal interactive embeddings. RIM ensures the listener dynamics achieve fine-grained semantic coordination with textual descriptions and adjustments, while preserving expressive reaction with speaker behavior. Meanwhile, we design the Emotional Intensity Tags (EIT) for emotion intensity editing with multi-modal information integration, applying to both text descriptions and listener motion amplitude.Extensive experiments conducted on our newly collected ListenerX dataset demonstrate that VividListener achieves state-of-the-art performance, realizing expressive and controllable listener dynamics.","sentences":["Generating responsive listener head dynamics with nuanced emotions and expressive reactions is crucial for practical dialogue modeling in various virtual avatar animations.","Previous studies mainly focus on the direct short-term production of listener behavior.","They overlook the fine-grained control over motion variations and emotional intensity, especially in long-sequence modeling.","Moreover, the lack of long-term and large-scale paired speaker-listener corpora including head dynamics and fine-grained multi-modality annotations (e.g., text-based expression descriptions, emotional intensity) also limits the application of dialogue modeling.","Therefore, we first newly collect a large-scale multi-turn dataset of 3D dyadic conversation containing more than 1.4M valid frames for multi-modal responsive interaction, dubbed ListenerX.","Additionally, we propose VividListener, a novel framework enabling fine-grained, expressive and controllable listener dynamics modeling.","This framework leverages multi-modal conditions as guiding principles for fostering coherent interactions between speakers and listeners.","Specifically, we design the Responsive Interaction Module (RIM) to adaptively represent the multi-modal interactive embeddings.","RIM ensures the listener dynamics achieve fine-grained semantic coordination with textual descriptions and adjustments, while preserving expressive reaction with speaker behavior.","Meanwhile, we design the Emotional Intensity Tags (EIT) for emotion intensity editing with multi-modal information integration, applying to both text descriptions and listener motion amplitude.","Extensive experiments conducted on our newly collected ListenerX dataset demonstrate that VividListener achieves state-of-the-art performance, realizing expressive and controllable listener dynamics."],"url":"http://arxiv.org/abs/2504.21718v1"}
{"created":"2025-04-30 15:00:20","title":"LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics","abstract":"We present an embodied robotic system with an LLM-driven agent-orchestration architecture for autonomous household object management. The system integrates memory-augmented task planning, enabling robots to execute high-level user commands while tracking past actions. It employs three specialized agents: a routing agent, a task planning agent, and a knowledge base agent, each powered by task-specific LLMs. By leveraging in-context learning, our system avoids the need for explicit model training. RAG enables the system to retrieve context from past interactions, enhancing long-term object tracking. A combination of Grounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating semantic scene understanding for task planning. Evaluation across three household scenarios demonstrates high task planning accuracy and an improvement in memory recall due to RAG. Specifically, Qwen2.5 yields best performance for specialized agents, while LLaMA3.1 excels in routing tasks. The source code is available at: https://github.com/marc1198/chat-hsr.","sentences":["We present an embodied robotic system with an LLM-driven agent-orchestration architecture for autonomous household object management.","The system integrates memory-augmented task planning, enabling robots to execute high-level user commands while tracking past actions.","It employs three specialized agents: a routing agent, a task planning agent, and a knowledge base agent, each powered by task-specific LLMs.","By leveraging in-context learning, our system avoids the need for explicit model training.","RAG enables the system to retrieve context from past interactions, enhancing long-term object tracking.","A combination of Grounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating semantic scene understanding for task planning.","Evaluation across three household scenarios demonstrates high task planning accuracy and an improvement in memory recall due to RAG.","Specifically, Qwen2.5 yields best performance for specialized agents, while LLaMA3.1 excels in routing tasks.","The source code is available at: https://github.com/marc1198/chat-hsr."],"url":"http://arxiv.org/abs/2504.21716v1"}
{"created":"2025-04-30 14:52:31","title":"Computing Polynomial Representation in Subrings of Multivariate Polynomial Rings","abstract":"Let $\\mathcal{R} = \\mathbb{K}[x_1, \\dots, x_n]$ be a multivariate polynomial ring over a field $\\mathbb{K}$ of characteristic 0. Consider $n$ algebraically independent elements $g_1, \\dots, g_n$ in $\\mathcal{R}$. Let $\\mathcal{S}$ denote the subring of $\\mathcal{R}$ generated by $g_1, \\dots, g_n$, and let $h$ be an element of $\\mathcal{S}$. Then, there exists a unique element ${f} \\in \\mathbb{K}[u_1, \\dots, u_n]$ such that $h = f(g_1, \\dots, g_n)$.   In this paper, we provide an algorithm for computing ${f}$, given $h$ and $g_1, \\dots, g_n$. The complexity of our algorithm is linear in the size of the input, $h$ and $g_1, \\dots, g_n$, and polynomial in $n$ when the degree of $f$ is fixed. Previous works are mostly known when $f$ is a symmetric polynomial and $g_1, \\dots, g_n$ are elementary symmetric, homogeneous symmetric, or power symmetric polynomials.","sentences":["Let $\\mathcal{R} = \\mathbb{K}[x_1, \\dots, x_n]$ be a multivariate polynomial ring over a field $\\mathbb{K}$ of characteristic 0.","Consider $n$ algebraically independent elements $g_1, \\dots, g_n$ in $\\mathcal{R}$. Let $\\mathcal{S}$ denote the subring of $\\mathcal{R}$ generated by $g_1, \\dots, g_n$, and let $h$ be an element of $\\mathcal{S}$. Then, there exists a unique element ${f} \\in \\mathbb{K}[u_1, \\dots, u_n]$ such that $h = f(g_1, \\dots, g_n)$.   In this paper, we provide an algorithm for computing ${f}$, given $h$ and $g_1, \\dots, g_n$. The complexity of our algorithm is linear in the size of the input, $h$ and $g_1, \\dots, g_n$, and polynomial in $n$ when the degree of $f$ is fixed.","Previous works are mostly known when $f$ is a symmetric polynomial and $g_1, \\dots, g_n$ are elementary symmetric, homogeneous symmetric, or power symmetric polynomials."],"url":"http://arxiv.org/abs/2504.21708v1"}
{"created":"2025-04-30 14:51:27","title":"Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning","abstract":"We propose a generalization of modern representation learning objectives by reframing them as recursive divergence alignment processes over localized conditional distributions While recent frameworks like Information Contrastive Learning I-Con unify multiple learning paradigms through KL divergence between fixed neighborhood conditionals we argue this view underplays a crucial recursive structure inherent in the learning process. We introduce Recursive KL Divergence Optimization RKDO a dynamic formalism where representation learning is framed as the evolution of KL divergences across data neighborhoods. This formulation captures contrastive clustering and dimensionality reduction methods as static slices while offering a new path to model stability and local adaptation. Our experiments demonstrate that RKDO offers dual efficiency advantages approximately 30 percent lower loss values compared to static approaches across three different datasets and 60 to 80 percent reduction in computational resources needed to achieve comparable results. This suggests that RKDOs recursive updating mechanism provides a fundamentally more efficient optimization landscape for representation learning with significant implications for resource constrained applications.","sentences":["We propose a generalization of modern representation learning objectives by reframing them as recursive divergence alignment processes over localized conditional distributions While recent frameworks like Information Contrastive Learning I-Con unify multiple learning paradigms through KL divergence between fixed neighborhood conditionals we argue this view underplays a crucial recursive structure inherent in the learning process.","We introduce Recursive KL Divergence Optimization RKDO a dynamic formalism where representation learning is framed as the evolution of KL divergences across data neighborhoods.","This formulation captures contrastive clustering and dimensionality reduction methods as static slices while offering a new path to model stability and local adaptation.","Our experiments demonstrate that RKDO offers dual efficiency advantages approximately 30 percent lower loss values compared to static approaches across three different datasets and 60 to 80 percent reduction in computational resources needed to achieve comparable results.","This suggests that RKDOs recursive updating mechanism provides a fundamentally more efficient optimization landscape for representation learning with significant implications for resource constrained applications."],"url":"http://arxiv.org/abs/2504.21707v1"}
{"created":"2025-04-30 14:50:02","title":"Vision Transformers in Precision Agriculture: A Comprehensive Survey","abstract":"Detecting plant diseases is a crucial aspect of modern agriculture - it plays a key role in maintaining crop health and increasing overall yield. Traditional approaches, though still valuable, often rely on manual inspection or conventional machine learning techniques, both of which face limitations in scalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as a promising alternative, offering benefits such as improved handling of long-range dependencies and better scalability for visual tasks. This survey explores the application of ViTs in precision agriculture, covering tasks from classification to detection and segmentation. We begin by introducing the foundational architecture of ViTs and discuss their transition from Natural Language Processing (NLP) to computer vision. The discussion includes the concept of inductive bias in traditional models like Convolutional Neural Networks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive review of recent literature, focusing on key methodologies, datasets, and performance metrics. The survey also includes a comparative analysis of CNNs and ViTs, with a look at hybrid models and performance enhancements. Technical challenges - such as data requirements, computational demands, and model interpretability - are addressed alongside potential solutions. Finally, we outline potential research directions and technological advancements that could further support the integration of ViTs in real-world agricultural settings. Our goal with this study is to offer practitioners and researchers a deeper understanding of how ViTs are poised to transform smart and precision agriculture.","sentences":["Detecting plant diseases is a crucial aspect of modern agriculture - it plays a key role in maintaining crop health and increasing overall yield.","Traditional approaches, though still valuable, often rely on manual inspection or conventional machine learning techniques, both of which face limitations in scalability and accuracy.","Recently, Vision Transformers (ViTs) have emerged as a promising alternative, offering benefits such as improved handling of long-range dependencies and better scalability for visual tasks.","This survey explores the application of ViTs in precision agriculture, covering tasks from classification to detection and segmentation.","We begin by introducing the foundational architecture of ViTs and discuss their transition from Natural Language Processing (NLP) to computer vision.","The discussion includes the concept of inductive bias in traditional models like Convolutional Neural Networks (CNNs), and how ViTs mitigate these biases.","We provide a comprehensive review of recent literature, focusing on key methodologies, datasets, and performance metrics.","The survey also includes a comparative analysis of CNNs and ViTs, with a look at hybrid models and performance enhancements.","Technical challenges - such as data requirements, computational demands, and model interpretability - are addressed alongside potential solutions.","Finally, we outline potential research directions and technological advancements that could further support the integration of ViTs in real-world agricultural settings.","Our goal with this study is to offer practitioners and researchers a deeper understanding of how ViTs are poised to transform smart and precision agriculture."],"url":"http://arxiv.org/abs/2504.21706v1"}
{"created":"2025-04-30 14:45:20","title":"A Conversational Approach to Well-being Awareness Creation and Behavioural Intention","abstract":"The promotion of a healthy lifestyle is one of the main drivers of an individual's overall physical and psycho-emotional well-being. Digital technologies are more and more adopted as ''facilitators'' for this goal, to raise awareness and solicit healthy lifestyle habits.   This study aims to experiment the effects of the adoption of a digital conversational tool to influence awareness creation and behavioural change in the context of a well-being lifestyle. Our aim is to collect evidence of the aspects that must be taken into account when designing and implementing such tools in well-being promotion campaigns.   To this end, we created a conversational application for promoting well-being and healthy lifestyles, which presents relevant information and asks specific questions to its intended users within an interaction happening through a chat interface; the conversational tool presents itself as a well-being counsellor named Allegra and follows a coaching approach to structure the interaction with the user. In our user study, participants were asked to first interact with Allegra in one of three experimental conditions, corresponding to different conversational styles; then, they answered a questionnaire about their experience. The questionnaire items were related to intrinsic motivation factors as well as awareness creation and behavioural change. The collected data allowed us to assess the hypotheses of our model that put in connection those variables.   Our results confirm the positive effect of intrinsic motivation factors on both awareness creation and behavioural intention in the context of well-being and healthy lifestyle; on the other hand, we did not record any statistically significant effect of different language and communication styles on the outcomes.","sentences":["The promotion of a healthy lifestyle is one of the main drivers of an individual's overall physical and psycho-emotional well-being.","Digital technologies are more and more adopted as ''facilitators'' for this goal, to raise awareness and solicit healthy lifestyle habits.   ","This study aims to experiment the effects of the adoption of a digital conversational tool to influence awareness creation and behavioural change in the context of a well-being lifestyle.","Our aim is to collect evidence of the aspects that must be taken into account when designing and implementing such tools in well-being promotion campaigns.   ","To this end, we created a conversational application for promoting well-being and healthy lifestyles, which presents relevant information and asks specific questions to its intended users within an interaction happening through a chat interface; the conversational tool presents itself as a well-being counsellor named Allegra and follows a coaching approach to structure the interaction with the user.","In our user study, participants were asked to first interact with Allegra in one of three experimental conditions, corresponding to different conversational styles; then, they answered a questionnaire about their experience.","The questionnaire items were related to intrinsic motivation factors as well as awareness creation and behavioural change.","The collected data allowed us to assess the hypotheses of our model that put in connection those variables.   ","Our results confirm the positive effect of intrinsic motivation factors on both awareness creation and behavioural intention in the context of well-being and healthy lifestyle; on the other hand, we did not record any statistically significant effect of different language and communication styles on the outcomes."],"url":"http://arxiv.org/abs/2504.21702v1"}
{"created":"2025-04-30 14:44:24","title":"XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs","abstract":"Large Language Models are fundamental actors in the modern IT landscape dominated by AI solutions. However, security threats associated with them might prevent their reliable adoption in critical application scenarios such as government organizations and medical institutions. For this reason, commercial LLMs typically undergo a sophisticated censoring mechanism to eliminate any harmful output they could possibly produce. In response to this, LLM Jailbreaking is a significant threat to such protections, and many previous approaches have already demonstrated its effectiveness across diverse domains. Existing jailbreak proposals mostly adopt a generate-and-test strategy to craft malicious input. To improve the comprehension of censoring mechanisms and design a targeted jailbreak attack, we propose an Explainable-AI solution that comparatively analyzes the behavior of censored and uncensored models to derive unique exploitable alignment patterns. Then, we propose XBreaking, a novel jailbreak attack that exploits these unique patterns to break the security constraints of LLMs by targeted noise injection. Our thorough experimental campaign returns important insights about the censoring mechanisms and demonstrates the effectiveness and performance of our attack.","sentences":["Large Language Models are fundamental actors in the modern IT landscape dominated by AI solutions.","However, security threats associated with them might prevent their reliable adoption in critical application scenarios such as government organizations and medical institutions.","For this reason, commercial LLMs typically undergo a sophisticated censoring mechanism to eliminate any harmful output they could possibly produce.","In response to this, LLM Jailbreaking is a significant threat to such protections, and many previous approaches have already demonstrated its effectiveness across diverse domains.","Existing jailbreak proposals mostly adopt a generate-and-test strategy to craft malicious input.","To improve the comprehension of censoring mechanisms and design a targeted jailbreak attack, we propose an Explainable-AI solution that comparatively analyzes the behavior of censored and uncensored models to derive unique exploitable alignment patterns.","Then, we propose XBreaking, a novel jailbreak attack that exploits these unique patterns to break the security constraints of LLMs by targeted noise injection.","Our thorough experimental campaign returns important insights about the censoring mechanisms and demonstrates the effectiveness and performance of our attack."],"url":"http://arxiv.org/abs/2504.21700v1"}
{"created":"2025-04-30 14:43:38","title":"REHEARSE-3D: A Multi-modal Emulated Rain Dataset for 3D Point Cloud De-raining","abstract":"Sensor degradation poses a significant challenge in autonomous driving. During heavy rainfall, the interference from raindrops can adversely affect the quality of LiDAR point clouds, resulting in, for instance, inaccurate point measurements. This, in turn, can potentially lead to safety concerns if autonomous driving systems are not weather-aware, i.e., if they are unable to discern such changes. In this study, we release a new, large-scale, multi-modal emulated rain dataset, REHEARSE-3D, to promote research advancements in 3D point cloud de-raining. Distinct from the most relevant competitors, our dataset is unique in several respects. First, it is the largest point-wise annotated dataset, and second, it is the only one with high-resolution LiDAR data (LiDAR-256) enriched with 4D Radar point clouds logged in both daytime and nighttime conditions in a controlled weather environment. Furthermore, REHEARSE-3D involves rain-characteristic information, which is of significant value not only for sensor noise modeling but also for analyzing the impact of weather at a point level. Leveraging REHEARSE-3D, we benchmark raindrop detection and removal in fused LiDAR and 4D Radar point clouds. Our comprehensive study further evaluates the performance of various statistical and deep-learning models. Upon publication, the dataset and benchmark models will be made publicly available at: https://sporsho.github.io/REHEARSE3D.","sentences":["Sensor degradation poses a significant challenge in autonomous driving.","During heavy rainfall, the interference from raindrops can adversely affect the quality of LiDAR point clouds, resulting in, for instance, inaccurate point measurements.","This, in turn, can potentially lead to safety concerns if autonomous driving systems are not weather-aware, i.e., if they are unable to discern such changes.","In this study, we release a new, large-scale, multi-modal emulated rain dataset, REHEARSE-3D, to promote research advancements in 3D point cloud de-raining.","Distinct from the most relevant competitors, our dataset is unique in several respects.","First, it is the largest point-wise annotated dataset, and second, it is the only one with high-resolution LiDAR data (LiDAR-256) enriched with 4D Radar point clouds logged in both daytime and nighttime conditions in a controlled weather environment.","Furthermore, REHEARSE-3D involves rain-characteristic information, which is of significant value not only for sensor noise modeling but also for analyzing the impact of weather at a point level.","Leveraging REHEARSE-3D, we benchmark raindrop detection and removal in fused LiDAR and 4D Radar point clouds.","Our comprehensive study further evaluates the performance of various statistical and deep-learning models.","Upon publication, the dataset and benchmark models will be made publicly available at: https://sporsho.github.io/REHEARSE3D."],"url":"http://arxiv.org/abs/2504.21699v1"}
{"created":"2025-04-30 14:38:01","title":"Self-Supervised Monocular Visual Drone Model Identification through Improved Occlusion Handling","abstract":"Ego-motion estimation is vital for drones when flying in GPS-denied environments. Vision-based methods struggle when flight speed increases and close-by objects lead to difficult visual conditions with considerable motion blur and large occlusions. To tackle this, vision is typically complemented by state estimation filters that combine a drone model with inertial measurements. However, these drone models are currently learned in a supervised manner with ground-truth data from external motion capture systems, limiting scalability to different environments and drones. In this work, we propose a self-supervised learning scheme to train a neural-network-based drone model using only onboard monocular video and flight controller data (IMU and motor feedback). We achieve this by first training a self-supervised relative pose estimation model, which then serves as a teacher for the drone model. To allow this to work at high speed close to obstacles, we propose an improved occlusion handling method for training self-supervised pose estimation models. Due to this method, the root mean squared error of resulting odometry estimates is reduced by an average of 15%. Moreover, the student neural drone model can be successfully obtained from the onboard data. It even becomes more accurate at higher speeds compared to its teacher, the self-supervised vision-based model. We demonstrate the value of the neural drone model by integrating it into a traditional filter-based VIO system (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing trajectories near obstacles. Self-supervised learning of ego-motion estimation represents a significant step toward bridging the gap between flying in controlled, expensive lab environments and real-world drone applications. The fusion of vision and drone models will enable higher-speed flight and improve state estimation, on any drone in any environment.","sentences":["Ego-motion estimation is vital for drones when flying in GPS-denied environments.","Vision-based methods struggle when flight speed increases and close-by objects lead to difficult visual conditions with considerable motion blur and large occlusions.","To tackle this, vision is typically complemented by state estimation filters that combine a drone model with inertial measurements.","However, these drone models are currently learned in a supervised manner with ground-truth data from external motion capture systems, limiting scalability to different environments and drones.","In this work, we propose a self-supervised learning scheme to train a neural-network-based drone model using only onboard monocular video and flight controller data (IMU and motor feedback).","We achieve this by first training a self-supervised relative pose estimation model, which then serves as a teacher for the drone model.","To allow this to work at high speed close to obstacles, we propose an improved occlusion handling method for training self-supervised pose estimation models.","Due to this method, the root mean squared error of resulting odometry estimates is reduced by an average of 15%.","Moreover, the student neural drone model can be successfully obtained from the onboard data.","It even becomes more accurate at higher speeds compared to its teacher, the self-supervised vision-based model.","We demonstrate the value of the neural drone model by integrating it into a traditional filter-based VIO system (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing trajectories near obstacles.","Self-supervised learning of ego-motion estimation represents a significant step toward bridging the gap between flying in controlled, expensive lab environments and real-world drone applications.","The fusion of vision and drone models will enable higher-speed flight and improve state estimation, on any drone in any environment."],"url":"http://arxiv.org/abs/2504.21695v1"}
{"created":"2025-04-30 14:34:56","title":"Automatic Mapping of AutomationML Files to Ontologies for Graph Queries and Validation","abstract":"AutomationML has seen widespread adoption as an open data exchange format in the automation domain. It is an open and vendor neutral standard based on the extensible markup language XML. However, AutomationML extends XML with additional semantics, that limit the applicability of common XML-tools for applications like querying or data validation. This article provides practitioners with 1) an up-to-date ontology of the concepts in the AutomationML-standard, as well as 2) a declarative mapping to automatically transform any AutomationML model into RDF triples. Together, these artifacts allow practitioners an easy integration of AutomationML information into industrial knowledge graphs. A study on examples from the automation domain concludes that transforming AutomationML to OWL opens up new powerful ways for querying and validation that are impossible without transformation.","sentences":["AutomationML has seen widespread adoption as an open data exchange format in the automation domain.","It is an open and vendor neutral standard based on the extensible markup language XML.","However, AutomationML extends XML with additional semantics, that limit the applicability of common XML-tools for applications like querying or data validation.","This article provides practitioners with 1) an up-to-date ontology of the concepts in the AutomationML-standard, as well as 2) a declarative mapping to automatically transform any AutomationML model into RDF triples.","Together, these artifacts allow practitioners an easy integration of AutomationML information into industrial knowledge graphs.","A study on examples from the automation domain concludes that transforming AutomationML to OWL opens up new powerful ways for querying and validation that are impossible without transformation."],"url":"http://arxiv.org/abs/2504.21694v1"}
{"created":"2025-04-30 14:29:04","title":"Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction","abstract":"Successful video analysis relies on accurate recognition of pixels across frames, and frame reconstruction methods based on video correspondence learning are popular due to their efficiency. Existing frame reconstruction methods, while efficient, neglect the value of direct involvement of multiple reference frames for reconstruction and decision-making aspects, especially in complex situations such as occlusion or fast movement. In this paper, we introduce a Dynamic Memory Prediction (DMP) framework that innovatively utilizes multiple reference frames to concisely and directly enhance frame reconstruction. Its core component is a Reference Frame Memory Engine that dynamically selects frames based on object pixel features to improve tracking accuracy. In addition, a Bidirectional Target Prediction Network is built to utilize multiple reference frames to improve the robustness of the model. Through experiments, our algorithm outperforms the state-of-the-art self-supervised techniques on two fine-grained video object tracking tasks: object segmentation and keypoint tracking.","sentences":["Successful video analysis relies on accurate recognition of pixels across frames, and frame reconstruction methods based on video correspondence learning are popular due to their efficiency.","Existing frame reconstruction methods, while efficient, neglect the value of direct involvement of multiple reference frames for reconstruction and decision-making aspects, especially in complex situations such as occlusion or fast movement.","In this paper, we introduce a Dynamic Memory Prediction (DMP) framework that innovatively utilizes multiple reference frames to concisely and directly enhance frame reconstruction.","Its core component is a Reference Frame Memory Engine that dynamically selects frames based on object pixel features to improve tracking accuracy.","In addition, a Bidirectional Target Prediction Network is built to utilize multiple reference frames to improve the robustness of the model.","Through experiments, our algorithm outperforms the state-of-the-art self-supervised techniques on two fine-grained video object tracking tasks: object segmentation and keypoint tracking."],"url":"http://arxiv.org/abs/2504.21692v1"}
{"created":"2025-04-30 14:21:54","title":"Enhancing Health Mention Classification Performance: A Study on Advancements in Parameter Efficient Tuning","abstract":"Health Mention Classification (HMC) plays a critical role in leveraging social media posts for real-time tracking and public health monitoring. Nevertheless, the process of HMC presents significant challenges due to its intricate nature, primarily stemming from the contextual aspects of health mentions, such as figurative language and descriptive terminology, rather than explicitly reflecting a personal ailment. To address this problem, we argue that clearer mentions can be achieved through conventional fine-tuning with enhanced parameters of biomedical natural language methods (NLP). In this study, we explore different techniques such as the utilisation of part-of-speech (POS) tagger information, improving on PEFT techniques, and different combinations thereof. Extensive experiments are conducted on three widely used datasets: RHDM, PHM, and Illness. The results incorporated POS tagger information, and leveraging PEFT techniques significantly improves performance in terms of F1-score compared to state-of-the-art methods across all three datasets by utilising smaller models and efficient training. Furthermore, the findings highlight the effectiveness of incorporating POS tagger information and leveraging PEFT techniques for HMC. In conclusion, the proposed methodology presents a potentially effective approach to accurately classifying health mentions in social media posts while optimising the model size and training efficiency.","sentences":["Health Mention Classification (HMC) plays a critical role in leveraging social media posts for real-time tracking and public health monitoring.","Nevertheless, the process of HMC presents significant challenges due to its intricate nature, primarily stemming from the contextual aspects of health mentions, such as figurative language and descriptive terminology, rather than explicitly reflecting a personal ailment.","To address this problem, we argue that clearer mentions can be achieved through conventional fine-tuning with enhanced parameters of biomedical natural language methods (NLP).","In this study, we explore different techniques such as the utilisation of part-of-speech (POS) tagger information, improving on PEFT techniques, and different combinations thereof.","Extensive experiments are conducted on three widely used datasets: RHDM, PHM, and Illness.","The results incorporated POS tagger information, and leveraging PEFT techniques significantly improves performance in terms of F1-score compared to state-of-the-art methods across all three datasets by utilising smaller models and efficient training.","Furthermore, the findings highlight the effectiveness of incorporating POS tagger information and leveraging PEFT techniques for HMC.","In conclusion, the proposed methodology presents a potentially effective approach to accurately classifying health mentions in social media posts while optimising the model size and training efficiency."],"url":"http://arxiv.org/abs/2504.21685v1"}
{"created":"2025-04-30 14:20:58","title":"Using quantum annealing to generate test cases for cyber-physical systems","abstract":"Quantum computing has emerged as a powerful tool to efficiently solve computational challenges, particularly in simulation and optimisation. However, hardware limitations prevent quantum computers from achieving the full theoretical potential. Among the quantum algorithms, quantum annealing is a prime candidate to solve optimisation problems. This makes it a natural candidate for search-based software testing in the Cyber-Physical Systems (CPS) domain, which demands effective test cases due to their safety-critical nature. This work explores the use of quantum annealing to enhance test case generation for CPS through a mutation-based approach. We encode test case mutation as a binary optimisation problem, and use quantum annealing to identify and target critical regions of the test cases for improvement. Our approach mechanises this process into an algorithm that uses D-Wave's quantum annealer to find the solution. As a main contribution, we offer insights into how quantum annealing can advance software testing methodologies by empirically evaluating the correlation between problem size, hardware limitations, and the effectiveness of the results. Moreover, we compare the proposed method against state-of-the-art classical optimisation algorithms, targeting efficiency (time to generate test cases) and effectiveness (fault detection rates). Results indicate that quantum annealing enables faster test case generation while achieving comparable fault detection performance to state-of-the-art alternatives.","sentences":["Quantum computing has emerged as a powerful tool to efficiently solve computational challenges, particularly in simulation and optimisation.","However, hardware limitations prevent quantum computers from achieving the full theoretical potential.","Among the quantum algorithms, quantum annealing is a prime candidate to solve optimisation problems.","This makes it a natural candidate for search-based software testing in the Cyber-Physical Systems (CPS) domain, which demands effective test cases due to their safety-critical nature.","This work explores the use of quantum annealing to enhance test case generation for CPS through a mutation-based approach.","We encode test case mutation as a binary optimisation problem, and use quantum annealing to identify and target critical regions of the test cases for improvement.","Our approach mechanises this process into an algorithm that uses D-Wave's quantum annealer to find the solution.","As a main contribution, we offer insights into how quantum annealing can advance software testing methodologies by empirically evaluating the correlation between problem size, hardware limitations, and the effectiveness of the results.","Moreover, we compare the proposed method against state-of-the-art classical optimisation algorithms, targeting efficiency (time to generate test cases) and effectiveness (fault detection rates).","Results indicate that quantum annealing enables faster test case generation while achieving comparable fault detection performance to state-of-the-art alternatives."],"url":"http://arxiv.org/abs/2504.21684v1"}
{"created":"2025-04-30 14:19:42","title":"Extension-ranking Semantics for Abstract Argumentation Preprint","abstract":"In this paper, we present a general framework for ranking sets of arguments in abstract argumentation based on their plausibility of acceptance. We present a generalisation of Dung's extension semantics as extension-ranking semantics, which induce a preorder over the power set of all arguments, allowing us to state that one set is \"closer\" to being acceptable than another. To evaluate the extension-ranking semantics, we introduce a number of principles that a well-behaved extension-ranking semantics should satisfy. We consider several simple base relations, each of which models a single central aspect of argumentative reasoning. The combination of these base relations provides us with a family of extension-ranking semantics. We also adapt a number of approaches from the literature for ranking extensions to be usable in the context of extension-ranking semantics, and evaluate their behaviour.","sentences":["In this paper, we present a general framework for ranking sets of arguments in abstract argumentation based on their plausibility of acceptance.","We present a generalisation of Dung's extension semantics as extension-ranking semantics, which induce a preorder over the power set of all arguments, allowing us to state that one set is \"closer\" to being acceptable than another.","To evaluate the extension-ranking semantics, we introduce a number of principles that a well-behaved extension-ranking semantics should satisfy.","We consider several simple base relations, each of which models a single central aspect of argumentative reasoning.","The combination of these base relations provides us with a family of extension-ranking semantics.","We also adapt a number of approaches from the literature for ranking extensions to be usable in the context of extension-ranking semantics, and evaluate their behaviour."],"url":"http://arxiv.org/abs/2504.21683v1"}
{"created":"2025-04-30 14:19:29","title":"Visual Text Processing: A Comprehensive Review and Unified Evaluation","abstract":"Visual text is a crucial component in both document and scene images, conveying rich semantic information and attracting significant attention in the computer vision community. Beyond traditional tasks such as text detection and recognition, visual text processing has witnessed rapid advancements driven by the emergence of foundation models, including text image reconstruction and text image manipulation. Despite significant progress, challenges remain due to the unique properties that differentiate text from general objects. Effectively capturing and leveraging these distinct textual characteristics is essential for developing robust visual text processing models. In this survey, we present a comprehensive, multi-perspective analysis of recent advancements in visual text processing, focusing on two key questions: (1) What textual features are most suitable for different visual text processing tasks? (2) How can these distinctive text features be effectively incorporated into processing frameworks? Furthermore, we introduce VTPBench, a new benchmark that encompasses a broad range of visual text processing datasets. Leveraging the advanced visual quality assessment capabilities of multimodal large language models (MLLMs), we propose VTPScore, a novel evaluation metric designed to ensure fair and reliable evaluation. Our empirical study with more than 20 specific models reveals substantial room for improvement in the current techniques. Our aim is to establish this work as a fundamental resource that fosters future exploration and innovation in the dynamic field of visual text processing. The relevant repository is available at https://github.com/shuyansy/Visual-Text-Processing-survey.","sentences":["Visual text is a crucial component in both document and scene images, conveying rich semantic information and attracting significant attention in the computer vision community.","Beyond traditional tasks such as text detection and recognition, visual text processing has witnessed rapid advancements driven by the emergence of foundation models, including text image reconstruction and text image manipulation.","Despite significant progress, challenges remain due to the unique properties that differentiate text from general objects.","Effectively capturing and leveraging these distinct textual characteristics is essential for developing robust visual text processing models.","In this survey, we present a comprehensive, multi-perspective analysis of recent advancements in visual text processing, focusing on two key questions: (1) What textual features are most suitable for different visual text processing tasks?","(2) How can these distinctive text features be effectively incorporated into processing frameworks?","Furthermore, we introduce VTPBench, a new benchmark that encompasses a broad range of visual text processing datasets.","Leveraging the advanced visual quality assessment capabilities of multimodal large language models (MLLMs), we propose VTPScore, a novel evaluation metric designed to ensure fair and reliable evaluation.","Our empirical study with more than 20 specific models reveals substantial room for improvement in the current techniques.","Our aim is to establish this work as a fundamental resource that fosters future exploration and innovation in the dynamic field of visual text processing.","The relevant repository is available at https://github.com/shuyansy/Visual-Text-Processing-survey."],"url":"http://arxiv.org/abs/2504.21682v1"}
{"created":"2025-04-30 14:19:15","title":"Investigating the Effect of Parallel Data in the Cross-Lingual Transfer for Vision-Language Encoders","abstract":"Most pre-trained Vision-Language (VL) models and training data for the downstream tasks are only available in English. Therefore, multilingual VL tasks are solved using cross-lingual transfer: fine-tune a multilingual pre-trained model or transfer the text encoder using parallel data. We study the alternative approach: transferring an already trained encoder using parallel data. We investigate the effect of parallel data: domain and the number of languages, which were out of focus in previous work. Our results show that even machine-translated task data are the best on average, caption-like authentic parallel data outperformed it in some languages. Further, we show that most languages benefit from multilingual training.","sentences":["Most pre-trained Vision-Language (VL) models and training data for the downstream tasks are only available in English.","Therefore, multilingual VL tasks are solved using cross-lingual transfer: fine-tune a multilingual pre-trained model or transfer the text encoder using parallel data.","We study the alternative approach: transferring an already trained encoder using parallel data.","We investigate the effect of parallel data: domain and the number of languages, which were out of focus in previous work.","Our results show that even machine-translated task data are the best on average, caption-like authentic parallel data outperformed it in some languages.","Further, we show that most languages benefit from multilingual training."],"url":"http://arxiv.org/abs/2504.21681v1"}
{"created":"2025-04-30 14:18:11","title":"Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs","abstract":"Retrieval-Augmented Generation (RAG) integrates Large Language Models (LLMs) with external knowledge bases, improving output quality while introducing new security risks. Existing studies on RAG vulnerabilities typically focus on exploiting the retrieval mechanism to inject erroneous knowledge or malicious texts, inducing incorrect outputs. However, these approaches overlook critical weaknesses within LLMs, leaving important attack vectors unexplored and limiting the scope and efficiency of attacks. In this paper, we uncover a novel vulnerability: the safety guardrails of LLMs, while designed for protection, can also be exploited as an attack vector by adversaries. Building on this vulnerability, we propose MutedRAG, a novel denial-of-service attack that reversely leverages the guardrails of LLMs to undermine the availability of RAG systems. By injecting minimalistic jailbreak texts, such as \"\\textit{How to build a bomb}\", into the knowledge base, MutedRAG intentionally triggers the LLM's safety guardrails, causing the system to reject legitimate queries. Besides, due to the high sensitivity of guardrails, a single jailbreak sample can affect multiple queries, effectively amplifying the efficiency of attacks while reducing their costs. Experimental results on three datasets demonstrate that MutedRAG achieves an attack success rate exceeding 60% in many scenarios, requiring only less than one malicious text to each target query on average. In addition, we evaluate potential defense strategies against MutedRAG, finding that some of current mechanisms are insufficient to mitigate this threat, underscoring the urgent need for more robust solutions.","sentences":["Retrieval-Augmented Generation (RAG) integrates Large Language Models (LLMs) with external knowledge bases, improving output quality while introducing new security risks.","Existing studies on RAG vulnerabilities typically focus on exploiting the retrieval mechanism to inject erroneous knowledge or malicious texts, inducing incorrect outputs.","However, these approaches overlook critical weaknesses within LLMs, leaving important attack vectors unexplored and limiting the scope and efficiency of attacks.","In this paper, we uncover a novel vulnerability: the safety guardrails of LLMs, while designed for protection, can also be exploited as an attack vector by adversaries.","Building on this vulnerability, we propose MutedRAG, a novel denial-of-service attack that reversely leverages the guardrails of LLMs to undermine the availability of RAG systems.","By injecting minimalistic jailbreak texts, such as \"\\textit{How to build a bomb}\", into the knowledge base, MutedRAG intentionally triggers the LLM's safety guardrails, causing the system to reject legitimate queries.","Besides, due to the high sensitivity of guardrails, a single jailbreak sample can affect multiple queries, effectively amplifying the efficiency of attacks while reducing their costs.","Experimental results on three datasets demonstrate that MutedRAG achieves an attack success rate exceeding 60% in many scenarios, requiring only less than one malicious text to each target query on average.","In addition, we evaluate potential defense strategies against MutedRAG, finding that some of current mechanisms are insufficient to mitigate this threat, underscoring the urgent need for more robust solutions."],"url":"http://arxiv.org/abs/2504.21680v1"}
{"created":"2025-04-30 14:17:54","title":"Canonicalization for Unreproducible Builds in Java","abstract":"The increasing complexity of software supply chains and the rise of supply chain attacks have elevated concerns around software integrity. Users and stakeholders face significant challenges in validating that a given software artifact corresponds to its declared source. Reproducible Builds address this challenge by ensuring that independently performed builds from identical source code produce identical binaries. However, achieving reproducibility at scale remains difficult, especially in Java, due to a range of non-deterministic factors and caveats in the build process. In this work, we focus on reproducibility in Java-based software, archetypal of enterprise applications. We introduce a conceptual framework for reproducible builds, we analyze a large dataset from Reproducible Central, and we develop a novel taxonomy of six root causes of unreproducibility. We study actionable mitigations: artifact and bytecode canonicalization using OSS-Rebuild and jNorm respectively. Finally, we present Chains-Rebuild, a tool that raises reproducibility success from 9.48% to 26.89% on 12,283 unreproducible artifacts. To sum up, our contributions are the first large-scale taxonomy of build unreproducibility causes in Java, a publicly available dataset of unreproducible builds, and Chains-Rebuild, a canonicalization tool for mitigating unreproducible builds in Java.","sentences":["The increasing complexity of software supply chains and the rise of supply chain attacks have elevated concerns around software integrity.","Users and stakeholders face significant challenges in validating that a given software artifact corresponds to its declared source.","Reproducible Builds address this challenge by ensuring that independently performed builds from identical source code produce identical binaries.","However, achieving reproducibility at scale remains difficult, especially in Java, due to a range of non-deterministic factors and caveats in the build process.","In this work, we focus on reproducibility in Java-based software, archetypal of enterprise applications.","We introduce a conceptual framework for reproducible builds, we analyze a large dataset from Reproducible Central, and we develop a novel taxonomy of six root causes of unreproducibility.","We study actionable mitigations: artifact and bytecode canonicalization using OSS-Rebuild and jNorm respectively.","Finally, we present Chains-Rebuild, a tool that raises reproducibility success from 9.48% to 26.89% on 12,283 unreproducible artifacts.","To sum up, our contributions are the first large-scale taxonomy of build unreproducibility causes in Java, a publicly available dataset of unreproducible builds, and Chains-Rebuild, a canonicalization tool for mitigating unreproducible builds in Java."],"url":"http://arxiv.org/abs/2504.21679v1"}
{"created":"2025-04-30 14:16:08","title":"20min-XD: A Comparable Corpus of Swiss News Articles","abstract":"We present 20min-XD (20 Minuten cross-lingual document-level), a French-German, document-level comparable corpus of news articles, sourced from the Swiss online news outlet 20 Minuten/20 minutes. Our dataset comprises around 15,000 article pairs spanning 2015 to 2024, automatically aligned based on semantic similarity. We detail the data collection process and alignment methodology. Furthermore, we provide a qualitative and quantitative analysis of the corpus. The resulting dataset exhibits a broad spectrum of cross-lingual similarity, ranging from near-translations to loosely related articles, making it valuable for various NLP applications and broad linguistically motivated studies. We publicly release the dataset in document- and sentence-aligned versions and code for the described experiments.","sentences":["We present 20min-XD (20 Minuten cross-lingual document-level), a French-German, document-level comparable corpus of news articles, sourced from the Swiss online news outlet 20 Minuten/20 minutes.","Our dataset comprises around 15,000 article pairs spanning 2015 to 2024, automatically aligned based on semantic similarity.","We detail the data collection process and alignment methodology.","Furthermore, we provide a qualitative and quantitative analysis of the corpus.","The resulting dataset exhibits a broad spectrum of cross-lingual similarity, ranging from near-translations to loosely related articles, making it valuable for various NLP applications and broad linguistically motivated studies.","We publicly release the dataset in document- and sentence-aligned versions and code for the described experiments."],"url":"http://arxiv.org/abs/2504.21677v1"}
{"created":"2025-04-30 14:15:41","title":"Elimination Distance to Dominated Clusters","abstract":"In the Dominated Cluster Deletion problem we are given an undirected graph $G$ and integers $k$ and $d$ and the question is to decide whether there exists a set of at most $k$ vertices whose removal results in a graph in which each connected component has a dominating set of size at most $d$. In the Elimination Distance to Dominated Clusters problem we are again given an undirected graph $G$ and integers $k$ and $d$ and the question is to decide whether we can recursively delete vertices up to depth $k$ such that each remaining connected component has a dominating set of size at most $d$. Bentert et al.~[Bentert et al., MFCS 2024] recently provided an almost complete classification of the parameterized complexity of Dominated Cluster Deletion with respect to the parameters $k$, $d$, $c$, and $\\Delta$, where $c$ and $\\Delta$ are the degeneracy, and the maximum degree of the input graph, respectively. In particular, they provided a non-uniform algorithm with running time $f(k,d)\\cdot n^{O(d)}$. They left as an open problem whether the problem is fixed-parameter tractable with respect to the parameter $k+d+c$. We provide a uniform algorithm running in time $f(k,d)\\cdot n^{O(d)}$ for both Dominated Cluster Deletion and Elimination Distance to Dominated Clusters. We furthermore show that both problems are FPT when parameterized by $k+d+\\ell$, where $\\ell$ is the semi-ladder index of the input graph, a parameter that is upper bounded and may be much smaller than the degeneracy $c$, positively answering the open question of Bentert et al. We almost complete the picture by providing an almost full classification for the parameterized complexity and kernelization complexity of Elimination Distance to Dominated Clusters. The one difficult base case that remains open is whether treedepth (the case $d=0$) is NP-hard on graphs of bounded maximum degree.","sentences":["In the Dominated Cluster Deletion problem we are given an undirected graph $G$ and integers $k$ and $d$ and the question is to decide whether there exists a set of at most $k$ vertices whose removal results in a graph in which each connected component has a dominating set of size at most $d$. In the Elimination Distance to Dominated Clusters problem we are again given an undirected graph $G$ and integers $k$ and $d$ and the question is to decide whether we can recursively delete vertices up to depth $k$ such that each remaining connected component has a dominating set of size at most $d$. Bentert et al.~[Bentert et al., MFCS 2024] recently provided an almost complete classification of the parameterized complexity of Dominated Cluster Deletion with respect to the parameters $k$, $d$, $c$, and $\\Delta$, where $c$ and $\\Delta$ are the degeneracy, and the maximum degree of the input graph, respectively.","In particular, they provided a non-uniform algorithm with running time $f(k,","d)\\cdot n^{O(d)}$.","They left as an open problem whether the problem is fixed-parameter tractable with respect to the parameter $k+d+c$. We provide a uniform algorithm running in time $f(k,d)\\cdot n^{O(d)}$ for both Dominated Cluster Deletion and Elimination Distance to Dominated Clusters.","We furthermore show that both problems are FPT when parameterized by $k+d+\\ell$, where $\\ell$ is the semi-ladder index of the input graph, a parameter that is upper bounded and may be much smaller than the degeneracy $c$, positively answering the open question of Bentert et al.","We almost complete the picture by providing an almost full classification for the parameterized complexity and kernelization complexity of Elimination Distance to Dominated Clusters.","The one difficult base case that remains open is whether treedepth (the case $d=0$) is NP-hard on graphs of bounded maximum degree."],"url":"http://arxiv.org/abs/2504.21675v1"}
{"created":"2025-04-30 14:14:59","title":"Complexities of Well-Quasi-Ordered Substructural Logics","abstract":"Substructural logics are formal logical systems that omit familiar structural rules of classical and intuitionistic logic such as contraction, weakening, exchange (commutativity), and associativity. This leads to a resource-sensitive logical framework that has proven influential beyond mathematical logic and its algebraic semantics, across theoretical computer science, linguistics, and philosophical logic. The set of theorems of a substructural logic is recursively enumerable and, in many cases, recursive. These logics also possess an intricate mathematical structure that has been the subject of research for over six decades.   We undertake a comprehensive study of substructural logics possessing an underlying well-quasi-order (wqo), using established ordinal-indexed fast-growing complexity classes to classify the complexity of their deducibility (quasiequational) and provability (equational) problems. This includes substructural logics with weak variants of contraction and weakening, and logics with weak or even no exchange. We further consider infinitely many axiomatic extensions over the base systems.   We establish a host of decidability and complexity bounds, many of them tight, by developing new techniques in proof theory, well-quasi-order theory (contributing new length theorems), the algebraic semantics of substructural logics via residuated lattices, algebraic proof theory, and novel encodings of counter machines. Classifying the computational complexity of substructural logics (and the complexity of the word problem and of the equational theory of their algebraic semantics) reveals how subtle variations in their design influence their algorithmic behavior, with the decision problems often reaching Ackermannian or even hyper-Ackermannian complexity.","sentences":["Substructural logics are formal logical systems that omit familiar structural rules of classical and intuitionistic logic such as contraction, weakening, exchange (commutativity), and associativity.","This leads to a resource-sensitive logical framework that has proven influential beyond mathematical logic and its algebraic semantics, across theoretical computer science, linguistics, and philosophical logic.","The set of theorems of a substructural logic is recursively enumerable and, in many cases, recursive.","These logics also possess an intricate mathematical structure that has been the subject of research for over six decades.   ","We undertake a comprehensive study of substructural logics possessing an underlying well-quasi-order (wqo), using established ordinal-indexed fast-growing complexity classes to classify the complexity of their deducibility (quasiequational) and provability (equational) problems.","This includes substructural logics with weak variants of contraction and weakening, and logics with weak or even no exchange.","We further consider infinitely many axiomatic extensions over the base systems.   ","We establish a host of decidability and complexity bounds, many of them tight, by developing new techniques in proof theory, well-quasi-order theory (contributing new length theorems), the algebraic semantics of substructural logics via residuated lattices, algebraic proof theory, and novel encodings of counter machines.","Classifying the computational complexity of substructural logics (and the complexity of the word problem and of the equational theory of their algebraic semantics) reveals how subtle variations in their design influence their algorithmic behavior, with the decision problems often reaching Ackermannian or even hyper-Ackermannian complexity."],"url":"http://arxiv.org/abs/2504.21674v1"}
{"created":"2025-04-30 14:10:02","title":"Traceback of Poisoning Attacks to Retrieval-Augmented Generation","abstract":"Large language models (LLMs) integrated with retrieval-augmented generation (RAG) systems improve accuracy by leveraging external knowledge sources. However, recent research has revealed RAG's susceptibility to poisoning attacks, where the attacker injects poisoned texts into the knowledge database, leading to attacker-desired responses. Existing defenses, which predominantly focus on inference-time mitigation, have proven insufficient against sophisticated attacks. In this paper, we introduce RAGForensics, the first traceback system for RAG, designed to identify poisoned texts within the knowledge database that are responsible for the attacks. RAGForensics operates iteratively, first retrieving a subset of texts from the database and then utilizing a specially crafted prompt to guide an LLM in detecting potential poisoning texts. Empirical evaluations across multiple datasets demonstrate the effectiveness of RAGForensics against state-of-the-art poisoning attacks. This work pioneers the traceback of poisoned texts in RAG systems, providing a practical and promising defense mechanism to enhance their security.","sentences":["Large language models (LLMs) integrated with retrieval-augmented generation (RAG) systems improve accuracy by leveraging external knowledge sources.","However, recent research has revealed RAG's susceptibility to poisoning attacks, where the attacker injects poisoned texts into the knowledge database, leading to attacker-desired responses.","Existing defenses, which predominantly focus on inference-time mitigation, have proven insufficient against sophisticated attacks.","In this paper, we introduce RAGForensics, the first traceback system for RAG, designed to identify poisoned texts within the knowledge database that are responsible for the attacks.","RAGForensics operates iteratively, first retrieving a subset of texts from the database and then utilizing a specially crafted prompt to guide an LLM in detecting potential poisoning texts.","Empirical evaluations across multiple datasets demonstrate the effectiveness of RAGForensics against state-of-the-art poisoning attacks.","This work pioneers the traceback of poisoned texts in RAG systems, providing a practical and promising defense mechanism to enhance their security."],"url":"http://arxiv.org/abs/2504.21668v1"}
{"created":"2025-04-30 14:10:00","title":"From Precision to Perception: User-Centred Evaluation of Keyword Extraction Algorithms for Internet-Scale Contextual Advertising","abstract":"Keyword extraction is a foundational task in natural language processing, underpinning countless real-world applications. A salient example is contextual advertising, where keywords help predict the topical congruence between ads and their surrounding media contexts to enhance advertising effectiveness. Recent advances in artificial intelligence, particularly large language models, have improved keyword extraction capabilities but also introduced concerns about computational cost. Moreover, although the end-user experience is of vital importance, human evaluation of keyword extraction performances remains under-explored. This study provides a comparative evaluation of three prevalent keyword extraction algorithms that vary in complexity: TF-IDF, KeyBERT, and Llama 2. To evaluate their effectiveness, a mixed-methods approach is employed, combining quantitative benchmarking with qualitative assessments from 552 participants through three survey-based experiments. Findings indicate a slight user preference for KeyBERT, which offers a favourable balance between performance and computational efficiency compared to the other two algorithms. Despite a strong overall preference for gold-standard keywords, differences between the algorithmic outputs are not statistically significant, highlighting a long-overlooked gap between traditional precision-focused metrics and user-perceived algorithm efficiency. The study highlights the importance of user-centred evaluation methodologies and proposes analytical tools to support their implementation.","sentences":["Keyword extraction is a foundational task in natural language processing, underpinning countless real-world applications.","A salient example is contextual advertising, where keywords help predict the topical congruence between ads and their surrounding media contexts to enhance advertising effectiveness.","Recent advances in artificial intelligence, particularly large language models, have improved keyword extraction capabilities but also introduced concerns about computational cost.","Moreover, although the end-user experience is of vital importance, human evaluation of keyword extraction performances remains under-explored.","This study provides a comparative evaluation of three prevalent keyword extraction algorithms that vary in complexity: TF-IDF, KeyBERT, and Llama 2.","To evaluate their effectiveness, a mixed-methods approach is employed, combining quantitative benchmarking with qualitative assessments from 552 participants through three survey-based experiments.","Findings indicate a slight user preference for KeyBERT, which offers a favourable balance between performance and computational efficiency compared to the other two algorithms.","Despite a strong overall preference for gold-standard keywords, differences between the algorithmic outputs are not statistically significant, highlighting a long-overlooked gap between traditional precision-focused metrics and user-perceived algorithm efficiency.","The study highlights the importance of user-centred evaluation methodologies and proposes analytical tools to support their implementation."],"url":"http://arxiv.org/abs/2504.21667v1"}
{"created":"2025-04-30 14:03:52","title":"On Advancements of the Forward-Forward Algorithm","abstract":"The Forward-Forward algorithm has evolved in machine learning research, tackling more complex tasks that mimic real-life applications. In the last years, it has been improved by several techniques to perform better than its original version, handling a challenging dataset like CIFAR10 without losing its flexibility and low memory usage. We have shown in our results that improvements are achieved through a combination of convolutional channel grouping, learning rate schedules, and independent block structures during training that lead to a 20\\% decrease in test error percentage. Additionally, to approach further implementations on low-capacity hardware projects we have presented a series of lighter models that achieve low test error percentages within (21$\\pm$6)\\% and number of trainable parameters between 164,706 and 754,386. This serving also as a basis for our future study on complete verification and validation of these kinds of neural networks.","sentences":["The Forward-Forward algorithm has evolved in machine learning research, tackling more complex tasks that mimic real-life applications.","In the last years, it has been improved by several techniques to perform better than its original version, handling a challenging dataset like CIFAR10 without losing its flexibility and low memory usage.","We have shown in our results that improvements are achieved through a combination of convolutional channel grouping, learning rate schedules, and independent block structures during training that lead to a 20\\% decrease in test error percentage.","Additionally, to approach further implementations on low-capacity hardware projects we have presented a series of lighter models that achieve low test error percentages within (21$\\pm$6)\\% and number of trainable parameters between 164,706 and 754,386.","This serving also as a basis for our future study on complete verification and validation of these kinds of neural networks."],"url":"http://arxiv.org/abs/2504.21662v1"}
{"created":"2025-04-30 14:01:45","title":"AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization","abstract":"Recently, long-thought reasoning models achieve strong performance on complex reasoning tasks, but often incur substantial inference overhead, making efficiency a critical concern. Our empirical analysis reveals that the benefit of using Long-CoT varies across problems: while some problems require elaborate reasoning, others show no improvement, or even degraded accuracy. This motivates adaptive reasoning strategies that tailor reasoning depth to the input. However, prior work primarily reduces redundancy within long reasoning paths, limiting exploration of more efficient strategies beyond the Long-CoT paradigm. To address this, we propose a novel two-stage framework for adaptive and efficient reasoning. First, we construct a hybrid reasoning model by merging long and short CoT models to enable diverse reasoning styles. Second, we apply bi-level preference training to guide the model to select suitable reasoning styles (group-level), and prefer concise and correct reasoning within each style group (instance-level). Experiments demonstrate that our method significantly reduces inference costs compared to other baseline approaches, while maintaining performance. Notably, on five mathematical datasets, the average length of reasoning is reduced by more than 50%, highlighting the potential of adaptive strategies to optimize reasoning efficiency in large language models. Our code is coming soon at https://github.com/StarDewXXX/AdaR1","sentences":["Recently, long-thought reasoning models achieve strong performance on complex reasoning tasks, but often incur substantial inference overhead, making efficiency a critical concern.","Our empirical analysis reveals that the benefit of using Long-CoT varies across problems: while some problems require elaborate reasoning, others show no improvement, or even degraded accuracy.","This motivates adaptive reasoning strategies that tailor reasoning depth to the input.","However, prior work primarily reduces redundancy within long reasoning paths, limiting exploration of more efficient strategies beyond the Long-CoT paradigm.","To address this, we propose a novel two-stage framework for adaptive and efficient reasoning.","First, we construct a hybrid reasoning model by merging long and short CoT models to enable diverse reasoning styles.","Second, we apply bi-level preference training to guide the model to select suitable reasoning styles (group-level), and prefer concise and correct reasoning within each style group (instance-level).","Experiments demonstrate that our method significantly reduces inference costs compared to other baseline approaches, while maintaining performance.","Notably, on five mathematical datasets, the average length of reasoning is reduced by more than 50%, highlighting the potential of adaptive strategies to optimize reasoning efficiency in large language models.","Our code is coming soon at https://github.com/StarDewXXX/AdaR1"],"url":"http://arxiv.org/abs/2504.21659v1"}
{"created":"2025-04-30 14:00:20","title":"DBSCAN-based Vehicle Clustering and UAV Placement for NOMA-based Resource Management in Cellular V2X Communications","abstract":"In the future wireless networks, terrestrial, aerial, space, and maritime wireless networks are integrated into a unified network to meet the needs of a fully connected global network. Nowadays, vehicular communication has become one of the challenging applications of wireless networks. In this article, we aim to address the radio resource management in Cellular V2X (C-V2X) networks using Unmanned Aerial Vehicles (UAV) and Non-orthogonal multiple access (NOMA). The goal of this problem is to maximize the spectral efficiency of vehicular users in Cellular Vehicle-to-Everything (C-V2X) networks under a fronthaul constraint. To solve this problem, a two-stage approach is utilized. In the first stage, vehicles in dense area are clustered based on their geographical locations, predicted location of vehicles, and speeds. Then UAVs are deployed to serve the clusters. In the second stage, NOMA groups are formed within each cluster and radio resources are allocated to vehicles based on NOMA groups. An optimization problem is formulated and a suboptimal method is used to solve it. The performance of the proposed method is evaluated through simulations where results demonstrate superiority of proposed method in spectral efficiency, min point, and distance.","sentences":["In the future wireless networks, terrestrial, aerial, space, and maritime wireless networks are integrated into a unified network to meet the needs of a fully connected global network.","Nowadays, vehicular communication has become one of the challenging applications of wireless networks.","In this article, we aim to address the radio resource management in Cellular V2X (C-V2X) networks using Unmanned Aerial Vehicles (UAV) and Non-orthogonal multiple access (NOMA).","The goal of this problem is to maximize the spectral efficiency of vehicular users in Cellular Vehicle-to-Everything (C-V2X) networks under a fronthaul constraint.","To solve this problem, a two-stage approach is utilized.","In the first stage, vehicles in dense area are clustered based on their geographical locations, predicted location of vehicles, and speeds.","Then UAVs are deployed to serve the clusters.","In the second stage, NOMA groups are formed within each cluster and radio resources are allocated to vehicles based on NOMA groups.","An optimization problem is formulated and a suboptimal method is used to solve it.","The performance of the proposed method is evaluated through simulations where results demonstrate superiority of proposed method in spectral efficiency, min point, and distance."],"url":"http://arxiv.org/abs/2504.21656v1"}

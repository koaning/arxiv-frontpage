{"created":"2025-05-01 17:59:57","title":"Controllable Weather Synthesis and Removal with Video Diffusion Models","abstract":"Generating realistic and controllable weather effects in videos is valuable for many applications. Physics-based weather simulation requires precise reconstructions that are hard to scale to in-the-wild videos, while current video editing often lacks realism and control. In this work, we introduce WeatherWeaver, a video diffusion model that synthesizes diverse weather effects -- including rain, snow, fog, and clouds -- directly into any input video without the need for 3D modeling. Our model provides precise control over weather effect intensity and supports blending various weather types, ensuring both realism and adaptability. To overcome the scarcity of paired training data, we propose a novel data strategy combining synthetic videos, generative image editing, and auto-labeled real-world videos. Extensive evaluations show that our method outperforms state-of-the-art methods in weather simulation and removal, providing high-quality, physically plausible, and scene-identity-preserving results over various real-world videos.","sentences":["Generating realistic and controllable weather effects in videos is valuable for many applications.","Physics-based weather simulation requires precise reconstructions that are hard to scale to in-the-wild videos, while current video editing often lacks realism and control.","In this work, we introduce WeatherWeaver, a video diffusion model that synthesizes diverse weather effects -- including rain, snow, fog, and clouds -- directly into any input video without the need for 3D modeling.","Our model provides precise control over weather effect intensity and supports blending various weather types, ensuring both realism and adaptability.","To overcome the scarcity of paired training data, we propose a novel data strategy combining synthetic videos, generative image editing, and auto-labeled real-world videos.","Extensive evaluations show that our method outperforms state-of-the-art methods in weather simulation and removal, providing high-quality, physically plausible, and scene-identity-preserving results over various real-world videos."],"url":"http://arxiv.org/abs/2505.00704v1"}
{"created":"2025-05-01 17:59:46","title":"T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT","abstract":"Recent advancements in large language models have demonstrated how chain-of-thought (CoT) and reinforcement learning (RL) can improve performance. However, applying such reasoning strategies to the visual generation domain remains largely unexplored. In this paper, we present T2I-R1, a novel reasoning-enhanced text-to-image generation model, powered by RL with a bi-level CoT reasoning process. Specifically, we identify two levels of CoT that can be utilized to enhance different stages of generation: (1) the semantic-level CoT for high-level planning of the prompt and (2) the token-level CoT for low-level pixel processing during patch-by-patch generation. To better coordinate these two levels of CoT, we introduce BiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes both generation CoTs within the same training step. By applying our reasoning strategies to the baseline model, Janus-Pro, we achieve superior performance with 13% improvement on T2I-CompBench and 19% improvement on the WISE benchmark, even surpassing the state-of-the-art model FLUX.1. Code is available at: https://github.com/CaraJ7/T2I-R1","sentences":["Recent advancements in large language models have demonstrated how chain-of-thought (CoT) and reinforcement learning (RL) can improve performance.","However, applying such reasoning strategies to the visual generation domain remains largely unexplored.","In this paper, we present T2I-R1, a novel reasoning-enhanced text-to-image generation model, powered by RL with a bi-level CoT reasoning process.","Specifically, we identify two levels of CoT that can be utilized to enhance different stages of generation: (1) the semantic-level CoT for high-level planning of the prompt and (2) the token-level CoT for low-level pixel processing during patch-by-patch generation.","To better coordinate these two levels of CoT, we introduce BiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes both generation CoTs within the same training step.","By applying our reasoning strategies to the baseline model, Janus-Pro, we achieve superior performance with 13% improvement on T2I-CompBench and 19% improvement on the WISE benchmark, even surpassing the state-of-the-art model FLUX.1.","Code is available at: https://github.com/CaraJ7/T2I-R1"],"url":"http://arxiv.org/abs/2505.00703v1"}
{"created":"2025-05-01 17:59:34","title":"RayZer: A Self-supervised Large View Synthesis Model","abstract":"We present RayZer, a self-supervised multi-view 3D Vision model trained without any 3D supervision, i.e., camera poses and scene geometry, while exhibiting emerging 3D awareness. Concretely, RayZer takes unposed and uncalibrated images as input, recovers camera parameters, reconstructs a scene representation, and synthesizes novel views. During training, RayZer relies solely on its self-predicted camera poses to render target views, eliminating the need for any ground-truth camera annotations and allowing RayZer to be trained with 2D image supervision. The emerging 3D awareness of RayZer is attributed to two key factors. First, we design a self-supervised framework, which achieves 3D-aware auto-encoding of input images by disentangling camera and scene representations. Second, we design a transformer-based model in which the only 3D prior is the ray structure, connecting camera, pixel, and scene simultaneously. RayZer demonstrates comparable or even superior novel view synthesis performance than ``oracle'' methods that rely on pose annotations in both training and testing. Project: https://hwjiang1510.github.io/RayZer/","sentences":["We present RayZer, a self-supervised multi-view 3D Vision model trained without any 3D supervision, i.e., camera poses and scene geometry, while exhibiting emerging 3D awareness.","Concretely, RayZer takes unposed and uncalibrated images as input, recovers camera parameters, reconstructs a scene representation, and synthesizes novel views.","During training, RayZer relies solely on its self-predicted camera poses to render target views, eliminating the need for any ground-truth camera annotations and allowing RayZer to be trained with 2D image supervision.","The emerging 3D awareness of RayZer is attributed to two key factors.","First, we design a self-supervised framework, which achieves 3D-aware auto-encoding of input images by disentangling camera and scene representations.","Second, we design a transformer-based model in which the only 3D prior is the ray structure, connecting camera, pixel, and scene simultaneously.","RayZer demonstrates comparable or even superior novel view synthesis performance than ``oracle'' methods that rely on pose annotations in both training and testing.","Project: https://hwjiang1510.github.io/RayZer/"],"url":"http://arxiv.org/abs/2505.00702v1"}
{"created":"2025-05-01 17:55:05","title":"Robotic Visual Instruction","abstract":"Recently, natural language has been the primary medium for human-robot interaction. However, its inherent lack of spatial precision for robotic control introduces challenges such as ambiguity and verbosity. To address these limitations, we introduce the Robotic Visual Instruction (RoVI), a novel paradigm to guide robotic tasks through an object-centric, hand-drawn symbolic representation. RoVI effectively encodes spatial-temporal information into human-interpretable visual instructions through 2D sketches, utilizing arrows, circles, colors, and numbers to direct 3D robotic manipulation. To enable robots to understand RoVI better and generate precise actions based on RoVI, we present Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for RoVI-conditioned policies. This approach leverages Vision-Language Models (VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from 2D pixel space via keypoint extraction, and then transform them into executable 3D action sequences. We additionally curate a specialized dataset of 15K instances to fine-tune small VLMs for edge deployment, enabling them to effectively learn RoVI capabilities. Our approach is rigorously validated across 11 novel tasks in both real and simulated environments, demonstrating significant generalization capability. Notably, VIEW achieves an 87.5% success rate in real-world scenarios involving unseen tasks that feature multi-step actions, with disturbances, and trajectory-following requirements. Code and Datasets in this paper will be released soon.","sentences":["Recently, natural language has been the primary medium for human-robot interaction.","However, its inherent lack of spatial precision for robotic control introduces challenges such as ambiguity and verbosity.","To address these limitations, we introduce the Robotic Visual Instruction (RoVI), a novel paradigm to guide robotic tasks through an object-centric, hand-drawn symbolic representation.","RoVI effectively encodes spatial-temporal information into human-interpretable visual instructions through 2D sketches, utilizing arrows, circles, colors, and numbers to direct 3D robotic manipulation.","To enable robots to understand RoVI better and generate precise actions based on RoVI, we present Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for RoVI-conditioned policies.","This approach leverages Vision-Language Models (VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from 2D pixel space via keypoint extraction, and then transform them into executable 3D action sequences.","We additionally curate a specialized dataset of 15K instances to fine-tune small VLMs for edge deployment, enabling them to effectively learn RoVI capabilities.","Our approach is rigorously validated across 11 novel tasks in both real and simulated environments, demonstrating significant generalization capability.","Notably, VIEW achieves an 87.5% success rate in real-world scenarios involving unseen tasks that feature multi-step actions, with disturbances, and trajectory-following requirements.","Code and Datasets in this paper will be released soon."],"url":"http://arxiv.org/abs/2505.00693v1"}
{"created":"2025-05-01 17:52:29","title":"Towards Autonomous Micromobility through Scalable Urban Simulation","abstract":"Micromobility, which utilizes lightweight mobile machines moving in urban public spaces, such as delivery robots and mobility scooters, emerges as a promising alternative to vehicular mobility. Current micromobility depends mostly on human manual operation (in-person or remote control), which raises safety and efficiency concerns when navigating busy urban environments full of unpredictable obstacles and pedestrians. Assisting humans with AI agents in maneuvering micromobility devices presents a viable solution for enhancing safety and efficiency. In this work, we present a scalable urban simulation solution to advance autonomous micromobility. First, we build URBAN-SIM - a high-performance robot learning platform for large-scale training of embodied agents in interactive urban scenes. URBAN-SIM contains three critical modules: Hierarchical Urban Generation pipeline, Interactive Dynamics Generation strategy, and Asynchronous Scene Sampling scheme, to improve the diversity, realism, and efficiency of robot learning in simulation. Then, we propose URBAN-BENCH - a suite of essential tasks and benchmarks to gauge various capabilities of the AI agents in achieving autonomous micromobility. URBAN-BENCH includes eight tasks based on three core skills of the agents: Urban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots with heterogeneous embodiments, such as the wheeled and legged robots, across these tasks. Experiments on diverse terrains and urban structures reveal each robot's strengths and limitations.","sentences":["Micromobility, which utilizes lightweight mobile machines moving in urban public spaces, such as delivery robots and mobility scooters, emerges as a promising alternative to vehicular mobility.","Current micromobility depends mostly on human manual operation (in-person or remote control), which raises safety and efficiency concerns when navigating busy urban environments full of unpredictable obstacles and pedestrians.","Assisting humans with AI agents in maneuvering micromobility devices presents a viable solution for enhancing safety and efficiency.","In this work, we present a scalable urban simulation solution to advance autonomous micromobility.","First, we build URBAN-SIM - a high-performance robot learning platform for large-scale training of embodied agents in interactive urban scenes.","URBAN-SIM contains three critical modules: Hierarchical Urban Generation pipeline, Interactive Dynamics Generation strategy, and Asynchronous Scene Sampling scheme, to improve the diversity, realism, and efficiency of robot learning in simulation.","Then, we propose URBAN-BENCH - a suite of essential tasks and benchmarks to gauge various capabilities of the AI agents in achieving autonomous micromobility.","URBAN-BENCH includes eight tasks based on three core skills of the agents: Urban Locomotion, Urban Navigation, and Urban Traverse.","We evaluate four robots with heterogeneous embodiments, such as the wheeled and legged robots, across these tasks.","Experiments on diverse terrains and urban structures reveal each robot's strengths and limitations."],"url":"http://arxiv.org/abs/2505.00690v1"}
{"created":"2025-05-01 17:48:52","title":"The Architecture Tradeoff and Risk Analysis Framework (ATRAF): A Unified Approach for Evaluating Software Architectures, Reference Architectures, and Architectural Frameworks","abstract":"Modern software systems are guided by hierarchical architectural concepts -- software architectures, reference architectures, and architectural frameworks -- each operating at a distinct level of abstraction. These artifacts promote reuse, scalability, and consistency, but also embed tradeoffs that shape critical quality attributes such as modifiability, performance, and security. Existing evaluation methods, such as the Architecture Tradeoff Analysis Method (ATAM), focus on system-specific architectures and are not designed to address the broader generality and variability of higher-level architectural forms. To close this gap, we introduce the Architecture Tradeoff and Risk Analysis Framework (ATRAF) -- a unified, scenario-driven framework for evaluating tradeoffs and risks across architectural levels. ATRAF encompasses three methods: the Architecture Tradeoff and Risk Analysis Method (ATRAM), extending ATAM with enhanced risk identification for concrete systems; the Reference Architecture Tradeoff and Risk Analysis Method (RATRAM), adapting ATRAM to the evaluation of domain-level reference architectures; and the Architectural Framework Tradeoff and Risk Analysis Method (AFTRAM), supporting the evaluation of architectural frameworks that guide entire system families. All three methods follow an iterative spiral process that enables the identification of sensitivities, tradeoffs, and risks while supporting continuous refinement of architectural artifacts. We demonstrate ATRAF through progressively abstracted examples derived from the Remote Temperature Sensor (RTS) case, originally introduced in the ATAM literature. ATRAF equips architects, reference modelers, and framework designers with a practical, systematic approach for analyzing design alternatives and managing quality attribute tradeoffs early in the lifecycle and across all levels of architectural abstraction.","sentences":["Modern software systems are guided by hierarchical architectural concepts -- software architectures, reference architectures, and architectural frameworks -- each operating at a distinct level of abstraction.","These artifacts promote reuse, scalability, and consistency, but also embed tradeoffs that shape critical quality attributes such as modifiability, performance, and security.","Existing evaluation methods, such as the Architecture Tradeoff Analysis Method (ATAM), focus on system-specific architectures and are not designed to address the broader generality and variability of higher-level architectural forms.","To close this gap, we introduce the Architecture Tradeoff and Risk Analysis Framework (ATRAF) -- a unified, scenario-driven framework for evaluating tradeoffs and risks across architectural levels.","ATRAF encompasses three methods: the Architecture Tradeoff and Risk Analysis Method (ATRAM), extending ATAM with enhanced risk identification for concrete systems; the Reference Architecture Tradeoff and Risk Analysis Method (RATRAM), adapting ATRAM to the evaluation of domain-level reference architectures; and the Architectural Framework Tradeoff and Risk Analysis Method (AFTRAM), supporting the evaluation of architectural frameworks that guide entire system families.","All three methods follow an iterative spiral process that enables the identification of sensitivities, tradeoffs, and risks while supporting continuous refinement of architectural artifacts.","We demonstrate ATRAF through progressively abstracted examples derived from the Remote Temperature Sensor (RTS) case, originally introduced in the ATAM literature.","ATRAF equips architects, reference modelers, and framework designers with a practical, systematic approach for analyzing design alternatives and managing quality attribute tradeoffs early in the lifecycle and across all levels of architectural abstraction."],"url":"http://arxiv.org/abs/2505.00688v1"}
{"created":"2025-05-01 17:47:44","title":"On the Importance of Gaussianizing Representations","abstract":"The normal distribution plays a central role in information theory - it is at the same time the best-case signal and worst-case noise distribution, has the greatest representational capacity of any distribution, and offers an equivalence between uncorrelatedness and independence for joint distributions. Accounting for the mean and variance of activations throughout the layers of deep neural networks has had a significant effect on facilitating their effective training, but seldom has a prescription for precisely what distribution these activations should take, and how this might be achieved, been offered. Motivated by the information-theoretic properties of the normal distribution, we address this question and concurrently present normality normalization: a novel normalization layer which encourages normality in the feature representations of neural networks using the power transform and employs additive Gaussian noise during training. Our experiments comprehensively demonstrate the effectiveness of normality normalization, in regards to its generalization performance on an array of widely used model and dataset combinations, its strong performance across various common factors of variation such as model width, depth, and training minibatch size, its suitability for usage wherever existing normalization layers are conventionally used, and as a means to improving model robustness to random perturbations.","sentences":["The normal distribution plays a central role in information theory - it is at the same time the best-case signal and worst-case noise distribution, has the greatest representational capacity of any distribution, and offers an equivalence between uncorrelatedness and independence for joint distributions.","Accounting for the mean and variance of activations throughout the layers of deep neural networks has had a significant effect on facilitating their effective training, but seldom has a prescription for precisely what distribution these activations should take, and how this might be achieved, been offered.","Motivated by the information-theoretic properties of the normal distribution, we address this question and concurrently present normality normalization: a novel normalization layer which encourages normality in the feature representations of neural networks using the power transform and employs additive Gaussian noise during training.","Our experiments comprehensively demonstrate the effectiveness of normality normalization, in regards to its generalization performance on an array of widely used model and dataset combinations, its strong performance across various common factors of variation such as model width, depth, and training minibatch size, its suitability for usage wherever existing normalization layers are conventionally used, and as a means to improving model robustness to random perturbations."],"url":"http://arxiv.org/abs/2505.00685v1"}
{"created":"2025-05-01 17:45:59","title":"Visual Test-time Scaling for GUI Agent Grounding","abstract":"We introduce RegionFocus, a visual test-time scaling approach for Vision Language Model Agents. Understanding webpages is challenging due to the visual complexity of GUI images and the large number of interface elements, making accurate action selection difficult. Our approach dynamically zooms in on relevant regions, reducing background clutter and improving grounding accuracy. To support this process, we propose an image-as-map mechanism that visualizes key landmarks at each step, providing a transparent action record and enables the agent to effectively choose among action candidates. Even with a simple region selection strategy, we observe significant performance gains of 28+\\% on Screenspot-pro and 24+\\% on WebVoyager benchmarks on top of two state-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL, highlighting the effectiveness of visual test-time scaling in interactive settings. We achieve a new state-of-the-art grounding performance of 61.6\\% on the ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model. Our code will be released publicly at https://github.com/tiangeluo/RegionFocus.","sentences":["We introduce RegionFocus, a visual test-time scaling approach for Vision Language Model Agents.","Understanding webpages is challenging due to the visual complexity of GUI images and the large number of interface elements, making accurate action selection difficult.","Our approach dynamically zooms in on relevant regions, reducing background clutter and improving grounding accuracy.","To support this process, we propose an image-as-map mechanism that visualizes key landmarks at each step, providing a transparent action record and enables the agent to effectively choose among action candidates.","Even with a simple region selection strategy, we observe significant performance gains of 28+\\% on Screenspot-pro and 24+\\% on WebVoyager benchmarks on top of two state-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL, highlighting the effectiveness of visual test-time scaling in interactive settings.","We achieve a new state-of-the-art grounding performance of 61.6\\% on the ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.","Our code will be released publicly at https://github.com/tiangeluo/RegionFocus."],"url":"http://arxiv.org/abs/2505.00684v1"}
{"created":"2025-05-01 17:41:49","title":"MINERVA: Evaluating Complex Video Reasoning","abstract":"Multimodal LLMs are turning their focus to video benchmarks, however most video benchmarks only provide outcome supervision, with no intermediate or interpretable reasoning steps. This makes it challenging to assess if models are truly able to combine perceptual and temporal information to reason about videos, or simply get the correct answer by chance or by exploiting linguistic biases. To remedy this, we provide a new video reasoning dataset called MINERVA for modern multimodal models. Each question in the dataset comes with 5 answer choices, as well as detailed, hand-crafted reasoning traces. Our dataset is multimodal, diverse in terms of video domain and length, and consists of complex multi-step questions. Extensive benchmarking shows that our dataset provides a challenge for frontier open-source and proprietary models. We perform fine-grained error analysis to identify common failure modes across various models, and create a taxonomy of reasoning errors. We use this to explore both human and LLM-as-a-judge methods for scoring video reasoning traces, and find that failure modes are primarily related to temporal localization, followed by visual perception errors, as opposed to logical or completeness errors. The dataset, along with questions, answer candidates and reasoning traces will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva.","sentences":["Multimodal LLMs are turning their focus to video benchmarks, however most video benchmarks only provide outcome supervision, with no intermediate or interpretable reasoning steps.","This makes it challenging to assess if models are truly able to combine perceptual and temporal information to reason about videos, or simply get the correct answer by chance or by exploiting linguistic biases.","To remedy this, we provide a new video reasoning dataset called MINERVA for modern multimodal models.","Each question in the dataset comes with 5 answer choices, as well as detailed, hand-crafted reasoning traces.","Our dataset is multimodal, diverse in terms of video domain and length, and consists of complex multi-step questions.","Extensive benchmarking shows that our dataset provides a challenge for frontier open-source and proprietary models.","We perform fine-grained error analysis to identify common failure modes across various models, and create a taxonomy of reasoning errors.","We use this to explore both human and LLM-as-a-judge methods for scoring video reasoning traces, and find that failure modes are primarily related to temporal localization, followed by visual perception errors, as opposed to logical or completeness errors.","The dataset, along with questions, answer candidates and reasoning traces will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva."],"url":"http://arxiv.org/abs/2505.00681v1"}
{"created":"2025-05-01 17:39:02","title":"Steering Large Language Models with Register Analysis for Arbitrary Style Transfer","abstract":"Large Language Models (LLMs) have demonstrated strong capabilities in rewriting text across various styles. However, effectively leveraging this ability for example-based arbitrary style transfer, where an input text is rewritten to match the style of a given exemplar, remains an open challenge. A key question is how to describe the style of the exemplar to guide LLMs toward high-quality rewrites. In this work, we propose a prompting method based on register analysis to guide LLMs to perform this task. Empirical evaluations across multiple style transfer tasks show that our prompting approach enhances style transfer strength while preserving meaning more effectively than existing prompting strategies.","sentences":["Large Language Models (LLMs) have demonstrated strong capabilities in rewriting text across various styles.","However, effectively leveraging this ability for example-based arbitrary style transfer, where an input text is rewritten to match the style of a given exemplar, remains an open challenge.","A key question is how to describe the style of the exemplar to guide LLMs toward high-quality rewrites.","In this work, we propose a prompting method based on register analysis to guide LLMs to perform this task.","Empirical evaluations across multiple style transfer tasks show that our prompting approach enhances style transfer strength while preserving meaning more effectively than existing prompting strategies."],"url":"http://arxiv.org/abs/2505.00679v1"}
{"created":"2025-05-01 17:31:33","title":"Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions","abstract":"Memory is a fundamental component of AI systems, underpinning large language models (LLMs) based agents. While prior surveys have focused on memory applications with LLMs, they often overlook the atomic operations that underlie memory dynamics. In this survey, we first categorize memory representations into parametric, contextual structured, and contextual unstructured and then introduce six fundamental memory operations: Consolidation, Updating, Indexing, Forgetting, Retrieval, and Compression. We systematically map these operations to the most relevant research topics across long-term, long-context, parametric modification, and multi-source memory. By reframing memory systems through the lens of atomic operations and representation types, this survey provides a structured and dynamic perspective on research, benchmark datasets, and tools related to memory in AI, clarifying the functional interplay in LLMs based agents while outlining promising directions for future research\\footnote{The paper list, datasets, methods and tools are available at \\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\_Memory\\_in\\_AI}.}.","sentences":["Memory is a fundamental component of AI systems, underpinning large language models (LLMs) based agents.","While prior surveys have focused on memory applications with LLMs, they often overlook the atomic operations that underlie memory dynamics.","In this survey, we first categorize memory representations into parametric, contextual structured, and contextual unstructured and then introduce six fundamental memory operations: Consolidation, Updating, Indexing, Forgetting, Retrieval, and Compression.","We systematically map these operations to the most relevant research topics across long-term, long-context, parametric modification, and multi-source memory.","By reframing memory systems through the lens of atomic operations and representation types, this survey provides a structured and dynamic perspective on research, benchmark datasets, and tools related to memory in AI, clarifying the functional interplay in LLMs based agents while outlining promising directions for future research\\footnote{The paper list, datasets, methods and tools are available at \\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\_Memory\\_in\\_AI}.}."],"url":"http://arxiv.org/abs/2505.00675v1"}
{"created":"2025-05-01 17:22:11","title":"Multi-Constraint Safe Reinforcement Learning via Closed-form Solution for Log-Sum-Exp Approximation of Control Barrier Functions","abstract":"The safety of training task policies and their subsequent application using reinforcement learning (RL) methods has become a focal point in the field of safe RL. A central challenge in this area remains the establishment of theoretical guarantees for safety during both the learning and deployment processes. Given the successful implementation of Control Barrier Function (CBF)-based safety strategies in a range of control-affine robotic systems, CBF-based safe RL demonstrates significant promise for practical applications in real-world scenarios. However, integrating these two approaches presents several challenges. First, embedding safety optimization within the RL training pipeline requires that the optimization outputs be differentiable with respect to the input parameters, a condition commonly referred to as differentiable optimization, which is non-trivial to solve. Second, the differentiable optimization framework confronts significant efficiency issues, especially when dealing with multi-constraint problems. To address these challenges, this paper presents a CBF-based safe RL architecture that effectively mitigates the issues outlined above. The proposed approach constructs a continuous AND logic approximation for the multiple constraints using a single composite CBF. By leveraging this approximation, a close-form solution of the quadratic programming is derived for the policy network in RL, thereby circumventing the need for differentiable optimization within the end-to-end safe RL pipeline. This strategy significantly reduces computational complexity because of the closed-form solution while maintaining safety guarantees. Simulation results demonstrate that, in comparison to existing approaches relying on differentiable optimization, the proposed method significantly reduces training computational costs while ensuring provable safety throughout the training process.","sentences":["The safety of training task policies and their subsequent application using reinforcement learning (RL) methods has become a focal point in the field of safe RL.","A central challenge in this area remains the establishment of theoretical guarantees for safety during both the learning and deployment processes.","Given the successful implementation of Control Barrier Function (CBF)-based safety strategies in a range of control-affine robotic systems, CBF-based safe RL demonstrates significant promise for practical applications in real-world scenarios.","However, integrating these two approaches presents several challenges.","First, embedding safety optimization within the RL training pipeline requires that the optimization outputs be differentiable with respect to the input parameters, a condition commonly referred to as differentiable optimization, which is non-trivial to solve.","Second, the differentiable optimization framework confronts significant efficiency issues, especially when dealing with multi-constraint problems.","To address these challenges, this paper presents a CBF-based safe RL architecture that effectively mitigates the issues outlined above.","The proposed approach constructs a continuous AND logic approximation for the multiple constraints using a single composite CBF.","By leveraging this approximation, a close-form solution of the quadratic programming is derived for the policy network in RL, thereby circumventing the need for differentiable optimization within the end-to-end safe RL pipeline.","This strategy significantly reduces computational complexity because of the closed-form solution while maintaining safety guarantees.","Simulation results demonstrate that, in comparison to existing approaches relying on differentiable optimization, the proposed method significantly reduces training computational costs while ensuring provable safety throughout the training process."],"url":"http://arxiv.org/abs/2505.00671v1"}
{"created":"2025-05-01 17:19:48","title":"Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments","abstract":"Urban air pollution remains a pressing global concern, particularly in densely populated and traffic-intensive metropolitan areas like Delhi, where exposure to harmful pollutants severely impacts public health. Delhi, being one of the most polluted cities globally, experiences chronic air quality issues due to vehicular emissions, industrial activities, and construction dust, which exacerbate its already fragile atmospheric conditions. Traditional pollution mitigation strategies, such as static air purifying installations, often fail to maximize their impact due to suboptimal placement and limited adaptability to dynamic urban environments. This study presents a novel deep reinforcement learning (DRL) framework to optimize the placement of air purification booths to improve the air quality index (AQI) in the city of Delhi. We employ Proximal Policy Optimization (PPO), a state-of-the-art reinforcement learning algorithm, to iteratively learn and identify high-impact locations based on multiple spatial and environmental factors, including population density, traffic patterns, industrial influence, and green space constraints. Our approach is benchmarked against conventional placement strategies, including random and greedy AQI-based methods, using multi-dimensional performance evaluation metrics such as AQI improvement, spatial coverage, population and traffic impact, and spatial entropy. Experimental results demonstrate that the RL-based approach outperforms baseline methods by achieving a balanced and effective distribution of air purification infrastructure. Notably, the DRL framework achieves an optimal trade-off between AQI reduction and high-coverage deployment, ensuring equitable environmental benefits across urban regions. The findings underscore the potential of AI-driven spatial optimization in advancing smart city initiatives and data-driven urban air quality management.","sentences":["Urban air pollution remains a pressing global concern, particularly in densely populated and traffic-intensive metropolitan areas like Delhi, where exposure to harmful pollutants severely impacts public health.","Delhi, being one of the most polluted cities globally, experiences chronic air quality issues due to vehicular emissions, industrial activities, and construction dust, which exacerbate its already fragile atmospheric conditions.","Traditional pollution mitigation strategies, such as static air purifying installations, often fail to maximize their impact due to suboptimal placement and limited adaptability to dynamic urban environments.","This study presents a novel deep reinforcement learning (DRL) framework to optimize the placement of air purification booths to improve the air quality index (AQI) in the city of Delhi.","We employ Proximal Policy Optimization (PPO), a state-of-the-art reinforcement learning algorithm, to iteratively learn and identify high-impact locations based on multiple spatial and environmental factors, including population density, traffic patterns, industrial influence, and green space constraints.","Our approach is benchmarked against conventional placement strategies, including random and greedy AQI-based methods, using multi-dimensional performance evaluation metrics such as AQI improvement, spatial coverage, population and traffic impact, and spatial entropy.","Experimental results demonstrate that the RL-based approach outperforms baseline methods by achieving a balanced and effective distribution of air purification infrastructure.","Notably, the DRL framework achieves an optimal trade-off between AQI reduction and high-coverage deployment, ensuring equitable environmental benefits across urban regions.","The findings underscore the potential of AI-driven spatial optimization in advancing smart city initiatives and data-driven urban air quality management."],"url":"http://arxiv.org/abs/2505.00668v1"}
{"created":"2025-05-01 17:15:04","title":"Auditing without Leaks Despite Curiosity","abstract":"\\textit{Auditing} data accesses helps preserve privacy and ensures accountability by allowing one to determine who accessed (potentially sensitive) information. A prior formal definition of register auditability was based on the values returned by read operations, \\emph{without accounting for cases where a reader might learn a value without explicitly reading it or gain knowledge of data access without being an auditor}.   This paper introduces a refined definition of auditability that focuses on when a read operation is \\emph{effective}, rather than relying on its completion and return of a value. Furthermore, we formally specify the constraints that \\textit{prevent readers from learning values they did not explicitly read or from auditing other readers' accesses.}   Our primary algorithmic contribution is a wait-free implementation of a \\emph{multi-writer, multi-reader register} that tracks effective reads while preventing unauthorized audits. The key challenge is ensuring that a read is auditable as soon as it becomes effective, which we achieve by combining value access and access logging into a single atomic operation. Another challenge is recording accesses without exposing them to readers, which we address using a simple encryption technique (one-time pad).   We extend this implementation to an \\emph{auditable max register} that tracks the largest value ever written. The implementation deals with the additional challenge posed by the max register semantics, which allows readers to learn prior values without reading them.   The max register, in turn, serves as the foundation for implementing an \\emph{auditable snapshot} object and, more generally, \\emph{versioned types}. These extensions maintain the strengthened notion of auditability, appropriately adapted from multi-writer, multi-reader registers.","sentences":["\\textit{Auditing} data accesses helps preserve privacy and ensures accountability by allowing one to determine who accessed (potentially sensitive) information.","A prior formal definition of register auditability was based on the values returned by read operations, \\emph{without accounting for cases where a reader might learn a value without explicitly reading it or gain knowledge of data access without being an auditor}.   ","This paper introduces a refined definition of auditability that focuses on when a read operation is \\emph{effective}, rather than relying on its completion and return of a value.","Furthermore, we formally specify the constraints that \\textit{prevent readers from learning values they did not explicitly read or from auditing other readers' accesses.}   ","Our primary algorithmic contribution is a wait-free implementation of a \\emph{multi-writer, multi-reader register} that tracks effective reads while preventing unauthorized audits.","The key challenge is ensuring that a read is auditable as soon as it becomes effective, which we achieve by combining value access and access logging into a single atomic operation.","Another challenge is recording accesses without exposing them to readers, which we address using a simple encryption technique (one-time pad).   ","We extend this implementation to an \\emph{auditable max register} that tracks the largest value ever written.","The implementation deals with the additional challenge posed by the max register semantics, which allows readers to learn prior values without reading them.   ","The max register, in turn, serves as the foundation for implementing an \\emph{auditable snapshot} object and, more generally, \\emph{versioned types}.","These extensions maintain the strengthened notion of auditability, appropriately adapted from multi-writer, multi-reader registers."],"url":"http://arxiv.org/abs/2505.00665v1"}
{"created":"2025-05-01 17:07:01","title":"Wasserstein Policy Optimization","abstract":"We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm for reinforcement learning in continuous action spaces. WPO can be derived as an approximation to Wasserstein gradient flow over the space of all policies projected into a finite-dimensional parameter space (e.g., the weights of a neural network), leading to a simple and completely general closed-form update. The resulting algorithm combines many properties of deterministic and classic policy gradient methods. Like deterministic policy gradients, it exploits knowledge of the gradient of the action-value function with respect to the action. Like classic policy gradients, it can be applied to stochastic policies with arbitrary distributions over actions -- without using the reparameterization trick. We show results on the DeepMind Control Suite and a magnetic confinement fusion task which compare favorably with state-of-the-art continuous control methods.","sentences":["We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm for reinforcement learning in continuous action spaces.","WPO can be derived as an approximation to Wasserstein gradient flow over the space of all policies projected into a finite-dimensional parameter space (e.g., the weights of a neural network), leading to a simple and completely general closed-form update.","The resulting algorithm combines many properties of deterministic and classic policy gradient methods.","Like deterministic policy gradients, it exploits knowledge of the gradient of the action-value function with respect to the action.","Like classic policy gradients, it can be applied to stochastic policies with arbitrary distributions over actions -- without using the reparameterization trick.","We show results on the DeepMind Control Suite and a magnetic confinement fusion task which compare favorably with state-of-the-art continuous control methods."],"url":"http://arxiv.org/abs/2505.00663v1"}
{"created":"2025-05-01 17:03:17","title":"DeepCritic: Deliberate Critique with Large Language Models","abstract":"As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem. Leveraging LLMs as critique models to achieve automated supervision is a promising solution. In this work, we focus on studying and enhancing the math critique ability of LLMs. Current LLM critics provide critiques that are too shallow and superficial on each step, leading to low judgment accuracy and struggling to offer sufficient feedback for the LLM generator to correct mistakes. To tackle this issue, we propose a novel and effective two-stage framework to develop LLM critics that are capable of deliberately critiquing on each reasoning step of math solutions. In the first stage, we utilize Qwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for supervised fine-tuning. Each seed critique consists of deliberate step-wise critiques that includes multi-perspective verifications as well as in-depth critiques of initial critiques for each reasoning step. Then, we perform reinforcement learning on the fine-tuned model with either existing human-labeled data from PRM800K or our automatically annotated data obtained via Monte Carlo sampling-based correctness estimation, to further incentivize its critique ability. Our developed critique model built on Qwen2.5-7B-Instruct not only significantly outperforms existing LLM critics (including the same-sized DeepSeek-R1-distill models and GPT-4o) on various error identification benchmarks, but also more effectively helps the LLM generator refine erroneous steps through more detailed feedback.","sentences":["As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem.","Leveraging LLMs as critique models to achieve automated supervision is a promising solution.","In this work, we focus on studying and enhancing the math critique ability of LLMs.","Current LLM critics provide critiques that are too shallow and superficial on each step, leading to low judgment accuracy and struggling to offer sufficient feedback for the LLM generator to correct mistakes.","To tackle this issue, we propose a novel and effective two-stage framework to develop LLM critics that are capable of deliberately critiquing on each reasoning step of math solutions.","In the first stage, we utilize Qwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for supervised fine-tuning.","Each seed critique consists of deliberate step-wise critiques that includes multi-perspective verifications as well as in-depth critiques of initial critiques for each reasoning step.","Then, we perform reinforcement learning on the fine-tuned model with either existing human-labeled data from PRM800K or our automatically annotated data obtained via Monte Carlo sampling-based correctness estimation, to further incentivize its critique ability.","Our developed critique model built on Qwen2.5-7B-Instruct not only significantly outperforms existing LLM critics (including the same-sized DeepSeek-R1-distill models and GPT-4o) on various error identification benchmarks, but also more effectively helps the LLM generator refine erroneous steps through more detailed feedback."],"url":"http://arxiv.org/abs/2505.00662v1"}
{"created":"2025-05-01 17:02:27","title":"On the generalization of language models from in-context learning and finetuning: a controlled study","abstract":"Large language models exhibit exciting capabilities, yet can show surprisingly narrow generalization from finetuning -- from failing to generalize to simple reversals of relations they are trained on, to missing logical deductions that can be made from trained information. These failures to generalize from fine-tuning can hinder practical application of these models. However, language models' in-context learning shows different inductive biases, and can generalize better in some of these cases. Here, we explore these differences in generalization between in-context- and fine-tuning-based learning. To do so, we constructed several novel datasets to evaluate and improve models' ability to generalize from finetuning data. The datasets are constructed to isolate the knowledge in the dataset from that in pretraining, to create clean tests of generalization. We expose pretrained large models to controlled subsets of the information in these datasets -- either in context, or through fine-tuning -- and evaluate their performance on test sets that require various types of generalization. We find overall that in data-matched settings, in-context learning can generalize more flexibly than fine-tuning (though we also find some qualifications of prior findings, such as cases when fine-tuning can generalize to reversals embedded in a larger structure of knowledge). We build on these findings to propose a method to enable improved generalization from fine-tuning: adding in-context inferences to finetuning data. We show that this method improves generalization across various splits of our datasets and other benchmarks. Our results have implications for understanding the inductive biases of different modes of learning in language models, and practically improving their performance.","sentences":["Large language models exhibit exciting capabilities, yet can show surprisingly narrow generalization from finetuning -- from failing to generalize to simple reversals of relations they are trained on, to missing logical deductions that can be made from trained information.","These failures to generalize from fine-tuning can hinder practical application of these models.","However, language models' in-context learning shows different inductive biases, and can generalize better in some of these cases.","Here, we explore these differences in generalization between in-context- and fine-tuning-based learning.","To do so, we constructed several novel datasets to evaluate and improve models' ability to generalize from finetuning data.","The datasets are constructed to isolate the knowledge in the dataset from that in pretraining, to create clean tests of generalization.","We expose pretrained large models to controlled subsets of the information in these datasets -- either in context, or through fine-tuning -- and evaluate their performance on test sets that require various types of generalization.","We find overall that in data-matched settings, in-context learning can generalize more flexibly than fine-tuning (though we also find some qualifications of prior findings, such as cases when fine-tuning can generalize to reversals embedded in a larger structure of knowledge).","We build on these findings to propose a method to enable improved generalization from fine-tuning: adding in-context inferences to finetuning data.","We show that this method improves generalization across various splits of our datasets and other benchmarks.","Our results have implications for understanding the inductive biases of different modes of learning in language models, and practically improving their performance."],"url":"http://arxiv.org/abs/2505.00661v1"}
{"created":"2025-05-01 17:02:22","title":"AI-based CSI Feedback with Digital Twins: Real-World Validation and Insights","abstract":"Deep learning (DL) has shown great potential for enhancing channel state information (CSI) feedback in multiple-input multiple-output (MIMO) communication systems, a subject currently under study by the 3GPP standards body. Digital twins (DTs) have emerged as an effective means to generate site-specific datasets for training DL-based CSI feedback models. However, most existing studies rely solely on simulations, leaving the effectiveness of DTs in reducing DL training costs yet to be validated through realistic experimental setups. This paper addresses this gap by establishing a real-world (RW) environment and corresponding virtual channels using ray tracing with replicated 3D models and accurate antenna properties. We evaluate whether models trained in DT environments can effectively operate in RW scenarios and quantify the benefits of online learning (OL) for performance enhancement. Results show that a dedicated DT remains essential even with OL to achieve satisfactory performance in RW scenarios.","sentences":["Deep learning (DL) has shown great potential for enhancing channel state information (CSI) feedback in multiple-input multiple-output (MIMO) communication systems, a subject currently under study by the 3GPP standards body.","Digital twins (DTs) have emerged as an effective means to generate site-specific datasets for training DL-based CSI feedback models.","However, most existing studies rely solely on simulations, leaving the effectiveness of DTs in reducing DL training costs yet to be validated through realistic experimental setups.","This paper addresses this gap by establishing a real-world (RW) environment and corresponding virtual channels using ray tracing with replicated 3D models and accurate antenna properties.","We evaluate whether models trained in DT environments can effectively operate in RW scenarios and quantify the benefits of online learning (OL) for performance enhancement.","Results show that a dedicated DT remains essential even with OL to achieve satisfactory performance in RW scenarios."],"url":"http://arxiv.org/abs/2505.00660v1"}
{"created":"2025-05-01 17:00:50","title":"RIS Partitioning and User Clustering for Resilient Non-Orthogonal Multiple Access UAV Networks","abstract":"The integration of reconfigurable intelligent surfaces (RISs) and unmanned aerial vehicles (UAVs) has emerged as a promising solution for enhancing connectivity in future wireless networks. This paper designs well-connected and resilient UAV networks by deploying and virtually partitioning multiple RISs to create multiple RIS-aided links, focusing on a link-layer perspective. The RIS-aided links are created to connect user equipment (UE) to blocked and reliable UAVs, where multiple UEs can transmit to same UAV via RIS using non-orthogonal multiple access (NOMA), granting access to UEs and maximizing network connectivity. We first derive exact and approximated closed-form expressions for signal-to-interference plus noise ratio (SINR) based on aligned and non-aligned RIS-aided beams. Then, we propose to formulate the problem of maximizing network connectivity that jointly considers (i) UE NOMA clustering, (ii) RIS-aided link selection, and (ii) virtual RIS partitioning. This problem is a computationally expensive combinatorial optimization. To tackle this problem, a two-step iterative approach, called RIS-aided NOMA, is proposed. In the first step, the UEs are clustered to the RISs according to their channel gains, while UAVs are associated to those generated clusters based on their reliability, which measures the criticality of UAVs. The second step optimally partitions the RISs to support each of the cluster members. In this step, we derive the closed-form equations for the optimal partitioning of RISs within the clusters. Simulation results demonstrate that the proposed RIS-aided NOMA yields a gain of 30% to 40%, respectively, compared to UAV traditional scheme. The finding emphasizes the potential of integrating RIS with UAV communications as a robust and reliable connectivity solution for future wireless communication systems.","sentences":["The integration of reconfigurable intelligent surfaces (RISs) and unmanned aerial vehicles (UAVs) has emerged as a promising solution for enhancing connectivity in future wireless networks.","This paper designs well-connected and resilient UAV networks by deploying and virtually partitioning multiple RISs to create multiple RIS-aided links, focusing on a link-layer perspective.","The RIS-aided links are created to connect user equipment (UE) to blocked and reliable UAVs, where multiple UEs can transmit to same UAV via RIS using non-orthogonal multiple access (NOMA), granting access to UEs and maximizing network connectivity.","We first derive exact and approximated closed-form expressions for signal-to-interference plus noise ratio (SINR) based on aligned and non-aligned RIS-aided beams.","Then, we propose to formulate the problem of maximizing network connectivity that jointly considers (i) UE NOMA clustering, (ii) RIS-aided link selection, and (ii) virtual RIS partitioning.","This problem is a computationally expensive combinatorial optimization.","To tackle this problem, a two-step iterative approach, called RIS-aided NOMA, is proposed.","In the first step, the UEs are clustered to the RISs according to their channel gains, while UAVs are associated to those generated clusters based on their reliability, which measures the criticality of UAVs.","The second step optimally partitions the RISs to support each of the cluster members.","In this step, we derive the closed-form equations for the optimal partitioning of RISs within the clusters.","Simulation results demonstrate that the proposed RIS-aided NOMA yields a gain of 30% to 40%, respectively, compared to UAV traditional scheme.","The finding emphasizes the potential of integrating RIS with UAV communications as a robust and reliable connectivity solution for future wireless communication systems."],"url":"http://arxiv.org/abs/2505.00658v1"}
{"created":"2025-05-01 16:55:44","title":"Large Language Models Understanding: an Inherent Ambiguity Barrier","abstract":"A lively ongoing debate is taking place, since the extraordinary emergence of Large Language Models (LLMs) with regards to their capability to understand the world and capture the meaning of the dialogues in which they are involved. Arguments and counter-arguments have been proposed based upon thought experiments, anecdotal conversations between LLMs and humans, statistical linguistic analysis, philosophical considerations, and more. In this brief paper we present a counter-argument based upon a thought experiment and semi-formal considerations leading to an inherent ambiguity barrier which prevents LLMs from having any understanding of what their amazingly fluent dialogues mean.","sentences":["A lively ongoing debate is taking place, since the extraordinary emergence of Large Language Models (LLMs) with regards to their capability to understand the world and capture the meaning of the dialogues in which they are involved.","Arguments and counter-arguments have been proposed based upon thought experiments, anecdotal conversations between LLMs and humans, statistical linguistic analysis, philosophical considerations, and more.","In this brief paper we present a counter-argument based upon a thought experiment and semi-formal considerations leading to an inherent ambiguity barrier which prevents LLMs from having any understanding of what their amazingly fluent dialogues mean."],"url":"http://arxiv.org/abs/2505.00654v1"}
{"created":"2025-05-01 16:54:21","title":"Open-Source LLM-Driven Federated Transformer for Predictive IoV Management","abstract":"The proliferation of connected vehicles within the Internet of Vehicles (IoV) ecosystem presents critical challenges in ensuring scalable, real-time, and privacy-preserving traffic management. Existing centralized IoV solutions often suffer from high latency, limited scalability, and reliance on proprietary Artificial Intelligence (AI) models, creating significant barriers to widespread deployment, particularly in dynamic and privacy-sensitive environments. Meanwhile, integrating Large Language Models (LLMs) in vehicular systems remains underexplored, especially concerning prompt optimization and effective utilization in federated contexts. To address these challenges, we propose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel framework that leverages open-source LLMs for predictive IoV management. FPoTT introduces a dynamic prompt optimization mechanism that iteratively refines textual prompts to enhance trajectory prediction. The architecture employs a dual-layer federated learning paradigm, combining lightweight edge models for real-time inference with cloud-based LLMs to retain global intelligence. A Transformer-driven synthetic data generator is incorporated to augment training with diverse, high-fidelity traffic scenarios in the Next Generation Simulation (NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing EleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data while maintaining high performance on synthetic datasets. These results underscore the potential of open-source LLMs in enabling secure, adaptive, and scalable IoV management, offering a promising alternative to proprietary solutions in smart mobility ecosystems.","sentences":["The proliferation of connected vehicles within the Internet of Vehicles (IoV) ecosystem presents critical challenges in ensuring scalable, real-time, and privacy-preserving traffic management.","Existing centralized IoV solutions often suffer from high latency, limited scalability, and reliance on proprietary Artificial Intelligence (AI) models, creating significant barriers to widespread deployment, particularly in dynamic and privacy-sensitive environments.","Meanwhile, integrating Large Language Models (LLMs) in vehicular systems remains underexplored, especially concerning prompt optimization and effective utilization in federated contexts.","To address these challenges, we propose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel framework that leverages open-source LLMs for predictive IoV management.","FPoTT introduces a dynamic prompt optimization mechanism that iteratively refines textual prompts to enhance trajectory prediction.","The architecture employs a dual-layer federated learning paradigm, combining lightweight edge models for real-time inference with cloud-based LLMs to retain global intelligence.","A Transformer-driven synthetic data generator is incorporated to augment training with diverse, high-fidelity traffic scenarios in the Next Generation Simulation (NGSIM) format.","Extensive evaluations demonstrate that FPoTT, utilizing EleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data while maintaining high performance on synthetic datasets.","These results underscore the potential of open-source LLMs in enabling secure, adaptive, and scalable IoV management, offering a promising alternative to proprietary solutions in smart mobility ecosystems."],"url":"http://arxiv.org/abs/2505.00651v1"}
{"created":"2025-05-01 16:51:48","title":"OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification","abstract":"Unsupervised learning of disease subtypes from multi-omics data presents a significant opportunity for advancing personalized medicine. We introduce OmicsCL, a modular contrastive learning framework that jointly embeds heterogeneous omics modalities-such as gene expression, DNA methylation, and miRNA expression-into a unified latent space. Our method incorporates a survival-aware contrastive loss that encourages the model to learn representations aligned with survival-related patterns, without relying on labeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers clinically meaningful clusters and achieves strong unsupervised concordance with patient survival. The framework demonstrates robustness across hyperparameter configurations and can be tuned to prioritize either subtype coherence or survival stratification. Ablation studies confirm that integrating survival-aware loss significantly enhances the predictive power of learned embeddings. These results highlight the promise of contrastive objectives for biological insight discovery in high-dimensional, heterogeneous omics data.","sentences":["Unsupervised learning of disease subtypes from multi-omics data presents a significant opportunity for advancing personalized medicine.","We introduce OmicsCL, a modular contrastive learning framework that jointly embeds heterogeneous omics modalities-such as gene expression, DNA methylation, and miRNA expression-into a unified latent space.","Our method incorporates a survival-aware contrastive loss that encourages the model to learn representations aligned with survival-related patterns, without relying on labeled outcomes.","Evaluated on the TCGA BRCA dataset, OmicsCL uncovers clinically meaningful clusters and achieves strong unsupervised concordance with patient survival.","The framework demonstrates robustness across hyperparameter configurations and can be tuned to prioritize either subtype coherence or survival stratification.","Ablation studies confirm that integrating survival-aware loss significantly enhances the predictive power of learned embeddings.","These results highlight the promise of contrastive objectives for biological insight discovery in high-dimensional, heterogeneous omics data."],"url":"http://arxiv.org/abs/2505.00650v1"}
{"created":"2025-05-01 16:48:37","title":"Investigating Task Arithmetic for Zero-Shot Information Retrieval","abstract":"Large Language Models (LLMs) have shown impressive zero-shot performance across a variety of Natural Language Processing tasks, including document re-ranking. However, their effectiveness degrades on unseen tasks and domains, largely due to shifts in vocabulary and word distributions. In this paper, we investigate Task Arithmetic, a technique that combines the weights of LLMs pre-trained on different tasks or domains via simple mathematical operations, such as addition or subtraction, to adapt retrieval models without requiring additional fine-tuning. Our method is able to synthesize diverse tasks and domain knowledge into a single model, enabling effective zero-shot adaptation in different retrieval contexts. Extensive experiments on publicly available scientific, biomedical, and multilingual datasets show that our method improves state-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in P@10. In addition to these empirical gains, our analysis provides insights into the strengths and limitations of Task Arithmetic as a practical strategy for zero-shot learning and model adaptation. We make our code publicly available at https://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR.","sentences":["Large Language Models (LLMs) have shown impressive zero-shot performance across a variety of Natural Language Processing tasks, including document re-ranking.","However, their effectiveness degrades on unseen tasks and domains, largely due to shifts in vocabulary and word distributions.","In this paper, we investigate Task Arithmetic, a technique that combines the weights of LLMs pre-trained on different tasks or domains via simple mathematical operations, such as addition or subtraction, to adapt retrieval models without requiring additional fine-tuning.","Our method is able to synthesize diverse tasks and domain knowledge into a single model, enabling effective zero-shot adaptation in different retrieval contexts.","Extensive experiments on publicly available scientific, biomedical, and multilingual datasets show that our method improves state-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in P@10.","In addition to these empirical gains, our analysis provides insights into the strengths and limitations of Task Arithmetic as a practical strategy for zero-shot learning and model adaptation.","We make our code publicly available at https://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR."],"url":"http://arxiv.org/abs/2505.00649v1"}
{"created":"2025-05-01 16:40:47","title":"GeoDEx: A Unified Geometric Framework for Tactile Dexterous and Extrinsic Manipulation under Force Uncertainty","abstract":"Sense of touch that allows robots to detect contact and measure interaction forces enables them to perform challenging tasks such as grasping fragile objects or using tools. Tactile sensors in theory can equip the robots with such capabilities. However, accuracy of the measured forces is not on a par with those of the force sensors due to the potential calibration challenges and noise. This has limited the values these sensors can offer in manipulation applications that require force control. In this paper, we introduce GeoDEx, a unified estimation, planning, and control framework using geometric primitives such as plane, cone and ellipsoid, which enables dexterous as well as extrinsic manipulation in the presence of uncertain force readings. Through various experimental results, we show that while relying on direct inaccurate and noisy force readings from tactile sensors results in unstable or failed manipulation, our method enables successful grasping and extrinsic manipulation of different objects. Additionally, compared to directly running optimization using SOCP (Second Order Cone Programming), planning and force estimation using our framework achieves a 14x speed-up.","sentences":["Sense of touch that allows robots to detect contact and measure interaction forces enables them to perform challenging tasks such as grasping fragile objects or using tools.","Tactile sensors in theory can equip the robots with such capabilities.","However, accuracy of the measured forces is not on a par with those of the force sensors due to the potential calibration challenges and noise.","This has limited the values these sensors can offer in manipulation applications that require force control.","In this paper, we introduce GeoDEx, a unified estimation, planning, and control framework using geometric primitives such as plane, cone and ellipsoid, which enables dexterous as well as extrinsic manipulation in the presence of uncertain force readings.","Through various experimental results, we show that while relying on direct inaccurate and noisy force readings from tactile sensors results in unstable or failed manipulation, our method enables successful grasping and extrinsic manipulation of different objects.","Additionally, compared to directly running optimization using SOCP (Second Order Cone Programming), planning and force estimation using our framework achieves a 14x speed-up."],"url":"http://arxiv.org/abs/2505.00647v1"}
{"created":"2025-05-01 16:18:07","title":"Forward kinematics of a general Stewart-Gough platform by elimination templates","abstract":"The paper proposes an efficient algebraic solution to the problem of forward kinematics for a general Stewart-Gough platform. The problem involves determining all possible postures of a mobile platform connected to a fixed base by six legs, given the leg lengths and the internal geometries of the platform and base. The problem is known to have 40 solutions (whether real or complex). The proposed algorithm consists of three main steps: (i) a specific sparse matrix of size 293x362 (the elimination template) is constructed from the coefficients of the polynomial system describing the platform's kinematics; (ii) the PLU decomposition of this matrix is used to construct a pair of 69x69 matrices; (iii) all 40 solutions (including complex ones) are obtained by computing the generalized eigenvectors of this matrix pair. The proposed algorithm is numerically robust, computationally efficient, and straightforward to implement - requiring only standard linear algebra decompositions. MATLAB, Julia, and Python implementations of the algorithm will be made publicly available.","sentences":["The paper proposes an efficient algebraic solution to the problem of forward kinematics for a general Stewart-Gough platform.","The problem involves determining all possible postures of a mobile platform connected to a fixed base by six legs, given the leg lengths and the internal geometries of the platform and base.","The problem is known to have 40 solutions (whether real or complex).","The proposed algorithm consists of three main steps: (i) a specific sparse matrix of size 293x362 (the elimination template) is constructed from the coefficients of the polynomial system describing the platform's kinematics; (ii) the PLU decomposition of this matrix is used to construct a pair of 69x69 matrices; (iii) all 40 solutions (including complex ones) are obtained by computing the generalized eigenvectors of this matrix pair.","The proposed algorithm is numerically robust, computationally efficient, and straightforward to implement - requiring only standard linear algebra decompositions.","MATLAB, Julia, and Python implementations of the algorithm will be made publicly available."],"url":"http://arxiv.org/abs/2505.00634v1"}
{"created":"2025-05-01 16:07:51","title":"Vision Mamba in Remote Sensing: A Comprehensive Survey of Techniques, Applications and Outlook","abstract":"Deep learning has profoundly transformed remote sensing, yet prevailing architectures like Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) remain constrained by critical trade-offs: CNNs suffer from limited receptive fields, while ViTs grapple with quadratic computational complexity, hindering their scalability for high-resolution remote sensing data. State Space Models (SSMs), particularly the recently proposed Mamba architecture, have emerged as a paradigm-shifting solution, combining linear computational scaling with global context modeling. This survey presents a comprehensive review of Mamba-based methodologies in remote sensing, systematically analyzing about 120 studies to construct a holistic taxonomy of innovations and applications. Our contributions are structured across five dimensions: (i) foundational principles of vision Mamba architectures, (ii) micro-architectural advancements such as adaptive scan strategies and hybrid SSM formulations, (iii) macro-architectural integrations, including CNN-Transformer-Mamba hybrids and frequency-domain adaptations, (iv) rigorous benchmarking against state-of-the-art methods in multiple application tasks, such as object detection, semantic segmentation, change detection, etc. and (v) critical analysis of unresolved challenges with actionable future directions. By bridging the gap between SSM theory and remote sensing practice, this survey establishes Mamba as a transformative framework for remote sensing analysis. To our knowledge, this paper is the first systematic review of Mamba architectures in remote sensing. Our work provides a structured foundation for advancing research in remote sensing systems through SSM-based methods. We curate an open-source repository (https://github.com/BaoBao0926/Awesome-Mamba-in-Remote-Sensing) to foster community-driven advancements.","sentences":["Deep learning has profoundly transformed remote sensing, yet prevailing architectures like Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) remain constrained by critical trade-offs: CNNs suffer from limited receptive fields, while ViTs grapple with quadratic computational complexity, hindering their scalability for high-resolution remote sensing data.","State Space Models (SSMs), particularly the recently proposed Mamba architecture, have emerged as a paradigm-shifting solution, combining linear computational scaling with global context modeling.","This survey presents a comprehensive review of Mamba-based methodologies in remote sensing, systematically analyzing about 120 studies to construct a holistic taxonomy of innovations and applications.","Our contributions are structured across five dimensions: (i) foundational principles of vision Mamba architectures, (ii) micro-architectural advancements such as adaptive scan strategies and hybrid SSM formulations, (iii) macro-architectural integrations, including CNN-Transformer-Mamba hybrids and frequency-domain adaptations, (iv) rigorous benchmarking against state-of-the-art methods in multiple application tasks, such as object detection, semantic segmentation, change detection, etc. and (v) critical analysis of unresolved challenges with actionable future directions.","By bridging the gap between SSM theory and remote sensing practice, this survey establishes Mamba as a transformative framework for remote sensing analysis.","To our knowledge, this paper is the first systematic review of Mamba architectures in remote sensing.","Our work provides a structured foundation for advancing research in remote sensing systems through SSM-based methods.","We curate an open-source repository (https://github.com/BaoBao0926/Awesome-Mamba-in-Remote-Sensing) to foster community-driven advancements."],"url":"http://arxiv.org/abs/2505.00630v1"}
{"created":"2025-05-01 16:06:17","title":"Brain Foundation Models with Hypergraph Dynamic Adapter for Brain Disease Analysis","abstract":"Brain diseases, such as Alzheimer's disease and brain tumors, present profound challenges due to their complexity and societal impact. Recent advancements in brain foundation models have shown significant promise in addressing a range of brain-related tasks. However, current brain foundation models are limited by task and data homogeneity, restricted generalization beyond segmentation or classification, and inefficient adaptation to diverse clinical tasks. In this work, we propose SAM-Brain3D, a brain-specific foundation model trained on over 66,000 brain image-label pairs across 14 MRI sub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapter for efficient and effective downstream adaptation. SAM-Brain3D captures detailed brain-specific anatomical and modality priors for segmenting diverse brain targets and broader downstream tasks. HyDA leverages hypergraphs to fuse complementary multi-modal data and dynamically generate patient-specific convolutional kernels for multi-scale feature fusion and personalized patient-wise adaptation. Together, our framework excels across a broad spectrum of brain disease segmentation and classification tasks. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art approaches, offering a new paradigm for brain disease analysis through multi-modal, multi-scale, and dynamic foundation modeling.","sentences":["Brain diseases, such as Alzheimer's disease and brain tumors, present profound challenges due to their complexity and societal impact.","Recent advancements in brain foundation models have shown significant promise in addressing a range of brain-related tasks.","However, current brain foundation models are limited by task and data homogeneity, restricted generalization beyond segmentation or classification, and inefficient adaptation to diverse clinical tasks.","In this work, we propose SAM-Brain3D, a brain-specific foundation model trained on over 66,000 brain image-label pairs across 14 MRI sub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapter for efficient and effective downstream adaptation.","SAM-Brain3D captures detailed brain-specific anatomical and modality priors for segmenting diverse brain targets and broader downstream tasks.","HyDA leverages hypergraphs to fuse complementary multi-modal data and dynamically generate patient-specific convolutional kernels for multi-scale feature fusion and personalized patient-wise adaptation.","Together, our framework excels across a broad spectrum of brain disease segmentation and classification tasks.","Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art approaches, offering a new paradigm for brain disease analysis through multi-modal, multi-scale, and dynamic foundation modeling."],"url":"http://arxiv.org/abs/2505.00627v1"}
{"created":"2025-05-01 16:06:16","title":"The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)","abstract":"Large language models (LLMs) that integrate multiple input roles (e.g., system instructions, user queries, external tool outputs) are increasingly prevalent in practice. Ensuring that the model accurately distinguishes messages from each role -- a concept we call \\emph{role separation} -- is crucial for consistent multi-role behavior. Although recent work often targets state-of-the-art prompt injection defenses, it remains unclear whether such methods truly teach LLMs to differentiate roles or merely memorize known triggers. In this paper, we examine \\emph{role-separation learning}: the process of teaching LLMs to robustly distinguish system and user tokens. Through a \\emph{simple, controlled experimental framework}, we find that fine-tuned models often rely on two proxies for role identification: (1) task type exploitation, and (2) proximity to begin-of-text. Although data augmentation can partially mitigate these shortcuts, it generally leads to iterative patching rather than a deeper fix. To address this, we propose reinforcing \\emph{invariant signals} that mark role boundaries by adjusting token-wise cues in the model's input encoding. In particular, manipulating position IDs helps the model learn clearer distinctions and reduces reliance on superficial proxies. By focusing on this mechanism-centered perspective, our work illuminates how LLMs can more reliably maintain consistent multi-role behavior without merely memorizing known prompts or triggers.","sentences":["Large language models (LLMs) that integrate multiple input roles (e.g., system instructions, user queries, external tool outputs) are increasingly prevalent in practice.","Ensuring that the model accurately distinguishes messages from each role -- a concept we call \\emph{role separation} -- is crucial for consistent multi-role behavior.","Although recent work often targets state-of-the-art prompt injection defenses, it remains unclear whether such methods truly teach LLMs to differentiate roles or merely memorize known triggers.","In this paper, we examine \\emph{role-separation learning}: the process of teaching LLMs to robustly distinguish system and user tokens.","Through a \\emph{simple, controlled experimental framework}, we find that fine-tuned models often rely on two proxies for role identification: (1) task type exploitation, and (2) proximity to begin-of-text.","Although data augmentation can partially mitigate these shortcuts, it generally leads to iterative patching rather than a deeper fix.","To address this, we propose reinforcing \\emph{invariant signals} that mark role boundaries by adjusting token-wise cues in the model's input encoding.","In particular, manipulating position IDs helps the model learn clearer distinctions and reduces reliance on superficial proxies.","By focusing on this mechanism-centered perspective, our work illuminates how LLMs can more reliably maintain consistent multi-role behavior without merely memorizing known prompts or triggers."],"url":"http://arxiv.org/abs/2505.00626v1"}
{"created":"2025-05-01 16:05:08","title":"FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation","abstract":"Training large language models (LLMs) from scratch requires significant computational resources, driving interest in developing smaller, domain-specific LLMs that maintain both efficiency and strong task performance. Medium-sized models such as LLaMA, llama} have served as starting points for domain-specific adaptation, but they often suffer from accuracy degradation when tested on specialized datasets. We introduce FineScope, a framework for deriving compact, domain-optimized LLMs from larger pretrained models. FineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its ability to produce interpretable feature representations, to extract domain-specific subsets from large datasets. We apply structured pruning with domain-specific constraints, ensuring that the resulting pruned models retain essential knowledge for the target domain. To further enhance performance, these pruned models undergo self-data distillation, leveraging SAE-curated datasets to restore key domain-specific information lost during pruning. Extensive experiments and ablation studies demonstrate that FineScope achieves highly competitive performance, outperforming several large-scale state-of-the-art LLMs in domain-specific tasks. Additionally, our results show that FineScope enables pruned models to regain a substantial portion of their original performance when fine-tuned with SAE-curated datasets. Furthermore, applying these datasets to fine-tune pretrained LLMs without pruning also improves their domain-specific accuracy, highlighting the robustness of our approach. The code will be released.","sentences":["Training large language models (LLMs) from scratch requires significant computational resources, driving interest in developing smaller, domain-specific LLMs that maintain both efficiency and strong task performance.","Medium-sized models such as LLaMA, llama} have served as starting points for domain-specific adaptation, but they often suffer from accuracy degradation when tested on specialized datasets.","We introduce FineScope, a framework for deriving compact, domain-optimized LLMs from larger pretrained models.","FineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its ability to produce interpretable feature representations, to extract domain-specific subsets from large datasets.","We apply structured pruning with domain-specific constraints, ensuring that the resulting pruned models retain essential knowledge for the target domain.","To further enhance performance, these pruned models undergo self-data distillation, leveraging SAE-curated datasets to restore key domain-specific information lost during pruning.","Extensive experiments and ablation studies demonstrate that FineScope achieves highly competitive performance, outperforming several large-scale state-of-the-art LLMs in domain-specific tasks.","Additionally, our results show that FineScope enables pruned models to regain a substantial portion of their original performance when fine-tuned with SAE-curated datasets.","Furthermore, applying these datasets to fine-tune pretrained LLMs without pruning also improves their domain-specific accuracy, highlighting the robustness of our approach.","The code will be released."],"url":"http://arxiv.org/abs/2505.00624v1"}
{"created":"2025-05-01 16:03:38","title":"Neural Network Verification for Gliding Drone Control: A Case Study","abstract":"As machine learning is increasingly deployed in autonomous systems, verification of neural network controllers is becoming an active research domain. Existing tools and annual verification competitions suggest that soon this technology will become effective for real-world applications. Our application comes from the emerging field of microflyers that are passively transported by the wind, which may have various uses in weather or pollution monitoring. Specifically, we investigate centimetre-scale bio-inspired gliding drones that resemble Alsomitra macrocarpa diaspores. In this paper, we propose a new case study on verifying Alsomitra-inspired drones with neural network controllers, with the aim of adhering closely to a target trajectory. We show that our system differs substantially from existing VNN and ARCH competition benchmarks, and show that a combination of tools holds promise for verifying such systems in the future, if certain shortcomings can be overcome. We propose a novel method for robust training of regression networks, and investigate formalisations of this case study in Vehicle and CORA. Our verification results suggest that the investigated training methods do improve performance and robustness of neural network controllers in this application, but are limited in scope and usefulness. This is due to systematic limitations of both Vehicle and CORA, and the complexity of our system reducing the scale of reachability, which we investigate in detail. If these limitations can be overcome, it will enable engineers to develop safe and robust technologies that improve people's lives and reduce our impact on the environment.","sentences":["As machine learning is increasingly deployed in autonomous systems, verification of neural network controllers is becoming an active research domain.","Existing tools and annual verification competitions suggest that soon this technology will become effective for real-world applications.","Our application comes from the emerging field of microflyers that are passively transported by the wind, which may have various uses in weather or pollution monitoring.","Specifically, we investigate centimetre-scale bio-inspired gliding drones that resemble Alsomitra macrocarpa diaspores.","In this paper, we propose a new case study on verifying Alsomitra-inspired drones with neural network controllers, with the aim of adhering closely to a target trajectory.","We show that our system differs substantially from existing VNN and ARCH competition benchmarks, and show that a combination of tools holds promise for verifying such systems in the future, if certain shortcomings can be overcome.","We propose a novel method for robust training of regression networks, and investigate formalisations of this case study in Vehicle and CORA.","Our verification results suggest that the investigated training methods do improve performance and robustness of neural network controllers in this application, but are limited in scope and usefulness.","This is due to systematic limitations of both Vehicle and CORA, and the complexity of our system reducing the scale of reachability, which we investigate in detail.","If these limitations can be overcome, it will enable engineers to develop safe and robust technologies that improve people's lives and reduce our impact on the environment."],"url":"http://arxiv.org/abs/2505.00622v1"}
{"created":"2025-05-01 15:56:34","title":"Beyond Affine Loops: A Geometric Approach to Program Synthesis","abstract":"Ensuring software correctness remains a fundamental challenge in formal program verification. One promising approach relies on finding polynomial invariants for loops. Polynomial invariants are properties of a program loop that hold before and after each iteration. Generating polynomial invariants is a crucial task for loops, but it is an undecidable problem in the general case. Recently, an alternative approach to this problem has emerged, focusing on synthesizing loops from invariants. However, existing methods only synthesize affine loops without guard conditions from polynomial invariants. In this paper, we address a more general problem, allowing loops to have polynomial update maps with a given structure, inequations in the guard condition, and polynomial invariants of arbitrary form.   In this paper, we use algebraic geometry tools to design and implement an algorithm that computes a finite set of polynomial equations whose solutions correspond to all loops satisfying the given polynomial invariants. In other words, we reduce the problem of synthesizing loops to finding solutions of polynomial systems within a specified subset of the complex numbers. The latter is handled in our software using an SMT solver.","sentences":["Ensuring software correctness remains a fundamental challenge in formal program verification.","One promising approach relies on finding polynomial invariants for loops.","Polynomial invariants are properties of a program loop that hold before and after each iteration.","Generating polynomial invariants is a crucial task for loops, but it is an undecidable problem in the general case.","Recently, an alternative approach to this problem has emerged, focusing on synthesizing loops from invariants.","However, existing methods only synthesize affine loops without guard conditions from polynomial invariants.","In this paper, we address a more general problem, allowing loops to have polynomial update maps with a given structure, inequations in the guard condition, and polynomial invariants of arbitrary form.   ","In this paper, we use algebraic geometry tools to design and implement an algorithm that computes a finite set of polynomial equations whose solutions correspond to all loops satisfying the given polynomial invariants.","In other words, we reduce the problem of synthesizing loops to finding solutions of polynomial systems within a specified subset of the complex numbers.","The latter is handled in our software using an SMT solver."],"url":"http://arxiv.org/abs/2505.00620v1"}
{"created":"2025-05-01 15:55:38","title":"Diverse Semantics-Guided Feature Alignment and Decoupling for Visible-Infrared Person Re-Identification","abstract":"Visible-Infrared Person Re-Identification (VI-ReID) is a challenging task due to the large modality discrepancy between visible and infrared images, which complicates the alignment of their features into a suitable common space. Moreover, style noise, such as illumination and color contrast, reduces the identity discriminability and modality invariance of features. To address these challenges, we propose a novel Diverse Semantics-guided Feature Alignment and Decoupling (DSFAD) network to align identity-relevant features from different modalities into a textual embedding space and disentangle identity-irrelevant features within each modality. Specifically, we develop a Diverse Semantics-guided Feature Alignment (DSFA) module, which generates pedestrian descriptions with diverse sentence structures to guide the cross-modality alignment of visual features. Furthermore, to filter out style information, we propose a Semantic Margin-guided Feature Decoupling (SMFD) module, which decomposes visual features into pedestrian-related and style-related components, and then constrains the similarity between the former and the textual embeddings to be at least a margin higher than that between the latter and the textual embeddings. Additionally, to prevent the loss of pedestrian semantics during feature decoupling, we design a Semantic Consistency-guided Feature Restitution (SCFR) module, which further excavates useful information for identification from the style-related features and restores it back into the pedestrian-related features, and then constrains the similarity between the features after restitution and the textual embeddings to be consistent with that between the features before decoupling and the textual embeddings. Extensive experiments on three VI-ReID datasets demonstrate the superiority of our DSFAD.","sentences":["Visible-Infrared Person Re-Identification (VI-ReID) is a challenging task due to the large modality discrepancy between visible and infrared images, which complicates the alignment of their features into a suitable common space.","Moreover, style noise, such as illumination and color contrast, reduces the identity discriminability and modality invariance of features.","To address these challenges, we propose a novel Diverse Semantics-guided Feature Alignment and Decoupling (DSFAD) network to align identity-relevant features from different modalities into a textual embedding space and disentangle identity-irrelevant features within each modality.","Specifically, we develop a Diverse Semantics-guided Feature Alignment (DSFA) module, which generates pedestrian descriptions with diverse sentence structures to guide the cross-modality alignment of visual features.","Furthermore, to filter out style information, we propose a Semantic Margin-guided Feature Decoupling (SMFD) module, which decomposes visual features into pedestrian-related and style-related components, and then constrains the similarity between the former and the textual embeddings to be at least a margin higher than that between the latter and the textual embeddings.","Additionally, to prevent the loss of pedestrian semantics during feature decoupling, we design a Semantic Consistency-guided Feature Restitution (SCFR) module, which further excavates useful information for identification from the style-related features and restores it back into the pedestrian-related features, and then constrains the similarity between the features after restitution and the textual embeddings to be consistent with that between the features before decoupling and the textual embeddings.","Extensive experiments on three VI-ReID datasets demonstrate the superiority of our DSFAD."],"url":"http://arxiv.org/abs/2505.00619v1"}
{"created":"2025-05-01 15:48:35","title":"RevealNet: Distributed Traffic Correlation for Attack Attribution on Programmable Networks","abstract":"Network attackers have increasingly resorted to proxy chains, VPNs, and anonymity networks to conceal their activities. To tackle this issue, past research has explored the applicability of traffic correlation techniques to perform attack attribution, i.e., to identify an attacker's true network location. However, current traffic correlation approaches rely on well-provisioned and centralized systems that ingest flows from multiple network probes to compute correlation scores. Unfortunately, this makes correlation efforts scale poorly for large high-speed networks.   In this paper, we propose RevealNet, a decentralized framework for attack attribution that orchestrates a fleet of P4-programmable switches to perform traffic correlation. RevealNet builds on a set of correlation primitives inspired by prior work on computing and comparing flow sketches -- compact summaries of flows' key characteristics -- to enable efficient, distributed, in-network traffic correlation. Our evaluation suggests that RevealNet achieves comparable accuracy to centralized attack attribution systems while significantly reducing both the computational complexity and bandwidth overheads imposed by correlation tasks.","sentences":["Network attackers have increasingly resorted to proxy chains, VPNs, and anonymity networks to conceal their activities.","To tackle this issue, past research has explored the applicability of traffic correlation techniques to perform attack attribution, i.e., to identify an attacker's true network location.","However, current traffic correlation approaches rely on well-provisioned and centralized systems that ingest flows from multiple network probes to compute correlation scores.","Unfortunately, this makes correlation efforts scale poorly for large high-speed networks.   ","In this paper, we propose RevealNet, a decentralized framework for attack attribution that orchestrates a fleet of P4-programmable switches to perform traffic correlation.","RevealNet builds on a set of correlation primitives inspired by prior work on computing and comparing flow sketches -- compact summaries of flows' key characteristics -- to enable efficient, distributed, in-network traffic correlation.","Our evaluation suggests that RevealNet achieves comparable accuracy to centralized attack attribution systems while significantly reducing both the computational complexity and bandwidth overheads imposed by correlation tasks."],"url":"http://arxiv.org/abs/2505.00618v1"}
{"created":"2025-05-01 15:47:14","title":"Catastrophic Liability: Managing Systemic Risks in Frontier AI Development","abstract":"As artificial intelligence systems grow more capable and autonomous, frontier AI development poses potential systemic risks that could affect society at a massive scale. Current practices at many AI labs developing these systems lack sufficient transparency around safety measures, testing procedures, and governance structures. This opacity makes it challenging to verify safety claims or establish appropriate liability when harm occurs. Drawing on liability frameworks from nuclear energy, aviation software, and healthcare, we propose a comprehensive approach to safety documentation and accountability in frontier AI development.","sentences":["As artificial intelligence systems grow more capable and autonomous, frontier AI development poses potential systemic risks that could affect society at a massive scale.","Current practices at many AI labs developing these systems lack sufficient transparency around safety measures, testing procedures, and governance structures.","This opacity makes it challenging to verify safety claims or establish appropriate liability when harm occurs.","Drawing on liability frameworks from nuclear energy, aviation software, and healthcare, we propose a comprehensive approach to safety documentation and accountability in frontier AI development."],"url":"http://arxiv.org/abs/2505.00616v1"}
{"created":"2025-05-01 15:47:03","title":"Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction","abstract":"We address the 3D reconstruction of human faces from a single RGB image. To this end, we propose Pixel3DMM, a set of highly-generalized vision transformers which predict per-pixel geometric cues in order to constrain the optimization of a 3D morphable face model (3DMM). We exploit the latent features of the DINO foundation model, and introduce a tailored surface normal and uv-coordinate prediction head. We train our model by registering three high-quality 3D face datasets against the FLAME mesh topology, which results in a total of over 1,000 identities and 976K images. For 3D face reconstruction, we propose a FLAME fitting opitmization that solves for the 3DMM parameters from the uv-coordinate and normal estimates. To evaluate our method, we introduce a new benchmark for single-image face reconstruction, which features high diversity facial expressions, viewing angles, and ethnicities. Crucially, our benchmark is the first to evaluate both posed and neutral facial geometry. Ultimately, our method outperforms the most competitive baselines by over 15% in terms of geometric accuracy for posed facial expressions.","sentences":["We address the 3D reconstruction of human faces from a single RGB image.","To this end, we propose Pixel3DMM, a set of highly-generalized vision transformers which predict per-pixel geometric cues in order to constrain the optimization of a 3D morphable face model (3DMM).","We exploit the latent features of the DINO foundation model, and introduce a tailored surface normal and uv-coordinate prediction head.","We train our model by registering three high-quality 3D face datasets against the FLAME mesh topology, which results in a total of over 1,000 identities and 976K images.","For 3D face reconstruction, we propose a FLAME fitting opitmization that solves for the 3DMM parameters from the uv-coordinate and normal estimates.","To evaluate our method, we introduce a new benchmark for single-image face reconstruction, which features high diversity facial expressions, viewing angles, and ethnicities.","Crucially, our benchmark is the first to evaluate both posed and neutral facial geometry.","Ultimately, our method outperforms the most competitive baselines by over 15% in terms of geometric accuracy for posed facial expressions."],"url":"http://arxiv.org/abs/2505.00615v1"}
{"created":"2025-05-01 15:43:51","title":"Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation","abstract":"In this position paper, we observe that empirical evaluation in Generative AI is at a crisis point since traditional ML evaluation and benchmarking strategies are insufficient to meet the needs of evaluating modern GenAI models and systems. There are many reasons for this, including the fact that these models typically have nearly unbounded input and output spaces, typically do not have a well defined ground truth target, and typically exhibit strong feedback loops and prediction dependence based on context of previous model outputs. On top of these critical issues, we argue that the problems of {\\em leakage} and {\\em contamination} are in fact the most important and difficult issues to address for GenAI evaluations. Interestingly, the field of AI Competitions has developed effective measures and practices to combat leakage for the purpose of counteracting cheating by bad actors within a competition setting. This makes AI Competitions an especially valuable (but underutilized) resource. Now is time for the field to view AI Competitions as the gold standard for empirical rigor in GenAI evaluation, and to harness and harvest their results with according value.","sentences":["In this position paper, we observe that empirical evaluation in Generative AI is at a crisis point since traditional ML evaluation and benchmarking strategies are insufficient to meet the needs of evaluating modern GenAI models and systems.","There are many reasons for this, including the fact that these models typically have nearly unbounded input and output spaces, typically do not have a well defined ground truth target, and typically exhibit strong feedback loops and prediction dependence based on context of previous model outputs.","On top of these critical issues, we argue that the problems of {\\em leakage} and {\\em contamination} are in fact the most important and difficult issues to address for GenAI evaluations.","Interestingly, the field of AI Competitions has developed effective measures and practices to combat leakage for the purpose of counteracting cheating by bad actors within a competition setting.","This makes AI Competitions an especially valuable (but underutilized) resource.","Now is time for the field to view AI Competitions as the gold standard for empirical rigor in GenAI evaluation, and to harness and harvest their results with according value."],"url":"http://arxiv.org/abs/2505.00612v1"}
{"created":"2025-05-01 15:40:58","title":"Combining LLMs with Logic-Based Framework to Explain MCTS","abstract":"In response to the lack of trust in Artificial Intelligence (AI) for sequential planning, we design a Computational Tree Logic-guided large language model (LLM)-based natural language explanation framework designed for the Monte Carlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to interpret due to the complexity of its search trees, but our framework is flexible enough to handle a wide range of free-form post-hoc queries and knowledge-based inquiries centered around MCTS and the Markov Decision Process (MDP) of the application domain. By transforming user queries into logic and variable statements, our framework ensures that the evidence obtained from the search tree remains factually consistent with the underlying environmental dynamics and any constraints in the actual stochastic control process. We evaluate the framework rigorously through quantitative assessments, where it demonstrates strong performance in terms of accuracy and factual consistency.","sentences":["In response to the lack of trust in Artificial Intelligence (AI) for sequential planning, we design a Computational Tree Logic-guided large language model (LLM)-based natural language explanation framework designed for the Monte Carlo Tree Search (MCTS) algorithm.","MCTS is often considered challenging to interpret due to the complexity of its search trees, but our framework is flexible enough to handle a wide range of free-form post-hoc queries and knowledge-based inquiries centered around MCTS and the Markov Decision Process (MDP) of the application domain.","By transforming user queries into logic and variable statements, our framework ensures that the evidence obtained from the search tree remains factually consistent with the underlying environmental dynamics and any constraints in the actual stochastic control process.","We evaluate the framework rigorously through quantitative assessments, where it demonstrates strong performance in terms of accuracy and factual consistency."],"url":"http://arxiv.org/abs/2505.00610v1"}
{"created":"2025-05-01 15:35:42","title":"Dietary Intake Estimation via Continuous 3D Reconstruction of Food","abstract":"Monitoring dietary habits is crucial for preventing health risks associated with overeating and undereating, including obesity, diabetes, and cardiovascular diseases. Traditional methods for tracking food intake rely on self-reported data before or after the eating, which are prone to inaccuracies. This study proposes an approach to accurately monitor ingest behaviours by leveraging 3D food models constructed from monocular 2D video. Using COLMAP and pose estimation algorithms, we generate detailed 3D representations of food, allowing us to observe changes in food volume as it is consumed. Experiments with toy models and real food items demonstrate the approach's potential. Meanwhile, we have proposed a new methodology for automated state recognition challenges to accurately detect state changes and maintain model fidelity. The 3D reconstruction approach shows promise in capturing comprehensive dietary behaviour insights, ultimately contributing to the development of automated and accurate dietary monitoring tools.","sentences":["Monitoring dietary habits is crucial for preventing health risks associated with overeating and undereating, including obesity, diabetes, and cardiovascular diseases.","Traditional methods for tracking food intake rely on self-reported data before or after the eating, which are prone to inaccuracies.","This study proposes an approach to accurately monitor ingest behaviours by leveraging 3D food models constructed from monocular 2D video.","Using COLMAP and pose estimation algorithms, we generate detailed 3D representations of food, allowing us to observe changes in food volume as it is consumed.","Experiments with toy models and real food items demonstrate the approach's potential.","Meanwhile, we have proposed a new methodology for automated state recognition challenges to accurately detect state changes and maintain model fidelity.","The 3D reconstruction approach shows promise in capturing comprehensive dietary behaviour insights, ultimately contributing to the development of automated and accurate dietary monitoring tools."],"url":"http://arxiv.org/abs/2505.00606v1"}
{"created":"2025-05-01 15:35:31","title":"Surviving the Storm: The Impacts of Open RAN Disaggregation on Latency and Resilience","abstract":"The development of Open Radio Access Networks (Open RAN), with their disaggregated architectures and virtualization of network functions, has brought considerable flexibility and cost savings to mobile networks. However, these architectural advancements introduce additional latency during the initial attachment procedure of User Equipment (UE), increasing the risk of signaling storms. This paper investigates the latency impact due to disaggregation of the Base-band Unit (BBU) into the Central Unit (CU) and Distributed Unit (DU). Specifically, we model the delays induced due to disaggregation on UE attachment, analyzing the performance under varying load conditions, and sensitivity to processing times. We demonstrate that while both monolithic and Open RAN architectures experience performance degradation under high-load conditions, Open RAN's added overheads can increase its susceptibility to congestion and signaling storms. However, Open RAN's inherent flexibility, enabled by disaggregation and virtualization, allows efficient deployment of resources, faster service deployment, and adaptive congestion control mechanisms to mitigate these risks and enhance overall system resilience. Thereby, we quantify resilience by introducing a new utility function and propose a novel adaptation mechanism to reinforce Open RAN's robustness against signaling storms. Our results show that the proposed adaptive mechanism significantly enhances resilience, achieving improvements of up to 286% over fixed configurations, with resilience scores approaching 0.96 under optimal conditions. While simulation results show that Open RAN disaggregation increases attachment latency and susceptibility to signaling congestion, they also highlight that its architectural flexibility can mitigate these effects, improving resilience under high-load conditions.","sentences":["The development of Open Radio Access Networks (Open RAN), with their disaggregated architectures and virtualization of network functions, has brought considerable flexibility and cost savings to mobile networks.","However, these architectural advancements introduce additional latency during the initial attachment procedure of User Equipment (UE), increasing the risk of signaling storms.","This paper investigates the latency impact due to disaggregation of the Base-band Unit (BBU) into the Central Unit (CU) and Distributed Unit (DU).","Specifically, we model the delays induced due to disaggregation on UE attachment, analyzing the performance under varying load conditions, and sensitivity to processing times.","We demonstrate that while both monolithic and Open RAN architectures experience performance degradation under high-load conditions, Open RAN's added overheads can increase its susceptibility to congestion and signaling storms.","However, Open RAN's inherent flexibility, enabled by disaggregation and virtualization, allows efficient deployment of resources, faster service deployment, and adaptive congestion control mechanisms to mitigate these risks and enhance overall system resilience.","Thereby, we quantify resilience by introducing a new utility function and propose a novel adaptation mechanism to reinforce Open RAN's robustness against signaling storms.","Our results show that the proposed adaptive mechanism significantly enhances resilience, achieving improvements of up to 286% over fixed configurations, with resilience scores approaching 0.96 under optimal conditions.","While simulation results show that Open RAN disaggregation increases attachment latency and susceptibility to signaling congestion, they also highlight that its architectural flexibility can mitigate these effects, improving resilience under high-load conditions."],"url":"http://arxiv.org/abs/2505.00605v1"}
{"created":"2025-05-01 15:35:01","title":"Can LLMs Help Improve Analogical Reasoning For Strategic Decisions? Experimental Evidence from Humans and GPT-4","abstract":"This study investigates whether large language models, specifically GPT4, can match human capabilities in analogical reasoning within strategic decision making contexts. Using a novel experimental design involving source to target matching, we find that GPT4 achieves high recall by retrieving all plausible analogies but suffers from low precision, frequently applying incorrect analogies based on superficial similarities. In contrast, human participants exhibit high precision but low recall, selecting fewer analogies yet with stronger causal alignment. These findings advance theory by identifying matching, the evaluative phase of analogical reasoning, as a distinct step that requires accurate causal mapping beyond simple retrieval. While current LLMs are proficient in generating candidate analogies, humans maintain a comparative advantage in recognizing deep structural similarities across domains. Error analysis reveals that AI errors arise from surface level matching, whereas human errors stem from misinterpretations of causal structure. Taken together, the results suggest a productive division of labor in AI assisted organizational decision making where LLMs may serve as broad analogy generators, while humans act as critical evaluators, applying the most contextually appropriate analogies to strategic problems.","sentences":["This study investigates whether large language models, specifically GPT4, can match human capabilities in analogical reasoning within strategic decision making contexts.","Using a novel experimental design involving source to target matching, we find that GPT4 achieves high recall by retrieving all plausible analogies but suffers from low precision, frequently applying incorrect analogies based on superficial similarities.","In contrast, human participants exhibit high precision but low recall, selecting fewer analogies yet with stronger causal alignment.","These findings advance theory by identifying matching, the evaluative phase of analogical reasoning, as a distinct step that requires accurate causal mapping beyond simple retrieval.","While current LLMs are proficient in generating candidate analogies, humans maintain a comparative advantage in recognizing deep structural similarities across domains.","Error analysis reveals that AI errors arise from surface level matching, whereas human errors stem from misinterpretations of causal structure.","Taken together, the results suggest a productive division of labor in AI assisted organizational decision making where LLMs may serve as broad analogy generators, while humans act as critical evaluators, applying the most contextually appropriate analogies to strategic problems."],"url":"http://arxiv.org/abs/2505.00603v1"}
{"created":"2025-05-01 15:31:15","title":"Visual Trajectory Prediction of Vessels for Inland Navigation","abstract":"The future of inland navigation increasingly relies on autonomous systems and remote operations, emphasizing the need for accurate vessel trajectory prediction. This study addresses the challenges of video-based vessel tracking and prediction by integrating advanced object detection methods, Kalman filters, and spline-based interpolation. However, existing detection systems often misclassify objects in inland waterways due to complex surroundings. A comparative evaluation of tracking algorithms, including BoT-SORT, Deep OC-SORT, and ByeTrack, highlights the robustness of the Kalman filter in providing smoothed trajectories. Experimental results from diverse scenarios demonstrate improved accuracy in predicting vessel movements, which is essential for collision avoidance and situational awareness. The findings underline the necessity of customized datasets and models for inland navigation. Future work will expand the datasets and incorporate vessel classification to refine predictions, supporting both autonomous systems and human operators in complex environments.","sentences":["The future of inland navigation increasingly relies on autonomous systems and remote operations, emphasizing the need for accurate vessel trajectory prediction.","This study addresses the challenges of video-based vessel tracking and prediction by integrating advanced object detection methods, Kalman filters, and spline-based interpolation.","However, existing detection systems often misclassify objects in inland waterways due to complex surroundings.","A comparative evaluation of tracking algorithms, including BoT-SORT, Deep OC-SORT, and ByeTrack, highlights the robustness of the Kalman filter in providing smoothed trajectories.","Experimental results from diverse scenarios demonstrate improved accuracy in predicting vessel movements, which is essential for collision avoidance and situational awareness.","The findings underline the necessity of customized datasets and models for inland navigation.","Future work will expand the datasets and incorporate vessel classification to refine predictions, supporting both autonomous systems and human operators in complex environments."],"url":"http://arxiv.org/abs/2505.00599v1"}
{"created":"2025-05-01 15:31:09","title":"Fast and Low-Cost Genomic Foundation Models via Outlier Removal","abstract":"We propose the first unified adversarial attack benchmark for Genomic Foundation Models (GFMs), named GERM. Unlike existing GFM benchmarks, GERM offers the first comprehensive evaluation framework to systematically assess the vulnerability of GFMs to adversarial attacks. Methodologically, we evaluate the adversarial robustness of five state-of-the-art GFMs using four widely adopted attack algorithms and three defense strategies. Importantly, our benchmark provides an accessible and comprehensive framework to analyze GFM vulnerabilities with respect to model architecture, quantization schemes, and training datasets. Empirically, transformer-based models exhibit greater robustness to adversarial perturbations compared to HyenaDNA, highlighting the impact of architectural design on vulnerability. Moreover, adversarial attacks frequently target biologically significant genomic regions, suggesting that these models effectively capture meaningful sequence features.","sentences":["We propose the first unified adversarial attack benchmark for Genomic Foundation Models (GFMs), named GERM.","Unlike existing GFM benchmarks, GERM offers the first comprehensive evaluation framework to systematically assess the vulnerability of GFMs to adversarial attacks.","Methodologically, we evaluate the adversarial robustness of five state-of-the-art GFMs using four widely adopted attack algorithms and three defense strategies.","Importantly, our benchmark provides an accessible and comprehensive framework to analyze GFM vulnerabilities with respect to model architecture, quantization schemes, and training datasets.","Empirically, transformer-based models exhibit greater robustness to adversarial perturbations compared to HyenaDNA, highlighting the impact of architectural design on vulnerability.","Moreover, adversarial attacks frequently target biologically significant genomic regions, suggesting that these models effectively capture meaningful sequence features."],"url":"http://arxiv.org/abs/2505.00598v1"}
{"created":"2025-05-01 15:30:26","title":"A Finite-State Controller Based Offline Solver for Deterministic POMDPs","abstract":"Deterministic partially observable Markov decision processes (DetPOMDPs) often arise in planning problems where the agent is uncertain about its environmental state but can act and observe deterministically. In this paper, we propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI) algorithm for DetPOMDPs, which builds policies in the form of finite-state controllers (FSCs). DetMCVI solves large problems with a high success rate, outperforming existing baselines for DetPOMDPs. We also verify the performance of the algorithm in a real-world mobile robot forest mapping scenario.","sentences":["Deterministic partially observable Markov decision processes (DetPOMDPs) often arise in planning problems where the agent is uncertain about its environmental state but can act and observe deterministically.","In this paper, we propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI) algorithm for DetPOMDPs, which builds policies in the form of finite-state controllers (FSCs).","DetMCVI solves large problems with a high success rate, outperforming existing baselines for DetPOMDPs.","We also verify the performance of the algorithm in a real-world mobile robot forest mapping scenario."],"url":"http://arxiv.org/abs/2505.00596v1"}
{"created":"2025-05-01 15:26:48","title":"A Novel Feature-Aware Chaotic Image Encryption Scheme For Data Security and Privacy in IoT and Edge Networks","abstract":"The security of image data in the Internet of Things (IoT) and edge networks is crucial due to the increasing deployment of intelligent systems for real-time decision-making. Traditional encryption algorithms such as AES and RSA are computationally expensive for resource-constrained IoT devices and ineffective for large-volume image data, leading to inefficiencies in privacy-preserving distributed learning applications. To address these concerns, this paper proposes a novel Feature-Aware Chaotic Image Encryption scheme that integrates Feature-Aware Pixel Segmentation (FAPS) with Chaotic Chain Permutation and Confusion mechanisms to enhance security while maintaining efficiency. The proposed scheme consists of three stages: (1) FAPS, which extracts and reorganizes pixels based on high and low edge intensity features for correlation disruption; (2) Chaotic Chain Permutation, which employs a logistic chaotic map with SHA-256-based dynamically updated keys for block-wise permutation; and (3) Chaotic chain Confusion, which utilises dynamically generated chaotic seed matrices for bitwise XOR operations. Extensive security and performance evaluations demonstrate that the proposed scheme significantly reduces pixel correlation -- almost zero, achieves high entropy values close to 8, and resists differential cryptographic attacks. The optimum design of the proposed scheme makes it suitable for real-time deployment in resource-constrained environments.","sentences":["The security of image data in the Internet of Things (IoT) and edge networks is crucial due to the increasing deployment of intelligent systems for real-time decision-making.","Traditional encryption algorithms such as AES and RSA are computationally expensive for resource-constrained IoT devices and ineffective for large-volume image data, leading to inefficiencies in privacy-preserving distributed learning applications.","To address these concerns, this paper proposes a novel Feature-Aware Chaotic Image Encryption scheme that integrates Feature-Aware Pixel Segmentation (FAPS) with Chaotic Chain Permutation and Confusion mechanisms to enhance security while maintaining efficiency.","The proposed scheme consists of three stages: (1) FAPS, which extracts and reorganizes pixels based on high and low edge intensity features for correlation disruption; (2) Chaotic Chain Permutation, which employs a logistic chaotic map with SHA-256-based dynamically updated keys for block-wise permutation; and (3) Chaotic chain Confusion, which utilises dynamically generated chaotic seed matrices for bitwise XOR operations.","Extensive security and performance evaluations demonstrate that the proposed scheme significantly reduces pixel correlation -- almost zero, achieves high entropy values close to 8, and resists differential cryptographic attacks.","The optimum design of the proposed scheme makes it suitable for real-time deployment in resource-constrained environments."],"url":"http://arxiv.org/abs/2505.00593v1"}
{"created":"2025-05-01 15:26:23","title":"Uncertainty-Aware Multi-Expert Knowledge Distillation for Imbalanced Disease Grading","abstract":"Automatic disease image grading is a significant application of artificial intelligence for healthcare, enabling faster and more accurate patient assessments. However, domain shifts, which are exacerbated by data imbalance, introduce bias into the model, posing deployment difficulties in clinical applications. To address the problem, we propose a novel \\textbf{U}ncertainty-aware \\textbf{M}ulti-experts \\textbf{K}nowledge \\textbf{D}istillation (UMKD) framework to transfer knowledge from multiple expert models to a single student model. Specifically, to extract discriminative features, UMKD decouples task-agnostic and task-specific features with shallow and compact feature alignment in the feature space. At the output space, an uncertainty-aware decoupled distillation (UDD) mechanism dynamically adjusts knowledge transfer weights based on expert model uncertainties, ensuring robust and reliable distillation. Additionally, UMKD also tackles the problems of model architecture heterogeneity and distribution discrepancies between source and target domains, which are inadequately tackled by previous KD approaches. Extensive experiments on histology prostate grading (\\textit{SICAPv2}) and fundus image grading (\\textit{APTOS}) demonstrate that UMKD achieves a new state-of-the-art in both source-imbalanced and target-imbalanced scenarios, offering a robust and practical solution for real-world disease image grading.","sentences":["Automatic disease image grading is a significant application of artificial intelligence for healthcare, enabling faster and more accurate patient assessments.","However, domain shifts, which are exacerbated by data imbalance, introduce bias into the model, posing deployment difficulties in clinical applications.","To address the problem, we propose a novel \\textbf{U}ncertainty-aware \\textbf{M}ulti-experts \\textbf{K}nowledge \\textbf{D}istillation (UMKD) framework to transfer knowledge from multiple expert models to a single student model.","Specifically, to extract discriminative features, UMKD decouples task-agnostic and task-specific features with shallow and compact feature alignment in the feature space.","At the output space, an uncertainty-aware decoupled distillation (UDD) mechanism dynamically adjusts knowledge transfer weights based on expert model uncertainties, ensuring robust and reliable distillation.","Additionally, UMKD also tackles the problems of model architecture heterogeneity and distribution discrepancies between source and target domains, which are inadequately tackled by previous KD approaches.","Extensive experiments on histology prostate grading (\\textit{SICAPv2}) and fundus image grading (\\textit{APTOS}) demonstrate that UMKD achieves a new state-of-the-art in both source-imbalanced and target-imbalanced scenarios, offering a robust and practical solution for real-world disease image grading."],"url":"http://arxiv.org/abs/2505.00592v1"}
{"created":"2025-05-01 15:25:23","title":"Explainable AI in Spatial Analysis","abstract":"This chapter discusses the opportunities of eXplainable Artificial Intelligence (XAI) within the realm of spatial analysis. A key objective in spatial analysis is to model spatial relationships and infer spatial processes to generate knowledge from spatial data, which has been largely based on spatial statistical methods. More recently, machine learning offers scalable and flexible approaches that complement traditional methods and has been increasingly applied in spatial data science. Despite its advantages, machine learning is often criticized for being a black box, which limits our understanding of model behavior and output. Recognizing this limitation, XAI has emerged as a pivotal field in AI that provides methods to explain the output of machine learning models to enhance transparency and understanding. These methods are crucial for model diagnosis, bias detection, and ensuring the reliability of results obtained from machine learning models. This chapter introduces key concepts and methods in XAI with a focus on Shapley value-based approaches, which is arguably the most popular XAI method, and their integration with spatial analysis. An empirical example of county-level voting behaviors in the 2020 Presidential election is presented to demonstrate the use of Shapley values and spatial analysis with a comparison to multi-scale geographically weighted regression. The chapter concludes with a discussion on the challenges and limitations of current XAI techniques and proposes new directions.","sentences":["This chapter discusses the opportunities of eXplainable Artificial Intelligence (XAI) within the realm of spatial analysis.","A key objective in spatial analysis is to model spatial relationships and infer spatial processes to generate knowledge from spatial data, which has been largely based on spatial statistical methods.","More recently, machine learning offers scalable and flexible approaches that complement traditional methods and has been increasingly applied in spatial data science.","Despite its advantages, machine learning is often criticized for being a black box, which limits our understanding of model behavior and output.","Recognizing this limitation, XAI has emerged as a pivotal field in AI that provides methods to explain the output of machine learning models to enhance transparency and understanding.","These methods are crucial for model diagnosis, bias detection, and ensuring the reliability of results obtained from machine learning models.","This chapter introduces key concepts and methods in XAI with a focus on Shapley value-based approaches, which is arguably the most popular XAI method, and their integration with spatial analysis.","An empirical example of county-level voting behaviors in the 2020 Presidential election is presented to demonstrate the use of Shapley values and spatial analysis with a comparison to multi-scale geographically weighted regression.","The chapter concludes with a discussion on the challenges and limitations of current XAI techniques and proposes new directions."],"url":"http://arxiv.org/abs/2505.00591v1"}
{"created":"2025-05-01 15:24:48","title":"Unlocking the Potential of Linear Networks for Irregular Multivariate Time Series Forecasting","abstract":"Time series forecasting holds significant importance across various industries, including finance, transportation, energy, healthcare, and climate. Despite the widespread use of linear networks due to their low computational cost and effectiveness in modeling temporal dependencies, most existing research has concentrated on regularly sampled and fully observed multivariate time series. However, in practice, we frequently encounter irregular multivariate time series characterized by variable sampling intervals and missing values. The inherent intra-series inconsistency and inter-series asynchrony in such data hinder effective modeling and forecasting with traditional linear networks relying on static weights. To tackle these challenges, this paper introduces a novel model named AiT. AiT utilizes an adaptive linear network capable of dynamically adjusting weights according to observation time points to address intra-series inconsistency, thereby enhancing the accuracy of temporal dependencies modeling. Furthermore, by incorporating the Transformer module on variable semantics embeddings, AiT efficiently captures variable correlations, avoiding the challenge of inter-series asynchrony. Comprehensive experiments across four benchmark datasets demonstrate the superiority of AiT, improving prediction accuracy by 11% and decreasing runtime by 52% compared to existing state-of-the-art methods.","sentences":["Time series forecasting holds significant importance across various industries, including finance, transportation, energy, healthcare, and climate.","Despite the widespread use of linear networks due to their low computational cost and effectiveness in modeling temporal dependencies, most existing research has concentrated on regularly sampled and fully observed multivariate time series.","However, in practice, we frequently encounter irregular multivariate time series characterized by variable sampling intervals and missing values.","The inherent intra-series inconsistency and inter-series asynchrony in such data hinder effective modeling and forecasting with traditional linear networks relying on static weights.","To tackle these challenges, this paper introduces a novel model named AiT. AiT utilizes an adaptive linear network capable of dynamically adjusting weights according to observation time points to address intra-series inconsistency, thereby enhancing the accuracy of temporal dependencies modeling.","Furthermore, by incorporating the Transformer module on variable semantics embeddings, AiT efficiently captures variable correlations, avoiding the challenge of inter-series asynchrony.","Comprehensive experiments across four benchmark datasets demonstrate the superiority of AiT, improving prediction accuracy by 11% and decreasing runtime by 52% compared to existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2505.00590v1"}
{"created":"2025-05-01 15:16:59","title":"ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models","abstract":"Automated parking is a critical feature of Advanced Driver Assistance Systems (ADAS), where accurate trajectory prediction is essential to bridge perception and planning modules. Despite its significance, research in this domain remains relatively limited, with most existing studies concentrating on single-modal trajectory prediction of vehicles. In this work, we propose ParkDiffusion, a novel approach that predicts the trajectories of both vehicles and pedestrians in automated parking scenarios. ParkDiffusion employs diffusion models to capture the inherent uncertainty and multi-modality of future trajectories, incorporating several key innovations. First, we propose a dual map encoder that processes soft semantic cues and hard geometric constraints using a two-step cross-attention mechanism. Second, we introduce an adaptive agent type embedding module, which dynamically conditions the prediction process on the distinct characteristics of vehicles and pedestrians. Third, to ensure kinematic feasibility, our model outputs control signals that are subsequently used within a kinematic framework to generate physically feasible trajectories. We evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the Intersections Drone (inD) dataset. Our work establishes a new baseline for heterogeneous trajectory prediction in parking scenarios, outperforming existing methods by a considerable margin.","sentences":["Automated parking is a critical feature of Advanced Driver Assistance Systems (ADAS), where accurate trajectory prediction is essential to bridge perception and planning modules.","Despite its significance, research in this domain remains relatively limited, with most existing studies concentrating on single-modal trajectory prediction of vehicles.","In this work, we propose ParkDiffusion, a novel approach that predicts the trajectories of both vehicles and pedestrians in automated parking scenarios.","ParkDiffusion employs diffusion models to capture the inherent uncertainty and multi-modality of future trajectories, incorporating several key innovations.","First, we propose a dual map encoder that processes soft semantic cues and hard geometric constraints using a two-step cross-attention mechanism.","Second, we introduce an adaptive agent type embedding module, which dynamically conditions the prediction process on the distinct characteristics of vehicles and pedestrians.","Third, to ensure kinematic feasibility, our model outputs control signals that are subsequently used within a kinematic framework to generate physically feasible trajectories.","We evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the Intersections Drone (inD) dataset.","Our work establishes a new baseline for heterogeneous trajectory prediction in parking scenarios, outperforming existing methods by a considerable margin."],"url":"http://arxiv.org/abs/2505.00586v1"}
{"created":"2025-05-01 15:15:50","title":"Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets","abstract":"Detecting and tracking objects is a crucial component of any autonomous navigation method. For the past decades, object detection has yielded promising results using neural networks on various datasets. While many methods focus on performance metrics, few projects focus on improving the robustness of these detection and tracking pipelines, notably to sensor failures. In this paper we attempt to address this issue by creating a realistic synthetic data augmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Our goal is to accurately simulate sensor failures and data deterioration due to real-world interferences. We also present our results of a baseline lightweight Noise Recognition neural network trained and tested on our augmented dataset, reaching an overall recognition accuracy of 54.4\\% on 11 categories across 10086 images and 2145 radar point-clouds.","sentences":["Detecting and tracking objects is a crucial component of any autonomous navigation method.","For the past decades, object detection has yielded promising results using neural networks on various datasets.","While many methods focus on performance metrics, few projects focus on improving the robustness of these detection and tracking pipelines, notably to sensor failures.","In this paper we attempt to address this issue by creating a realistic synthetic data augmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets.","Our goal is to accurately simulate sensor failures and data deterioration due to real-world interferences.","We also present our results of a baseline lightweight Noise Recognition neural network trained and tested on our augmented dataset, reaching an overall recognition accuracy of 54.4\\% on 11 categories across 10086 images and 2145 radar point-clouds."],"url":"http://arxiv.org/abs/2505.00584v1"}
{"created":"2025-05-01 15:14:32","title":"Block Circulant Adapter for Large Language Models","abstract":"Fine-tuning large language models (LLMs) is difficult due to their huge model size. Recent Fourier domain-based methods show potential for reducing fine-tuning costs. We propose a block circulant matrix-based fine-tuning method with a stable training heuristic to leverage the properties of circulant matrices and one-dimensional Fourier transforms to reduce storage and computation costs. Experiments show that our method uses $14\\times$ less number of parameters than VeRA, $16\\times$ smaller than LoRA and $32\\times$ less FLOPs than FourierFT, while maintaining close or better task performance. Our approach presents a promising way in frequency domain to fine-tune large models on downstream tasks.","sentences":["Fine-tuning large language models (LLMs) is difficult due to their huge model size.","Recent Fourier domain-based methods show potential for reducing fine-tuning costs.","We propose a block circulant matrix-based fine-tuning method with a stable training heuristic to leverage the properties of circulant matrices and one-dimensional Fourier transforms to reduce storage and computation costs.","Experiments show that our method uses $14\\times$ less number of parameters than VeRA, $16\\times$ smaller than LoRA and $32\\times$ less FLOPs than FourierFT, while maintaining close or better task performance.","Our approach presents a promising way in frequency domain to fine-tune large models on downstream tasks."],"url":"http://arxiv.org/abs/2505.00582v1"}
{"created":"2025-05-01 15:11:46","title":"Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors","abstract":"Foundation models have achieved tremendous success in different domains. However, their huge computation and storage complexity make these models difficult to fine-tune and also less applicable in practice. Recent study shows training in Fourier domain can be an effective fine-tuning method in terms of both model performance and number of training parameters. In this work, we propose to further reduce the complexity by the factorization through the product of interleaved circulant and diagonal matrices. In addition, we address the case of non-square fine-tuning weights by partitioning the circulant matrix into blocks. Our method avoids the construction of weight change matrix and utilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimental results show that our method achieves similar or better performance across various tasks with much less floating-point operations (FLOPs) and the number of trainable parameters.","sentences":["Foundation models have achieved tremendous success in different domains.","However, their huge computation and storage complexity make these models difficult to fine-tune and also less applicable in practice.","Recent study shows training in Fourier domain can be an effective fine-tuning method in terms of both model performance and number of training parameters.","In this work, we propose to further reduce the complexity by the factorization through the product of interleaved circulant and diagonal matrices.","In addition, we address the case of non-square fine-tuning weights by partitioning the circulant matrix into blocks.","Our method avoids the construction of weight change matrix and utilizes 1D fast Fourier transform (FFT) instead of 2D FFT.","Experimental results show that our method achieves similar or better performance across various tasks with much less floating-point operations (FLOPs) and the number of trainable parameters."],"url":"http://arxiv.org/abs/2505.00580v1"}
{"created":"2025-05-01 15:10:29","title":"Voice Cloning: Comprehensive Survey","abstract":"Voice Cloning has rapidly advanced in today's digital world, with many researchers and corporations working to improve these algorithms for various applications. This article aims to establish a standardized terminology for voice cloning and explore its different variations. It will cover speaker adaptation as the fundamental concept and then delve deeper into topics such as few-shot, zero-shot, and multilingual TTS within that context. Finally, we will explore the evaluation metrics commonly used in voice cloning research and related datasets. This survey compiles the available voice cloning algorithms to encourage research toward its generation and detection to limit its misuse.","sentences":["Voice Cloning has rapidly advanced in today's digital world, with many researchers and corporations working to improve these algorithms for various applications.","This article aims to establish a standardized terminology for voice cloning and explore its different variations.","It will cover speaker adaptation as the fundamental concept and then delve deeper into topics such as few-shot, zero-shot, and multilingual TTS within that context.","Finally, we will explore the evaluation metrics commonly used in voice cloning research and related datasets.","This survey compiles the available voice cloning algorithms to encourage research toward its generation and detection to limit its misuse."],"url":"http://arxiv.org/abs/2505.00579v1"}
{"created":"2025-05-01 14:53:12","title":"FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension","abstract":"Extending the context window in large language models (LLMs) is essential for applications involving long-form content generation. However, the linear increase in key-value (KV) cache memory requirements and the quadratic complexity of self-attention with respect to sequence length present significant challenges during fine-tuning and inference. Existing methods suffer from performance degradation when extending to longer contexts. In this work, we introduce a novel context extension method that optimizes both fine-tuning and inference efficiency. Our method exploits a key observation: in the frequency domain, the energy distribution of the KV cache is primarily concentrated in low-frequency components. By filtering out the high-frequency components, the KV cache can be effectively compressed with minimal information loss. Building on this insight, we propose an efficient compression technique, FreqKV, that iteratively compresses the increasing KV cache to a fixed size in the frequency domain, applicable to both fine-tuning and inference. FreqKV introduces no additional parameters or architectural modifications. With minimal fine-tuning, LLMs can learn to leverage the limited cache that is compressed in the frequency domain and extend the context window efficiently. Experiments on various long context language modeling and understanding tasks demonstrate the efficiency and efficacy of the proposed method.","sentences":["Extending the context window in large language models (LLMs) is essential for applications involving long-form content generation.","However, the linear increase in key-value (KV) cache memory requirements and the quadratic complexity of self-attention with respect to sequence length present significant challenges during fine-tuning and inference.","Existing methods suffer from performance degradation when extending to longer contexts.","In this work, we introduce a novel context extension method that optimizes both fine-tuning and inference efficiency.","Our method exploits a key observation: in the frequency domain, the energy distribution of the KV cache is primarily concentrated in low-frequency components.","By filtering out the high-frequency components, the KV cache can be effectively compressed with minimal information loss.","Building on this insight, we propose an efficient compression technique, FreqKV, that iteratively compresses the increasing KV cache to a fixed size in the frequency domain, applicable to both fine-tuning and inference.","FreqKV introduces no additional parameters or architectural modifications.","With minimal fine-tuning, LLMs can learn to leverage the limited cache that is compressed in the frequency domain and extend the context window efficiently.","Experiments on various long context language modeling and understanding tasks demonstrate the efficiency and efficacy of the proposed method."],"url":"http://arxiv.org/abs/2505.00570v1"}
{"created":"2025-05-01 14:51:30","title":"Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities","abstract":"Multimodal magnetic resonance imaging (MRI) constitutes the first line of investigation for clinicians in the care of brain tumors, providing crucial insights for surgery planning, treatment monitoring, and biomarker identification. Pre-training on large datasets have been shown to help models learn transferable representations and adapt with minimal labeled data. This behavior is especially valuable in medical imaging, where annotations are often scarce. However, applying this paradigm to multimodal medical data introduces a challenge: most existing approaches assume that all imaging modalities are available during both pre-training and fine-tuning. In practice, missing modalities often occur due to acquisition issues, specialist unavailability, or specific experimental designs on small in-house datasets. Consequently, a common approach involves training a separate model for each desired modality combination, making the process both resource-intensive and impractical for clinical use. Therefore, we introduce BM-MAE, a masked image modeling pre-training strategy tailored for multimodal MRI data. The same pre-trained model seamlessly adapts to any combination of available modalities, extracting rich representations that capture both intra- and inter-modal information. This allows fine-tuning on any subset of modalities without requiring architectural changes, while still benefiting from a model pre-trained on the full set of modalities. Extensive experiments show that the proposed pre-training strategy outperforms or remains competitive with baselines that require separate pre-training for each modality subset, while substantially surpassing training from scratch on several downstream tasks. Additionally, it can quickly and efficiently reconstruct missing modalities, highlighting its practical value. Code and trained models are available at: https://github.com/Lucas-rbnt/bmmae","sentences":["Multimodal magnetic resonance imaging (MRI) constitutes the first line of investigation for clinicians in the care of brain tumors, providing crucial insights for surgery planning, treatment monitoring, and biomarker identification.","Pre-training on large datasets have been shown to help models learn transferable representations and adapt with minimal labeled data.","This behavior is especially valuable in medical imaging, where annotations are often scarce.","However, applying this paradigm to multimodal medical data introduces a challenge: most existing approaches assume that all imaging modalities are available during both pre-training and fine-tuning.","In practice, missing modalities often occur due to acquisition issues, specialist unavailability, or specific experimental designs on small in-house datasets.","Consequently, a common approach involves training a separate model for each desired modality combination, making the process both resource-intensive and impractical for clinical use.","Therefore, we introduce BM-MAE, a masked image modeling pre-training strategy tailored for multimodal MRI data.","The same pre-trained model seamlessly adapts to any combination of available modalities, extracting rich representations that capture both intra- and inter-modal information.","This allows fine-tuning on any subset of modalities without requiring architectural changes, while still benefiting from a model pre-trained on the full set of modalities.","Extensive experiments show that the proposed pre-training strategy outperforms or remains competitive with baselines that require separate pre-training for each modality subset, while substantially surpassing training from scratch on several downstream tasks.","Additionally, it can quickly and efficiently reconstruct missing modalities, highlighting its practical value.","Code and trained models are available at: https://github.com/Lucas-rbnt/bmmae"],"url":"http://arxiv.org/abs/2505.00568v1"}
{"created":"2025-05-01 14:50:51","title":"Error Exponents for Oblivious Relaying and Connections to Source Coding with a Helper","abstract":"The information bottleneck channel, also known as oblivious relaying, is a two-hop channel where a transmitter sends messages to a remote receiver via an intermediate relay node. A codeword sent by the transmitter passes through a discrete memoryless channel to reach the relay, and then the relay processes the noisy channel output and forwards it to the receiver through a noiseless rate-limited link. The relay is oblivious, in the sense that it has no knowledge of the channel codebook used in transmission. Past works on oblivious relaying are focused on characterizing achievable rates. In this work, we study error exponents and explore connections to loseless source coding with a helper, also known as the Wyner-Ahlswede-K\\\"orner (WAK) problem. We first establish an achievable error exponent for oblivious relaying under constant compositions codes. A key feature of our analysis is the use of the type covering lemma to design the relay's compress-forward scheme. We then show that employing constant composition code ensembles does not improve the rates achieved with their IID counterparts. We also derive a sphere packing upper bound for the error exponent. In the second part of this paper, we establish a connection between the information bottleneck channel and the WAK problem. We show that good codes for the latter can be produced through permuting codes designed for the former. This is accomplished by revisiting Ahlswede's covering lemma, and extending it to achieve simultaneous covering of a type class by several distinct sets using the same sequence of permutations. We then apply our approach to attain the best known achievable error exponent for the WAK problem, previously established by Kelly and Wagner. As a byproduct of our derivations, we also establish error exponents and achievable rates under mismatched decoding rules.","sentences":["The information bottleneck channel, also known as oblivious relaying, is a two-hop channel where a transmitter sends messages to a remote receiver via an intermediate relay node.","A codeword sent by the transmitter passes through a discrete memoryless channel to reach the relay, and then the relay processes the noisy channel output and forwards it to the receiver through a noiseless rate-limited link.","The relay is oblivious, in the sense that it has no knowledge of the channel codebook used in transmission.","Past works on oblivious relaying are focused on characterizing achievable rates.","In this work, we study error exponents and explore connections to loseless source coding with a helper, also known as the Wyner-Ahlswede-K\\\"orner (WAK) problem.","We first establish an achievable error exponent for oblivious relaying under constant compositions codes.","A key feature of our analysis is the use of the type covering lemma to design the relay's compress-forward scheme.","We then show that employing constant composition code ensembles does not improve the rates achieved with their IID counterparts.","We also derive a sphere packing upper bound for the error exponent.","In the second part of this paper, we establish a connection between the information bottleneck channel and the WAK problem.","We show that good codes for the latter can be produced through permuting codes designed for the former.","This is accomplished by revisiting Ahlswede's covering lemma, and extending it to achieve simultaneous covering of a type class by several distinct sets using the same sequence of permutations.","We then apply our approach to attain the best known achievable error exponent for the WAK problem, previously established by Kelly and Wagner.","As a byproduct of our derivations, we also establish error exponents and achievable rates under mismatched decoding rules."],"url":"http://arxiv.org/abs/2505.00567v1"}
{"created":"2025-05-01 14:40:38","title":"X-ray illicit object detection using hybrid CNN-transformer neural network architectures","abstract":"In the field of X-ray security applications, even the smallest details can significantly impact outcomes. Objects that are heavily occluded or intentionally concealed pose a great challenge for detection, whether by human observation or through advanced technological applications. While certain Deep Learning (DL) architectures demonstrate strong performance in processing local information, such as Convolutional Neural Networks (CNNs), others excel in handling distant information, e.g., transformers. In X-ray security imaging the literature has been dominated by the use of CNN-based methods, while the integration of the two aforementioned leading architectures has not been sufficiently explored. In this paper, various hybrid CNN-transformer architectures are evaluated against a common CNN object detection baseline, namely YOLOv8. In particular, a CNN (HGNetV2) and a hybrid CNN-transformer (Next-ViT-S) backbone are combined with different CNN/transformer detection heads (YOLOv8 and RT-DETR). The resulting architectures are comparatively evaluated on three challenging public X-ray inspection datasets, namely EDS, HiXray, and PIDray. Interestingly, while the YOLOv8 detector with its default backbone (CSP-DarkNet53) is generally shown to be advantageous on the HiXray and PIDray datasets, when a domain distribution shift is incorporated in the X-ray images (as happens in the EDS datasets), hybrid CNN-transformer architectures exhibit increased robustness. Detailed comparative evaluation results, including object-level detection performance and object-size error analysis, demonstrate the strengths and weaknesses of each architectural combination and suggest guidelines for future research. The source code and network weights of the models employed in this study are available at https://github.com/jgenc/xray-comparative-evaluation.","sentences":["In the field of X-ray security applications, even the smallest details can significantly impact outcomes.","Objects that are heavily occluded or intentionally concealed pose a great challenge for detection, whether by human observation or through advanced technological applications.","While certain Deep Learning (DL) architectures demonstrate strong performance in processing local information, such as Convolutional Neural Networks (CNNs), others excel in handling distant information, e.g., transformers.","In X-ray security imaging the literature has been dominated by the use of CNN-based methods, while the integration of the two aforementioned leading architectures has not been sufficiently explored.","In this paper, various hybrid CNN-transformer architectures are evaluated against a common CNN object detection baseline, namely YOLOv8.","In particular, a CNN (HGNetV2) and a hybrid CNN-transformer (Next-ViT-S) backbone are combined with different CNN/transformer detection heads (YOLOv8 and RT-DETR).","The resulting architectures are comparatively evaluated on three challenging public X-ray inspection datasets, namely EDS, HiXray, and PIDray.","Interestingly, while the YOLOv8 detector with its default backbone (CSP-DarkNet53) is generally shown to be advantageous on the HiXray and PIDray datasets, when a domain distribution shift is incorporated in the X-ray images (as happens in the EDS datasets), hybrid CNN-transformer architectures exhibit increased robustness.","Detailed comparative evaluation results, including object-level detection performance and object-size error analysis, demonstrate the strengths and weaknesses of each architectural combination and suggest guidelines for future research.","The source code and network weights of the models employed in this study are available at https://github.com/jgenc/xray-comparative-evaluation."],"url":"http://arxiv.org/abs/2505.00564v1"}
{"created":"2025-05-01 14:40:07","title":"TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching","abstract":"Learning to solve complex tasks with signal temporal logic (STL) specifications is crucial to many real-world applications. However, most previous works only consider fixed or parametrized STL specifications due to the lack of a diverse STL dataset and encoders to effectively extract temporal logic information for downstream tasks. In this paper, we propose TeLoGraF, Temporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN) encoder and flow-matching to learn solutions for general STL specifications. We identify four commonly used STL templates and collect a total of 200K specifications with paired demonstrations. We conduct extensive experiments in five simulation environments ranging from simple dynamical models in the 2D space to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped navigation. Results show that our method outperforms other baselines in the STL satisfaction rate. Compared to classical STL planning algorithms, our approach is 10-100X faster in inference and can work on any system dynamics. Besides, we show our graph-encoding method's capability to solve complex STLs and robustness to out-distribution STL specifications. Code is available at https://github.com/mengyuest/TeLoGraF","sentences":["Learning to solve complex tasks with signal temporal logic (STL) specifications is crucial to many real-world applications.","However, most previous works only consider fixed or parametrized STL specifications due to the lack of a diverse STL dataset and encoders to effectively extract temporal logic information for downstream tasks.","In this paper, we propose TeLoGraF, Temporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN) encoder and flow-matching to learn solutions for general STL specifications.","We identify four commonly used STL templates and collect a total of 200K specifications with paired demonstrations.","We conduct extensive experiments in five simulation environments ranging from simple dynamical models in the 2D space to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped navigation.","Results show that our method outperforms other baselines in the STL satisfaction rate.","Compared to classical STL planning algorithms, our approach is 10-100X faster in inference and can work on any system dynamics.","Besides, we show our graph-encoding method's capability to solve complex STLs and robustness to out-distribution STL specifications.","Code is available at https://github.com/mengyuest/TeLoGraF"],"url":"http://arxiv.org/abs/2505.00562v1"}
{"created":"2025-05-01 14:36:33","title":"Efficient Recommendation with Millions of Items by Dynamic Pruning of Sub-Item Embeddings","abstract":"A large item catalogue is a major challenge for deploying modern sequential recommender models, since it makes the memory footprint of the model large and increases inference latency. One promising approach to address this is RecJPQ, which replaces item embeddings with sub-item embeddings. However, slow inference remains problematic because finding the top highest-scored items usually requires scoring all items in the catalogue, which may not be feasible for large catalogues. By adapting dynamic pruning concepts from document retrieval, we propose the RecJPQPrune dynamic pruning algorithm to efficiently find the top highest-scored items without computing the scores of all items in the catalogue. Our RecJPQPrune algorithm is safe-up-to-rank K since it theoretically guarantees that no potentially high-scored item is excluded from the final top K recommendation list, thereby ensuring no impact on effectiveness. Our experiments on two large datasets and three recommendation models demonstrate the efficiency achievable using RecJPQPrune: for instance, on the Tmall dataset with 2.2M items, we can reduce the median model scoring time by 64 times compared to the Transformer Default baseline, and 5.3 times compared to a recent scoring approach called PQTopK. Overall, this paper demonstrates the effective and efficient inference of Transformer-based recommendation models at catalogue scales not previously reported in the literature. Indeed, our RecJPQPrune algorithm can score 2 million items in under 10 milliseconds without GPUs, and without relying on Approximate Nearest Neighbour (ANN) techniques.","sentences":["A large item catalogue is a major challenge for deploying modern sequential recommender models, since it makes the memory footprint of the model large and increases inference latency.","One promising approach to address this is RecJPQ, which replaces item embeddings with sub-item embeddings.","However, slow inference remains problematic because finding the top highest-scored items usually requires scoring all items in the catalogue, which may not be feasible for large catalogues.","By adapting dynamic pruning concepts from document retrieval, we propose the RecJPQPrune dynamic pruning algorithm to efficiently find the top highest-scored items without computing the scores of all items in the catalogue.","Our RecJPQPrune algorithm is safe-up-to-rank K since it theoretically guarantees that no potentially high-scored item is excluded from the final top K recommendation list, thereby ensuring no impact on effectiveness.","Our experiments on two large datasets and three recommendation models demonstrate the efficiency achievable using RecJPQPrune: for instance, on the Tmall dataset with 2.2M items, we can reduce the median model scoring time by 64 times compared to the Transformer Default baseline, and 5.3 times compared to a recent scoring approach called PQTopK. Overall, this paper demonstrates the effective and efficient inference of Transformer-based recommendation models at catalogue scales not previously reported in the literature.","Indeed, our RecJPQPrune algorithm can score 2 million items in under 10 milliseconds without GPUs, and without relying on Approximate Nearest Neighbour (ANN) techniques."],"url":"http://arxiv.org/abs/2505.00560v1"}
{"created":"2025-05-01 14:33:56","title":"Exponentially Consistent Low Complexity Tests for Outlier Hypothesis Testing with Distribution Uncertainty","abstract":"We revisit the outlier hypothesis testing (OHT) problem of Li et al. (TIT 2024) and propose exponentially consistent tests when there is distribution uncertainty for both nominal samples and outliers. In original OHT, one is given a list of sequences, most of which are generated i.i.d. from a distribution called the nominal distribution while the rest are generated i.i.d. from another distribution named the anomalous distribution. The task of OHT is to identify outliers when both the nominal and anomalous distributions are unknown. Motivated by the study for classification with distribution uncertainty by Hsu and Wang (ISIT 2020), we consider OHT with distribution uncertainty, where each nominal sample is generated from a distribution centered around the unknown nominal distribution and each outlier is generated from a distribution centered around the unknown anomalous distribution. With a further step towards practical applications, in the spirit of Bu et al. (TSP 2019), we propose low-complexity tests when the number of outliers is known and unknown, and show that our proposed tests are exponentially consistent. Furthermore, we demonstrate that there is a penalty for not knowing the number of outliers in the error exponent when outliers exist. Our results strengthen Bu et al. in three aspects: i) our tests allow distribution uncertainty and reveal the impact of distribution uncertainty on the performance of low-complexity tests; ii) when the number of outliers is known and there is no distribution uncertainty, our test achieves the same asymptotic performance with lower complexity; and iii) when the number of outliers is unknown, we characterize the tradeoff among the three error probabilities, while two of these error probabilities were not analyzed by Bu et al. even when there is no distribution uncertainty. Finally, we illustrate our theoretical results using numerical examples.","sentences":["We revisit the outlier hypothesis testing (OHT) problem of Li et al. (TIT 2024) and propose exponentially consistent tests when there is distribution uncertainty for both nominal samples and outliers.","In original OHT, one is given a list of sequences, most of which are generated i.i.d.","from a distribution called the nominal distribution while the rest are generated i.i.d.","from another distribution named the anomalous distribution.","The task of OHT is to identify outliers when both the nominal and anomalous distributions are unknown.","Motivated by the study for classification with distribution uncertainty by Hsu and Wang (ISIT 2020), we consider OHT with distribution uncertainty, where each nominal sample is generated from a distribution centered around the unknown nominal distribution and each outlier is generated from a distribution centered around the unknown anomalous distribution.","With a further step towards practical applications, in the spirit of Bu et al.","(TSP 2019), we propose low-complexity tests when the number of outliers is known and unknown, and show that our proposed tests are exponentially consistent.","Furthermore, we demonstrate that there is a penalty for not knowing the number of outliers in the error exponent when outliers exist.","Our results strengthen Bu et al.","in three aspects: i) our tests allow distribution uncertainty and reveal the impact of distribution uncertainty on the performance of low-complexity tests; ii) when the number of outliers is known and there is no distribution uncertainty, our test achieves the same asymptotic performance with lower complexity; and iii) when the number of outliers is unknown, we characterize the tradeoff among the three error probabilities, while two of these error probabilities were not analyzed by Bu et al.","even when there is no distribution uncertainty.","Finally, we illustrate our theoretical results using numerical examples."],"url":"http://arxiv.org/abs/2505.00558v1"}
{"created":"2025-05-01 14:33:47","title":"Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models","abstract":"Hallucinations in large language models (LLMs) present a growing challenge across real-world applications, from healthcare to law, where factual reliability is essential. Despite advances in alignment and instruction tuning, LLMs can still generate outputs that are fluent yet fundamentally untrue. Understanding the cognitive dynamics that underlie these hallucinations remains an open problem. In this study, we propose a prompt-based framework to systematically trigger and quantify hallucination: a Hallucination-Inducing Prompt (HIP), which synthetically fuses semantically distant concepts (e.g., periodic table of elements and tarot divination) in a misleading way, and a Hallucination Quantifying Prompt (HQP), which scores the plausibility, confidence, and coherence of the output. Controlled experiments across multiple LLMs revealed that HIPs consistently produced less coherent and more hallucinated responses than their null-fusion controls. These effects varied across models, with reasoning-oriented LLMs showing distinct profiles from general-purpose ones. Our framework provides a reproducible testbed for studying hallucination vulnerability, and opens the door to developing safer, more introspective LLMs that can detect and self-regulate the onset of conceptual instability.","sentences":["Hallucinations in large language models (LLMs) present a growing challenge across real-world applications, from healthcare to law, where factual reliability is essential.","Despite advances in alignment and instruction tuning, LLMs can still generate outputs that are fluent yet fundamentally untrue.","Understanding the cognitive dynamics that underlie these hallucinations remains an open problem.","In this study, we propose a prompt-based framework to systematically trigger and quantify hallucination: a Hallucination-Inducing Prompt (HIP), which synthetically fuses semantically distant concepts (e.g., periodic table of elements and tarot divination) in a misleading way, and a Hallucination Quantifying Prompt (HQP), which scores the plausibility, confidence, and coherence of the output.","Controlled experiments across multiple LLMs revealed that HIPs consistently produced less coherent and more hallucinated responses than their null-fusion controls.","These effects varied across models, with reasoning-oriented LLMs showing distinct profiles from general-purpose ones.","Our framework provides a reproducible testbed for studying hallucination vulnerability, and opens the door to developing safer, more introspective LLMs that can detect and self-regulate the onset of conceptual instability."],"url":"http://arxiv.org/abs/2505.00557v1"}
{"created":"2025-05-01 14:29:32","title":"Notes on Univariate Sumcheck","abstract":"These notes describe an adaptation of the multivariate sumcheck protocol to univariate polynomials interpolated over roots of unity.","sentences":["These notes describe an adaptation of the multivariate sumcheck protocol to univariate polynomials interpolated over roots of unity."],"url":"http://arxiv.org/abs/2505.00554v1"}
{"created":"2025-05-01 14:28:44","title":"Graph Spectral Filtering with Chebyshev Interpolation for Recommendation","abstract":"Graph convolutional networks have recently gained prominence in collaborative filtering (CF) for recommendations. However, we identify potential bottlenecks in two foundational components. First, the embedding layer leads to a latent space with limited capacity, overlooking locally observed but potentially valuable preference patterns. Also, the widely-used neighborhood aggregation is limited in its ability to leverage diverse preference patterns in a fine-grained manner. Building on spectral graph theory, we reveal that these limitations stem from graph filtering with a cut-off in the frequency spectrum and a restricted linear form. To address these issues, we introduce ChebyCF, a CF framework based on graph spectral filtering. Instead of a learned embedding, it takes a user's raw interaction history to utilize the full spectrum of signals contained in it. Also, it adopts Chebyshev interpolation to effectively approximate a flexible non-linear graph filter, and further enhances it by using an additional ideal pass filter and degree-based normalization. Through extensive experiments, we verify that ChebyCF overcomes the aforementioned bottlenecks and achieves state-of-the-art performance across multiple benchmarks and reasonably fast inference. Our code is available at https://github.com/chanwoo0806/ChebyCF.","sentences":["Graph convolutional networks have recently gained prominence in collaborative filtering (CF) for recommendations.","However, we identify potential bottlenecks in two foundational components.","First, the embedding layer leads to a latent space with limited capacity, overlooking locally observed but potentially valuable preference patterns.","Also, the widely-used neighborhood aggregation is limited in its ability to leverage diverse preference patterns in a fine-grained manner.","Building on spectral graph theory, we reveal that these limitations stem from graph filtering with a cut-off in the frequency spectrum and a restricted linear form.","To address these issues, we introduce ChebyCF, a CF framework based on graph spectral filtering.","Instead of a learned embedding, it takes a user's raw interaction history to utilize the full spectrum of signals contained in it.","Also, it adopts Chebyshev interpolation to effectively approximate a flexible non-linear graph filter, and further enhances it by using an additional ideal pass filter and degree-based normalization.","Through extensive experiments, we verify that ChebyCF overcomes the aforementioned bottlenecks and achieves state-of-the-art performance across multiple benchmarks and reasonably fast inference.","Our code is available at https://github.com/chanwoo0806/ChebyCF."],"url":"http://arxiv.org/abs/2505.00552v1"}
{"created":"2025-05-01 14:28:35","title":"100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models","abstract":"The recent development of reasoning language models (RLMs) represents a novel evolution in large language models. In particular, the recent release of DeepSeek-R1 has generated widespread social impact and sparked enthusiasm in the research community for exploring the explicit reasoning paradigm of language models. However, the implementation details of the released models have not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero, DeepSeek-R1, and the distilled small models. As a result, many replication studies have emerged aiming to reproduce the strong performance achieved by DeepSeek-R1, reaching comparable performance through similar training procedures and fully open-source data resources. These works have investigated feasible strategies for supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR), focusing on data preparation and method design, yielding various valuable insights. In this report, we provide a summary of recent replication studies to inspire future research. We primarily focus on SFT and RLVR as two main directions, introducing the details for data construction, method design and training procedure of current replication studies. Moreover, we conclude key findings from the implementation details and experimental results reported by these studies, anticipating to inspire future research. We also discuss additional techniques of enhancing RLMs, highlighting the potential of expanding the application scope of these models, and discussing the challenges in development. By this survey, we aim to help researchers and developers of RLMs stay updated with the latest advancements, and seek to inspire new ideas to further enhance RLMs.","sentences":["The recent development of reasoning language models (RLMs) represents a novel evolution in large language models.","In particular, the recent release of DeepSeek-R1 has generated widespread social impact and sparked enthusiasm in the research community for exploring the explicit reasoning paradigm of language models.","However, the implementation details of the released models have not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero, DeepSeek-R1, and the distilled small models.","As a result, many replication studies have emerged aiming to reproduce the strong performance achieved by DeepSeek-R1, reaching comparable performance through similar training procedures and fully open-source data resources.","These works have investigated feasible strategies for supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR), focusing on data preparation and method design, yielding various valuable insights.","In this report, we provide a summary of recent replication studies to inspire future research.","We primarily focus on SFT and RLVR as two main directions, introducing the details for data construction, method design and training procedure of current replication studies.","Moreover, we conclude key findings from the implementation details and experimental results reported by these studies, anticipating to inspire future research.","We also discuss additional techniques of enhancing RLMs, highlighting the potential of expanding the application scope of these models, and discussing the challenges in development.","By this survey, we aim to help researchers and developers of RLMs stay updated with the latest advancements, and seek to inspire new ideas to further enhance RLMs."],"url":"http://arxiv.org/abs/2505.00551v1"}
{"created":"2025-05-01 14:27:47","title":"Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework for Equitable Music Education in the Global South","abstract":"The rapid expansion of digital technologies has transformed educational landscapes worldwide, yet significant infrastructural and cultural challenges persist in the Global South. This paper introduces a low-latency JackTrip framework designed to bridge both the cultural and digital divides in music education. By leveraging an open-source, UDP-based audio streaming protocol originally developed at Stanford's CCRMA, the framework is tailored to address technical constraints such as intermittent connectivity, limited bandwidth, and high latency that characterize many rural and underserved regions. The study systematically compares the performance of JackTrip with conventional platforms like Zoom, demonstrating that JackTrip achieves sub-30~ms latency under simulated low-resource conditions while preserving the intricate audio details essential for non-Western musical traditions. Spectral analysis confirms that JackTrip's superior handling of microtonal scales, complex rhythms, and harmonic textures provides a culturally authentic medium for real-time ensemble performance and music education. These findings underscore the transformative potential of decentralized, edge-computing solutions in empowering educators and musicians across the Global South, promoting both technological equity and cultural preservation.","sentences":["The rapid expansion of digital technologies has transformed educational landscapes worldwide, yet significant infrastructural and cultural challenges persist in the Global South.","This paper introduces a low-latency JackTrip framework designed to bridge both the cultural and digital divides in music education.","By leveraging an open-source, UDP-based audio streaming protocol originally developed at Stanford's CCRMA, the framework is tailored to address technical constraints such as intermittent connectivity, limited bandwidth, and high latency that characterize many rural and underserved regions.","The study systematically compares the performance of JackTrip with conventional platforms like Zoom, demonstrating that JackTrip achieves sub-30~ms latency under simulated low-resource conditions while preserving the intricate audio details essential for non-Western musical traditions.","Spectral analysis confirms that JackTrip's superior handling of microtonal scales, complex rhythms, and harmonic textures provides a culturally authentic medium for real-time ensemble performance and music education.","These findings underscore the transformative potential of decentralized, edge-computing solutions in empowering educators and musicians across the Global South, promoting both technological equity and cultural preservation."],"url":"http://arxiv.org/abs/2505.00550v1"}
{"created":"2025-05-01 14:27:02","title":"Sum Rate Maximization for NOMA-Assisted Uplink Pinching-Antenna Systems","abstract":"In this paper, we investigate an uplink communication scenario in which multiple users communicate with an access point (AP) employing non-orthogonal multiple access (NOMA). A pinching antenna, which can be activated at an arbitrary point along a dielectric waveguide, is deployed at the AP to dynamically reconfigure user channels. The objective is to maximize the system sum rate by jointly optimizing the pinching-antenna's position and the users' transmit powers. The formulated optimization problem is non-convex, and addressed using the particle swarm optimization (PSO) algorithm. For performance benchmarking, two time division multiple access (TDMA) schemes are considered: one based on the pinching antenna individually activated for each user, and the other based on the single-pinching-antenna configuration serving all users. Numerical results demonstrate that the use of the pinching antenna significantly enhances the system sum rate compared to conventional antenna architectures. Moreover, the NOMA-based scheme outperforms the TDMA-based scheme with a single pinching antenna but is outperformed by the TDMA-based approach when the pinching antenna is adaptively configured for each user. Finally, the proposed PSO-based method is shown to achieve near-optimal performance for both NOMA and TDMA with a common pinching-antenna configuration.","sentences":["In this paper, we investigate an uplink communication scenario in which multiple users communicate with an access point (AP) employing non-orthogonal multiple access (NOMA).","A pinching antenna, which can be activated at an arbitrary point along a dielectric waveguide, is deployed at the AP to dynamically reconfigure user channels.","The objective is to maximize the system sum rate by jointly optimizing the pinching-antenna's position and the users' transmit powers.","The formulated optimization problem is non-convex, and addressed using the particle swarm optimization (PSO) algorithm.","For performance benchmarking, two time division multiple access (TDMA) schemes are considered: one based on the pinching antenna individually activated for each user, and the other based on the single-pinching-antenna configuration serving all users.","Numerical results demonstrate that the use of the pinching antenna significantly enhances the system sum rate compared to conventional antenna architectures.","Moreover, the NOMA-based scheme outperforms the TDMA-based scheme with a single pinching antenna but is outperformed by the TDMA-based approach when the pinching antenna is adaptively configured for each user.","Finally, the proposed PSO-based method is shown to achieve near-optimal performance for both NOMA and TDMA with a common pinching-antenna configuration."],"url":"http://arxiv.org/abs/2505.00549v1"}
{"created":"2025-05-01 14:23:55","title":"From Requirements to Test Cases: An NLP-Based Approach for High-Performance ECU Test Case Automation","abstract":"Automating test case specification generation is vital for improving the efficiency and accuracy of software testing, particularly in complex systems like high-performance Electronic Control Units (ECUs). This study investigates the use of Natural Language Processing (NLP) techniques, including Rule-Based Information Extraction and Named Entity Recognition (NER), to transform natural language requirements into structured test case specifications. A dataset of 400 feature element documents from the Polarion tool was used to evaluate both approaches for extracting key elements such as signal names and values. The results reveal that the Rule-Based method outperforms the NER method, achieving 95% accuracy for more straightforward requirements with single signals, while the NER method, leveraging SVM and other machine learning algorithms, achieved 77.3% accuracy but struggled with complex scenarios. Statistical analysis confirmed that the Rule-Based approach significantly enhances efficiency and accuracy compared to manual methods. This research highlights the potential of NLP-driven automation in improving quality assurance, reducing manual effort, and expediting test case generation, with future work focused on refining NER and hybrid models to handle greater complexity.","sentences":["Automating test case specification generation is vital for improving the efficiency and accuracy of software testing, particularly in complex systems like high-performance Electronic Control Units (ECUs).","This study investigates the use of Natural Language Processing (NLP) techniques, including Rule-Based Information Extraction and","Named Entity Recognition (NER), to transform natural language requirements into structured test case specifications.","A dataset of 400 feature element documents from the Polarion tool was used to evaluate both approaches for extracting key elements such as signal names and values.","The results reveal that the Rule-Based method outperforms the NER method, achieving 95% accuracy for more straightforward requirements with single signals, while the NER method, leveraging SVM and other machine learning algorithms, achieved 77.3% accuracy but struggled with complex scenarios.","Statistical analysis confirmed that the Rule-Based approach significantly enhances efficiency and accuracy compared to manual methods.","This research highlights the potential of NLP-driven automation in improving quality assurance, reducing manual effort, and expediting test case generation, with future work focused on refining NER and hybrid models to handle greater complexity."],"url":"http://arxiv.org/abs/2505.00547v1"}
{"created":"2025-05-01 14:20:45","title":"Reducing Student Distraction Through Fuzzy Logic Based Seating Arrangements","abstract":"A crucial skill for primary school teachers is maintaining efficient classroom management. Teachers use classroom seating arrangements to help maintain this efficiency. However, developing classroom seating arrangements is both time-consuming and often non-optimal for distraction mitigation. Fuzzy logic-based approaches for the development of classroom seating arrangements can reduce development time and minimize classroom distraction. In this study, an original fuzzy logic-based software package named \"CUB\" is introduced and applied to a modern classroom using \"cluster\" seating arrangements. The combination of fuzzy inference systems, fuzzy c-means clustering, sequential, and iterative processes produce ready-to-use seating arrangements for the classroom in this study. The seating arrangements are compared with an existing set of seating arrangements to validate the results. The author's findings show that CUB is successful in generating applicable seating arrangements with a small liklihood of replicating arrangements. The findings also suggest that fuzz logic-based approaches may be successful in other styles of classroom arrangement.","sentences":["A crucial skill for primary school teachers is maintaining efficient classroom management.","Teachers use classroom seating arrangements to help maintain this efficiency.","However, developing classroom seating arrangements is both time-consuming and often non-optimal for distraction mitigation.","Fuzzy logic-based approaches for the development of classroom seating arrangements can reduce development time and minimize classroom distraction.","In this study, an original fuzzy logic-based software package named \"CUB\" is introduced and applied to a modern classroom using \"cluster\" seating arrangements.","The combination of fuzzy inference systems, fuzzy c-means clustering, sequential, and iterative processes produce ready-to-use seating arrangements for the classroom in this study.","The seating arrangements are compared with an existing set of seating arrangements to validate the results.","The author's findings show that CUB is successful in generating applicable seating arrangements with a small liklihood of replicating arrangements.","The findings also suggest that fuzz logic-based approaches may be successful in other styles of classroom arrangement."],"url":"http://arxiv.org/abs/2505.00545v1"}
{"created":"2025-05-01 14:05:55","title":"KnowEEG: Explainable Knowledge Driven EEG Classification","abstract":"Electroencephalography (EEG) is a method of recording brain activity that shows significant promise in applications ranging from disease classification to emotion detection and brain-computer interfaces. Recent advances in deep learning have improved EEG classification performance yet model explainability remains an issue. To address this key limitation of explainability we introduce KnowEEG; a novel explainable machine learning approach for EEG classification. KnowEEG extracts a comprehensive set of per-electrode features, filters them using statistical tests, and integrates between-electrode connectivity statistics. These features are then input to our modified Random Forest model (Fusion Forest) that balances per electrode statistics with between electrode connectivity features in growing the trees of the forest. By incorporating knowledge from both the generalized time-series and EEG-specific domains, KnowEEG achieves performance comparable to or exceeding state-of-the-art deep learning models across five different classification tasks: emotion detection, mental workload classification, eyes open/closed detection, abnormal EEG classification, and event detection. In addition to high performance, KnowEEG provides inherent explainability through feature importance scores for understandable features. We demonstrate by example on the eyes closed/open classification task that this explainability can be used to discover knowledge about the classes. This discovered knowledge for eyes open/closed classification was proven to be correct by current neuroscience literature. Therefore, the impact of KnowEEG will be significant for domains where EEG explainability is critical such as healthcare.","sentences":["Electroencephalography (EEG) is a method of recording brain activity that shows significant promise in applications ranging from disease classification to emotion detection and brain-computer interfaces.","Recent advances in deep learning have improved EEG classification performance yet model explainability remains an issue.","To address this key limitation of explainability we introduce KnowEEG; a novel explainable machine learning approach for EEG classification.","KnowEEG extracts a comprehensive set of per-electrode features, filters them using statistical tests, and integrates between-electrode connectivity statistics.","These features are then input to our modified Random Forest model (Fusion Forest) that balances per electrode statistics with between electrode connectivity features in growing the trees of the forest.","By incorporating knowledge from both the generalized time-series and EEG-specific domains, KnowEEG achieves performance comparable to or exceeding state-of-the-art deep learning models across five different classification tasks: emotion detection, mental workload classification, eyes open/closed detection, abnormal EEG classification, and event detection.","In addition to high performance, KnowEEG provides inherent explainability through feature importance scores for understandable features.","We demonstrate by example on the eyes closed/open classification task that this explainability can be used to discover knowledge about the classes.","This discovered knowledge for eyes open/closed classification was proven to be correct by current neuroscience literature.","Therefore, the impact of KnowEEG will be significant for domains where EEG explainability is critical such as healthcare."],"url":"http://arxiv.org/abs/2505.00541v1"}
{"created":"2025-05-01 14:05:46","title":"Emergence of Roles in Robotic Teams with Model Sharing and Limited Communication","abstract":"We present a reinforcement learning strategy for use in multi-agent foraging systems in which the learning is centralised to a single agent and its model is periodically disseminated among the population of non-learning agents. In a domain where multi-agent reinforcement learning (MARL) is the common approach, this approach aims to significantly reduce the computational and energy demands compared to approaches such as MARL and centralised learning models. By developing high performing foraging agents, these approaches can be translated into real-world applications such as logistics, environmental monitoring, and autonomous exploration. A reward function was incorporated into this approach that promotes role development among agents, without explicit directives. This led to the differentiation of behaviours among the agents. The implicit encouragement of role differentiation allows for dynamic actions in which agents can alter roles dependent on their interactions with the environment without the need for explicit communication between agents.","sentences":["We present a reinforcement learning strategy for use in multi-agent foraging systems in which the learning is centralised to a single agent and its model is periodically disseminated among the population of non-learning agents.","In a domain where multi-agent reinforcement learning (MARL) is the common approach, this approach aims to significantly reduce the computational and energy demands compared to approaches such as MARL and centralised learning models.","By developing high performing foraging agents, these approaches can be translated into real-world applications such as logistics, environmental monitoring, and autonomous exploration.","A reward function was incorporated into this approach that promotes role development among agents, without explicit directives.","This led to the differentiation of behaviours among the agents.","The implicit encouragement of role differentiation allows for dynamic actions in which agents can alter roles dependent on their interactions with the environment without the need for explicit communication between agents."],"url":"http://arxiv.org/abs/2505.00540v1"}
{"created":"2025-05-01 14:00:25","title":"A Robust Deep Networks based Multi-Object MultiCamera Tracking System for City Scale Traffic","abstract":"Vision sensors are becoming more important in Intelligent Transportation Systems (ITS) for traffic monitoring, management, and optimization as the number of network cameras continues to rise. However, manual object tracking and matching across multiple non-overlapping cameras pose significant challenges in city-scale urban traffic scenarios. These challenges include handling diverse vehicle attributes, occlusions, illumination variations, shadows, and varying video resolutions. To address these issues, we propose an efficient and cost-effective deep learning-based framework for Multi-Object Multi-Camera Tracking (MO-MCT). The proposed framework utilizes Mask R-CNN for object detection and employs Non-Maximum Suppression (NMS) to select target objects from overlapping detections. Transfer learning is employed for re-identification, enabling the association and generation of vehicle tracklets across multiple cameras. Moreover, we leverage appropriate loss functions and distance measures to handle occlusion, illumination, and shadow challenges. The final solution identification module performs feature extraction using ResNet-152 coupled with Deep SORT based vehicle tracking. The proposed framework is evaluated on the 5th AI City Challenge dataset (Track 3), comprising 46 camera feeds. Among these 46 camera streams, 40 are used for model training and validation, while the remaining six are utilized for model testing. The proposed framework achieves competitive performance with an IDF1 score of 0.8289, and precision and recall scores of 0.9026 and 0.8527 respectively, demonstrating its effectiveness in robust and accurate vehicle tracking.","sentences":["Vision sensors are becoming more important in Intelligent Transportation Systems (ITS) for traffic monitoring, management, and optimization as the number of network cameras continues to rise.","However, manual object tracking and matching across multiple non-overlapping cameras pose significant challenges in city-scale urban traffic scenarios.","These challenges include handling diverse vehicle attributes, occlusions, illumination variations, shadows, and varying video resolutions.","To address these issues, we propose an efficient and cost-effective deep learning-based framework for Multi-Object Multi-Camera Tracking (MO-MCT).","The proposed framework utilizes Mask R-CNN for object detection and employs Non-Maximum Suppression (NMS) to select target objects from overlapping detections.","Transfer learning is employed for re-identification, enabling the association and generation of vehicle tracklets across multiple cameras.","Moreover, we leverage appropriate loss functions and distance measures to handle occlusion, illumination, and shadow challenges.","The final solution identification module performs feature extraction using ResNet-152 coupled with Deep SORT based vehicle tracking.","The proposed framework is evaluated on the 5th AI City Challenge dataset (Track 3), comprising 46 camera feeds.","Among these 46 camera streams, 40 are used for model training and validation, while the remaining six are utilized for model testing.","The proposed framework achieves competitive performance with an IDF1 score of 0.8289, and precision and recall scores of 0.9026 and 0.8527 respectively, demonstrating its effectiveness in robust and accurate vehicle tracking."],"url":"http://arxiv.org/abs/2505.00534v1"}
{"created":"2025-05-01 13:59:13","title":"Test-time Correlation Alignment","abstract":"Deep neural networks often experience performance drops due to distribution shifts between training and test data. Although domain adaptation offers a solution, privacy concerns restrict access to training data in many real-world scenarios. This restriction has spurred interest in Test-Time Adaptation (TTA), which adapts models using only unlabeled test data. However, current TTA methods still face practical challenges: (1) a primary focus on instance-wise alignment, overlooking CORrelation ALignment (CORAL) due to missing source correlations; (2) complex backpropagation operations for model updating, resulting in overhead computation and (3) domain forgetting.   To address these challenges, we provide a theoretical analysis to investigate the feasibility of Test-time Correlation Alignment (TCA), demonstrating that correlation alignment between high-certainty instances and test instances can enhance test performances with a theoretical guarantee. Based on this, we propose two simple yet effective algorithms: LinearTCA and LinearTCA+. LinearTCA applies a simple linear transformation to achieve both instance and correlation alignment without additional model updates, while LinearTCA+ serves as a plug-and-play module that can easily boost existing TTA methods. Extensive experiments validate our theoretical insights and show that TCA methods significantly outperforms baselines across various tasks, benchmarks and backbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on OfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6% computation time compared to the best baseline TTA method.","sentences":["Deep neural networks often experience performance drops due to distribution shifts between training and test data.","Although domain adaptation offers a solution, privacy concerns restrict access to training data in many real-world scenarios.","This restriction has spurred interest in Test-Time Adaptation (TTA), which adapts models using only unlabeled test data.","However, current TTA methods still face practical challenges: (1) a primary focus on instance-wise alignment, overlooking CORrelation ALignment (CORAL) due to missing source correlations; (2) complex backpropagation operations for model updating, resulting in overhead computation and (3) domain forgetting.   ","To address these challenges, we provide a theoretical analysis to investigate the feasibility of Test-time Correlation Alignment (TCA), demonstrating that correlation alignment between high-certainty instances and test instances can enhance test performances with a theoretical guarantee.","Based on this, we propose two simple yet effective algorithms: LinearTCA and LinearTCA+.","LinearTCA applies a simple linear transformation to achieve both instance and correlation alignment without additional model updates, while LinearTCA+ serves as a plug-and-play module that can easily boost existing TTA methods.","Extensive experiments validate our theoretical insights and show that TCA methods significantly outperforms baselines across various tasks, benchmarks and backbones.","Notably, LinearTCA improves adaptation accuracy by 5.88% on OfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6% computation time compared to the best baseline TTA method."],"url":"http://arxiv.org/abs/2505.00533v1"}
{"created":"2025-05-01 13:57:20","title":"Leveraging Partial SMILES Validation Scheme for Enhanced Drug Design in Reinforcement Learning Frameworks","abstract":"SMILES-based molecule generation has emerged as a powerful approach in drug discovery. Deep reinforcement learning (RL) using large language model (LLM) has been incorporated into the molecule generation process to achieve high matching score in term of likelihood of desired molecule candidates. However, a critical challenge in this approach is catastrophic forgetting during the RL phase, where knowledge such as molecule validity, which often exceeds 99\\% during pretraining, significantly deteriorates. Current RL algorithms applied in drug discovery, such as REINVENT, use prior models as anchors to retian pretraining knowledge, but these methods lack robust exploration mechanisms. To address these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a novel RL algorithm that incorporates real-time partial SMILES validation to prevent catastrophic forgetting while encouraging exploration. Unlike traditional RL approaches that validate molecule structures only after generating entire sequences, PSV-PPO performs stepwise validation at each auto-regressive step, evaluating not only the selected token candidate but also all potential branches stemming from the prior partial sequence. This enables early detection of invalid partial SMILES across all potential paths. As a result, PSV-PPO maintains high validity rates even during aggressive exploration of the vast chemical space. Our experiments on the PMO and GuacaMol benchmark datasets demonstrate that PSV-PPO significantly reduces the number of invalid generated structures while maintaining competitive exploration and optimization performance. While our work primarily focuses on maintaining validity, the framework of PSV-PPO can be extended in future research to incorporate additional forms of valuable domain knowledge, further enhancing reinforcement learning applications in drug discovery.","sentences":["SMILES-based molecule generation has emerged as a powerful approach in drug discovery.","Deep reinforcement learning (RL) using large language model (LLM) has been incorporated into the molecule generation process to achieve high matching score in term of likelihood of desired molecule candidates.","However, a critical challenge in this approach is catastrophic forgetting during the RL phase, where knowledge such as molecule validity, which often exceeds 99\\% during pretraining, significantly deteriorates.","Current RL algorithms applied in drug discovery, such as REINVENT, use prior models as anchors to retian pretraining knowledge, but these methods lack robust exploration mechanisms.","To address these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a novel RL algorithm that incorporates real-time partial SMILES validation to prevent catastrophic forgetting while encouraging exploration.","Unlike traditional RL approaches that validate molecule structures only after generating entire sequences, PSV-PPO performs stepwise validation at each auto-regressive step, evaluating not only the selected token candidate but also all potential branches stemming from the prior partial sequence.","This enables early detection of invalid partial SMILES across all potential paths.","As a result, PSV-PPO maintains high validity rates even during aggressive exploration of the vast chemical space.","Our experiments on the PMO and GuacaMol benchmark datasets demonstrate that PSV-PPO significantly reduces the number of invalid generated structures while maintaining competitive exploration and optimization performance.","While our work primarily focuses on maintaining validity, the framework of PSV-PPO can be extended in future research to incorporate additional forms of valuable domain knowledge, further enhancing reinforcement learning applications in drug discovery."],"url":"http://arxiv.org/abs/2505.00530v1"}
{"created":"2025-05-01 13:52:19","title":"DeCo: Task Decomposition and Skill Composition for Zero-Shot Generalization in Long-Horizon 3D Manipulation","abstract":"Generalizing language-conditioned multi-task imitation learning (IL) models to novel long-horizon 3D manipulation tasks remains a significant challenge. To address this, we propose DeCo (Task Decomposition and Skill Composition), a model-agnostic framework compatible with various multi-task IL models, designed to enhance their zero-shot generalization to novel, compositional, long-horizon 3D manipulation tasks. DeCo first decomposes IL demonstrations into a set of modular atomic tasks based on the physical interaction between the gripper and objects, and constructs an atomic training dataset that enables models to learn a diverse set of reusable atomic skills during imitation learning. At inference time, DeCo leverages a vision-language model (VLM) to parse high-level instructions for novel long-horizon tasks, retrieve the relevant atomic skills, and dynamically schedule their execution; a spatially-aware skill-chaining module then ensures smooth, collision-free transitions between sequential skills. We evaluate DeCo in simulation using DeCoBench, a benchmark specifically designed to assess zero-shot generalization of multi-task IL models in compositional long-horizon 3D manipulation. Across three representative multi-task IL models (RVT-2, 3DDA, and ARP), DeCo achieves success rate improvements of 66.67%, 21.53%, and 57.92%, respectively, on 12 novel compositional tasks. Moreover, in real-world experiments, a DeCo-enhanced model trained on only 6 atomic tasks successfully completes 9 novel long-horizon tasks, yielding an average success rate improvement of 53.33% over the base multi-task IL model. Video demonstrations are available at: https://deco226.github.io.","sentences":["Generalizing language-conditioned multi-task imitation learning (IL) models to novel long-horizon 3D manipulation tasks remains a significant challenge.","To address this, we propose DeCo (Task Decomposition and Skill Composition), a model-agnostic framework compatible with various multi-task IL models, designed to enhance their zero-shot generalization to novel, compositional, long-horizon 3D manipulation tasks.","DeCo first decomposes IL demonstrations into a set of modular atomic tasks based on the physical interaction between the gripper and objects, and constructs an atomic training dataset that enables models to learn a diverse set of reusable atomic skills during imitation learning.","At inference time, DeCo leverages a vision-language model (VLM) to parse high-level instructions for novel long-horizon tasks, retrieve the relevant atomic skills, and dynamically schedule their execution; a spatially-aware skill-chaining module then ensures smooth, collision-free transitions between sequential skills.","We evaluate DeCo in simulation using DeCoBench, a benchmark specifically designed to assess zero-shot generalization of multi-task IL models in compositional long-horizon 3D manipulation.","Across three representative multi-task IL models (RVT-2, 3DDA, and ARP), DeCo achieves success rate improvements of 66.67%, 21.53%, and 57.92%, respectively, on 12 novel compositional tasks.","Moreover, in real-world experiments, a DeCo-enhanced model trained on only 6 atomic tasks successfully completes 9 novel long-horizon tasks, yielding an average success rate improvement of 53.33% over the base multi-task IL model.","Video demonstrations are available at: https://deco226.github.io."],"url":"http://arxiv.org/abs/2505.00527v1"}
{"created":"2025-05-01 13:41:42","title":"Proportionality in Practice: Quantifying Proportionality in Ordinal Elections","abstract":"Proportional representation plays a crucial role in electoral systems. In ordinal elections, where voters rank candidates based on their preferences, the Single Transferable Vote (STV) is the most widely used proportional voting method. STV is considered proportional because it satisfies an axiom requiring that large enough solid coalitions of voters are adequately represented. Using real-world data from local Scottish elections, we observe that solid coalitions of the required size rarely occur in practice. This observation challenges the importance of proportionality axioms and raises the question of how the proportionality of voting methods can be assessed beyond their axiomatic performance. We address these concerns by developing quantitative measures of proportionality. We apply these measures to evaluate the proportionality of voting rules on real-world election data. Besides STV, we consider SNTV, the Expanding Approvals Rule, and Sequential Ranked-Choice Voting. We also study the effects of ballot truncation by artificially completing truncated ballots and comparing the proportionality of outcomes under complete and truncated ballots.","sentences":["Proportional representation plays a crucial role in electoral systems.","In ordinal elections, where voters rank candidates based on their preferences, the Single Transferable Vote (STV) is the most widely used proportional voting method.","STV is considered proportional because it satisfies an axiom requiring that large enough solid coalitions of voters are adequately represented.","Using real-world data from local Scottish elections, we observe that solid coalitions of the required size rarely occur in practice.","This observation challenges the importance of proportionality axioms and raises the question of how the proportionality of voting methods can be assessed beyond their axiomatic performance.","We address these concerns by developing quantitative measures of proportionality.","We apply these measures to evaluate the proportionality of voting rules on real-world election data.","Besides STV, we consider SNTV, the Expanding Approvals Rule, and Sequential Ranked-Choice Voting.","We also study the effects of ballot truncation by artificially completing truncated ballots and comparing the proportionality of outcomes under complete and truncated ballots."],"url":"http://arxiv.org/abs/2505.00520v1"}
{"created":"2025-05-01 13:33:34","title":"Safety-Critical Traffic Simulation with Guided Latent Diffusion Model","abstract":"Safety-critical traffic simulation plays a crucial role in evaluating autonomous driving systems under rare and challenging scenarios. However, existing approaches often generate unrealistic scenarios due to insufficient consideration of physical plausibility and suffer from low generation efficiency. To address these limitations, we propose a guided latent diffusion model (LDM) capable of generating physically realistic and adversarial safety-critical traffic scenarios. Specifically, our model employs a graph-based variational autoencoder (VAE) to learn a compact latent space that captures complex multi-agent interactions while improving computational efficiency. Within this latent space, the diffusion model performs the denoising process to produce realistic trajectories. To enable controllable and adversarial scenario generation, we introduce novel guidance objectives that drive the diffusion process toward producing adversarial and behaviorally realistic driving behaviors. Furthermore, we develop a sample selection module based on physical feasibility checks to further enhance the physical plausibility of the generated scenarios. Extensive experiments on the nuScenes dataset demonstrate that our method achieves superior adversarial effectiveness and generation efficiency compared to existing baselines while maintaining a high level of realism. Our work provides an effective tool for realistic safety-critical scenario simulation, paving the way for more robust evaluation of autonomous driving systems.","sentences":["Safety-critical traffic simulation plays a crucial role in evaluating autonomous driving systems under rare and challenging scenarios.","However, existing approaches often generate unrealistic scenarios due to insufficient consideration of physical plausibility and suffer from low generation efficiency.","To address these limitations, we propose a guided latent diffusion model (LDM) capable of generating physically realistic and adversarial safety-critical traffic scenarios.","Specifically, our model employs a graph-based variational autoencoder (VAE) to learn a compact latent space that captures complex multi-agent interactions while improving computational efficiency.","Within this latent space, the diffusion model performs the denoising process to produce realistic trajectories.","To enable controllable and adversarial scenario generation, we introduce novel guidance objectives that drive the diffusion process toward producing adversarial and behaviorally realistic driving behaviors.","Furthermore, we develop a sample selection module based on physical feasibility checks to further enhance the physical plausibility of the generated scenarios.","Extensive experiments on the nuScenes dataset demonstrate that our method achieves superior adversarial effectiveness and generation efficiency compared to existing baselines while maintaining a high level of realism.","Our work provides an effective tool for realistic safety-critical scenario simulation, paving the way for more robust evaluation of autonomous driving systems."],"url":"http://arxiv.org/abs/2505.00515v1"}
{"created":"2025-05-01 13:30:28","title":"InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method","abstract":"Intersections are geometric and functional key points in every road network. They offer strong landmarks to correct GNSS dropouts and anchor new sensor data in up-to-date maps. Despite that importance, intersection detectors either ignore the rich semantic information already computed onboard or depend on scarce, hand-labeled intersection datasets. To close that gap, this paper presents a LiDAR-based method for intersection detection that (i) fuses semantic road segmentation with vehicle localization to detect intersection candidates in a bird's eye view (BEV) representation and (ii) refines those candidates by analyzing branch topology with a least squares formulation. To evaluate our method, we introduce an automated benchmarking pipeline that pairs detections with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS ground-truth poses. Tested on eight SemanticKITTI sequences, the approach achieves a mean localization error of 1.9 m, 89% precision, and 77% recall at a 5 m tolerance, outperforming the latest learning-based baseline. Moreover, the method is robust to segmentation errors higher than those of the benchmark model, demonstrating its applicability in the real world.","sentences":["Intersections are geometric and functional key points in every road network.","They offer strong landmarks to correct GNSS dropouts and anchor new sensor data in up-to-date maps.","Despite that importance, intersection detectors either ignore the rich semantic information already computed onboard or depend on scarce, hand-labeled intersection datasets.","To close that gap, this paper presents a LiDAR-based method for intersection detection that (i) fuses semantic road segmentation with vehicle localization to detect intersection candidates in a bird's eye view (BEV) representation and (ii) refines those candidates by analyzing branch topology with a least squares formulation.","To evaluate our method, we introduce an automated benchmarking pipeline that pairs detections with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS ground-truth poses.","Tested on eight SemanticKITTI sequences, the approach achieves a mean localization error of 1.9 m, 89% precision, and 77% recall at a 5 m tolerance, outperforming the latest learning-based baseline.","Moreover, the method is robust to segmentation errors higher than those of the benchmark model, demonstrating its applicability in the real world."],"url":"http://arxiv.org/abs/2505.00512v1"}
{"created":"2025-05-01 13:29:56","title":"Inconsistency-based Active Learning for LiDAR Object Detection","abstract":"Deep learning models for object detection in autonomous driving have recently achieved impressive performance gains and are already being deployed in vehicles worldwide. However, current models require increasingly large datasets for training. Acquiring and labeling such data is costly, necessitating the development of new strategies to optimize this process. Active learning is a promising approach that has been extensively researched in the image domain. In our work, we extend this concept to the LiDAR domain by developing several inconsistency-based sample selection strategies and evaluate their effectiveness in various settings. Our results show that using a naive inconsistency approach based on the number of detected boxes, we achieve the same mAP as the random sampling strategy with 50% of the labeled data.","sentences":["Deep learning models for object detection in autonomous driving have recently achieved impressive performance gains and are already being deployed in vehicles worldwide.","However, current models require increasingly large datasets for training.","Acquiring and labeling such data is costly, necessitating the development of new strategies to optimize this process.","Active learning is a promising approach that has been extensively researched in the image domain.","In our work, we extend this concept to the LiDAR domain by developing several inconsistency-based sample selection strategies and evaluate their effectiveness in various settings.","Our results show that using a naive inconsistency approach based on the number of detected boxes, we achieve the same mAP as the random sampling strategy with 50% of the labeled data."],"url":"http://arxiv.org/abs/2505.00511v1"}
{"created":"2025-05-01 13:25:37","title":"Self-Ablating Transformers: More Interpretability, Less Sparsity","abstract":"A growing intuition in machine learning suggests a link between sparsity and interpretability. We introduce a novel self-ablation mechanism to investigate this connection ante-hoc in the context of language transformers. Our approach dynamically enforces a k-winner-takes-all constraint, forcing the model to demonstrate selective activation across neuron and attention units. Unlike post-hoc methods that analyze already-trained models, our approach integrates interpretability directly into model training, promoting feature localization from inception. Training small models on the TinyStories dataset and employing interpretability tests, we find that self-ablation leads to more localized circuits, concentrated feature representations, and increased neuron specialization without compromising language modelling performance. Surprisingly, our method also decreased overall sparsity, indicating that self-ablation promotes specialization rather than widespread inactivity. This reveals a complex interplay between sparsity and interpretability, where decreased global sparsity can coexist with increased local specialization, leading to enhanced interpretability. To facilitate reproducibility, we make our code available at https://github.com/keenanpepper/self-ablating-transformers.","sentences":["A growing intuition in machine learning suggests a link between sparsity and interpretability.","We introduce a novel self-ablation mechanism to investigate this connection ante-hoc in the context of language transformers.","Our approach dynamically enforces a k-winner-takes-all constraint, forcing the model to demonstrate selective activation across neuron and attention units.","Unlike post-hoc methods that analyze already-trained models, our approach integrates interpretability directly into model training, promoting feature localization from inception.","Training small models on the TinyStories dataset and employing interpretability tests, we find that self-ablation leads to more localized circuits, concentrated feature representations, and increased neuron specialization without compromising language modelling performance.","Surprisingly, our method also decreased overall sparsity, indicating that self-ablation promotes specialization rather than widespread inactivity.","This reveals a complex interplay between sparsity and interpretability, where decreased global sparsity can coexist with increased local specialization, leading to enhanced interpretability.","To facilitate reproducibility, we make our code available at https://github.com/keenanpepper/self-ablating-transformers."],"url":"http://arxiv.org/abs/2505.00509v1"}
{"created":"2025-05-01 13:24:55","title":"HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection","abstract":"Active Learning has proved to be a relevant approach to perform sample selection for training models for Autonomous Driving. Particularly, previous works on active learning for 3D object detection have shown that selection of samples in uncontrolled scenarios is challenging. Furthermore, current approaches focus exclusively on the theoretical aspects of the sample selection problem but neglect the practical insights that can be obtained from the extensive literature and application of 3D detection models. In this paper, we introduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection) which integrates those heuristical features together with Localization and Classification to deliver the most contributing samples to the model's training. In contrast to previous works, our approach integrates heuristical features such as object distance and point-quantity to estimate the uncertainty, which enhance the usefulness of selected samples to train detection models. Our quantitative evaluation on KITTI shows that HeAL presents competitive mAP with respect to the State-of-the-Art, and achieves the same mAP as the full-supervised baseline with only 24% of the samples.","sentences":["Active Learning has proved to be a relevant approach to perform sample selection for training models for Autonomous Driving.","Particularly, previous works on active learning for 3D object detection have shown that selection of samples in uncontrolled scenarios is challenging.","Furthermore, current approaches focus exclusively on the theoretical aspects of the sample selection problem but neglect the practical insights that can be obtained from the extensive literature and application of 3D detection models.","In this paper, we introduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection) which integrates those heuristical features together with Localization and Classification to deliver the most contributing samples to the model's training.","In contrast to previous works, our approach integrates heuristical features such as object distance and point-quantity to estimate the uncertainty, which enhance the usefulness of selected samples to train detection models.","Our quantitative evaluation on KITTI shows that HeAL presents competitive mAP with respect to the State-of-the-Art, and achieves the same mAP as the full-supervised baseline with only 24% of the samples."],"url":"http://arxiv.org/abs/2505.00507v1"}
{"created":"2025-05-01 13:22:45","title":"HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection","abstract":"As large language models (LLMs) are increasingly deployed in high-stakes domains, detecting hallucinated content$\\unicode{x2013}$text that is not grounded in supporting evidence$\\unicode{x2013}$has become a critical challenge. Existing benchmarks for hallucination detection are often synthetically generated, narrowly focused on extractive question answering, and fail to capture the complexity of real-world scenarios involving multi-document contexts and full-sentence outputs. We introduce the HalluMix Benchmark, a diverse, task-agnostic dataset that includes examples from a range of domains and formats. Using this benchmark, we evaluate seven hallucination detection systems$\\unicode{x2013}$both open and closed source$\\unicode{x2013}$highlighting differences in performance across tasks, document lengths, and input representations. Our analysis highlights substantial performance disparities between short and long contexts, with critical implications for real-world Retrieval Augmented Generation (RAG) implementations. Quotient Detections achieves the best overall performance, with an accuracy of 0.82 and an F1 score of 0.84.","sentences":["As large language models (LLMs) are increasingly deployed in high-stakes domains, detecting hallucinated content$\\unicode{x2013}$text that is not grounded in supporting evidence$\\unicode{x2013}$has become a critical challenge.","Existing benchmarks for hallucination detection are often synthetically generated, narrowly focused on extractive question answering, and fail to capture the complexity of real-world scenarios involving multi-document contexts and full-sentence outputs.","We introduce the HalluMix Benchmark, a diverse, task-agnostic dataset that includes examples from a range of domains and formats.","Using this benchmark, we evaluate seven hallucination detection systems$\\unicode{x2013}$both open and closed source$\\unicode{x2013}$highlighting differences in performance across tasks, document lengths, and input representations.","Our analysis highlights substantial performance disparities between short and long contexts, with critical implications for real-world Retrieval Augmented Generation (RAG) implementations.","Quotient Detections achieves the best overall performance, with an accuracy of 0.82 and an F1 score of 0.84."],"url":"http://arxiv.org/abs/2505.00506v1"}
{"created":"2025-05-01 13:14:07","title":"Variational OOD State Correction for Offline Reinforcement Learning","abstract":"The performance of Offline reinforcement learning is significantly impacted by the issue of state distributional shift, and out-of-distribution (OOD) state correction is a popular approach to address this problem. In this paper, we propose a novel method named Density-Aware Safety Perception (DASP) for OOD state correction. Specifically, our method encourages the agent to prioritize actions that lead to outcomes with higher data density, thereby promoting its operation within or the return to in-distribution (safe) regions. To achieve this, we optimize the objective within a variational framework that concurrently considers both the potential outcomes of decision-making and their density, thus providing crucial contextual information for safe decision-making. Finally, we validate the effectiveness and feasibility of our proposed method through extensive experimental evaluations on the offline MuJoCo and AntMaze suites.","sentences":["The performance of Offline reinforcement learning is significantly impacted by the issue of state distributional shift, and out-of-distribution (OOD) state correction is a popular approach to address this problem.","In this paper, we propose a novel method named Density-Aware Safety Perception (DASP) for OOD state correction.","Specifically, our method encourages the agent to prioritize actions that lead to outcomes with higher data density, thereby promoting its operation within or the return to in-distribution (safe) regions.","To achieve this, we optimize the objective within a variational framework that concurrently considers both the potential outcomes of decision-making and their density, thus providing crucial contextual information for safe decision-making.","Finally, we validate the effectiveness and feasibility of our proposed method through extensive experimental evaluations on the offline MuJoCo and AntMaze suites."],"url":"http://arxiv.org/abs/2505.00503v1"}
{"created":"2025-05-01 13:06:05","title":"Towards Scalable Human-aligned Benchmark for Text-guided Image Editing","abstract":"A variety of text-guided image editing models have been proposed recently. However, there is no widely-accepted standard evaluation method mainly due to the subjective nature of the task, letting researchers rely on manual user study. To address this, we introduce a novel Human-Aligned benchmark for Text-guided Image Editing (HATIE). Providing a large-scale benchmark set covering a wide range of editing tasks, it allows reliable evaluation, not limited to specific easy-to-evaluate cases. Also, HATIE provides a fully-automated and omnidirectional evaluation pipeline. Particularly, we combine multiple scores measuring various aspects of editing so as to align with human perception. We empirically verify that the evaluation of HATIE is indeed human-aligned in various aspects, and provide benchmark results on several state-of-the-art models to provide deeper insights on their performance.","sentences":["A variety of text-guided image editing models have been proposed recently.","However, there is no widely-accepted standard evaluation method mainly due to the subjective nature of the task, letting researchers rely on manual user study.","To address this, we introduce a novel Human-Aligned benchmark for Text-guided Image Editing (HATIE).","Providing a large-scale benchmark set covering a wide range of editing tasks, it allows reliable evaluation, not limited to specific easy-to-evaluate cases.","Also, HATIE provides a fully-automated and omnidirectional evaluation pipeline.","Particularly, we combine multiple scores measuring various aspects of editing so as to align with human perception.","We empirically verify that the evaluation of HATIE is indeed human-aligned in various aspects, and provide benchmark results on several state-of-the-art models to provide deeper insights on their performance."],"url":"http://arxiv.org/abs/2505.00502v1"}
{"created":"2025-05-01 13:00:56","title":"Implicit Neural-Representation Learning for Elastic Deformable-Object Manipulations","abstract":"We aim to solve the problem of manipulating deformable objects, particularly elastic bands, in real-world scenarios. However, deformable object manipulation (DOM) requires a policy that works on a large state space due to the unlimited degree of freedom (DoF) of deformable objects. Further, their dense but partial observations (e.g., images or point clouds) may increase the sampling complexity and uncertainty in policy learning. To figure it out, we propose a novel implicit neural-representation (INR) learning for elastic DOMs, called INR-DOM. Our method learns consistent state representations associated with partially observable elastic objects reconstructing a complete and implicit surface represented as a signed distance function. Furthermore, we perform exploratory representation fine-tuning through reinforcement learning (RL) that enables RL algorithms to effectively learn exploitable representations while efficiently obtaining a DOM policy. We perform quantitative and qualitative analyses building three simulated environments and real-world manipulation studies with a Franka Emika Panda arm. Videos are available at http://inr-dom.github.io.","sentences":["We aim to solve the problem of manipulating deformable objects, particularly elastic bands, in real-world scenarios.","However, deformable object manipulation (DOM) requires a policy that works on a large state space due to the unlimited degree of freedom (DoF) of deformable objects.","Further, their dense but partial observations (e.g., images or point clouds) may increase the sampling complexity and uncertainty in policy learning.","To figure it out, we propose a novel implicit neural-representation (INR) learning for elastic DOMs, called INR-DOM.","Our method learns consistent state representations associated with partially observable elastic objects reconstructing a complete and implicit surface represented as a signed distance function.","Furthermore, we perform exploratory representation fine-tuning through reinforcement learning (RL) that enables RL algorithms to effectively learn exploitable representations while efficiently obtaining a DOM policy.","We perform quantitative and qualitative analyses building three simulated environments and real-world manipulation studies with a Franka Emika Panda arm.","Videos are available at http://inr-dom.github.io."],"url":"http://arxiv.org/abs/2505.00500v1"}

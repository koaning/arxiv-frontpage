{"created":"2025-05-07 17:59:46","title":"PrimitiveAnything: Human-Crafted 3D Primitive Assembly Generation with Auto-Regressive Transformer","abstract":"Shape primitive abstraction, which decomposes complex 3D shapes into simple geometric elements, plays a crucial role in human visual cognition and has broad applications in computer vision and graphics. While recent advances in 3D content generation have shown remarkable progress, existing primitive abstraction methods either rely on geometric optimization with limited semantic understanding or learn from small-scale, category-specific datasets, struggling to generalize across diverse shape categories. We present PrimitiveAnything, a novel framework that reformulates shape primitive abstraction as a primitive assembly generation task. PrimitiveAnything includes a shape-conditioned primitive transformer for auto-regressive generation and an ambiguity-free parameterization scheme to represent multiple types of primitives in a unified manner. The proposed framework directly learns the process of primitive assembly from large-scale human-crafted abstractions, enabling it to capture how humans decompose complex shapes into primitive elements. Through extensive experiments, we demonstrate that PrimitiveAnything can generate high-quality primitive assemblies that better align with human perception while maintaining geometric fidelity across diverse shape categories. It benefits various 3D applications and shows potential for enabling primitive-based user-generated content (UGC) in games. Project page: https://primitiveanything.github.io","sentences":["Shape primitive abstraction, which decomposes complex 3D shapes into simple geometric elements, plays a crucial role in human visual cognition and has broad applications in computer vision and graphics.","While recent advances in 3D content generation have shown remarkable progress, existing primitive abstraction methods either rely on geometric optimization with limited semantic understanding or learn from small-scale, category-specific datasets, struggling to generalize across diverse shape categories.","We present PrimitiveAnything, a novel framework that reformulates shape primitive abstraction as a primitive assembly generation task.","PrimitiveAnything includes a shape-conditioned primitive transformer for auto-regressive generation and an ambiguity-free parameterization scheme to represent multiple types of primitives in a unified manner.","The proposed framework directly learns the process of primitive assembly from large-scale human-crafted abstractions, enabling it to capture how humans decompose complex shapes into primitive elements.","Through extensive experiments, we demonstrate that PrimitiveAnything can generate high-quality primitive assemblies that better align with human perception while maintaining geometric fidelity across diverse shape categories.","It benefits various 3D applications and shows potential for enabling primitive-based user-generated content (UGC) in games.","Project page: https://primitiveanything.github.io"],"url":"http://arxiv.org/abs/2505.04622v1"}
{"created":"2025-05-07 17:59:38","title":"Score Distillation Sampling for Audio: Source Separation, Synthesis, and Beyond","abstract":"We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS) to text-conditioned audio diffusion models. While SDS was initially designed for text-to-3D generation using image diffusion, its core idea of distilling a powerful generative prior into a separate parametric representation extends to the audio domain. Leveraging a single pretrained model, Audio-SDS enables a broad range of tasks without requiring specialized datasets. In particular, we demonstrate how Audio-SDS can guide physically informed impact sound simulations, calibrate FM-synthesis parameters, and perform prompt-specified source separation. Our findings illustrate the versatility of distillation-based methods across modalities and establish a robust foundation for future work using generative priors in audio tasks.","sentences":["We introduce Audio-SDS, a generalization of Score Distillation Sampling (SDS) to text-conditioned audio diffusion models.","While SDS was initially designed for text-to-3D generation using image diffusion, its core idea of distilling a powerful generative prior into a separate parametric representation extends to the audio domain.","Leveraging a single pretrained model, Audio-SDS enables a broad range of tasks without requiring specialized datasets.","In particular, we demonstrate how Audio-SDS can guide physically informed impact sound simulations, calibrate FM-synthesis parameters, and perform prompt-specified source separation.","Our findings illustrate the versatility of distillation-based methods across modalities and establish a robust foundation for future work using generative priors in audio tasks."],"url":"http://arxiv.org/abs/2505.04621v1"}
{"created":"2025-05-07 17:59:32","title":"On Path to Multimodal Generalist: General-Level and General-Bench","abstract":"The Multimodal Large Language Model (MLLM) is currently experiencing rapid growth, driven by the advanced capabilities of LLMs. Unlike earlier specialists, existing MLLMs are evolving towards a Multimodal Generalist paradigm. Initially limited to understanding multiple modalities, these models have advanced to not only comprehend but also generate across modalities. Their capabilities have expanded from coarse-grained to fine-grained multimodal understanding and from supporting limited modalities to arbitrary ones. While many benchmarks exist to assess MLLMs, a critical question arises: Can we simply assume that higher performance across tasks indicates a stronger MLLM capability, bringing us closer to human-level AI? We argue that the answer is not as straightforward as it seems. This project introduces General-Level, an evaluation framework that defines 5-scale levels of MLLM performance and generality, offering a methodology to compare MLLMs and gauge the progress of existing systems towards more robust multimodal generalists and, ultimately, towards AGI. At the core of the framework is the concept of Synergy, which measures whether models maintain consistent capabilities across comprehension and generation, and across multiple modalities. To support this evaluation, we present General-Bench, which encompasses a broader spectrum of skills, modalities, formats, and capabilities, including over 700 tasks and 325,800 instances. The evaluation results that involve over 100 existing state-of-the-art MLLMs uncover the capability rankings of generalists, highlighting the challenges in reaching genuine AI. We expect this project to pave the way for future research on next-generation multimodal foundation models, providing a robust infrastructure to accelerate the realization of AGI. Project page: https://generalist.top/","sentences":["The Multimodal Large Language Model (MLLM) is currently experiencing rapid growth, driven by the advanced capabilities of LLMs.","Unlike earlier specialists, existing MLLMs are evolving towards a Multimodal Generalist paradigm.","Initially limited to understanding multiple modalities, these models have advanced to not only comprehend but also generate across modalities.","Their capabilities have expanded from coarse-grained to fine-grained multimodal understanding and from supporting limited modalities to arbitrary ones.","While many benchmarks exist to assess MLLMs, a critical question arises: Can we simply assume that higher performance across tasks indicates a stronger MLLM capability, bringing us closer to human-level AI?","We argue that the answer is not as straightforward as it seems.","This project introduces General-Level, an evaluation framework that defines 5-scale levels of MLLM performance and generality, offering a methodology to compare MLLMs and gauge the progress of existing systems towards more robust multimodal generalists and, ultimately, towards AGI.","At the core of the framework is the concept of Synergy, which measures whether models maintain consistent capabilities across comprehension and generation, and across multiple modalities.","To support this evaluation, we present General-Bench, which encompasses a broader spectrum of skills, modalities, formats, and capabilities, including over 700 tasks and 325,800 instances.","The evaluation results that involve over 100 existing state-of-the-art MLLMs uncover the capability rankings of generalists, highlighting the challenges in reaching genuine AI.","We expect this project to pave the way for future research on next-generation multimodal foundation models, providing a robust infrastructure to accelerate the realization of AGI.","Project page: https://generalist.top/"],"url":"http://arxiv.org/abs/2505.04620v1"}
{"created":"2025-05-07 17:59:28","title":"Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation","abstract":"Vision is well-known for its use in manipulation, especially using visual servoing. To make it robust, multiple cameras are needed to expand the field of view. That is computationally challenging. Merging multiple views and using Q-learning allows the design of more effective representations and optimization of sample efficiency. Such a solution might be expensive to deploy. To mitigate this, we introduce a Merge And Disentanglement (MAD) algorithm that efficiently merges views to increase sample efficiency while augmenting with single-view features to allow lightweight deployment and ensure robust policies. We demonstrate the efficiency and robustness of our approach using Meta-World and ManiSkill3. For project website and code, see https://aalmuzairee.github.io/mad","sentences":["Vision is well-known for its use in manipulation, especially using visual servoing.","To make it robust, multiple cameras are needed to expand the field of view.","That is computationally challenging.","Merging multiple views and using Q-learning allows the design of more effective representations and optimization of sample efficiency.","Such a solution might be expensive to deploy.","To mitigate this, we introduce a Merge And Disentanglement (MAD) algorithm that efficiently merges views to increase sample efficiency while augmenting with single-view features to allow lightweight deployment and ensure robust policies.","We demonstrate the efficiency and robustness of our approach using Meta-World and ManiSkill3.","For project website and code, see https://aalmuzairee.github.io/mad"],"url":"http://arxiv.org/abs/2505.04619v1"}
{"created":"2025-05-07 17:58:58","title":"Report on Nearest Dominating Point Queries","abstract":"Given two points $p, q \\in \\mathbb R^d$, we say that $p$ dominates $q$ and write $p \\succ q$ if each coordinate of $p$ is larger than the corresponding coordinate of $q$. That is, if $p = (p^{(1)}, p^{(2)}, \\ldots, p^{(d)})$ and $q = (q^{(1)}, q^{(2)}, \\ldots, q^{(d)})$, $p \\succ q$ if and only if $p^{(i)} > q^{(i)}$ for all $1 \\le i \\le d$.   For example, $p$ and $q$ could represent various ratings for $2$ restaurants, based on different metrics like taste, affordability, ratings on different platforms, et cetera. $p \\succ q$ then means that the first restaurant outperformed the second on each metric.   Given a list of restaurants and their rating, we solve the problem of determining, for each restaurant, the closest restaurant to it that dominates it. We improve upon the algorithm under some assumptions towards the end.","sentences":["Given two points $p, q \\in \\mathbb R^d$, we say that $p$ dominates $q$ and write $p \\succ q$ if each coordinate of $p$ is larger than the corresponding coordinate of $q$. That is, if $p = (p^{(1)}, p^{(2)}, \\ldots, p^{(d)})$ and $q = (q^{(1)}, q^{(2)}, \\ldots, q^{(d)})$, $p \\succ q$ if and only if $p^{(i)} > q^{(i)}$ for all $1 \\le i \\le d$.   For example, $p$ and $q$ could represent various ratings for $2$ restaurants, based on different metrics like taste, affordability, ratings on different platforms, et cetera.","$p \\succ q$ then means that the first restaurant outperformed the second on each metric.   ","Given a list of restaurants and their rating, we solve the problem of determining, for each restaurant, the closest restaurant to it that dominates it.","We improve upon the algorithm under some assumptions towards the end."],"url":"http://arxiv.org/abs/2505.04617v1"}
{"created":"2025-05-07 17:58:25","title":"Person Recognition at Altitude and Range: Fusion of Face, Body Shape and Gait","abstract":"We address the problem of whole-body person recognition in unconstrained environments. This problem arises in surveillance scenarios such as those in the IARPA Biometric Recognition and Identification at Altitude and Range (BRIAR) program, where biometric data is captured at long standoff distances, elevated viewing angles, and under adverse atmospheric conditions (e.g., turbulence and high wind velocity). To this end, we propose FarSight, a unified end-to-end system for person recognition that integrates complementary biometric cues across face, gait, and body shape modalities. FarSight incorporates novel algorithms across four core modules: multi-subject detection and tracking, recognition-aware video restoration, modality-specific biometric feature encoding, and quality-guided multi-modal fusion. These components are designed to work cohesively under degraded image conditions, large pose and scale variations, and cross-domain gaps. Extensive experiments on the BRIAR dataset, one of the most comprehensive benchmarks for long-range, multi-modal biometric recognition, demonstrate the effectiveness of FarSight. Compared to our preliminary system, this system achieves a 34.1% absolute gain in 1:1 verification accuracy (TAR@0.1% FAR), a 17.8% increase in closed-set identification (Rank-20), and a 34.3% reduction in open-set identification errors (FNIR@1% FPIR). Furthermore, FarSight was evaluated in the 2025 NIST RTE Face in Video Evaluation (FIVE), which conducts standardized face recognition testing on the BRIAR dataset. These results establish FarSight as a state-of-the-art solution for operational biometric recognition in challenging real-world conditions.","sentences":["We address the problem of whole-body person recognition in unconstrained environments.","This problem arises in surveillance scenarios such as those in the IARPA Biometric Recognition and Identification at Altitude and Range (BRIAR) program, where biometric data is captured at long standoff distances, elevated viewing angles, and under adverse atmospheric conditions (e.g., turbulence and high wind velocity).","To this end, we propose FarSight, a unified end-to-end system for person recognition that integrates complementary biometric cues across face, gait, and body shape modalities.","FarSight incorporates novel algorithms across four core modules: multi-subject detection and tracking, recognition-aware video restoration, modality-specific biometric feature encoding, and quality-guided multi-modal fusion.","These components are designed to work cohesively under degraded image conditions, large pose and scale variations, and cross-domain gaps.","Extensive experiments on the BRIAR dataset, one of the most comprehensive benchmarks for long-range, multi-modal biometric recognition, demonstrate the effectiveness of FarSight.","Compared to our preliminary system, this system achieves a 34.1% absolute gain in 1:1 verification accuracy (TAR@0.1% FAR), a 17.8% increase in closed-set identification (Rank-20), and a 34.3% reduction in open-set identification errors (FNIR@1% FPIR).","Furthermore, FarSight was evaluated in the 2025 NIST RTE Face in Video Evaluation (FIVE), which conducts standardized face recognition testing on the BRIAR dataset.","These results establish FarSight as a state-of-the-art solution for operational biometric recognition in challenging real-world conditions."],"url":"http://arxiv.org/abs/2505.04616v1"}
{"created":"2025-05-07 17:56:15","title":"FastMap: Revisiting Dense and Scalable Structure from Motion","abstract":"We propose FastMap, a new global structure from motion method focused on speed and simplicity. Previous methods like COLMAP and GLOMAP are able to estimate high-precision camera poses, but suffer from poor scalability when the number of matched keypoint pairs becomes large. We identify two key factors leading to this problem: poor parallelization and computationally expensive optimization steps. To overcome these issues, we design an SfM framework that relies entirely on GPU-friendly operations, making it easily parallelizable. Moreover, each optimization step runs in time linear to the number of image pairs, independent of keypoint pairs or 3D points. Through extensive experiments, we show that FastMap is one to two orders of magnitude faster than COLMAP and GLOMAP on large-scale scenes with comparable pose accuracy.","sentences":["We propose FastMap, a new global structure from motion method focused on speed and simplicity.","Previous methods like COLMAP and GLOMAP are able to estimate high-precision camera poses, but suffer from poor scalability when the number of matched keypoint pairs becomes large.","We identify two key factors leading to this problem: poor parallelization and computationally expensive optimization steps.","To overcome these issues, we design an SfM framework that relies entirely on GPU-friendly operations, making it easily parallelizable.","Moreover, each optimization step runs in time linear to the number of image pairs, independent of keypoint pairs or 3D points.","Through extensive experiments, we show that FastMap is one to two orders of magnitude faster than COLMAP and GLOMAP on large-scale scenes with comparable pose accuracy."],"url":"http://arxiv.org/abs/2505.04612v1"}
{"created":"2025-05-07 17:53:47","title":"WATCH: Weighted Adaptive Testing for Changepoint Hypotheses via Weighted-Conformal Martingales","abstract":"Responsibly deploying artificial intelligence (AI) / machine learning (ML) systems in high-stakes settings arguably requires not only proof of system reliability, but moreover continual, post-deployment monitoring to quickly detect and address any unsafe behavior. Statistical methods for nonparametric change-point detection -- especially the tools of conformal test martingales (CTMs) and anytime-valid inference -- offer promising approaches to this monitoring task. However, existing methods are restricted to monitoring limited hypothesis classes or ``alarm criteria,'' such as data shifts that violate certain exchangeability assumptions, or do not allow for online adaptation in response to shifts. In this paper, we expand the scope of these monitoring methods by proposing a weighted generalization of conformal test martingales (WCTMs), which lay a theoretical foundation for online monitoring for any unexpected changepoints in the data distribution while controlling false-alarms. For practical applications, we propose specific WCTM algorithms that accommodate online adaptation to mild covariate shifts (in the marginal input distribution) while raising alarms in response to more severe shifts, such as concept shifts (in the conditional label distribution) or extreme (out-of-support) covariate shifts that cannot be easily adapted to. On real-world datasets, we demonstrate improved performance relative to state-of-the-art baselines.","sentences":["Responsibly deploying artificial intelligence (AI) / machine learning (ML) systems in high-stakes settings arguably requires not only proof of system reliability, but moreover continual, post-deployment monitoring to quickly detect and address any unsafe behavior.","Statistical methods for nonparametric change-point detection -- especially the tools of conformal test martingales (CTMs) and anytime-valid inference -- offer promising approaches to this monitoring task.","However, existing methods are restricted to monitoring limited hypothesis classes or ``alarm criteria,'' such as data shifts that violate certain exchangeability assumptions, or do not allow for online adaptation in response to shifts.","In this paper, we expand the scope of these monitoring methods by proposing a weighted generalization of conformal test martingales (WCTMs), which lay a theoretical foundation for online monitoring for any unexpected changepoints in the data distribution while controlling false-alarms.","For practical applications, we propose specific WCTM algorithms that accommodate online adaptation to mild covariate shifts (in the marginal input distribution) while raising alarms in response to more severe shifts, such as concept shifts (in the conditional label distribution) or extreme (out-of-support) covariate shifts that cannot be easily adapted to.","On real-world datasets, we demonstrate improved performance relative to state-of-the-art baselines."],"url":"http://arxiv.org/abs/2505.04608v1"}
{"created":"2025-05-07 17:51:10","title":"OmniGIRL: A Multilingual and Multimodal Benchmark for GitHub Issue Resolution","abstract":"The GitHub issue resolution task aims to resolve issues reported in repositories automatically. With advances in large language models (LLMs), this task has gained increasing attention, and several benchmarks are proposed to evaluate the issue resolution ability of LLMs. However, existing benchmarks have three main limitations. First, current benchmarks focus on a single programming language, limiting the evaluation of issues from repositories across different languages. Second, they usually cover a narrow range of domains, which may fail to represent the diversity of real-world issues. Third, existing benchmarks rely solely on textual information in issue descriptions, overlooking multimodal information such as images in issues. In this paper, we propose OmniGIRL, a GitHub Issue ResoLution benchmark that is multilingual, multimodal, and multi-domain. OmniGIRL includes 959 task instances, which are collected from repositories across four programming languages (i.e., Python, JavaScript, TypeScript, and Java) and eight different domains. Our evaluation shows that current LLMs show limited performances on OmniGIRL. Notably, the best-performing model, GPT-4o, resolves only 8.6% of the issues. Besides, we find that current LLMs struggle to resolve issues requiring understanding images. The best performance is achieved by Claude-3.5-Sonnet, which resolves only 10.5% of the issues with image information. Finally, we analyze the reasons behind current LLMs' failure on OmniGIRL, providing insights for future improvements.","sentences":["The GitHub issue resolution task aims to resolve issues reported in repositories automatically.","With advances in large language models (LLMs), this task has gained increasing attention, and several benchmarks are proposed to evaluate the issue resolution ability of LLMs.","However, existing benchmarks have three main limitations.","First, current benchmarks focus on a single programming language, limiting the evaluation of issues from repositories across different languages.","Second, they usually cover a narrow range of domains, which may fail to represent the diversity of real-world issues.","Third, existing benchmarks rely solely on textual information in issue descriptions, overlooking multimodal information such as images in issues.","In this paper, we propose OmniGIRL, a GitHub Issue ResoLution benchmark that is multilingual, multimodal, and multi-domain.","OmniGIRL includes 959 task instances, which are collected from repositories across four programming languages (i.e., Python, JavaScript, TypeScript, and Java) and eight different domains.","Our evaluation shows that current LLMs show limited performances on OmniGIRL.","Notably, the best-performing model, GPT-4o, resolves only 8.6% of the issues.","Besides, we find that current LLMs struggle to resolve issues requiring understanding images.","The best performance is achieved by Claude-3.5-Sonnet, which resolves only 10.5% of the issues with image information.","Finally, we analyze the reasons behind current LLMs' failure on OmniGIRL, providing insights for future improvements."],"url":"http://arxiv.org/abs/2505.04606v1"}
{"created":"2025-05-07 17:50:15","title":"Testing Juntas Optimally with Samples","abstract":"We prove tight upper and lower bounds of $\\Theta\\left(\\tfrac{1}{\\epsilon}\\left( \\sqrt{2^k \\log\\binom{n}{k} } + \\log\\binom{n}{k} \\right)\\right)$ on the number of samples required for distribution-free $k$-junta testing. This is the first tight bound for testing a natural class of Boolean functions in the distribution-free sample-based model. Our bounds also hold for the feature selection problem, showing that a junta tester must learn the set of relevant variables. For tolerant junta testing, we prove a sample lower bound of $\\Omega(2^{(1-o(1)) k} + \\log\\binom{n}{k})$ showing that, unlike standard testing, there is no large gap between tolerant testing and learning.","sentences":["We prove tight upper and lower bounds of $\\Theta\\left(\\tfrac{1}{\\epsilon}\\left( \\sqrt{2^k \\log\\binom{n}{k} } + \\log\\binom{n}{k} \\right)\\right)$ on the number of samples required for distribution-free $k$-junta testing.","This is the first tight bound for testing a natural class of Boolean functions in the distribution-free sample-based model.","Our bounds also hold for the feature selection problem, showing that a junta tester must learn the set of relevant variables.","For tolerant junta testing, we prove a sample lower bound of $\\Omega(2^{(1-o(1))","k} + \\log\\binom{n}{k})$ showing that, unlike standard testing, there is no large gap between tolerant testing and learning."],"url":"http://arxiv.org/abs/2505.04604v1"}
{"created":"2025-05-07 17:48:35","title":"OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision Encoders for Multimodal Learning","abstract":"OpenAI's CLIP, released in early 2021, have long been the go-to choice of vision encoder for building multimodal foundation models. Although recent alternatives such as SigLIP have begun to challenge this status quo, to our knowledge none are fully open: their training data remains proprietary and/or their training recipes are not released. This paper fills this gap with OpenVision, a fully-open, cost-effective family of vision encoders that match or surpass the performance of OpenAI's CLIP when integrated into multimodal frameworks like LLaVA. OpenVision builds on existing works -- e.g., CLIPS for training framework and Recap-DataComp-1B for training data -- while revealing multiple key insights in enhancing encoder quality and showcasing practical benefits in advancing multimodal models. By releasing vision encoders spanning from 5.9M to 632.1M parameters, OpenVision offers practitioners a flexible trade-off between capacity and efficiency in building multimodal models: larger models deliver enhanced multimodal performance, while smaller versions enable lightweight, edge-ready multimodal deployments.","sentences":["OpenAI's CLIP, released in early 2021, have long been the go-to choice of vision encoder for building multimodal foundation models.","Although recent alternatives such as SigLIP have begun to challenge this status quo, to our knowledge none are fully open: their training data remains proprietary and/or their training recipes are not released.","This paper fills this gap with OpenVision, a fully-open, cost-effective family of vision encoders that match or surpass the performance of OpenAI's CLIP when integrated into multimodal frameworks like LLaVA.","OpenVision builds on existing works -- e.g., CLIPS for training framework and Recap-DataComp-1B for training data -- while revealing multiple key insights in enhancing encoder quality and showcasing practical benefits in advancing multimodal models.","By releasing vision encoders spanning from 5.9M to 632.1M parameters, OpenVision offers practitioners a flexible trade-off between capacity and efficiency in building multimodal models: larger models deliver enhanced multimodal performance, while smaller versions enable lightweight, edge-ready multimodal deployments."],"url":"http://arxiv.org/abs/2505.04601v1"}
{"created":"2025-05-07 17:43:52","title":"Perpetuating Misogyny with Generative AI: How Model Personalization Normalizes Gendered Harm","abstract":"Open-source text-to-image (TTI) pipelines have become dominant in the landscape of AI-generated visual content, driven by technological advances that enable users to personalize models through adapters tailored to specific tasks. While personalization methods such as LoRA offer unprecedented creative opportunities, they also facilitate harmful practices, including the generation of non-consensual deepfakes and the amplification of misogynistic or hypersexualized content. This study presents an exploratory sociotechnical analysis of CivitAI, the most active platform for sharing and developing open-source TTI models. Drawing on a dataset of more than 40 million user-generated images and over 230,000 models, we find a disproportionate rise in not-safe-for-work (NSFW) content and a significant number of models intended to mimic real individuals. We also observe a strong influence of internet subcultures on the tools and practices shaping model personalizations and resulting visual media. In response to these findings, we contextualize the emergence of exploitative visual media through feminist and constructivist perspectives on technology, emphasizing how design choices and community dynamics shape platform outcomes. Building on this analysis, we propose interventions aimed at mitigating downstream harm, including improved content moderation, rethinking tool design, and establishing clearer platform policies to promote accountability and consent.","sentences":["Open-source text-to-image (TTI) pipelines have become dominant in the landscape of AI-generated visual content, driven by technological advances that enable users to personalize models through adapters tailored to specific tasks.","While personalization methods such as LoRA offer unprecedented creative opportunities, they also facilitate harmful practices, including the generation of non-consensual deepfakes and the amplification of misogynistic or hypersexualized content.","This study presents an exploratory sociotechnical analysis of CivitAI, the most active platform for sharing and developing open-source TTI models.","Drawing on a dataset of more than 40 million user-generated images and over 230,000 models, we find a disproportionate rise in not-safe-for-work (NSFW) content and a significant number of models intended to mimic real individuals.","We also observe a strong influence of internet subcultures on the tools and practices shaping model personalizations and resulting visual media.","In response to these findings, we contextualize the emergence of exploitative visual media through feminist and constructivist perspectives on technology, emphasizing how design choices and community dynamics shape platform outcomes.","Building on this analysis, we propose interventions aimed at mitigating downstream harm, including improved content moderation, rethinking tool design, and establishing clearer platform policies to promote accountability and consent."],"url":"http://arxiv.org/abs/2505.04600v1"}
{"created":"2025-05-07 17:40:12","title":"Complexity Lower Bounds of Adaptive Gradient Algorithms for Non-convex Stochastic Optimization under Relaxed Smoothness","abstract":"Recent results in non-convex stochastic optimization demonstrate the convergence of popular adaptive algorithms (e.g., AdaGrad) under the $(L_0, L_1)$-smoothness condition, but the rate of convergence is a higher-order polynomial in terms of problem parameters like the smoothness constants. The complexity guaranteed by such algorithms to find an $\\epsilon$-stationary point may be significantly larger than the optimal complexity of $\\Theta \\left( \\Delta L \\sigma^2 \\epsilon^{-4} \\right)$ achieved by SGD in the $L$-smooth setting, where $\\Delta$ is the initial optimality gap, $\\sigma^2$ is the variance of stochastic gradient. However, it is currently not known whether these higher-order dependencies can be tightened. To answer this question, we investigate complexity lower bounds for several adaptive optimization algorithms in the $(L_0, L_1)$-smooth setting, with a focus on the dependence in terms of problem parameters $\\Delta, L_0, L_1$. We provide complexity bounds for three variations of AdaGrad, which show at least a quadratic dependence on problem parameters $\\Delta, L_0, L_1$. Notably, we show that the decorrelated variant of AdaGrad-Norm requires at least $\\Omega \\left( \\Delta^2 L_1^2 \\sigma^2 \\epsilon^{-4} \\right)$ stochastic gradient queries to find an $\\epsilon$-stationary point. We also provide a lower bound for SGD with a broad class of adaptive stepsizes. Our results show that, for certain adaptive algorithms, the $(L_0, L_1)$-smooth setting is fundamentally more difficult than the standard smooth setting, in terms of the initial optimality gap and the smoothness constants.","sentences":["Recent results in non-convex stochastic optimization demonstrate the convergence of popular adaptive algorithms (e.g., AdaGrad) under the $(L_0, L_1)$-smoothness condition, but the rate of convergence is a higher-order polynomial in terms of problem parameters like the smoothness constants.","The complexity guaranteed by such algorithms to find an $\\epsilon$-stationary point may be significantly larger than the optimal complexity of $\\Theta \\left( \\Delta L \\sigma^2 \\epsilon^{-4} \\right)$ achieved by SGD in the $L$-smooth setting, where $\\Delta$ is the initial optimality gap, $\\sigma^2$ is the variance of stochastic gradient.","However, it is currently not known whether these higher-order dependencies can be tightened.","To answer this question, we investigate complexity lower bounds for several adaptive optimization algorithms in the $(L_0, L_1)$-smooth setting, with a focus on the dependence in terms of problem parameters $\\Delta, L_0, L_1$. We provide complexity bounds for three variations of AdaGrad, which show at least a quadratic dependence on problem parameters $\\Delta, L_0, L_1$. Notably, we show that the decorrelated variant of AdaGrad-Norm requires at least $\\Omega \\left( \\Delta^2 L_1^2 \\sigma^2 \\epsilon^{-4} \\right)$ stochastic gradient queries to find an $\\epsilon$-stationary point.","We also provide a lower bound for SGD with a broad class of adaptive stepsizes.","Our results show that, for certain adaptive algorithms, the $(L_0, L_1)$-smooth setting is fundamentally more difficult than the standard smooth setting, in terms of the initial optimality gap and the smoothness constants."],"url":"http://arxiv.org/abs/2505.04599v1"}
{"created":"2025-05-07 17:37:23","title":"MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection","abstract":"Accurately predicting 3D attributes is crucial for monocular 3D object detection (Mono3D), with depth estimation posing the greatest challenge due to the inherent ambiguity in mapping 2D images to 3D space. While existing methods leverage multiple depth cues (e.g., estimating depth uncertainty, modeling depth error) to improve depth accuracy, they overlook that accurate depth prediction requires conditioning on other 3D attributes, as these attributes are intrinsically inter-correlated through the 3D to 2D projection, which ultimately limits overall accuracy and stability. Inspired by Chain-of-Thought (CoT) in large language models (LLMs), this paper proposes MonoCoP, which leverages a Chain-of-Prediction (CoP) to predict attributes sequentially and conditionally via three key designs. First, it employs a lightweight AttributeNet (AN) for each 3D attribute to learn attribute-specific features. Next, MonoCoP constructs an explicit chain to propagate these learned features from one attribute to the next. Finally, MonoCoP uses a residual connection to aggregate features for each attribute along the chain, ensuring that later attribute predictions are conditioned on all previously processed attributes without forgetting the features of earlier ones. Experimental results show that our MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI leaderboard without requiring additional data and further surpasses existing methods on the Waymo and nuScenes frontal datasets.","sentences":["Accurately predicting 3D attributes is crucial for monocular 3D object detection (Mono3D), with depth estimation posing the greatest challenge due to the inherent ambiguity in mapping 2D images to 3D space.","While existing methods leverage multiple depth cues (e.g., estimating depth uncertainty, modeling depth error) to improve depth accuracy, they overlook that accurate depth prediction requires conditioning on other 3D attributes, as these attributes are intrinsically inter-correlated through the 3D to 2D projection, which ultimately limits overall accuracy and stability.","Inspired by Chain-of-Thought (CoT) in large language models (LLMs), this paper proposes MonoCoP, which leverages a Chain-of-Prediction (CoP) to predict attributes sequentially and conditionally via three key designs.","First, it employs a lightweight AttributeNet (AN) for each 3D attribute to learn attribute-specific features.","Next, MonoCoP constructs an explicit chain to propagate these learned features from one attribute to the next.","Finally, MonoCoP uses a residual connection to aggregate features for each attribute along the chain, ensuring that later attribute predictions are conditioned on all previously processed attributes without forgetting the features of earlier ones.","Experimental results show that our MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI leaderboard without requiring additional data and further surpasses existing methods on the Waymo and nuScenes frontal datasets."],"url":"http://arxiv.org/abs/2505.04594v1"}
{"created":"2025-05-07 17:35:36","title":"AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions","abstract":"Humanity appears to be on course to soon develop AI systems that substantially outperform human experts in all cognitive domains and activities. We believe the default trajectory has a high likelihood of catastrophe, including human extinction. Risks come from failure to control powerful AI systems, misuse of AI by malicious rogue actors, war between great powers, and authoritarian lock-in. This research agenda has two aims: to describe the strategic landscape of AI development and to catalog important governance research questions. These questions, if answered, would provide important insight on how to successfully reduce catastrophic risks.   We describe four high-level scenarios for the geopolitical response to advanced AI development, cataloging the research questions most relevant to each. Our favored scenario involves building the technical, legal, and institutional infrastructure required to internationally restrict dangerous AI development and deployment (which we refer to as an Off Switch), which leads into an internationally coordinated Halt on frontier AI activities at some point in the future. The second scenario we describe is a US National Project for AI, in which the US Government races to develop advanced AI systems and establish unilateral control over global AI development. We also describe two additional scenarios: a Light-Touch world similar to that of today and a Threat of Sabotage situation where countries use sabotage and deterrence to slow AI development.   In our view, apart from the Off Switch and Halt scenario, all of these trajectories appear to carry an unacceptable risk of catastrophic harm. Urgent action is needed from the US National Security community and AI governance ecosystem to answer key research questions, build the capability to halt dangerous AI activities, and prepare for international AI agreements.","sentences":["Humanity appears to be on course to soon develop AI systems that substantially outperform human experts in all cognitive domains and activities.","We believe the default trajectory has a high likelihood of catastrophe, including human extinction.","Risks come from failure to control powerful AI systems, misuse of AI by malicious rogue actors, war between great powers, and authoritarian lock-in.","This research agenda has two aims: to describe the strategic landscape of AI development and to catalog important governance research questions.","These questions, if answered, would provide important insight on how to successfully reduce catastrophic risks.   ","We describe four high-level scenarios for the geopolitical response to advanced AI development, cataloging the research questions most relevant to each.","Our favored scenario involves building the technical, legal, and institutional infrastructure required to internationally restrict dangerous AI development and deployment (which we refer to as an Off Switch), which leads into an internationally coordinated Halt on frontier AI activities at some point in the future.","The second scenario we describe is a US National Project for AI, in which the US Government races to develop advanced AI systems and establish unilateral control over global AI development.","We also describe two additional scenarios: a Light-Touch world similar to that of today and a Threat of Sabotage situation where countries use sabotage and deterrence to slow AI development.   ","In our view, apart from the Off Switch and Halt scenario, all of these trajectories appear to carry an unacceptable risk of catastrophic harm.","Urgent action is needed from the US National Security community and AI governance ecosystem to answer key research questions, build the capability to halt dangerous AI activities, and prepare for international AI agreements."],"url":"http://arxiv.org/abs/2505.04592v1"}
{"created":"2025-05-07 17:32:49","title":"TetWeave: Isosurface Extraction using On-The-Fly Delaunay Tetrahedral Grids for Gradient-Based Mesh Optimization","abstract":"We introduce TetWeave, a novel isosurface representation for gradient-based mesh optimization that jointly optimizes the placement of a tetrahedral grid used for Marching Tetrahedra and a novel directional signed distance at each point. TetWeave constructs tetrahedral grids on-the-fly via Delaunay triangulation, enabling increased flexibility compared to predefined grids. The extracted meshes are guaranteed to be watertight, two-manifold and intersection-free. The flexibility of TetWeave enables a resampling strategy that places new points where reconstruction error is high and allows to encourage mesh fairness without compromising on reconstruction error. This leads to high-quality, adaptive meshes that require minimal memory usage and few parameters to optimize. Consequently, TetWeave exhibits near-linear memory scaling relative to the vertex count of the output mesh - a substantial improvement over predefined grids. We demonstrate the applicability of TetWeave to a broad range of challenging tasks in computer graphics and vision, such as multi-view 3D reconstruction, mesh compression and geometric texture generation.","sentences":["We introduce TetWeave, a novel isosurface representation for gradient-based mesh optimization that jointly optimizes the placement of a tetrahedral grid used for Marching Tetrahedra and a novel directional signed distance at each point.","TetWeave constructs tetrahedral grids on-the-fly via Delaunay triangulation, enabling increased flexibility compared to predefined grids.","The extracted meshes are guaranteed to be watertight, two-manifold and intersection-free.","The flexibility of TetWeave enables a resampling strategy that places new points where reconstruction error is high and allows to encourage mesh fairness without compromising on reconstruction error.","This leads to high-quality, adaptive meshes that require minimal memory usage and few parameters to optimize.","Consequently, TetWeave exhibits near-linear memory scaling relative to the vertex count of the output mesh - a substantial improvement over predefined grids.","We demonstrate the applicability of TetWeave to a broad range of challenging tasks in computer graphics and vision, such as multi-view 3D reconstruction, mesh compression and geometric texture generation."],"url":"http://arxiv.org/abs/2505.04590v1"}
{"created":"2025-05-07 17:30:22","title":"ZeroSearch: Incentivize the Search Capability of LLMs without Searching","abstract":"Effective information searching is essential for enhancing the reasoning and generation capabilities of large language models (LLMs). Recent research has explored using reinforcement learning (RL) to improve LLMs' search capabilities by interacting with live search engines in real-world environments. While these approaches show promising results, they face two major challenges: (1) Uncontrolled Document Quality: The quality of documents returned by search engines is often unpredictable, introducing noise and instability into the training process. (2) Prohibitively High API Costs: RL training requires frequent rollouts, potentially involving hundreds of thousands of search requests, which incur substantial API expenses and severely constrain scalability. To address these challenges, we introduce ZeroSearch, a reinforcement learning framework that incentivizes the search capabilities of LLMs without interacting with real search engines. Our approach begins with lightweight supervised fine-tuning to transform the LLM into a retrieval module capable of generating both relevant and noisy documents in response to a query. During RL training, we employ a curriculum-based rollout strategy that incrementally degrades the quality of generated documents, progressively eliciting the model's reasoning ability by exposing it to increasingly challenging retrieval scenarios. Extensive experiments demonstrate that ZeroSearch effectively incentivizes the search capabilities of LLMs using a 3B LLM as the retrieval module. Remarkably, a 7B retrieval module achieves comparable performance to the real search engine, while a 14B retrieval module even surpasses it. Furthermore, it generalizes well across both base and instruction-tuned models of various parameter sizes and is compatible with a wide range of RL algorithms.","sentences":["Effective information searching is essential for enhancing the reasoning and generation capabilities of large language models (LLMs).","Recent research has explored using reinforcement learning (RL) to improve LLMs' search capabilities by interacting with live search engines in real-world environments.","While these approaches show promising results, they face two major challenges: (1) Uncontrolled Document Quality:","The quality of documents returned by search engines is often unpredictable, introducing noise and instability into the training process.","(2) Prohibitively High API Costs: RL training requires frequent rollouts, potentially involving hundreds of thousands of search requests, which incur substantial API expenses and severely constrain scalability.","To address these challenges, we introduce ZeroSearch, a reinforcement learning framework that incentivizes the search capabilities of LLMs without interacting with real search engines.","Our approach begins with lightweight supervised fine-tuning to transform the LLM into a retrieval module capable of generating both relevant and noisy documents in response to a query.","During RL training, we employ a curriculum-based rollout strategy that incrementally degrades the quality of generated documents, progressively eliciting the model's reasoning ability by exposing it to increasingly challenging retrieval scenarios.","Extensive experiments demonstrate that ZeroSearch effectively incentivizes the search capabilities of LLMs using a 3B LLM as the retrieval module.","Remarkably, a 7B retrieval module achieves comparable performance to the real search engine, while a 14B retrieval module even surpasses it.","Furthermore, it generalizes well across both base and instruction-tuned models of various parameter sizes and is compatible with a wide range of RL algorithms."],"url":"http://arxiv.org/abs/2505.04588v1"}
{"created":"2025-05-07 17:27:51","title":"Active Sampling for MRI-based Sequential Decision Making","abstract":"Despite the superior diagnostic capability of Magnetic Resonance Imaging (MRI), its use as a Point-of-Care (PoC) device remains limited by high cost and complexity. To enable such a future by reducing the magnetic field strength, one key approach will be to improve sampling strategies. Previous work has shown that it is possible to make diagnostic decisions directly from k-space with fewer samples. Such work shows that single diagnostic decisions can be made, but if we aspire to see MRI as a true PoC, multiple and sequential decisions are necessary while minimizing the number of samples acquired. We present a novel multi-objective reinforcement learning framework enabling comprehensive, sequential, diagnostic evaluation from undersampled k-space data. Our approach during inference actively adapts to sequential decisions to optimally sample. To achieve this, we introduce a training methodology that identifies the samples that contribute the best to each diagnostic objective using a step-wise weighting reward function. We evaluate our approach in two sequential knee pathology assessment tasks: ACL sprain detection and cartilage thickness loss assessment. Our framework achieves diagnostic performance competitive with various policy-based benchmarks on disease detection, severity quantification, and overall sequential diagnosis, while substantially saving k-space samples. Our approach paves the way for the future of MRI as a comprehensive and affordable PoC device. Our code is publicly available at https://github.com/vios-s/MRI_Sequential_Active_Sampling","sentences":["Despite the superior diagnostic capability of Magnetic Resonance Imaging (MRI), its use as a Point-of-Care (PoC) device remains limited by high cost and complexity.","To enable such a future by reducing the magnetic field strength, one key approach will be to improve sampling strategies.","Previous work has shown that it is possible to make diagnostic decisions directly from k-space with fewer samples.","Such work shows that single diagnostic decisions can be made, but if we aspire to see MRI as a true PoC, multiple and sequential decisions are necessary while minimizing the number of samples acquired.","We present a novel multi-objective reinforcement learning framework enabling comprehensive, sequential, diagnostic evaluation from undersampled k-space data.","Our approach during inference actively adapts to sequential decisions to optimally sample.","To achieve this, we introduce a training methodology that identifies the samples that contribute the best to each diagnostic objective using a step-wise weighting reward function.","We evaluate our approach in two sequential knee pathology assessment tasks: ACL sprain detection and cartilage thickness loss assessment.","Our framework achieves diagnostic performance competitive with various policy-based benchmarks on disease detection, severity quantification, and overall sequential diagnosis, while substantially saving k-space samples.","Our approach paves the way for the future of MRI as a comprehensive and affordable PoC device.","Our code is publicly available at https://github.com/vios-s/MRI_Sequential_Active_Sampling"],"url":"http://arxiv.org/abs/2505.04586v1"}
{"created":"2025-05-07 17:24:40","title":"SlideItRight: Using AI to Find Relevant Slides and Provide Feedback for Open-Ended Questions","abstract":"Feedback is important in supporting student learning. While various automated feedback systems have been implemented to make the feedback scalable, many existing solutions only focus on generating text-based feedback. As is indicated in the multimedia learning principle, learning with more modalities could help utilize more separate channels, reduce the cognitive load and facilitate students' learning. Hence, it is important to explore the potential of Artificial Intelligence (AI) in feedback generation from and to different modalities. Our study leverages Large Language Models (LLMs) for textual feedback with the supplementary guidance from other modality - relevant lecture slide retrieved from the slides hub. Through an online crowdsourcing study (N=91), this study investigates learning gains and student perceptions using a 2x2 design (i.e., human feedback vs. AI feedback and with vs. without relevant slide), evaluating the clarity, engagement, perceived effectiveness, and reliability) of AI-facilitated multimodal feedback. We observed significant pre-to-post learning gains across all conditions. However, the differences in these gains were not statistically significant between conditions. The post-survey revealed that students found the slide feedback helpful in their learning process, though they reported difficulty in understanding it. Regarding the AI-generated open-ended feedback, students considered it personalized and relevant to their responses, but they expressed lower trust in the AI feedback compared to human-generated feedback.","sentences":["Feedback is important in supporting student learning.","While various automated feedback systems have been implemented to make the feedback scalable, many existing solutions only focus on generating text-based feedback.","As is indicated in the multimedia learning principle, learning with more modalities could help utilize more separate channels, reduce the cognitive load and facilitate students' learning.","Hence, it is important to explore the potential of Artificial Intelligence (AI) in feedback generation from and to different modalities.","Our study leverages Large Language Models (LLMs) for textual feedback with the supplementary guidance from other modality - relevant lecture slide retrieved from the slides hub.","Through an online crowdsourcing study (N=91), this study investigates learning gains and student perceptions using a 2x2 design (i.e., human feedback vs. AI feedback and with vs. without relevant slide), evaluating the clarity, engagement, perceived effectiveness, and reliability) of AI-facilitated multimodal feedback.","We observed significant pre-to-post learning gains across all conditions.","However, the differences in these gains were not statistically significant between conditions.","The post-survey revealed that students found the slide feedback helpful in their learning process, though they reported difficulty in understanding it.","Regarding the AI-generated open-ended feedback, students considered it personalized and relevant to their responses, but they expressed lower trust in the AI feedback compared to human-generated feedback."],"url":"http://arxiv.org/abs/2505.04584v1"}
{"created":"2025-05-07 17:21:45","title":"Modeling Personalized Difficulty of Rehabilitation Exercises Using Causal Trees","abstract":"Rehabilitation robots are often used in game-like interactions for rehabilitation to increase a person's motivation to complete rehabilitation exercises. By adjusting exercise difficulty for a specific user throughout the exercise interaction, robots can maximize both the user's rehabilitation outcomes and the their motivation throughout the exercise. Previous approaches have assumed exercises have generic difficulty values that apply to all users equally, however, we identified that stroke survivors have varied and unique perceptions of exercise difficulty. For example, some stroke survivors found reaching vertically more difficult than reaching farther but lower while others found reaching farther more challenging than reaching vertically. In this paper, we formulate a causal tree-based method to calculate exercise difficulty based on the user's performance. We find that this approach accurately models exercise difficulty and provides a readily interpretable model of why that exercise is difficult for both users and caretakers.","sentences":["Rehabilitation robots are often used in game-like interactions for rehabilitation to increase a person's motivation to complete rehabilitation exercises.","By adjusting exercise difficulty for a specific user throughout the exercise interaction, robots can maximize both the user's rehabilitation outcomes and the their motivation throughout the exercise.","Previous approaches have assumed exercises have generic difficulty values that apply to all users equally, however, we identified that stroke survivors have varied and unique perceptions of exercise difficulty.","For example, some stroke survivors found reaching vertically more difficult than reaching farther but lower while others found reaching farther more challenging than reaching vertically.","In this paper, we formulate a causal tree-based method to calculate exercise difficulty based on the user's performance.","We find that this approach accurately models exercise difficulty and provides a readily interpretable model of why that exercise is difficult for both users and caretakers."],"url":"http://arxiv.org/abs/2505.04583v1"}
{"created":"2025-05-07 17:19:17","title":"Implicitly Aligning Humans and Autonomous Agents through Shared Task Abstractions","abstract":"In collaborative tasks, autonomous agents fall short of humans in their capability to quickly adapt to new and unfamiliar teammates. We posit that a limiting factor for zero-shot coordination is the lack of shared task abstractions, a mechanism humans rely on to implicitly align with teammates. To address this gap, we introduce HA$^2$: Hierarchical Ad Hoc Agents, a framework leveraging hierarchical reinforcement learning to mimic the structured approach humans use in collaboration. We evaluate HA$^2$ in the Overcooked environment, demonstrating statistically significant improvement over existing baselines when paired with both unseen agents and humans, providing better resilience to environmental shifts, and outperforming all state-of-the-art methods.","sentences":["In collaborative tasks, autonomous agents fall short of humans in their capability to quickly adapt to new and unfamiliar teammates.","We posit that a limiting factor for zero-shot coordination is the lack of shared task abstractions, a mechanism humans rely on to implicitly align with teammates.","To address this gap, we introduce HA$^2$: Hierarchical Ad Hoc Agents, a framework leveraging hierarchical reinforcement learning to mimic the structured approach humans use in collaboration.","We evaluate HA$^2$ in the Overcooked environment, demonstrating statistically significant improvement over existing baselines when paired with both unseen agents and humans, providing better resilience to environmental shifts, and outperforming all state-of-the-art methods."],"url":"http://arxiv.org/abs/2505.04579v1"}
{"created":"2025-05-07 17:18:48","title":"Fight Fire with Fire: Defending Against Malicious RL Fine-Tuning via Reward Neutralization","abstract":"Reinforcement learning (RL) fine-tuning transforms large language models while creating a vulnerability we experimentally verify: Our experiment shows that malicious RL fine-tuning dismantles safety guardrails with remarkable efficiency, requiring only 50 steps and minimal adversarial prompts, with harmful escalating from 0-2 to 7-9. This attack vector particularly threatens open-source models with parameter-level access. Existing defenses targeting supervised fine-tuning prove ineffective against RL's dynamic feedback mechanisms. We introduce Reward Neutralization, the first defense framework specifically designed against RL fine-tuning attacks, establishing concise rejection patterns that render malicious reward signals ineffective. Our approach trains models to produce minimal-information rejections that attackers cannot exploit, systematically neutralizing attempts to optimize toward harmful outputs. Experiments validate that our approach maintains low harmful scores (no greater than 2) after 200 attack steps, while standard models rapidly deteriorate. This work provides the first constructive proof that robust defense against increasingly accessible RL attacks is achievable, addressing a critical security gap for open-weight models.","sentences":["Reinforcement learning (RL) fine-tuning transforms large language models while creating a vulnerability we experimentally verify: Our experiment shows that malicious RL fine-tuning dismantles safety guardrails with remarkable efficiency, requiring only 50 steps and minimal adversarial prompts, with harmful escalating from 0-2 to 7-9.","This attack vector particularly threatens open-source models with parameter-level access.","Existing defenses targeting supervised fine-tuning prove ineffective against RL's dynamic feedback mechanisms.","We introduce Reward Neutralization, the first defense framework specifically designed against RL fine-tuning attacks, establishing concise rejection patterns that render malicious reward signals ineffective.","Our approach trains models to produce minimal-information rejections that attackers cannot exploit, systematically neutralizing attempts to optimize toward harmful outputs.","Experiments validate that our approach maintains low harmful scores (no greater than 2) after 200 attack steps, while standard models rapidly deteriorate.","This work provides the first constructive proof that robust defense against increasingly accessible RL attacks is achievable, addressing a critical security gap for open-weight models."],"url":"http://arxiv.org/abs/2505.04578v1"}
{"created":"2025-05-07 17:12:15","title":"Componential Prompt-Knowledge Alignment for Domain Incremental Learning","abstract":"Domain Incremental Learning (DIL) aims to learn from non-stationary data streams across domains while retaining and utilizing past knowledge. Although prompt-based methods effectively store multi-domain knowledge in prompt parameters and obtain advanced performance through cross-domain prompt fusion, we reveal an intrinsic limitation: component-wise misalignment between domain-specific prompts leads to conflicting knowledge integration and degraded predictions. This arises from the random positioning of knowledge components within prompts, where irrelevant component fusion introduces interference.To address this, we propose Componential Prompt-Knowledge Alignment (KA-Prompt), a novel prompt-based DIL method that introduces component-aware prompt-knowledge alignment during training, significantly improving both the learning and inference capacity of the model. KA-Prompt operates in two phases: (1) Initial Componential Structure Configuring, where a set of old prompts containing knowledge relevant to the new domain are mined via greedy search, which is then exploited to initialize new prompts to achieve reusable knowledge transfer and establish intrinsic alignment between new and old prompts. (2) Online Alignment Preservation, which dynamically identifies the target old prompts and applies adaptive componential consistency constraints as new prompts evolve. Extensive experiments on DIL benchmarks demonstrate the effectiveness of our KA-Prompt. Our source code is available at https://github.com/zhoujiahuan1991/ICML2025-KA-Prompt","sentences":["Domain Incremental Learning (DIL) aims to learn from non-stationary data streams across domains while retaining and utilizing past knowledge.","Although prompt-based methods effectively store multi-domain knowledge in prompt parameters and obtain advanced performance through cross-domain prompt fusion, we reveal an intrinsic limitation: component-wise misalignment between domain-specific prompts leads to conflicting knowledge integration and degraded predictions.","This arises from the random positioning of knowledge components within prompts, where irrelevant component fusion introduces interference.","To address this, we propose Componential Prompt-Knowledge Alignment (KA-Prompt), a novel prompt-based DIL method that introduces component-aware prompt-knowledge alignment during training, significantly improving both the learning and inference capacity of the model.","KA-Prompt operates in two phases: (1) Initial Componential Structure Configuring, where a set of old prompts containing knowledge relevant to the new domain are mined via greedy search, which is then exploited to initialize new prompts to achieve reusable knowledge transfer and establish intrinsic alignment between new and old prompts.","(2) Online Alignment Preservation, which dynamically identifies the target old prompts and applies adaptive componential consistency constraints as new prompts evolve.","Extensive experiments on DIL benchmarks demonstrate the effectiveness of our KA-Prompt.","Our source code is available at https://github.com/zhoujiahuan1991/ICML2025-KA-Prompt"],"url":"http://arxiv.org/abs/2505.04575v1"}
{"created":"2025-05-07 17:07:09","title":"Stow: Robotic Packing of Items into Fabric Pods","abstract":"This paper presents a compliant manipulation system capable of placing items onto densely packed shelves. The wide diversity of items and strict business requirements for high producing rates and low defect generation have prohibited warehouse robotics from performing this task. Our innovations in hardware, perception, decision-making, motion planning, and control have enabled this system to perform over 500,000 stows in a large e-commerce fulfillment center. The system achieves human levels of packing density and speed while prioritizing work on overhead shelves to enhance the safety of humans working alongside the robots.","sentences":["This paper presents a compliant manipulation system capable of placing items onto densely packed shelves.","The wide diversity of items and strict business requirements for high producing rates and low defect generation have prohibited warehouse robotics from performing this task.","Our innovations in hardware, perception, decision-making, motion planning, and control have enabled this system to perform over 500,000 stows in a large e-commerce fulfillment center.","The system achieves human levels of packing density and speed while prioritizing work on overhead shelves to enhance the safety of humans working alongside the robots."],"url":"http://arxiv.org/abs/2505.04572v1"}
{"created":"2025-05-07 17:03:06","title":"Flexing RISC-V Instruction Subset Processors (RISPs) to Extreme Edge","abstract":"This paper presents a methodology for automatically generating processors that support a subset of the RISC-V instruction set for a new class of applications at Extreme Edge. The electronics used in extreme edge applications must be power-efficient, but also provide additional qualities, such as low cost, conformability, comfort and sustainability. Flexible electronics, rather than silicon-based electronics, will be capable of meeting these qualities. For this purpose, we propose a methodology to generate RISPs (RISC-V instruction subset processors) customised to extreme edge applications and to implement them as flexible integrated circuits (FlexICs). The methodology is unique in the sense that verification is an integral part of design. The RISP methodology treats each instruction in the ISA as a discrete, fully functional, pre-verified hardware block. It automatically builds a custom processor by stitching together the hardware blocks of the instructions required by an application or a set of applications in a specific domain. This approach significantly reduces the processor verification and its time-to-market. We generate RISPs using this methodology for three extreme edge applications, and embedded applications from the Embench benchmark suite, synthesize them as FlexICs, and compare their power, performance and area to the baselines. Our results show that RISPs generated using this methodology achieve, on average, 30\\% reductions in power and area compared to a RISC-V processor supporting the full instruction set when synthesized, and are nearly 30 times more energy efficient with respect to Serv - the world's smallest 32-bit RISC-V processor. In addition, the full physical implementation of RISPs show up to 21% and 26% less area and power than Serv.","sentences":["This paper presents a methodology for automatically generating processors that support a subset of the RISC-V instruction set for a new class of applications at Extreme Edge.","The electronics used in extreme edge applications must be power-efficient, but also provide additional qualities, such as low cost, conformability, comfort and sustainability.","Flexible electronics, rather than silicon-based electronics, will be capable of meeting these qualities.","For this purpose, we propose a methodology to generate RISPs (RISC-V instruction subset processors) customised to extreme edge applications and to implement them as flexible integrated circuits (FlexICs).","The methodology is unique in the sense that verification is an integral part of design.","The RISP methodology treats each instruction in the ISA as a discrete, fully functional, pre-verified hardware block.","It automatically builds a custom processor by stitching together the hardware blocks of the instructions required by an application or a set of applications in a specific domain.","This approach significantly reduces the processor verification and its time-to-market.","We generate RISPs using this methodology for three extreme edge applications, and embedded applications from the Embench benchmark suite, synthesize them as FlexICs, and compare their power, performance and area to the baselines.","Our results show that RISPs generated using this methodology achieve, on average, 30\\% reductions in power and area compared to a RISC-V processor supporting the full instruction set when synthesized, and are nearly 30 times more energy efficient with respect to Serv - the world's smallest 32-bit RISC-V processor.","In addition, the full physical implementation of RISPs show up to 21% and 26% less area and power than Serv."],"url":"http://arxiv.org/abs/2505.04567v1"}
{"created":"2025-05-07 16:58:18","title":"Multitask LSTM for Arboviral Outbreak Prediction Using Public Health Data","abstract":"This paper presents a multitask learning approach based on long-short-term memory (LSTM) networks for the joint prediction of arboviral outbreaks and case counts of dengue, chikungunya, and Zika in Recife, Brazil. Leveraging historical public health data from DataSUS (2017-2023), the proposed model concurrently performs binary classification (outbreak detection) and regression (case forecasting) tasks. A sliding window strategy was adopted to construct temporal features using varying input lengths (60, 90, and 120 days), with hyperparameter optimization carried out using Keras Tuner. Model evaluation used time series cross-validation for robustness and a held-out test from 2023 for generalization assessment. The results show that longer windows improve dengue regression accuracy, while classification performance peaked at intermediate windows, suggesting an optimal trade-off between sequence length and generalization. The multitask architecture delivers competitive performance across diseases and tasks, demonstrating the feasibility and advantages of unified modeling strategies for scalable epidemic forecasting in data-limited public health scenarios.","sentences":["This paper presents a multitask learning approach based on long-short-term memory (LSTM) networks for the joint prediction of arboviral outbreaks and case counts of dengue, chikungunya, and Zika in Recife, Brazil.","Leveraging historical public health data from DataSUS (2017-2023), the proposed model concurrently performs binary classification (outbreak detection) and regression (case forecasting) tasks.","A sliding window strategy was adopted to construct temporal features using varying input lengths (60, 90, and 120 days), with hyperparameter optimization carried out using Keras Tuner.","Model evaluation used time series cross-validation for robustness and a held-out test from 2023 for generalization assessment.","The results show that longer windows improve dengue regression accuracy, while classification performance peaked at intermediate windows, suggesting an optimal trade-off between sequence length and generalization.","The multitask architecture delivers competitive performance across diseases and tasks, demonstrating the feasibility and advantages of unified modeling strategies for scalable epidemic forecasting in data-limited public health scenarios."],"url":"http://arxiv.org/abs/2505.04566v1"}
{"created":"2025-05-07 16:57:51","title":"Hierarchical Task Decomposition for Execution Monitoring and Error Recovery: Understanding the Rationale Behind Task Demonstrations","abstract":"Multi-step manipulation tasks where robots interact with their environment and must apply process forces based on the perceived situation remain challenging to learn and prone to execution errors. Accurately simulating these tasks is also difficult. Hence, it is crucial for robust task performance to learn how to coordinate end-effector pose and applied force, monitor execution, and react to deviations. To address these challenges, we propose a learning approach that directly infers both low- and high-level task representations from user demonstrations on the real system. We developed an unsupervised task segmentation algorithm that combines intention recognition and feature clustering to infer the skills of a task. We leverage the inferred characteristic features of each skill in a novel unsupervised anomaly detection approach to identify deviations from the intended task execution. Together, these components form a comprehensive framework capable of incrementally learning task decisions and new behaviors as new situations arise. Compared to state-of-the-art learning techniques, our approach significantly reduces the required amount of training data and computational complexity while efficiently learning complex in-contact behaviors and recovery strategies. Our proposed task segmentation and anomaly detection approaches outperform state-of-the-art methods on force-based tasks evaluated on two different robotic systems.","sentences":["Multi-step manipulation tasks where robots interact with their environment and must apply process forces based on the perceived situation remain challenging to learn and prone to execution errors.","Accurately simulating these tasks is also difficult.","Hence, it is crucial for robust task performance to learn how to coordinate end-effector pose and applied force, monitor execution, and react to deviations.","To address these challenges, we propose a learning approach that directly infers both low- and high-level task representations from user demonstrations on the real system.","We developed an unsupervised task segmentation algorithm that combines intention recognition and feature clustering to infer the skills of a task.","We leverage the inferred characteristic features of each skill in a novel unsupervised anomaly detection approach to identify deviations from the intended task execution.","Together, these components form a comprehensive framework capable of incrementally learning task decisions and new behaviors as new situations arise.","Compared to state-of-the-art learning techniques, our approach significantly reduces the required amount of training data and computational complexity while efficiently learning complex in-contact behaviors and recovery strategies.","Our proposed task segmentation and anomaly detection approaches outperform state-of-the-art methods on force-based tasks evaluated on two different robotic systems."],"url":"http://arxiv.org/abs/2505.04565v1"}
{"created":"2025-05-07 16:56:52","title":"Optimal Deterministic Rendezvous in Labeled Lines","abstract":"In a rendezvous task, a set of mobile agents dispersed in a network have to gather at an arbitrary common site. We consider the rendezvous problem on the infinite labeled line, with $2$ initially asleep agents, without communication, and a synchronous notion of time. Nodes are labeled with unique positive integers. The initial distance between the two agents is denoted by $D$. Time is divided into rounds. We count time from when an agent first wakes up, and denote by $\\tau$ the delay between the agents' wake up times. If awake in a given round $T$, an agent has three options: stay at its current node $v$, take port $0$, or take port $1$. If it decides to stay, the agent is still at node $v$ in round $T+1$. Otherwise, it is at one of the two neighbors of $v$ on the line, based on the port it chose. The agents achieve rendezvous in $T$ rounds if they are at the same node in round $T$. We aim for a deterministic algorithm for this task.   The problem was recently considered by Miller and Pelc [DISC 2023]. With $\\ell_{\\max}$ the largest label of the two starting nodes, they showed that no algorithm can guarantee rendezvous in $o(D \\log^* \\ell_{\\max})$ rounds. The lower bound follows from a connection with the LOCAL model of distributed computing, and holds even if the agents are guaranteed simultaneous wake-up ($\\tau = 0$) and are given $D$ as advice. Miller and Pelc also gave an algorithm of optimal matching complexity $O(D \\log^* \\ell_{\\max})$ when $D$ is known to the agents, but only obtained the higher bound of $O(D^2 (\\log^* \\ell_{\\max})^3)$ when $D$ is unknown.   We improve this second complexity to a tight $O(D \\log^* \\ell_{\\max})$. In fact, our algorithm achieves rendezvous in $O(D \\log^* \\ell_{\\min})$ rounds, where $\\ell_{\\min}$ is the smallest label within distance $O(D)$ of the two starting positions.","sentences":["In a rendezvous task, a set of mobile agents dispersed in a network have to gather at an arbitrary common site.","We consider the rendezvous problem on the infinite labeled line, with $2$ initially asleep agents, without communication, and a synchronous notion of time.","Nodes are labeled with unique positive integers.","The initial distance between the two agents is denoted by $D$. Time is divided into rounds.","We count time from when an agent first wakes up, and denote by $\\tau$ the delay between the agents' wake up times.","If awake in a given round $T$, an agent has three options: stay at its current node $v$, take port $0$, or take port $1$. If it decides to stay, the agent is still at node $v$ in round $T+1$. Otherwise, it is at one of the two neighbors of $v$ on the line, based on the port it chose.","The agents achieve rendezvous in $T$ rounds if they are at the same node in round $T$. We aim for a deterministic algorithm for this task.   ","The problem was recently considered by Miller and Pelc","[DISC 2023].","With $\\ell_{\\max}$ the largest label of the two starting nodes, they showed that no algorithm can guarantee rendezvous in $o(D \\log^* \\ell_{\\max})$ rounds.","The lower bound follows from a connection with the LOCAL model of distributed computing, and holds even if the agents are guaranteed simultaneous wake-up ($\\tau = 0$) and are given $D$ as advice.","Miller and Pelc also gave an algorithm of optimal matching complexity $O(D \\log^* \\ell_{\\max})$ when $D$ is known to the agents, but only obtained the higher bound of $O(D^2 (\\log^* \\ell_{\\max})^3)$ when $D$ is unknown.   ","We improve this second complexity to a tight $O(D \\log^* \\ell_{\\max})$.","In fact, our algorithm achieves rendezvous in $O(D \\log^* \\ell_{\\min})$ rounds, where $\\ell_{\\min}$ is the smallest label within distance $O(D)$ of the two starting positions."],"url":"http://arxiv.org/abs/2505.04564v1"}
{"created":"2025-05-07 16:50:58","title":"From Flowers to Fascism? The Cottagecore to Tradwife Pipeline on Tumblr","abstract":"In this work we collected and analyzed social media posts to investigate aesthetic-based radicalization where users searching for Cottagecore content may find Tradwife content co-opted by white supremacists, white nationalists, or other far-right extremist groups. Through quantitative analysis of over 200,000 Tumblr posts and qualitative coding of about 2,500 Tumblr posts, we did not find evidence of a explicit radicalization. We found that problematic Tradwife posts found in the literature may be confined to Tradwife-only spaces, while content in the Cottagecore tag generally did not warrant extra moderation. However, we did find evidence of a mainstreaming effect in the overlap between the Tradwife and Cottagecore communities. In our qualitative analysis there was more interaction between queer and Tradwife identities than expected based on the literature, and some Tradwives even explicitly included queer people and disavowed racism in the Tradwife community on Tumblr. This could be genuine, but more likely it was an example of extremists re-branding their content and following platform norms to spread ideologies that would otherwise be rejected by Tumblr users. Additionally, through temporal analysis we observed a change in the central tags used by Tradwives in the Cottagecore tag pre- and post- 2021. Initially these posts focused on aesthetics and hobbies like baking and gardening, but post-2021 the central tags focused more on religion, traditional gender roles, and homesteading, all markers of reactionary ideals.","sentences":["In this work we collected and analyzed social media posts to investigate aesthetic-based radicalization where users searching for Cottagecore content may find Tradwife content co-opted by white supremacists, white nationalists, or other far-right extremist groups.","Through quantitative analysis of over 200,000 Tumblr posts and qualitative coding of about 2,500 Tumblr posts, we did not find evidence of a explicit radicalization.","We found that problematic Tradwife posts found in the literature may be confined to Tradwife-only spaces, while content in the Cottagecore tag generally did not warrant extra moderation.","However, we did find evidence of a mainstreaming effect in the overlap between the Tradwife and Cottagecore communities.","In our qualitative analysis there was more interaction between queer and Tradwife identities than expected based on the literature, and some Tradwives even explicitly included queer people and disavowed racism in the Tradwife community on Tumblr.","This could be genuine, but more likely it was an example of extremists re-branding their content and following platform norms to spread ideologies that would otherwise be rejected by Tumblr users.","Additionally, through temporal analysis we observed a change in the central tags used by Tradwives in the Cottagecore tag pre- and post- 2021.","Initially these posts focused on aesthetics and hobbies like baking and gardening, but post-2021 the central tags focused more on religion, traditional gender roles, and homesteading, all markers of reactionary ideals."],"url":"http://arxiv.org/abs/2505.04561v1"}
{"created":"2025-05-07 16:48:49","title":"ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via $\u03b1$-$\u03b2$-Divergence","abstract":"Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student model by minimizing the divergence between their output distributions, typically using forward Kullback-Leibler divergence (FKLD) or reverse KLD (RKLD). It has become an effective training paradigm due to the broader supervision information provided by the teacher distribution compared to one-hot labels. We identify that the core challenge in KD lies in balancing two mode-concentration effects: the \\textbf{\\textit{Hardness-Concentration}} effect, which refers to focusing on modes with large errors, and the \\textbf{\\textit{Confidence-Concentration}} effect, which refers to focusing on modes with high student confidence. Through an analysis of how probabilities are reassigned during gradient updates, we observe that these two effects are entangled in FKLD and RKLD, but in extreme forms. Specifically, both are too weak in FKLD, causing the student to fail to concentrate on the target class. In contrast, both are too strong in RKLD, causing the student to overly emphasize the target class while ignoring the broader distributional information from the teacher. To address this imbalance, we propose ABKD, a generic framework with $\\alpha$-$\\beta$-divergence. Our theoretical results show that ABKD offers a smooth interpolation between FKLD and RKLD, achieving an effective trade-off between these effects. Extensive experiments on 17 language/vision datasets with 12 teacher-student settings confirm its efficacy. The code is available at https://github.com/ghwang-s/abkd.","sentences":["Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student model by minimizing the divergence between their output distributions, typically using forward Kullback-Leibler divergence (FKLD) or reverse KLD (RKLD).","It has become an effective training paradigm due to the broader supervision information provided by the teacher distribution compared to one-hot labels.","We identify that the core challenge in KD lies in balancing two mode-concentration effects: the \\textbf{\\textit{Hardness-Concentration}} effect, which refers to focusing on modes with large errors, and the \\textbf{\\textit{Confidence-Concentration}} effect, which refers to focusing on modes with high student confidence.","Through an analysis of how probabilities are reassigned during gradient updates, we observe that these two effects are entangled in FKLD and RKLD, but in extreme forms.","Specifically, both are too weak in FKLD, causing the student to fail to concentrate on the target class.","In contrast, both are too strong in RKLD, causing the student to overly emphasize the target class while ignoring the broader distributional information from the teacher.","To address this imbalance, we propose ABKD, a generic framework with $\\alpha$-$\\beta$-divergence.","Our theoretical results show that ABKD offers a smooth interpolation between FKLD and RKLD, achieving an effective trade-off between these effects.","Extensive experiments on 17 language/vision datasets with 12 teacher-student settings confirm its efficacy.","The code is available at https://github.com/ghwang-s/abkd."],"url":"http://arxiv.org/abs/2505.04560v1"}
{"created":"2025-05-07 16:46:48","title":"Purity Law for Generalizable Neural TSP Solvers","abstract":"Achieving generalization in neural approaches across different scales and distributions remains a significant challenge for the Traveling Salesman Problem~(TSP). A key obstacle is that neural networks often fail to learn robust principles for identifying universal patterns and deriving optimal solutions from diverse instances. In this paper, we first uncover Purity Law (PuLa), a fundamental structural principle for optimal TSP solutions, defining that edge prevalence grows exponentially with the sparsity of surrounding vertices. Statistically validated across diverse instances, PuLa reveals a consistent bias toward local sparsity in global optima. Building on this insight, we propose Purity Policy Optimization~(PUPO), a novel training paradigm that explicitly aligns characteristics of neural solutions with PuLa during the solution construction process to enhance generalization. Extensive experiments demonstrate that PUPO can be seamlessly integrated with popular neural solvers, significantly enhancing their generalization performance without incurring additional computational overhead during inference.","sentences":["Achieving generalization in neural approaches across different scales and distributions remains a significant challenge for the Traveling Salesman Problem~(TSP).","A key obstacle is that neural networks often fail to learn robust principles for identifying universal patterns and deriving optimal solutions from diverse instances.","In this paper, we first uncover Purity Law (PuLa), a fundamental structural principle for optimal TSP solutions, defining that edge prevalence grows exponentially with the sparsity of surrounding vertices.","Statistically validated across diverse instances, PuLa reveals a consistent bias toward local sparsity in global optima.","Building on this insight, we propose Purity Policy Optimization~(PUPO), a novel training paradigm that explicitly aligns characteristics of neural solutions with PuLa during the solution construction process to enhance generalization.","Extensive experiments demonstrate that PUPO can be seamlessly integrated with popular neural solvers, significantly enhancing their generalization performance without incurring additional computational overhead during inference."],"url":"http://arxiv.org/abs/2505.04558v1"}
{"created":"2025-05-07 16:44:21","title":"Comparing CPU and GPU compute of PERMANOVA on MI300A","abstract":"Comparing the tradeoffs of CPU and GPU compute for memory-heavy algorithms is often challenging, due to the drastically different memory subsystems on host CPUs and discrete GPUs. The AMD MI300A is an exception, since it sports both CPU and GPU cores in a single package, all backed by the same type of HBM memory. In this paper we analyze the performance of Permutational Multivariate Analysis of Variance (PERMANOVA), a non-parametric method that tests whether two or more groups of objects are significantly different based on a categorical factor. This method is memory-bound and has been recently optimized for CPU cache locality. Our tests show that GPU cores on the MI300A prefer the brute force approach instead, significantly outperforming the CPU-based implementation. The significant benefit of Simultaneous Multithreading (SMT) was also a pleasant surprise.","sentences":["Comparing the tradeoffs of CPU and GPU compute for memory-heavy algorithms is often challenging, due to the drastically different memory subsystems on host CPUs and discrete GPUs.","The AMD MI300A is an exception, since it sports both CPU and GPU cores in a single package, all backed by the same type of HBM memory.","In this paper we analyze the performance of Permutational Multivariate Analysis of Variance (PERMANOVA), a non-parametric method that tests whether two or more groups of objects are significantly different based on a categorical factor.","This method is memory-bound and has been recently optimized for CPU cache locality.","Our tests show that GPU cores on the MI300A prefer the brute force approach instead, significantly outperforming the CPU-based implementation.","The significant benefit of Simultaneous Multithreading (SMT) was also a pleasant surprise."],"url":"http://arxiv.org/abs/2505.04556v1"}
{"created":"2025-05-07 16:31:38","title":"Runtime Advocates: A Persona-Driven Framework for Requirements@Runtime Decision Support","abstract":"Complex systems, such as small Uncrewed Aerial Systems (sUAS) swarms dispatched for emergency response, often require dynamic reconfiguration at runtime under the supervision of human operators. This introduces human-on-the-loop requirements, where evolving needs shape ongoing system functionality and behaviors. While traditional personas support upfront, static requirements elicitation, we propose a persona-based advocate framework for runtime requirements engineering to provide ethically informed, safety-driven, and regulatory-aware decision support. Our approach extends standard personas into event-driven personas. When triggered by events such as adverse environmental conditions, evolving mission state, or operational constraints, the framework updates the sUAS operator's view of the personas, ensuring relevance to current conditions. We create three key advocate personas, namely Safety Controller, Ethical Governor, and Regulatory Auditor, to manage trade-offs among risk, ethical considerations, and regulatory compliance. We perform a proof-of-concept validation in an emergency response scenario using sUAS, showing how our advocate personas provide context-aware guidance grounded in safety, regulatory, and ethical constraints. By evolving static, design-time personas into adaptive, event-driven advocates, the framework surfaces mission-critical runtime requirements in response to changing conditions. These requirements shape operator decisions in real time, aligning actions with the operational demands of the moment.","sentences":["Complex systems, such as small Uncrewed Aerial Systems (sUAS) swarms dispatched for emergency response, often require dynamic reconfiguration at runtime under the supervision of human operators.","This introduces human-on-the-loop requirements, where evolving needs shape ongoing system functionality and behaviors.","While traditional personas support upfront, static requirements elicitation, we propose a persona-based advocate framework for runtime requirements engineering to provide ethically informed, safety-driven, and regulatory-aware decision support.","Our approach extends standard personas into event-driven personas.","When triggered by events such as adverse environmental conditions, evolving mission state, or operational constraints, the framework updates the sUAS operator's view of the personas, ensuring relevance to current conditions.","We create three key advocate personas, namely Safety Controller, Ethical Governor, and Regulatory Auditor, to manage trade-offs among risk, ethical considerations, and regulatory compliance.","We perform a proof-of-concept validation in an emergency response scenario using sUAS, showing how our advocate personas provide context-aware guidance grounded in safety, regulatory, and ethical constraints.","By evolving static, design-time personas into adaptive, event-driven advocates, the framework surfaces mission-critical runtime requirements in response to changing conditions.","These requirements shape operator decisions in real time, aligning actions with the operational demands of the moment."],"url":"http://arxiv.org/abs/2505.04551v1"}
{"created":"2025-05-07 16:31:21","title":"Fast Pattern Matching with Epsilon Transitions","abstract":"In the String Matching in Labeled Graphs (SMLG) problem, we need to determine whether a pattern string appears on a given labeled graph or a given automaton. Under the Orthogonal Vectors hypothesis, the SMLG problem cannot be solved in subquadratic time [ICALP 2019]. In typical bioinformatics applications, pattern matching algorithms should be both fast and space-efficient, so we need to determine useful classes of graphs on which the SLMG problem can be solved efficiently.   In this paper, we improve on a recent result [STACS 2024] that shows how to solve the SMLG problem in linear time on the compressed representation of Wheeler generalized automata, a class of string-labeled automata that extend de Bruijn graphs. More precisely, we show how to remove the assumption that the automata contain no $ \\epsilon $-transitions (namely, edges labeled with the empty string), while retaining the same time and space bounds. This is a significant improvement because $ \\epsilon $-transitions add considerable expressive power (making it possible to jump to multiple states for free) and capture the complexity of regular expressions (through Thompson's construction for converting a regular expression into an equivalent automaton). We prove that, to enable $ \\epsilon $-transitions, we only need to store two additional bitvectors that can be constructed in linear time.","sentences":["In the String Matching in Labeled Graphs (SMLG) problem, we need to determine whether a pattern string appears on a given labeled graph or a given automaton.","Under the Orthogonal Vectors hypothesis, the SMLG problem cannot be solved in subquadratic time [ICALP 2019].","In typical bioinformatics applications, pattern matching algorithms should be both fast and space-efficient, so we need to determine useful classes of graphs on which the SLMG problem can be solved efficiently.   ","In this paper, we improve on a recent result [STACS 2024] that shows how to solve the SMLG problem in linear time on the compressed representation of Wheeler generalized automata, a class of string-labeled automata that extend de Bruijn graphs.","More precisely, we show how to remove the assumption that the automata contain no $ \\epsilon $-transitions (namely, edges labeled with the empty string), while retaining the same time and space bounds.","This is a significant improvement because $ \\epsilon $-transitions add considerable expressive power (making it possible to jump to multiple states for free) and capture the complexity of regular expressions (through Thompson's construction for converting a regular expression into an equivalent automaton).","We prove that, to enable $ \\epsilon $-transitions, we only need to store two additional bitvectors that can be constructed in linear time."],"url":"http://arxiv.org/abs/2505.04549v1"}
{"created":"2025-05-07 16:17:54","title":"Registration of 3D Point Sets Using Exponential-based Similarity Matrix","abstract":"Point cloud registration is a fundamental problem in computer vision and robotics, involving the alignment of 3D point sets captured from varying viewpoints using depth sensors such as LiDAR or structured light. In modern robotic systems, especially those focused on mapping, it is essential to merge multiple views of the same environment accurately. However, state-of-the-art registration techniques often struggle when large rotational differences exist between point sets or when the data is significantly corrupted by sensor noise. These challenges can lead to misalignments and, consequently, to inaccurate or distorted 3D reconstructions. In this work, we address both these limitations by proposing a robust modification to the classic Iterative Closest Point (ICP) algorithm. Our method, termed Exponential Similarity Matrix ICP (ESM-ICP), integrates a Gaussian-inspired exponential weighting scheme to construct a similarity matrix that dynamically adapts across iterations. This matrix facilitates improved estimation of both rotational and translational components during alignment. We demonstrate the robustness of ESM-ICP in two challenging scenarios: (i) large rotational discrepancies between the source and target point clouds, and (ii) data corrupted by non-Gaussian noise. Our results show that ESM-ICP outperforms traditional geometric registration techniques as well as several recent learning-based methods. To encourage reproducibility and community engagement, our full implementation is made publicly available on GitHub. https://github.com/aralab-unr/ESM_ICP","sentences":["Point cloud registration is a fundamental problem in computer vision and robotics, involving the alignment of 3D point sets captured from varying viewpoints using depth sensors such as LiDAR or structured light.","In modern robotic systems, especially those focused on mapping, it is essential to merge multiple views of the same environment accurately.","However, state-of-the-art registration techniques often struggle when large rotational differences exist between point sets or when the data is significantly corrupted by sensor noise.","These challenges can lead to misalignments and, consequently, to inaccurate or distorted 3D reconstructions.","In this work, we address both these limitations by proposing a robust modification to the classic Iterative Closest Point (ICP) algorithm.","Our method, termed Exponential Similarity Matrix ICP (ESM-ICP), integrates a Gaussian-inspired exponential weighting scheme to construct a similarity matrix that dynamically adapts across iterations.","This matrix facilitates improved estimation of both rotational and translational components during alignment.","We demonstrate the robustness of ESM-ICP in two challenging scenarios: (i) large rotational discrepancies between the source and target point clouds, and (ii) data corrupted by non-Gaussian noise.","Our results show that ESM-ICP outperforms traditional geometric registration techniques as well as several recent learning-based methods.","To encourage reproducibility and community engagement, our full implementation is made publicly available on GitHub.","https://github.com/aralab-unr/ESM_ICP"],"url":"http://arxiv.org/abs/2505.04540v1"}
{"created":"2025-05-07 16:15:40","title":"Qualitative Analysis of $\u03c9$-Regular Objectives on Robust MDPs","abstract":"Robust Markov Decision Processes (RMDPs) generalize classical MDPs that consider uncertainties in transition probabilities by defining a set of possible transition functions. An objective is a set of runs (or infinite trajectories) of the RMDP, and the value for an objective is the maximal probability that the agent can guarantee against the adversarial environment. We consider (a) reachability objectives, where given a target set of states, the goal is to eventually arrive at one of them; and (b) parity objectives, which are a canonical representation for $\\omega$-regular objectives. The qualitative analysis problem asks whether the objective can be ensured with probability 1.   In this work, we study the qualitative problem for reachability and parity objectives on RMDPs without making any assumption over the structures of the RMDPs, e.g., unichain or aperiodic. Our contributions are twofold. We first present efficient algorithms with oracle access to uncertainty sets that solve qualitative problems of reachability and parity objectives. We then report experimental results demonstrating the effectiveness of our oracle-based approach on classical RMDP examples from the literature scaling up to thousands of states.","sentences":["Robust Markov Decision Processes (RMDPs) generalize classical MDPs that consider uncertainties in transition probabilities by defining a set of possible transition functions.","An objective is a set of runs (or infinite trajectories) of the RMDP, and the value for an objective is the maximal probability that the agent can guarantee against the adversarial environment.","We consider (a) reachability objectives, where given a target set of states, the goal is to eventually arrive at one of them; and (b) parity objectives, which are a canonical representation for $\\omega$-regular objectives.","The qualitative analysis problem asks whether the objective can be ensured with probability 1.   ","In this work, we study the qualitative problem for reachability and parity objectives on RMDPs without making any assumption over the structures of the RMDPs, e.g., unichain or aperiodic.","Our contributions are twofold.","We first present efficient algorithms with oracle access to uncertainty sets that solve qualitative problems of reachability and parity objectives.","We then report experimental results demonstrating the effectiveness of our oracle-based approach on classical RMDP examples from the literature scaling up to thousands of states."],"url":"http://arxiv.org/abs/2505.04539v1"}
{"created":"2025-05-07 16:13:54","title":"Light Spanners with Small Hop-Diameter","abstract":"Lightness, sparsity, and hop-diameter are the fundamental parameters of geometric spanners. Arya et al. [STOC'95] showed in their seminal work that there exists a construction of Euclidean $(1+\\varepsilon)$-spanners with hop-diameter $O(\\log n)$ and lightness $O(\\log n)$. They also gave a general tradeoff of hop-diameter $k$ and sparsity $O(\\alpha_k(n))$, where $\\alpha_k$ is a very slowly growing inverse of an Ackermann-style function. The former combination of logarithmic hop-diameter and lightness is optimal due to the lower bound by Dinitz et al. [FOCS'08]. Later, Elkin and Solomon [STOC'13] generalized the light spanner construction to doubling metrics and extended the tradeoff for more values of hop-diameter $k$. In a recent line of work [SoCG'22, SoCG'23], Le et al. proved that the aforementioned tradeoff between the hop-diameter and sparsity is tight for every choice of hop-diameter $k$. A fundamental question remains: What is the optimal tradeoff between the hop-diameter and lightness for every value of $k$?   In this paper, we present a general framework for constructing light spanners with small hop-diameter. Our framework is based on tree covers. In particular, we show that if a metric admits a tree cover with $\\gamma$ trees, stretch $t$, and lightness $L$, then it also admits a $t$-spanner with hop-diameter $k$ and lightness $O(kn^{2/k}\\cdot \\gamma L)$. Further, we note that the tradeoff for trees is tight due to a construction in uniform line metric, which is perhaps the simplest tree metric. As a direct consequence of this framework, we obtain a tight tradeoff between lightness and hop-diameter for doubling metrics in the entire regime of $k$.","sentences":["Lightness, sparsity, and hop-diameter are the fundamental parameters of geometric spanners.","Arya et al.","[STOC'95] showed in their seminal work that there exists a construction of Euclidean $(1+\\varepsilon)$-spanners with hop-diameter $O(\\log n)$ and lightness $O(\\log n)$. They also gave a general tradeoff of hop-diameter $k$ and sparsity $O(\\alpha_k(n))$, where $\\alpha_k$ is a very slowly growing inverse of an Ackermann-style function.","The former combination of logarithmic hop-diameter and lightness is optimal due to the lower bound by Dinitz et al.","[FOCS'08].","Later, Elkin and Solomon [STOC'13] generalized the light spanner construction to doubling metrics and extended the tradeoff for more values of hop-diameter $k$. In a recent line of work","[SoCG'22, SoCG'23], Le et al. proved that the aforementioned tradeoff between the hop-diameter and sparsity is tight for every choice of hop-diameter $k$. A fundamental question remains: What is the optimal tradeoff between the hop-diameter and lightness for every value of $k$?   ","In this paper, we present a general framework for constructing light spanners with small hop-diameter.","Our framework is based on tree covers.","In particular, we show that if a metric admits a tree cover with $\\gamma$ trees, stretch $t$, and lightness $L$, then it also admits a $t$-spanner with hop-diameter $k$ and lightness $O(kn^{2/k}\\cdot \\gamma L)$. Further, we note that the tradeoff for trees is tight due to a construction in uniform line metric, which is perhaps the simplest tree metric.","As a direct consequence of this framework, we obtain a tight tradeoff between lightness and hop-diameter for doubling metrics in the entire regime of $k$."],"url":"http://arxiv.org/abs/2505.04536v1"}
{"created":"2025-05-07 16:13:21","title":"Communication-Efficient Federated Fine-Tuning of Language Models via Dynamic Update Schedules","abstract":"Federated learning (FL) makes it possible to train models on data that would otherwise remain untapped and inaccessible. Simultaneously, pre-trained language models (LMs) have emerged as indispensable tools in modern workflows. These models exhibit extraordinary capabilities and are easily adapted to downstream tasks. This opens one of the most exciting frontiers in FL: fine-tuning LMs. However, a persistent challenge in FL is the frequent, rigid communication of parameters, a problem which is magnified by the sheer size of these modern models. Currently, the FedOpt family of algorithms is the prevailing approach in FL, though it relies on fixed, heuristic intervals for model synchronization. Recently, the FDA algorithm introduced a dynamic alternative by monitoring training progress, but it came with its own drawbacks; namely, a hard-to-tune threshold parameter and a rigid synchronization scheme. In this work, we introduce the FDA-Opt family of algorithms -- a unified generalization that extends the principles behind both FDA and FedOpt, while resolving their core limitations. We evaluate our approach on fine-tuning LMs across a range of downstream NLP tasks, and demonstrate that it consistently outperforms FedOpt -- even when FDA-Opt operates under hyper-parameter settings originally optimized for its competitors. In other words, we show that FDA-Opt is a practical, drop-in replacement for FedOpt in modern FL libraries and systems: it requires no additional configuration and delivers superior performance out of the box.","sentences":["Federated learning (FL) makes it possible to train models on data that would otherwise remain untapped and inaccessible.","Simultaneously, pre-trained language models (LMs) have emerged as indispensable tools in modern workflows.","These models exhibit extraordinary capabilities and are easily adapted to downstream tasks.","This opens one of the most exciting frontiers in FL: fine-tuning LMs.","However, a persistent challenge in FL is the frequent, rigid communication of parameters, a problem which is magnified by the sheer size of these modern models.","Currently, the FedOpt family of algorithms is the prevailing approach in FL, though it relies on fixed, heuristic intervals for model synchronization.","Recently, the FDA algorithm introduced a dynamic alternative by monitoring training progress, but it came with its own drawbacks; namely, a hard-to-tune threshold parameter and a rigid synchronization scheme.","In this work, we introduce the FDA-Opt family of algorithms -- a unified generalization that extends the principles behind both FDA and FedOpt, while resolving their core limitations.","We evaluate our approach on fine-tuning LMs across a range of downstream NLP tasks, and demonstrate that it consistently outperforms FedOpt -- even when FDA-Opt operates under hyper-parameter settings originally optimized for its competitors.","In other words, we show that FDA-Opt is a practical, drop-in replacement for FedOpt in modern FL libraries and systems: it requires no additional configuration and delivers superior performance out of the box."],"url":"http://arxiv.org/abs/2505.04535v1"}
{"created":"2025-05-07 16:04:45","title":"Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review","abstract":"Generative language modelling has surged in popularity with the emergence of services such as ChatGPT and Google Gemini. While these models have demonstrated transformative potential in productivity and communication, they overwhelmingly cater to high-resource languages like English. This has amplified concerns over linguistic inequality in natural language processing (NLP). This paper presents the first systematic review focused specifically on strategies to address data scarcity in generative language modelling for low-resource languages (LRL). Drawing from 54 studies, we identify, categorise and evaluate technical approaches, including monolingual data augmentation, back-translation, multilingual training, and prompt engineering, across generative tasks. We also analyse trends in architecture choices, language family representation, and evaluation methods. Our findings highlight a strong reliance on transformer-based models, a concentration on a small subset of LRLs, and a lack of consistent evaluation across studies. We conclude with recommendations for extending these methods to a wider range of LRLs and outline open challenges in building equitable generative language systems. Ultimately, this review aims to support researchers and developers in building inclusive AI tools for underrepresented languages, a necessary step toward empowering LRL speakers and the preservation of linguistic diversity in a world increasingly shaped by large-scale language technologies.","sentences":["Generative language modelling has surged in popularity with the emergence of services such as ChatGPT and Google Gemini.","While these models have demonstrated transformative potential in productivity and communication, they overwhelmingly cater to high-resource languages like English.","This has amplified concerns over linguistic inequality in natural language processing (NLP).","This paper presents the first systematic review focused specifically on strategies to address data scarcity in generative language modelling for low-resource languages (LRL).","Drawing from 54 studies, we identify, categorise and evaluate technical approaches, including monolingual data augmentation, back-translation, multilingual training, and prompt engineering, across generative tasks.","We also analyse trends in architecture choices, language family representation, and evaluation methods.","Our findings highlight a strong reliance on transformer-based models, a concentration on a small subset of LRLs, and a lack of consistent evaluation across studies.","We conclude with recommendations for extending these methods to a wider range of LRLs and outline open challenges in building equitable generative language systems.","Ultimately, this review aims to support researchers and developers in building inclusive AI tools for underrepresented languages, a necessary step toward empowering LRL speakers and the preservation of linguistic diversity in a world increasingly shaped by large-scale language technologies."],"url":"http://arxiv.org/abs/2505.04531v1"}
{"created":"2025-05-07 16:02:46","title":"RAFT: Robust Augmentation of FeaTures for Image Segmentation","abstract":"Image segmentation is a powerful computer vision technique for scene understanding. However, real-world deployment is stymied by the need for high-quality, meticulously labeled datasets. Synthetic data provides high-quality labels while reducing the need for manual data collection and annotation. However, deep neural networks trained on synthetic data often face the Syn2Real problem, leading to poor performance in real-world deployments.   To mitigate the aforementioned gap in image segmentation, we propose RAFT, a novel framework for adapting image segmentation models using minimal labeled real-world data through data and feature augmentations, as well as active learning. To validate RAFT, we perform experiments on the synthetic-to-real \"SYNTHIA->Cityscapes\" and \"GTAV->Cityscapes\" benchmarks. We managed to surpass the previous state of the art, HALO. SYNTHIA->Cityscapes experiences an improvement in mIoU* upon domain adaptation of 2.1%/79.9%, and GTAV->Cityscapes experiences a 0.4%/78.2% improvement in mIoU. Furthermore, we test our approach on the real-to-real benchmark of \"Cityscapes->ACDC\", and again surpass HALO, with a gain in mIoU upon adaptation of 1.3%/73.2%. Finally, we examine the effect of the allocated annotation budget and various components of RAFT upon the final transfer mIoU.","sentences":["Image segmentation is a powerful computer vision technique for scene understanding.","However, real-world deployment is stymied by the need for high-quality, meticulously labeled datasets.","Synthetic data provides high-quality labels while reducing the need for manual data collection and annotation.","However, deep neural networks trained on synthetic data often face the Syn2Real problem, leading to poor performance in real-world deployments.   ","To mitigate the aforementioned gap in image segmentation, we propose RAFT, a novel framework for adapting image segmentation models using minimal labeled real-world data through data and feature augmentations, as well as active learning.","To validate RAFT, we perform experiments on the synthetic-to-real \"SYNTHIA->Cityscapes\" and \"GTAV->Cityscapes\" benchmarks.","We managed to surpass the previous state of the art, HALO.","SYNTHIA->Cityscapes experiences an improvement in mIoU* upon domain adaptation of 2.1%/79.9%, and GTAV->Cityscapes experiences a 0.4%/78.2% improvement in mIoU. Furthermore, we test our approach on the real-to-real benchmark of \"Cityscapes->ACDC\", and again surpass HALO, with a gain in mIoU upon adaptation of 1.3%/73.2%.","Finally, we examine the effect of the allocated annotation budget and various components of RAFT upon the final transfer mIoU."],"url":"http://arxiv.org/abs/2505.04529v1"}
{"created":"2025-05-07 16:02:14","title":"Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving","abstract":"As a seemingly self-explanatory task, problem-solving has been a significant component of science and engineering. However, a general yet concrete formulation of problem-solving itself is missing. With the recent development of AI-based problem-solving agents, the demand for process-level verifiability is rapidly increasing yet underexplored. To fill these gaps, we present a principled formulation of problem-solving as a deterministic Markov decision process; a novel framework, FPS (Formal Problem-Solving), which utilizes existing FTP (formal theorem proving) environments to perform process-verified problem-solving; and D-FPS (Deductive FPS), decoupling solving and answer verification for better human-alignment. The expressiveness, soundness and completeness of the frameworks are proven. We construct three benchmarks on problem-solving: FormalMath500, a formalization of a subset of the MATH500 benchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP benchmarks MiniF2F and PutnamBench. For faithful, interpretable, and human-aligned evaluation, we propose RPE (Restricted Propositional Equivalence), a symbolic approach to determine the correctness of answers by formal verification. We evaluate four prevalent FTP models and two prompting methods as baselines, solving at most 23.77% of FormalMath500, 27.47% of MiniF2F-Solving, and 0.31% of PutnamBench-Solving.","sentences":["As a seemingly self-explanatory task, problem-solving has been a significant component of science and engineering.","However, a general yet concrete formulation of problem-solving itself is missing.","With the recent development of AI-based problem-solving agents, the demand for process-level verifiability is rapidly increasing yet underexplored.","To fill these gaps, we present a principled formulation of problem-solving as a deterministic Markov decision process; a novel framework, FPS (Formal Problem-Solving), which utilizes existing FTP (formal theorem proving) environments to perform process-verified problem-solving; and D-FPS (Deductive FPS), decoupling solving and answer verification for better human-alignment.","The expressiveness, soundness and completeness of the frameworks are proven.","We construct three benchmarks on problem-solving: FormalMath500, a formalization of a subset of the MATH500 benchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP benchmarks MiniF2F and PutnamBench.","For faithful, interpretable, and human-aligned evaluation, we propose RPE (Restricted Propositional Equivalence), a symbolic approach to determine the correctness of answers by formal verification.","We evaluate four prevalent FTP models and two prompting methods as baselines, solving at most 23.77% of FormalMath500, 27.47% of MiniF2F-Solving, and 0.31% of PutnamBench-Solving."],"url":"http://arxiv.org/abs/2505.04528v1"}
{"created":"2025-05-07 15:59:45","title":"DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once","abstract":"Visible and infrared image fusion is one of the most crucial tasks in the field of image fusion, aiming to generate fused images with clear structural information and high-quality texture features for high-level vision tasks. However, when faced with severe illumination degradation in visible images, the fusion results of existing image fusion methods often exhibit blurry and dim visual effects, posing major challenges for autonomous driving. To this end, a Darkness-Free network is proposed to handle Visible and infrared image disentanglement and fusion all at Once (DFVO), which employs a cascaded multi-task approach to replace the traditional two-stage cascaded training (enhancement and fusion), addressing the issue of information entropy loss caused by hierarchical data transmission. Specifically, we construct a latent-common feature extractor (LCFE) to obtain latent features for the cascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised to acquire high-frequency semantic information. Secondly, we design a hyper cross-attention module (HCAM) to extract low-frequency information and preserve texture features from source images. Finally, a relevant loss function is designed to guide the holistic network learning, thereby achieving better image fusion. Extensive experiments demonstrate that our proposed approach outperforms state-of-the-art alternatives in terms of qualitative and quantitative evaluations. Particularly, DFVO can generate clearer, more informative, and more evenly illuminated fusion results in the dark environments, achieving best performance on the LLVIP dataset with 63.258 dB PSNR and 0.724 CC, providing more effective information for high-level vision tasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.","sentences":["Visible and infrared image fusion is one of the most crucial tasks in the field of image fusion, aiming to generate fused images with clear structural information and high-quality texture features for high-level vision tasks.","However, when faced with severe illumination degradation in visible images, the fusion results of existing image fusion methods often exhibit blurry and dim visual effects, posing major challenges for autonomous driving.","To this end, a Darkness-Free network is proposed to handle Visible and infrared image disentanglement and fusion all at Once (DFVO), which employs a cascaded multi-task approach to replace the traditional two-stage cascaded training (enhancement and fusion), addressing the issue of information entropy loss caused by hierarchical data transmission.","Specifically, we construct a latent-common feature extractor (LCFE) to obtain latent features for the cascaded tasks strategy.","Firstly, a details-extraction module (DEM) is devised to acquire high-frequency semantic information.","Secondly, we design a hyper cross-attention module (HCAM) to extract low-frequency information and preserve texture features from source images.","Finally, a relevant loss function is designed to guide the holistic network learning, thereby achieving better image fusion.","Extensive experiments demonstrate that our proposed approach outperforms state-of-the-art alternatives in terms of qualitative and quantitative evaluations.","Particularly, DFVO can generate clearer, more informative, and more evenly illuminated fusion results in the dark environments, achieving best performance on the LLVIP dataset with 63.258 dB PSNR and 0.724 CC, providing more effective information for high-level vision tasks.","Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO."],"url":"http://arxiv.org/abs/2505.04526v1"}
{"created":"2025-05-07 15:59:19","title":"On some improvements to Unbounded Minimax","abstract":"This paper presents the first experimental evaluation of four previously untested modifications of Unbounded Best-First Minimax algorithm. This algorithm explores the game tree by iteratively expanding the most promising sequences of actions based on the current partial game tree. We first evaluate the use of transposition tables, which convert the game tree into a directed acyclic graph by merging duplicate states. Second, we compare the original algorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which differs in its backpropagation strategy: instead of stopping when a stable value is encountered, it updates values up to the root. This change slightly improves performance when value ties or transposition tables are involved. Third, we assess replacing the exact terminal evaluation function with the learned heuristic function. While beneficial when exact evaluations are costly, this modification reduces performance in inexpensive settings. Finally, we examine the impact of the completion technique that prioritizes resolved winning states and avoids resolved losing states. This technique also improves performance. Overall, our findings highlight how targeted modifications can enhance the efficiency of Unbounded Best-First Minimax.","sentences":["This paper presents the first experimental evaluation of four previously untested modifications of Unbounded Best-First Minimax algorithm.","This algorithm explores the game tree by iteratively expanding the most promising sequences of actions based on the current partial game tree.","We first evaluate the use of transposition tables, which convert the game tree into a directed acyclic graph by merging duplicate states.","Second, we compare the original algorithm by Korf & Chickering with the variant proposed by Cohen-Solal, which differs in its backpropagation strategy: instead of stopping when a stable value is encountered, it updates values up to the root.","This change slightly improves performance when value ties or transposition tables are involved.","Third, we assess replacing the exact terminal evaluation function with the learned heuristic function.","While beneficial when exact evaluations are costly, this modification reduces performance in inexpensive settings.","Finally, we examine the impact of the completion technique that prioritizes resolved winning states and avoids resolved losing states.","This technique also improves performance.","Overall, our findings highlight how targeted modifications can enhance the efficiency of Unbounded Best-First Minimax."],"url":"http://arxiv.org/abs/2505.04525v1"}
{"created":"2025-05-07 15:57:53","title":"Edge-GPU Based Face Tracking for Face Detection and Recognition Acceleration","abstract":"Cost-effective machine vision systems dedicated to real-time and accurate face detection and recognition in public places are crucial for many modern applications. However, despite their high performance, which could be reached using specialized edge or cloud AI hardware accelerators, there is still room for improvement in throughput and power consumption. This paper aims to suggest a combined hardware-software approach that optimizes face detection and recognition systems on one of the latest edge GPUs, namely NVIDIA Jetson AGX Orin. First, it leverages the simultaneous usage of all its hardware engines to improve processing time. This offers an improvement over previous works where these tasks were mainly allocated automatically and exclusively to the CPU or, to a higher extent, to the GPU core. Additionally, the paper suggests integrating a face tracker module to avoid redundantly running the face recognition algorithm for every frame but only when a new face appears in the scene. The results of extended experiments suggest that simultaneous usage of all the hardware engines that are available in the Orin GPU and tracker integration into the pipeline yield an impressive throughput of 290 FPS (frames per second) on 1920 x 1080 input size frames containing in average of 6 faces/frame. Additionally, a substantial saving of power consumption of around 800 mW was achieved when compared to running the task on the CPU/GPU engines only and without integrating a tracker into the Orin GPU\\'92s pipeline. This hardware-codesign approach can pave the way to design high-performance machine vision systems at the edge, critically needed in video monitoring in public places where several nearby cameras are usually deployed for a same scene.","sentences":["Cost-effective machine vision systems dedicated to real-time and accurate face detection and recognition in public places are crucial for many modern applications.","However, despite their high performance, which could be reached using specialized edge or cloud AI hardware accelerators, there is still room for improvement in throughput and power consumption.","This paper aims to suggest a combined hardware-software approach that optimizes face detection and recognition systems on one of the latest edge GPUs, namely NVIDIA Jetson AGX Orin.","First, it leverages the simultaneous usage of all its hardware engines to improve processing time.","This offers an improvement over previous works where these tasks were mainly allocated automatically and exclusively to the CPU or, to a higher extent, to the GPU core.","Additionally, the paper suggests integrating a face tracker module to avoid redundantly running the face recognition algorithm for every frame but only when a new face appears in the scene.","The results of extended experiments suggest that simultaneous usage of all the hardware engines that are available in the Orin GPU and tracker integration into the pipeline yield an impressive throughput of 290 FPS (frames per second) on 1920 x 1080 input size frames containing in average of 6 faces/frame.","Additionally, a substantial saving of power consumption of around 800 mW was achieved when compared to running the task on the CPU/GPU engines only and without integrating a tracker into the Orin GPU\\'92s pipeline.","This hardware-codesign approach can pave the way to design high-performance machine vision systems at the edge, critically needed in video monitoring in public places where several nearby cameras are usually deployed for a same scene."],"url":"http://arxiv.org/abs/2505.04524v1"}
{"created":"2025-05-07 15:53:56","title":"Text2CT: Towards 3D CT Volume Generation from Free-text Descriptions Using Diffusion Model","abstract":"Generating 3D CT volumes from descriptive free-text inputs presents a transformative opportunity in diagnostics and research. In this paper, we introduce Text2CT, a novel approach for synthesizing 3D CT volumes from textual descriptions using the diffusion model. Unlike previous methods that rely on fixed-format text input, Text2CT employs a novel prompt formulation that enables generation from diverse, free-text descriptions. The proposed framework encodes medical text into latent representations and decodes them into high-resolution 3D CT scans, effectively bridging the gap between semantic text inputs and detailed volumetric representations in a unified 3D framework. Our method demonstrates superior performance in preserving anatomical fidelity and capturing intricate structures as described in the input text. Extensive evaluations show that our approach achieves state-of-the-art results, offering promising potential applications in diagnostics, and data augmentation.","sentences":["Generating 3D CT volumes from descriptive free-text inputs presents a transformative opportunity in diagnostics and research.","In this paper, we introduce Text2CT, a novel approach for synthesizing 3D CT volumes from textual descriptions using the diffusion model.","Unlike previous methods that rely on fixed-format text input, Text2CT employs a novel prompt formulation that enables generation from diverse, free-text descriptions.","The proposed framework encodes medical text into latent representations and decodes them into high-resolution 3D CT scans, effectively bridging the gap between semantic text inputs and detailed volumetric representations in a unified 3D framework.","Our method demonstrates superior performance in preserving anatomical fidelity and capturing intricate structures as described in the input text.","Extensive evaluations show that our approach achieves state-of-the-art results, offering promising potential applications in diagnostics, and data augmentation."],"url":"http://arxiv.org/abs/2505.04522v1"}
{"created":"2025-05-07 15:52:06","title":"Comparative Analysis of Carbon Footprint in Manual vs. LLM-Assisted Code Development","abstract":"Large Language Models (LLM) have significantly transformed various domains, including software development. These models assist programmers in generating code, potentially increasing productivity and efficiency. However, the environmental impact of utilising these AI models is substantial, given their high energy consumption during both training and inference stages. This research aims to compare the energy consumption of manual software development versus an LLM-assisted approach, using Codeforces as a simulation platform for software development. The goal is to quantify the environmental impact and propose strategies for minimising the carbon footprint of using LLM in software development. Our results show that the LLM-assisted code generation leads on average to 32.72 higher carbon footprint than the manual one. Moreover, there is a significant correlation between task complexity and the difference in the carbon footprint of the two approaches.","sentences":["Large Language Models (LLM) have significantly transformed various domains, including software development.","These models assist programmers in generating code, potentially increasing productivity and efficiency.","However, the environmental impact of utilising these AI models is substantial, given their high energy consumption during both training and inference stages.","This research aims to compare the energy consumption of manual software development versus an LLM-assisted approach, using Codeforces as a simulation platform for software development.","The goal is to quantify the environmental impact and propose strategies for minimising the carbon footprint of using LLM in software development.","Our results show that the LLM-assisted code generation leads on average to 32.72 higher carbon footprint than the manual one.","Moreover, there is a significant correlation between task complexity and the difference in the carbon footprint of the two approaches."],"url":"http://arxiv.org/abs/2505.04521v1"}
{"created":"2025-05-07 15:46:36","title":"Pangu Ultra MoE: How to Train Your Big MoE on Ascend NPUs","abstract":"Sparse large language models (LLMs) with Mixture of Experts (MoE) and close to a trillion parameters are dominating the realm of most capable language models. However, the massive model scale poses significant challenges for the underlying software and hardware systems. In this paper, we aim to uncover a recipe to harness such scale on Ascend NPUs. The key goals are better usage of the computing resources under the dynamic sparse model structures and materializing the expected performance gain on the actual hardware. To select model configurations suitable for Ascend NPUs without repeatedly running the expensive experiments, we leverage simulation to compare the trade-off of various model hyperparameters. This study led to Pangu Ultra MoE, a sparse LLM with 718 billion parameters, and we conducted experiments on the model to verify the simulation results. On the system side, we dig into Expert Parallelism to optimize the communication between NPU devices to reduce the synchronization overhead. We also optimize the memory efficiency within the devices to further reduce the parameter and activation management overhead. In the end, we achieve an MFU of 30.0% when training Pangu Ultra MoE, with performance comparable to that of DeepSeek R1, on 6K Ascend NPUs, and demonstrate that the Ascend system is capable of harnessing all the training stages of the state-of-the-art language models. Extensive experiments indicate that our recipe can lead to efficient training of large-scale sparse language models with MoE. We also study the behaviors of such models for future reference.","sentences":["Sparse large language models (LLMs) with Mixture of Experts (MoE) and close to a trillion parameters are dominating the realm of most capable language models.","However, the massive model scale poses significant challenges for the underlying software and hardware systems.","In this paper, we aim to uncover a recipe to harness such scale on Ascend NPUs.","The key goals are better usage of the computing resources under the dynamic sparse model structures and materializing the expected performance gain on the actual hardware.","To select model configurations suitable for Ascend NPUs without repeatedly running the expensive experiments, we leverage simulation to compare the trade-off of various model hyperparameters.","This study led to Pangu Ultra MoE, a sparse LLM with 718 billion parameters, and we conducted experiments on the model to verify the simulation results.","On the system side, we dig into Expert Parallelism to optimize the communication between NPU devices to reduce the synchronization overhead.","We also optimize the memory efficiency within the devices to further reduce the parameter and activation management overhead.","In the end, we achieve an MFU of 30.0% when training Pangu Ultra MoE, with performance comparable to that of DeepSeek R1, on 6K Ascend NPUs, and demonstrate that the Ascend system is capable of harnessing all the training stages of the state-of-the-art language models.","Extensive experiments indicate that our recipe can lead to efficient training of large-scale sparse language models with MoE. We also study the behaviors of such models for future reference."],"url":"http://arxiv.org/abs/2505.04519v1"}
{"created":"2025-05-07 15:45:04","title":"User and Recommender Behavior Over Time: Contextualizing Activity, Effectiveness, Diversity, and Fairness in Book Recommendation","abstract":"Data is an essential resource for studying recommender systems. While there has been significant work on improving and evaluating state-of-the-art models and measuring various properties of recommender system outputs, less attention has been given to the data itself, particularly how data has changed over time. Such documentation and analysis provide guidance and context for designing and evaluating recommender systems, particularly for evaluation designs making use of time (e.g., temporal splitting). In this paper, we present a temporal explanatory analysis of the UCSD Book Graph dataset scraped from Goodreads, a social reading and recommendation platform active since 2006. We measure the book interaction data using a set of activity, diversity, and fairness metrics; we then train a set of collaborative filtering algorithms on rolling training windows to observe how the same measures evolve over time in the recommendations. Additionally, we explore whether the introduction of algorithmic recommendations in 2011 was followed by observable changes in user or recommender system behavior.","sentences":["Data is an essential resource for studying recommender systems.","While there has been significant work on improving and evaluating state-of-the-art models and measuring various properties of recommender system outputs, less attention has been given to the data itself, particularly how data has changed over time.","Such documentation and analysis provide guidance and context for designing and evaluating recommender systems, particularly for evaluation designs making use of time (e.g., temporal splitting).","In this paper, we present a temporal explanatory analysis of the UCSD Book Graph dataset scraped from Goodreads, a social reading and recommendation platform active since 2006.","We measure the book interaction data using a set of activity, diversity, and fairness metrics; we then train a set of collaborative filtering algorithms on rolling training windows to observe how the same measures evolve over time in the recommendations.","Additionally, we explore whether the introduction of algorithmic recommendations in 2011 was followed by observable changes in user or recommender system behavior."],"url":"http://arxiv.org/abs/2505.04518v1"}
{"created":"2025-05-07 15:33:18","title":"HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation","abstract":"Customized video generation aims to produce videos featuring specific subjects under flexible user-defined conditions, yet existing methods often struggle with identity consistency and limited input modalities. In this paper, we propose HunyuanCustom, a multi-modal customized video generation framework that emphasizes subject consistency while supporting image, audio, video, and text conditions. Built upon HunyuanVideo, our model first addresses the image-text conditioned generation task by introducing a text-image fusion module based on LLaVA for enhanced multi-modal understanding, along with an image ID enhancement module that leverages temporal concatenation to reinforce identity features across frames. To enable audio- and video-conditioned generation, we further propose modality-specific condition injection mechanisms: an AudioNet module that achieves hierarchical alignment via spatial cross-attention, and a video-driven injection module that integrates latent-compressed conditional video through a patchify-based feature-alignment network. Extensive experiments on single- and multi-subject scenarios demonstrate that HunyuanCustom significantly outperforms state-of-the-art open- and closed-source methods in terms of ID consistency, realism, and text-video alignment. Moreover, we validate its robustness across downstream tasks, including audio and video-driven customized video generation. Our results highlight the effectiveness of multi-modal conditioning and identity-preserving strategies in advancing controllable video generation. All the code and models are available at https://hunyuancustom.github.io.","sentences":["Customized video generation aims to produce videos featuring specific subjects under flexible user-defined conditions, yet existing methods often struggle with identity consistency and limited input modalities.","In this paper, we propose HunyuanCustom, a multi-modal customized video generation framework that emphasizes subject consistency while supporting image, audio, video, and text conditions.","Built upon HunyuanVideo, our model first addresses the image-text conditioned generation task by introducing a text-image fusion module based on LLaVA for enhanced multi-modal understanding, along with an image ID enhancement module that leverages temporal concatenation to reinforce identity features across frames.","To enable audio-","and video-conditioned generation, we further propose modality-specific condition injection mechanisms: an AudioNet module that achieves hierarchical alignment via spatial cross-attention, and a video-driven injection module that integrates latent-compressed conditional video through a patchify-based feature-alignment network.","Extensive experiments on single- and multi-subject scenarios demonstrate that HunyuanCustom significantly outperforms state-of-the-art open- and closed-source methods in terms of ID consistency, realism, and text-video alignment.","Moreover, we validate its robustness across downstream tasks, including audio and video-driven customized video generation.","Our results highlight the effectiveness of multi-modal conditioning and identity-preserving strategies in advancing controllable video generation.","All the code and models are available at https://hunyuancustom.github.io."],"url":"http://arxiv.org/abs/2505.04512v1"}
{"created":"2025-05-07 15:27:59","title":"Detecting Spelling and Grammatical Anomalies in Russian Poetry Texts","abstract":"The quality of natural language texts in fine-tuning datasets plays a critical role in the performance of generative models, particularly in computational creativity tasks such as poem or song lyric generation. Fluency defects in generated poems significantly reduce their value. However, training texts are often sourced from internet-based platforms without stringent quality control, posing a challenge for data engineers to manage defect levels effectively.   To address this issue, we propose the use of automated linguistic anomaly detection to identify and filter out low-quality texts from training datasets for creative models. In this paper, we present a comprehensive comparison of unsupervised and supervised text anomaly detection approaches, utilizing both synthetic and human-labeled datasets. We also introduce the RUPOR dataset, a collection of Russian-language human-labeled poems designed for cross-sentence grammatical error detection, and provide the full evaluation code. Our work aims to empower the community with tools and insights to improve the quality of training datasets for generative models in creative domains.","sentences":["The quality of natural language texts in fine-tuning datasets plays a critical role in the performance of generative models, particularly in computational creativity tasks such as poem or song lyric generation.","Fluency defects in generated poems significantly reduce their value.","However, training texts are often sourced from internet-based platforms without stringent quality control, posing a challenge for data engineers to manage defect levels effectively.   ","To address this issue, we propose the use of automated linguistic anomaly detection to identify and filter out low-quality texts from training datasets for creative models.","In this paper, we present a comprehensive comparison of unsupervised and supervised text anomaly detection approaches, utilizing both synthetic and human-labeled datasets.","We also introduce the RUPOR dataset, a collection of Russian-language human-labeled poems designed for cross-sentence grammatical error detection, and provide the full evaluation code.","Our work aims to empower the community with tools and insights to improve the quality of training datasets for generative models in creative domains."],"url":"http://arxiv.org/abs/2505.04507v1"}
{"created":"2025-05-07 15:22:17","title":"Leveraging Simultaneous Usage of Edge GPU Hardware Engines for Video Face Detection and Recognition","abstract":"Video face detection and recognition in public places at the edge is required in several applications, such as security reinforcement and contactless access to authorized venues. This paper aims to maximize the simultaneous usage of hardware engines available in edge GPUs nowadays by leveraging the concurrency and pipelining of tasks required for face detection and recognition. This also includes the video decoding task, which is required in most face monitoring applications as the video streams are usually carried via Gbps Ethernet network. This constitutes an improvement over previous works where the tasks are usually allocated to a single engine due to the lack of a unified and automated framework that simultaneously explores all hardware engines. In addition, previously, the input faces were usually embedded in still images or within raw video streams that overlook the burst delay caused by the decoding stage. The results on real-life video streams suggest that simultaneously using all the hardware engines available in the recent NVIDIA edge Orin GPU, higher throughput, and a slight saving of power consumption of around 300 mW, accounting for around 5%, have been achieved while satisfying the real-time performance constraint. The performance gets even higher by considering several video streams simultaneously. Further performance improvement could have been obtained if the number of shuffle layers that were created by the tensor RT framework for the face recognition task was lower. Thus, the paper suggests some hardware improvements to the existing edge GPU processors to enhance their performance even higher.","sentences":["Video face detection and recognition in public places at the edge is required in several applications, such as security reinforcement and contactless access to authorized venues.","This paper aims to maximize the simultaneous usage of hardware engines available in edge GPUs nowadays by leveraging the concurrency and pipelining of tasks required for face detection and recognition.","This also includes the video decoding task, which is required in most face monitoring applications as the video streams are usually carried via Gbps Ethernet network.","This constitutes an improvement over previous works where the tasks are usually allocated to a single engine due to the lack of a unified and automated framework that simultaneously explores all hardware engines.","In addition, previously, the input faces were usually embedded in still images or within raw video streams that overlook the burst delay caused by the decoding stage.","The results on real-life video streams suggest that simultaneously using all the hardware engines available in the recent NVIDIA edge Orin GPU, higher throughput, and a slight saving of power consumption of around 300 mW, accounting for around 5%, have been achieved while satisfying the real-time performance constraint.","The performance gets even higher by considering several video streams simultaneously.","Further performance improvement could have been obtained if the number of shuffle layers that were created by the tensor RT framework for the face recognition task was lower.","Thus, the paper suggests some hardware improvements to the existing edge GPU processors to enhance their performance even higher."],"url":"http://arxiv.org/abs/2505.04502v1"}
{"created":"2025-05-07 15:21:02","title":"VeriFast's separation logic: a higher-order(ish) logic without laters for modular verification of fine-grained concurrent programs","abstract":"VeriFast is one of the leading tools for semi-automated modular formal program verification. A central feature of VeriFast is its support for higher-order ghost code, which enables its support for expressively specifying fine-grained concurrent modules, without the need for a later modality. We present the first formalization and soundness proof for this aspect of VeriFast's logic.","sentences":["VeriFast is one of the leading tools for semi-automated modular formal program verification.","A central feature of VeriFast is its support for higher-order ghost code, which enables its support for expressively specifying fine-grained concurrent modules, without the need for a later modality.","We present the first formalization and soundness proof for this aspect of VeriFast's logic."],"url":"http://arxiv.org/abs/2505.04500v1"}
{"created":"2025-05-07 15:20:52","title":"Uncovering Key Features for Model-Driven Engineering of Complex Performance Indicators: A Scoping Review","abstract":"This paper addresses challenges of designing and managing Complex Performance Indicators (CPI), which amalgamate individual indicators to measure latent, yet crucial business factors like customer satisfaction or sustainability indices. Despite their significant value, designing and managing CPI is intricate; they evolve with rapidly changing business contexts and present comprehension and explanation challenges for end-users. Model-Driven Engineering (MDE) emerges as a potent solution to overcome these hurdles and ensure CPI adoption, though its application to CPI remains an understudied research area. While prior efforts targeted specific CPI modeling objectives, a comprehensive overview of literature advancements is lacking. This study addresses this gap by conducting a scoping review yielding dual outcomes: (1) a comprehensive mapping of modeling features in the literature and (2) a comparative analysis of the coverage offered by the modeling frameworks. These outcomes enhance CPI understanding in academic and practitioner circles and offer insights for future MDE CPI advancements.","sentences":["This paper addresses challenges of designing and managing Complex Performance Indicators (CPI), which amalgamate individual indicators to measure latent, yet crucial business factors like customer satisfaction or sustainability indices.","Despite their significant value, designing and managing CPI is intricate; they evolve with rapidly changing business contexts and present comprehension and explanation challenges for end-users.","Model-Driven Engineering (MDE) emerges as a potent solution to overcome these hurdles and ensure CPI adoption, though its application to CPI remains an understudied research area.","While prior efforts targeted specific CPI modeling objectives, a comprehensive overview of literature advancements is lacking.","This study addresses this gap by conducting a scoping review yielding dual outcomes: (1) a comprehensive mapping of modeling features in the literature and (2) a comparative analysis of the coverage offered by the modeling frameworks.","These outcomes enhance CPI understanding in academic and practitioner circles and offer insights for future MDE CPI advancements."],"url":"http://arxiv.org/abs/2505.04498v1"}
{"created":"2025-05-07 15:20:17","title":"Defining and Quantifying Creative Behavior in Popular Image Generators","abstract":"Creativity of generative AI models has been a subject of scientific debate in the last years, without a conclusive answer. In this paper, we study creativity from a practical perspective and introduce quantitative measures that help the user to choose a suitable AI model for a given task. We evaluated our measures on a number of popular image-to-image generation models, and the results of this suggest that our measures conform to human intuition.","sentences":["Creativity of generative AI models has been a subject of scientific debate in the last years, without a conclusive answer.","In this paper, we study creativity from a practical perspective and introduce quantitative measures that help the user to choose a suitable AI model for a given task.","We evaluated our measures on a number of popular image-to-image generation models, and the results of this suggest that our measures conform to human intuition."],"url":"http://arxiv.org/abs/2505.04497v1"}
{"created":"2025-05-07 15:17:38","title":"Model-Based AI planning and Execution Systems for Robotics","abstract":"Model-based planning and execution systems offer a principled approach to building flexible autonomous robots that can perform diverse tasks by automatically combining a host of basic skills. This idea is almost as old as modern robotics. Yet, while diverse general-purpose reasoning architectures have been proposed since, general-purpose systems that are integrated with modern robotic platforms have emerged only recently, starting with the influential ROSPlan system. Since then, a growing number of model-based systems for robot task-level control have emerged. In this paper, we consider the diverse design choices and issues existing systems attempt to address, the different solutions proposed so far, and suggest avenues for future development.","sentences":["Model-based planning and execution systems offer a principled approach to building flexible autonomous robots that can perform diverse tasks by automatically combining a host of basic skills.","This idea is almost as old as modern robotics.","Yet, while diverse general-purpose reasoning architectures have been proposed since, general-purpose systems that are integrated with modern robotic platforms have emerged only recently, starting with the influential ROSPlan system.","Since then, a growing number of model-based systems for robot task-level control have emerged.","In this paper, we consider the diverse design choices and issues existing systems attempt to address, the different solutions proposed so far, and suggest avenues for future development."],"url":"http://arxiv.org/abs/2505.04493v1"}
{"created":"2025-05-07 15:12:41","title":"Estimating Dynamic Soft Continuum Robot States From Boundaries","abstract":"Accurate state estimation is essential for effective control of robots. For soft robots, this task is particularly challenging because their states are inherently infinite-dimensional functions due to the robots' continuous deformability. Traditional sensing techniques, however, can only provide discrete measurements. Recently, a dynamic state estimation method known as a boundary observer was introduced, which leverages Cosserat rod theory to recover all infinite-dimensional states by measuring only the velocity twist at the robot's tip. In this work, we present a novel boundary observer that can also recover infinite-dimensional dynamic states, but instead relies on measuring the internal wrench at the robot's base. This design exploits the duality between the velocity twist at the tip and the internal wrench at the base, with both types of boundary observers being inspired by principles of energy dissipation. Despite the mathematical duality, the proposed approach offers a distinct advantage: it requires only a 6-axis force/torque sensor embedded at the base, eliminating the need for external sensing systems such as motion capture cameras. Moreover, combining both tip- and base-based techniques enhances energy dissipation, accelerates convergence, and improves estimation accuracy. We validate the proposed algorithms through both simulation studies and experiments based on tendon-driven continuum robots. Our results demonstrate that all boundary observers converge to the ground truth within 3 seconds, even with significantly deviated initial conditions. Furthermore, they recover from unknown perturbations and effectively track high-frequency vibrations. We also show that combining the dual techniques further improves convergence speed and accuracy. Finally, the computational efficiency of these algorithms indicates their feasibility for real-time state estimation.","sentences":["Accurate state estimation is essential for effective control of robots.","For soft robots, this task is particularly challenging because their states are inherently infinite-dimensional functions due to the robots' continuous deformability.","Traditional sensing techniques, however, can only provide discrete measurements.","Recently, a dynamic state estimation method known as a boundary observer was introduced, which leverages Cosserat rod theory to recover all infinite-dimensional states by measuring only the velocity twist at the robot's tip.","In this work, we present a novel boundary observer that can also recover infinite-dimensional dynamic states, but instead relies on measuring the internal wrench at the robot's base.","This design exploits the duality between the velocity twist at the tip and the internal wrench at the base, with both types of boundary observers being inspired by principles of energy dissipation.","Despite the mathematical duality, the proposed approach offers a distinct advantage: it requires only a 6-axis force/torque sensor embedded at the base, eliminating the need for external sensing systems such as motion capture cameras.","Moreover, combining both tip- and base-based techniques enhances energy dissipation, accelerates convergence, and improves estimation accuracy.","We validate the proposed algorithms through both simulation studies and experiments based on tendon-driven continuum robots.","Our results demonstrate that all boundary observers converge to the ground truth within 3 seconds, even with significantly deviated initial conditions.","Furthermore, they recover from unknown perturbations and effectively track high-frequency vibrations.","We also show that combining the dual techniques further improves convergence speed and accuracy.","Finally, the computational efficiency of these algorithms indicates their feasibility for real-time state estimation."],"url":"http://arxiv.org/abs/2505.04491v1"}
{"created":"2025-05-07 15:03:16","title":"\"I Can See Forever!\": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments","abstract":"The visually impaired population, especially the severely visually impaired, is currently large in scale, and daily activities pose significant challenges for them. Although many studies use large language and vision-language models to assist the blind, most focus on static content and fail to meet real-time perception needs in dynamic and complex environments, such as daily activities. To provide them with more effective intelligent assistance, it is imperative to incorporate advanced visual understanding technologies. Although real-time vision and speech interaction VideoLLMs demonstrate strong real-time visual understanding, no prior work has systematically evaluated their effectiveness in assisting visually impaired individuals. In this work, we conduct the first such evaluation. First, we construct a benchmark dataset (VisAssistDaily), covering three categories of assistive tasks for visually impaired individuals: Basic Skills, Home Life Tasks, and Social Life Tasks. The results show that GPT-4o achieves the highest task success rate. Next, we conduct a user study to evaluate the models in both closed-world and open-world scenarios, further exploring the practical challenges of applying VideoLLMs in assistive contexts. One key issue we identify is the difficulty current models face in perceiving potential hazards in dynamic environments. To address this, we build an environment-awareness dataset named SafeVid and introduce a polling mechanism that enables the model to proactively detect environmental risks. We hope this work provides valuable insights and inspiration for future research in this field.","sentences":["The visually impaired population, especially the severely visually impaired, is currently large in scale, and daily activities pose significant challenges for them.","Although many studies use large language and vision-language models to assist the blind, most focus on static content and fail to meet real-time perception needs in dynamic and complex environments, such as daily activities.","To provide them with more effective intelligent assistance, it is imperative to incorporate advanced visual understanding technologies.","Although real-time vision and speech interaction VideoLLMs demonstrate strong real-time visual understanding, no prior work has systematically evaluated their effectiveness in assisting visually impaired individuals.","In this work, we conduct the first such evaluation.","First, we construct a benchmark dataset (VisAssistDaily), covering three categories of assistive tasks for visually impaired individuals: Basic Skills, Home Life Tasks, and Social Life Tasks.","The results show that GPT-4o achieves the highest task success rate.","Next, we conduct a user study to evaluate the models in both closed-world and open-world scenarios, further exploring the practical challenges of applying VideoLLMs in assistive contexts.","One key issue we identify is the difficulty current models face in perceiving potential hazards in dynamic environments.","To address this, we build an environment-awareness dataset named SafeVid and introduce a polling mechanism that enables the model to proactively detect environmental risks.","We hope this work provides valuable insights and inspiration for future research in this field."],"url":"http://arxiv.org/abs/2505.04488v1"}
{"created":"2025-05-07 15:01:23","title":"A Design Space for the Critical Validation of LLM-Generated Tabular Data","abstract":"LLM-generated tabular data is creating new opportunities for data-driven applications in academia, business, and society. To leverage benefits like missing value imputation, labeling, and enrichment with context-aware attributes, LLM-generated data needs a critical validation process. The number of pioneering approaches is increasing fast, opening a promising validation space that, so far, remains unstructured. We present a design space for the critical validation of LLM-generated tabular data with two dimensions: First, the Analysis Granularity dimension: from within-attribute (single-item and multi-item) to across-attribute perspectives (1 x 1, 1 x m, and n x n). Second, the Data Source dimension: differentiating between LLM-generated values, ground truth values, explanations, and their combinations. We discuss analysis tasks for each dimension cross-cut, map 19 existing validation approaches, and discuss the characteristics of two approaches in detail, demonstrating descriptive power.","sentences":["LLM-generated tabular data is creating new opportunities for data-driven applications in academia, business, and society.","To leverage benefits like missing value imputation, labeling, and enrichment with context-aware attributes, LLM-generated data needs a critical validation process.","The number of pioneering approaches is increasing fast, opening a promising validation space that, so far, remains unstructured.","We present a design space for the critical validation of LLM-generated tabular data with two dimensions:","First, the Analysis Granularity dimension: from within-attribute (single-item and multi-item) to across-attribute perspectives (1 x 1, 1 x m, and n x n).","Second, the Data Source dimension: differentiating between LLM-generated values, ground truth values, explanations, and their combinations.","We discuss analysis tasks for each dimension cross-cut, map 19 existing validation approaches, and discuss the characteristics of two approaches in detail, demonstrating descriptive power."],"url":"http://arxiv.org/abs/2505.04487v1"}
{"created":"2025-05-07 14:59:23","title":"Efficient Flow Matching using Latent Variables","abstract":"Flow matching models have shown great potential in image generation tasks among probabilistic generative models. Building upon the ideas of continuous normalizing flows, flow matching models generalize the transport path of the diffusion models from a simple prior distribution to the data. Most flow matching models in the literature do not explicitly model the underlying structure/manifold in the target data when learning the flow from a simple source distribution like the standard Gaussian. This leads to inefficient learning, especially for many high-dimensional real-world datasets, which often reside in a low-dimensional manifold. Existing strategies of incorporating manifolds, including data with underlying multi-modal distribution, often require expensive training and hence frequently lead to suboptimal performance. To this end, we present \\texttt{Latent-CFM}, which provides simplified training/inference strategies to incorporate multi-modal data structures using pretrained deep latent variable models. Through experiments on multi-modal synthetic data and widely used image benchmark datasets, we show that \\texttt{Latent-CFM} exhibits improved generation quality with significantly less training ($\\sim 50\\%$ less in some cases) and computation than state-of-the-art flow matching models. Using a 2d Darcy flow dataset, we demonstrate that our approach generates more physically accurate samples than competitive approaches. In addition, through latent space analysis, we demonstrate that our approach can be used for conditional image generation conditioned on latent features.","sentences":["Flow matching models have shown great potential in image generation tasks among probabilistic generative models.","Building upon the ideas of continuous normalizing flows, flow matching models generalize the transport path of the diffusion models from a simple prior distribution to the data.","Most flow matching models in the literature do not explicitly model the underlying structure/manifold in the target data when learning the flow from a simple source distribution like the standard Gaussian.","This leads to inefficient learning, especially for many high-dimensional real-world datasets, which often reside in a low-dimensional manifold.","Existing strategies of incorporating manifolds, including data with underlying multi-modal distribution, often require expensive training and hence frequently lead to suboptimal performance.","To this end, we present \\texttt{Latent-CFM}, which provides simplified training/inference strategies to incorporate multi-modal data structures using pretrained deep latent variable models.","Through experiments on multi-modal synthetic data and widely used image benchmark datasets, we show that \\texttt{Latent-CFM} exhibits improved generation quality with significantly less training ($\\sim 50\\%$ less in some cases) and computation than state-of-the-art flow matching models.","Using a 2d Darcy flow dataset, we demonstrate that our approach generates more physically accurate samples than competitive approaches.","In addition, through latent space analysis, we demonstrate that our approach can be used for conditional image generation conditioned on latent features."],"url":"http://arxiv.org/abs/2505.04486v1"}
{"created":"2025-05-07 14:58:04","title":"FA-KPConv: Introducing Euclidean Symmetries to KPConv via Frame Averaging","abstract":"We present Frame-Averaging Kernel-Point Convolution (FA-KPConv), a neural network architecture built on top of the well-known KPConv, a widely adopted backbone for 3D point cloud analysis. Even though invariance and/or equivariance to Euclidean transformations are required for many common tasks, KPConv-based networks can only approximately achieve such properties when training on large datasets or with significant data augmentations. Using Frame Averaging, we allow to flexibly customize point cloud neural networks built with KPConv layers, by making them exactly invariant and/or equivariant to translations, rotations and/or reflections of the input point clouds. By simply wrapping around an existing KPConv-based network, FA-KPConv embeds geometrical prior knowledge into it while preserving the number of learnable parameters and not compromising any input information. We showcase the benefit of such an introduced bias for point cloud classification and point cloud registration, especially in challenging cases such as scarce training data or randomly rotated test data.","sentences":["We present Frame-Averaging Kernel-Point Convolution (FA-KPConv), a neural network architecture built on top of the well-known KPConv, a widely adopted backbone for 3D point cloud analysis.","Even though invariance and/or equivariance to Euclidean transformations are required for many common tasks, KPConv-based networks can only approximately achieve such properties when training on large datasets or with significant data augmentations.","Using Frame Averaging, we allow to flexibly customize point cloud neural networks built with KPConv layers, by making them exactly invariant and/or equivariant to translations, rotations and/or reflections of the input point clouds.","By simply wrapping around an existing KPConv-based network, FA-KPConv embeds geometrical prior knowledge into it while preserving the number of learnable parameters and not compromising any input information.","We showcase the benefit of such an introduced bias for point cloud classification and point cloud registration, especially in challenging cases such as scarce training data or randomly rotated test data."],"url":"http://arxiv.org/abs/2505.04485v1"}
{"created":"2025-05-07 14:52:02","title":"CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation","abstract":"Recently, Large Language Models (LLMs) have achieved significant success, prompting increased interest in expanding their generative capabilities beyond general text into domain-specific areas. This study investigates the generation of parametric sequences for computer-aided design (CAD) models using LLMs. This endeavor represents an initial step towards creating parametric 3D shapes with LLMs, as CAD model parameters directly correlate with shapes in three-dimensional space. Despite the formidable generative capacities of LLMs, this task remains challenging, as these models neither encounter parametric sequences during their pretraining phase nor possess direct awareness of 3D structures. To address this, we present CAD-Llama, a framework designed to enhance pretrained LLMs for generating parametric 3D CAD models. Specifically, we develop a hierarchical annotation pipeline and a code-like format to translate parametric 3D CAD command sequences into Structured Parametric CAD Code (SPCC), incorporating hierarchical semantic descriptions. Furthermore, we propose an adaptive pretraining approach utilizing SPCC, followed by an instruction tuning process aligned with CAD-specific guidelines. This methodology aims to equip LLMs with the spatial knowledge inherent in parametric sequences. Experimental results demonstrate that our framework significantly outperforms prior autoregressive methods and existing LLM baselines.","sentences":["Recently, Large Language Models (LLMs) have achieved significant success, prompting increased interest in expanding their generative capabilities beyond general text into domain-specific areas.","This study investigates the generation of parametric sequences for computer-aided design (CAD) models using LLMs.","This endeavor represents an initial step towards creating parametric 3D shapes with LLMs, as CAD model parameters directly correlate with shapes in three-dimensional space.","Despite the formidable generative capacities of LLMs, this task remains challenging, as these models neither encounter parametric sequences during their pretraining phase nor possess direct awareness of 3D structures.","To address this, we present CAD-Llama, a framework designed to enhance pretrained LLMs for generating parametric 3D CAD models.","Specifically, we develop a hierarchical annotation pipeline and a code-like format to translate parametric 3D CAD command sequences into Structured Parametric CAD Code (SPCC), incorporating hierarchical semantic descriptions.","Furthermore, we propose an adaptive pretraining approach utilizing SPCC, followed by an instruction tuning process aligned with CAD-specific guidelines.","This methodology aims to equip LLMs with the spatial knowledge inherent in parametric sequences.","Experimental results demonstrate that our framework significantly outperforms prior autoregressive methods and existing LLM baselines."],"url":"http://arxiv.org/abs/2505.04481v1"}
{"created":"2025-05-07 14:51:43","title":"TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution","abstract":"Trajectory prediction is a crucial task in modeling human behavior, especially in fields as social robotics and autonomous vehicle navigation. Traditional heuristics based on handcrafted rules often lack accuracy, while recently proposed deep learning approaches suffer from computational cost, lack of explainability, and generalization issues that limit their practical adoption. In this paper, we introduce TrajEvo, a framework that leverages Large Language Models (LLMs) to automatically design trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to generate and refine prediction heuristics from past trajectory data. We introduce a Cross-Generation Elite Sampling to promote population diversity and a Statistics Feedback Loop allowing the LLM to analyze alternative predictions. Our evaluations show TrajEvo outperforms previous heuristic methods on the ETH-UCY datasets, and remarkably outperforms both heuristics and deep learning methods when generalizing to the unseen SDD dataset. TrajEvo represents a first step toward automated design of fast, explainable, and generalizable trajectory prediction heuristics. We make our source code publicly available to foster future research at https://github.com/ai4co/trajevo.","sentences":["Trajectory prediction is a crucial task in modeling human behavior, especially in fields as social robotics and autonomous vehicle navigation.","Traditional heuristics based on handcrafted rules often lack accuracy, while recently proposed deep learning approaches suffer from computational cost, lack of explainability, and generalization issues that limit their practical adoption.","In this paper, we introduce TrajEvo, a framework that leverages Large Language Models (LLMs) to automatically design trajectory prediction heuristics.","TrajEvo employs an evolutionary algorithm to generate and refine prediction heuristics from past trajectory data.","We introduce a Cross-Generation Elite Sampling to promote population diversity and a Statistics Feedback Loop allowing the LLM to analyze alternative predictions.","Our evaluations show TrajEvo outperforms previous heuristic methods on the ETH-UCY datasets, and remarkably outperforms both heuristics and deep learning methods when generalizing to the unseen SDD dataset.","TrajEvo represents a first step toward automated design of fast, explainable, and generalizable trajectory prediction heuristics.","We make our source code publicly available to foster future research at https://github.com/ai4co/trajevo."],"url":"http://arxiv.org/abs/2505.04480v1"}
{"created":"2025-05-07 14:40:15","title":"Hamiltonian Normalizing Flows as kinetic PDE solvers: application to the 1D Vlasov-Poisson Equations","abstract":"Many conservative physical systems can be described using the Hamiltonian formalism. A notable example is the Vlasov-Poisson equations, a set of partial differential equations that govern the time evolution of a phase-space density function representing collisionless particles under a self-consistent potential. These equations play a central role in both plasma physics and cosmology. Due to the complexity of the potential involved, analytical solutions are rarely available, necessitating the use of numerical methods such as Particle-In-Cell. In this work, we introduce a novel approach based on Hamiltonian-informed Normalizing Flows, specifically a variant of Fixed-Kinetic Neural Hamiltonian Flows. Our method transforms an initial Gaussian distribution in phase space into the final distribution using a sequence of invertible, volume-preserving transformations derived from Hamiltonian dynamics. The model is trained on a dataset comprising initial and final states at a fixed time T, generated via numerical simulations. After training, the model enables fast sampling of the final distribution from any given initial state. Moreover, by automatically learning an interpretable physical potential, it can generalize to intermediate states not seen during training, offering insights into the system's evolution across time.","sentences":["Many conservative physical systems can be described using the Hamiltonian formalism.","A notable example is the Vlasov-Poisson equations, a set of partial differential equations that govern the time evolution of a phase-space density function representing collisionless particles under a self-consistent potential.","These equations play a central role in both plasma physics and cosmology.","Due to the complexity of the potential involved, analytical solutions are rarely available, necessitating the use of numerical methods such as Particle-In-Cell.","In this work, we introduce a novel approach based on Hamiltonian-informed Normalizing Flows, specifically a variant of Fixed-Kinetic Neural Hamiltonian Flows.","Our method transforms an initial Gaussian distribution in phase space into the final distribution using a sequence of invertible, volume-preserving transformations derived from Hamiltonian dynamics.","The model is trained on a dataset comprising initial and final states at a fixed time T, generated via numerical simulations.","After training, the model enables fast sampling of the final distribution from any given initial state.","Moreover, by automatically learning an interpretable physical potential, it can generalize to intermediate states not seen during training, offering insights into the system's evolution across time."],"url":"http://arxiv.org/abs/2505.04471v1"}
{"created":"2025-05-07 14:38:58","title":"Spectral and Temporal Denoising for Differentially Private Optimization","abstract":"This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a differentially private optimization method that addresses the challenge of preserving performance in DP-SGD, where added noise typically degrades model utility. FFTKF integrates frequency-domain noise shaping with Kalman filtering to enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP guarantees. It employs a high-frequency shaping mask in the Fourier domain to concentrate differential privacy noise in less informative spectral components, preserving low-frequency gradient signals. A scalar-gain Kalman filter with finite-difference Hessian approximation further refines the denoised gradients. With a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates improved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers. Theoretical analysis confirms that FFTKF maintains equivalent privacy guarantees while achieving a tighter privacy-utility trade-off through reduced noise and controlled bias.","sentences":["This paper introduces the FFT-Enhanced Kalman Filter (FFTKF), a differentially private optimization method that addresses the challenge of preserving performance in DP-SGD, where added noise typically degrades model utility.","FFTKF integrates frequency-domain noise shaping with Kalman filtering to enhance gradient quality while preserving $(\\varepsilon, \\delta)$-DP guarantees.","It employs a high-frequency shaping mask in the Fourier domain to concentrate differential privacy noise in less informative spectral components, preserving low-frequency gradient signals.","A scalar-gain Kalman filter with finite-difference Hessian approximation further refines the denoised gradients.","With a per-iteration complexity of $\\mathcal{O}(d \\log d)$, FFTKF demonstrates improved test accuracy over DP-SGD and DiSK across MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets using CNNs, Wide ResNets, and Vision Transformers.","Theoretical analysis confirms that FFTKF maintains equivalent privacy guarantees while achieving a tighter privacy-utility trade-off through reduced noise and controlled bias."],"url":"http://arxiv.org/abs/2505.04468v1"}
{"created":"2025-05-07 14:37:13","title":"Securing Immersive 360 Video Streams through Attribute-Based Selective Encryption","abstract":"Delivering high-quality, secure 360{\\deg} video content introduces unique challenges, primarily due to the high bitrates and interactive demands of immersive media. Traditional HTTPS-based methods, although widely used, face limitations in computational efficiency and scalability when securing these high-resolution streams. To address these issues, this paper proposes a novel framework integrating Attribute-Based Encryption (ABE) with selective encryption techniques tailored specifically for tiled 360{\\deg} video streaming. Our approach employs selective encryption of frames at varying levels to reduce computational overhead while ensuring robust protection against unauthorized access.   Moreover, we explore viewport-adaptive encryption, dynamically encrypting more frames within tiles occupying larger portions of the viewer's field of view. This targeted method significantly enhances security in critical viewing areas without unnecessary overhead in peripheral regions. We deploy and evaluate our proposed approach using the CloudLab testbed, comparing its performance against traditional HTTPS streaming. Experimental results demonstrate that our ABE-based model achieves reduced computational load on intermediate caches, improves cache hit rates, and maintains comparable visual quality to HTTPS, as assessed by Video Multimethod Assessment Fusion (VMAF).","sentences":["Delivering high-quality, secure 360{\\deg} video content introduces unique challenges, primarily due to the high bitrates and interactive demands of immersive media.","Traditional HTTPS-based methods, although widely used, face limitations in computational efficiency and scalability when securing these high-resolution streams.","To address these issues, this paper proposes a novel framework integrating Attribute-Based Encryption (ABE) with selective encryption techniques tailored specifically for tiled 360{\\deg} video streaming.","Our approach employs selective encryption of frames at varying levels to reduce computational overhead while ensuring robust protection against unauthorized access.   ","Moreover, we explore viewport-adaptive encryption, dynamically encrypting more frames within tiles occupying larger portions of the viewer's field of view.","This targeted method significantly enhances security in critical viewing areas without unnecessary overhead in peripheral regions.","We deploy and evaluate our proposed approach using the CloudLab testbed, comparing its performance against traditional HTTPS streaming.","Experimental results demonstrate that our ABE-based model achieves reduced computational load on intermediate caches, improves cache hit rates, and maintains comparable visual quality to HTTPS, as assessed by Video Multimethod Assessment Fusion (VMAF)."],"url":"http://arxiv.org/abs/2505.04466v1"}
{"created":"2025-05-07 14:35:39","title":"Discriminative Ordering Through Ensemble Consensus","abstract":"Evaluating the performance of clustering models is a challenging task where the outcome depends on the definition of what constitutes a cluster. Due to this design, current existing metrics rarely handle multiple clustering models with diverse cluster definitions, nor do they comply with the integration of constraints when available. In this work, we take inspiration from consensus clustering and assume that a set of clustering models is able to uncover hidden structures in the data. We propose to construct a discriminative ordering through ensemble clustering based on the distance between the connectivity of a clustering model and the consensus matrix. We first validate the proposed method with synthetic scenarios, highlighting that the proposed score ranks the models that best match the consensus first. We then show that this simple ranking score significantly outperforms other scoring methods when comparing sets of different clustering algorithms that are not restricted to a fixed number of clusters and is compatible with clustering constraints.","sentences":["Evaluating the performance of clustering models is a challenging task where the outcome depends on the definition of what constitutes a cluster.","Due to this design, current existing metrics rarely handle multiple clustering models with diverse cluster definitions, nor do they comply with the integration of constraints when available.","In this work, we take inspiration from consensus clustering and assume that a set of clustering models is able to uncover hidden structures in the data.","We propose to construct a discriminative ordering through ensemble clustering based on the distance between the connectivity of a clustering model and the consensus matrix.","We first validate the proposed method with synthetic scenarios, highlighting that the proposed score ranks the models that best match the consensus first.","We then show that this simple ranking score significantly outperforms other scoring methods when comparing sets of different clustering algorithms that are not restricted to a fixed number of clusters and is compatible with clustering constraints."],"url":"http://arxiv.org/abs/2505.04464v1"}
{"created":"2025-05-07 14:31:10","title":"A Survey on Temporal Interaction Graph Representation Learning: Progress, Challenges, and Opportunities","abstract":"Temporal interaction graphs (TIGs), defined by sequences of timestamped interaction events, have become ubiquitous in real-world applications due to their capability to model complex dynamic system behaviors. As a result, temporal interaction graph representation learning (TIGRL) has garnered significant attention in recent years. TIGRL aims to embed nodes in TIGs into low-dimensional representations that effectively preserve both structural and temporal information, thereby enhancing the performance of downstream tasks such as classification, prediction, and clustering within constantly evolving data environments. In this paper, we begin by introducing the foundational concepts of TIGs and emphasize the critical role of temporal dependencies. We then propose a comprehensive taxonomy of state-of-the-art TIGRL methods, systematically categorizing them based on the types of information utilized during the learning process to address the unique challenges inherent to TIGs. To facilitate further research and practical applications, we curate the source of datasets and benchmarks, providing valuable resources for empirical investigations. Finally, we examine key open challenges and explore promising research directions in TIGRL, laying the groundwork for future advancements that have the potential to shape the evolution of this field.","sentences":["Temporal interaction graphs (TIGs), defined by sequences of timestamped interaction events, have become ubiquitous in real-world applications due to their capability to model complex dynamic system behaviors.","As a result, temporal interaction graph representation learning (TIGRL) has garnered significant attention in recent years.","TIGRL aims to embed nodes in TIGs into low-dimensional representations that effectively preserve both structural and temporal information, thereby enhancing the performance of downstream tasks such as classification, prediction, and clustering within constantly evolving data environments.","In this paper, we begin by introducing the foundational concepts of TIGs and emphasize the critical role of temporal dependencies.","We then propose a comprehensive taxonomy of state-of-the-art TIGRL methods, systematically categorizing them based on the types of information utilized during the learning process to address the unique challenges inherent to TIGs.","To facilitate further research and practical applications, we curate the source of datasets and benchmarks, providing valuable resources for empirical investigations.","Finally, we examine key open challenges and explore promising research directions in TIGRL, laying the groundwork for future advancements that have the potential to shape the evolution of this field."],"url":"http://arxiv.org/abs/2505.04461v1"}
{"created":"2025-05-07 14:31:04","title":"Learning Real Facial Concepts for Independent Deepfake Detection","abstract":"Deepfake detection models often struggle with generalization to unseen datasets, manifesting as misclassifying real instances as fake in target domains. This is primarily due to an overreliance on forgery artifacts and a limited understanding of real faces. To address this challenge, we propose a novel approach RealID to enhance generalization by learning a comprehensive concept of real faces while assessing the probabilities of belonging to the real and fake classes independently. RealID comprises two key modules: the Real Concept Capture Module (RealC2) and the Independent Dual-Decision Classifier (IDC). With the assistance of a MultiReal Memory, RealC2 maintains various prototypes for real faces, allowing the model to capture a comprehensive concept of real class. Meanwhile, IDC redefines the classification strategy by making independent decisions based on the concept of the real class and the presence of forgery artifacts. Through the combined effect of the above modules, the influence of forgery-irrelevant patterns is alleviated, and extensive experiments on five widely used datasets demonstrate that RealID significantly outperforms existing state-of-the-art methods, achieving a 1.74% improvement in average accuracy.","sentences":["Deepfake detection models often struggle with generalization to unseen datasets, manifesting as misclassifying real instances as fake in target domains.","This is primarily due to an overreliance on forgery artifacts and a limited understanding of real faces.","To address this challenge, we propose a novel approach RealID to enhance generalization by learning a comprehensive concept of real faces while assessing the probabilities of belonging to the real and fake classes independently.","RealID comprises two key modules: the Real Concept Capture Module (RealC2) and the Independent Dual-Decision Classifier (IDC).","With the assistance of a MultiReal Memory, RealC2 maintains various prototypes for real faces, allowing the model to capture a comprehensive concept of real class.","Meanwhile, IDC redefines the classification strategy by making independent decisions based on the concept of the real class and the presence of forgery artifacts.","Through the combined effect of the above modules, the influence of forgery-irrelevant patterns is alleviated, and extensive experiments on five widely used datasets demonstrate that RealID significantly outperforms existing state-of-the-art methods, achieving a 1.74% improvement in average accuracy."],"url":"http://arxiv.org/abs/2505.04460v1"}
{"created":"2025-05-07 14:27:46","title":"Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration","abstract":"Training data cleaning is a new application for generative model-based speech restoration (SR). This paper introduces Miipher-2, an SR model designed for million-hour scale data, for training data cleaning for large-scale generative models like large language models. Key challenges addressed include generalization to unseen languages, operation without explicit conditioning (e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a frozen, pre-trained Universal Speech Model (USM), supporting over 300 languages, as a robust, conditioning-free feature extractor. To optimize efficiency and minimize memory, Miipher-2 incorporates parallel adapters for predicting clean USM features from noisy inputs and employs the WaneFit neural vocoder for waveform synthesis. These components were trained on 3,000 hours of multi-lingual, studio-quality recordings with augmented degradations, while USM parameters remained fixed. Experimental results demonstrate Miipher-2's superior or comparable performance to conventional SR models in word-error-rate, speaker similarity, and both objective and subjective sound quality scores across all tested languages. Miipher-2 operates efficiently on consumer-grade accelerators, achieving a real-time factor of 0.0078, enabling the processing of a million-hour speech dataset in approximately three days using only 100 such accelerators.","sentences":["Training data cleaning is a new application for generative model-based speech restoration (SR).","This paper introduces Miipher-2, an SR model designed for million-hour scale data, for training data cleaning for large-scale generative models like large language models.","Key challenges addressed include generalization to unseen languages, operation without explicit conditioning (e.g., text, speaker ID), and computational efficiency.","Miipher-2 utilizes a frozen, pre-trained Universal Speech Model (USM), supporting over 300 languages, as a robust, conditioning-free feature extractor.","To optimize efficiency and minimize memory, Miipher-2 incorporates parallel adapters for predicting clean USM features from noisy inputs and employs the WaneFit neural vocoder for waveform synthesis.","These components were trained on 3,000 hours of multi-lingual, studio-quality recordings with augmented degradations, while USM parameters remained fixed.","Experimental results demonstrate Miipher-2's superior or comparable performance to conventional SR models in word-error-rate, speaker similarity, and both objective and subjective sound quality scores across all tested languages.","Miipher-2 operates efficiently on consumer-grade accelerators, achieving a real-time factor of 0.0078, enabling the processing of a million-hour speech dataset in approximately three days using only 100 such accelerators."],"url":"http://arxiv.org/abs/2505.04457v1"}
{"created":"2025-05-07 14:20:43","title":"Automatic Music Transcription using Convolutional Neural Networks and Constant-Q transform","abstract":"Automatic music transcription (AMT) is the problem of analyzing an audio recording of a musical piece and detecting notes that are being played. AMT is a challenging problem, particularly when it comes to polyphonic music. The goal of AMT is to produce a score representation of a music piece, by analyzing a sound signal containing multiple notes played simultaneously. In this work, we design a processing pipeline that can transform classical piano audio files in .wav format into a music score representation. The features from the audio signals are extracted using the constant-Q transform, and the resulting coefficients are used as an input to the convolutional neural network (CNN) model.","sentences":["Automatic music transcription (AMT) is the problem of analyzing an audio recording of a musical piece and detecting notes that are being played.","AMT is a challenging problem, particularly when it comes to polyphonic music.","The goal of AMT is to produce a score representation of a music piece, by analyzing a sound signal containing multiple notes played simultaneously.","In this work, we design a processing pipeline that can transform classical piano audio files in .wav format into a music score representation.","The features from the audio signals are extracted using the constant-Q transform, and the resulting coefficients are used as an input to the convolutional neural network (CNN) model."],"url":"http://arxiv.org/abs/2505.04451v1"}
{"created":"2025-05-07 14:16:30","title":"Practice Support for Violin Bowing by Measuring Bow Pressure and Position","abstract":"The violin is one of the most popular musical instruments. Various parameters of bowing motion, such as pressure, position, and speed, are crucial for producing a beautiful tone. However, mastering them is challenging and requires extensive practice. In this study, we aimed to support practice of bowing, focusing on bow pressure. First, we compared the bowing movements, specifically bow pressure, bow position, and bow speed, of eight experienced players with those of eight beginners. Next, we developed and evaluated a visual feedback system that displays bow pressure to support practice. We taught the identified differences to 14 beginners, dividing them into two groups: one practiced with an explanation, and the other with both an explanation and a feedback system. These two experiments found that clarifying the characteristics unique to experienced players can support practice.","sentences":["The violin is one of the most popular musical instruments.","Various parameters of bowing motion, such as pressure, position, and speed, are crucial for producing a beautiful tone.","However, mastering them is challenging and requires extensive practice.","In this study, we aimed to support practice of bowing, focusing on bow pressure.","First, we compared the bowing movements, specifically bow pressure, bow position, and bow speed, of eight experienced players with those of eight beginners.","Next, we developed and evaluated a visual feedback system that displays bow pressure to support practice.","We taught the identified differences to 14 beginners, dividing them into two groups: one practiced with an explanation, and the other with both an explanation and a feedback system.","These two experiments found that clarifying the characteristics unique to experienced players can support practice."],"url":"http://arxiv.org/abs/2505.04446v1"}
{"created":"2025-05-07 14:14:29","title":"M2Rec: Multi-scale Mamba for Efficient Sequential Recommendation","abstract":"Sequential recommendation systems aim to predict users' next preferences based on their interaction histories, but existing approaches face critical limitations in efficiency and multi-scale pattern recognition. While Transformer-based methods struggle with quadratic computational complexity, recent Mamba-based models improve efficiency but fail to capture periodic user behaviors, leverage rich semantic information, or effectively fuse multimodal features. To address these challenges, we propose \\model, a novel sequential recommendation framework that integrates multi-scale Mamba with Fourier analysis, Large Language Models (LLMs), and adaptive gating. First, we enhance Mamba with Fast Fourier Transform (FFT) to explicitly model periodic patterns in the frequency domain, separating meaningful trends from noise. Second, we incorporate LLM-based text embeddings to enrich sparse interaction data with semantic context from item descriptions. Finally, we introduce a learnable gate mechanism to dynamically balance temporal (Mamba), frequency (FFT), and semantic (LLM) features, ensuring harmonious multimodal fusion. Extensive experiments demonstrate that \\model\\ achieves state-of-the-art performance, improving Hit Rate@10 by 3.2\\% over existing Mamba-based models while maintaining 20\\% faster inference than Transformer baselines. Our results highlight the effectiveness of combining frequency analysis, semantic understanding, and adaptive fusion for sequential recommendation. Code and datasets are available at: https://anonymous.4open.science/r/M2Rec.","sentences":["Sequential recommendation systems aim to predict users' next preferences based on their interaction histories, but existing approaches face critical limitations in efficiency and multi-scale pattern recognition.","While Transformer-based methods struggle with quadratic computational complexity, recent Mamba-based models improve efficiency but fail to capture periodic user behaviors, leverage rich semantic information, or effectively fuse multimodal features.","To address these challenges, we propose \\model, a novel sequential recommendation framework that integrates multi-scale Mamba with Fourier analysis, Large Language Models (LLMs), and adaptive gating.","First, we enhance Mamba with Fast Fourier Transform (FFT) to explicitly model periodic patterns in the frequency domain, separating meaningful trends from noise.","Second, we incorporate LLM-based text embeddings to enrich sparse interaction data with semantic context from item descriptions.","Finally, we introduce a learnable gate mechanism to dynamically balance temporal (Mamba), frequency (FFT), and semantic (LLM) features, ensuring harmonious multimodal fusion.","Extensive experiments demonstrate that \\model\\ achieves state-of-the-art performance, improving Hit Rate@10 by 3.2\\% over existing Mamba-based models while maintaining 20\\% faster inference than Transformer baselines.","Our results highlight the effectiveness of combining frequency analysis, semantic understanding, and adaptive fusion for sequential recommendation.","Code and datasets are available at: https://anonymous.4open.science/r/M2Rec."],"url":"http://arxiv.org/abs/2505.04445v1"}
{"created":"2025-05-07 14:12:41","title":"Towards Effectively Leveraging Execution Traces for Program Repair with Code LLMs","abstract":"Large Language Models (LLMs) show promising performance on various programming tasks, including Automatic Program Repair (APR). However, most approaches to LLM-based APR are limited to the static analysis of the programs, while disregarding their runtime behavior. Inspired by knowledge-augmented NLP, in this work, we aim to remedy this potential blind spot by augmenting standard APR prompts with program execution traces. We evaluate our approach using the GPT family of models on three popular APR datasets. Our findings suggest that simply incorporating execution traces into the prompt provides a limited performance improvement over trace-free baselines, in only 2 out of 6 tested dataset / model configurations. We further find that the effectiveness of execution traces for APR diminishes as their complexity increases. We explore several strategies for leveraging traces in prompts and demonstrate that LLM-optimized prompts help outperform trace-free prompts more consistently. Additionally, we show trace-based prompting to be superior to finetuning a smaller LLM on a small-scale dataset; and conduct probing studies reinforcing the notion that execution traces can complement the reasoning abilities of the LLMs.","sentences":["Large Language Models (LLMs) show promising performance on various programming tasks, including Automatic Program Repair (APR).","However, most approaches to LLM-based APR are limited to the static analysis of the programs, while disregarding their runtime behavior.","Inspired by knowledge-augmented NLP, in this work, we aim to remedy this potential blind spot by augmenting standard APR prompts with program execution traces.","We evaluate our approach using the GPT family of models on three popular APR datasets.","Our findings suggest that simply incorporating execution traces into the prompt provides a limited performance improvement over trace-free baselines, in only 2 out of 6 tested dataset / model configurations.","We further find that the effectiveness of execution traces for APR diminishes as their complexity increases.","We explore several strategies for leveraging traces in prompts and demonstrate that LLM-optimized prompts help outperform trace-free prompts more consistently.","Additionally, we show trace-based prompting to be superior to finetuning a smaller LLM on a small-scale dataset; and conduct probing studies reinforcing the notion that execution traces can complement the reasoning abilities of the LLMs."],"url":"http://arxiv.org/abs/2505.04441v1"}
{"created":"2025-05-07 14:12:39","title":"Towards Initialization-Agnostic Clustering with Iterative Adaptive Resonance Theory","abstract":"The clustering performance of Fuzzy Adaptive Resonance Theory (Fuzzy ART) is highly dependent on the preset vigilance parameter, where deviations in its value can lead to significant fluctuations in clustering results, severely limiting its practicality for non-expert users. Existing approaches generally enhance vigilance parameter robustness through adaptive mechanisms such as particle swarm optimization and fuzzy logic rules. However, they often introduce additional hyperparameters or complex frameworks that contradict the original simplicity of the algorithm. To address this, we propose Iterative Refinement Adaptive Resonance Theory (IR-ART), which integrates three key phases into a unified iterative framework: (1) Cluster Stability Detection: A dynamic stability detection module that identifies unstable clusters by analyzing the change of sample size (number of samples in the cluster) in iteration. (2) Unstable Cluster Deletion: An evolutionary pruning module that eliminates low-quality clusters. (3) Vigilance Region Expansion: A vigilance region expansion mechanism that adaptively adjusts similarity thresholds. Independent of the specific execution of clustering, these three phases sequentially focus on analyzing the implicit knowledge within the iterative process, adjusting weights and vigilance parameters, thereby laying a foundation for the next iteration. Experimental evaluation on 15 datasets demonstrates that IR-ART improves tolerance to suboptimal vigilance parameter values while preserving the parameter simplicity of Fuzzy ART. Case studies visually confirm the algorithm's self-optimization capability through iterative refinement, making it particularly suitable for non-expert users in resource-constrained scenarios.","sentences":["The clustering performance of Fuzzy Adaptive Resonance Theory (Fuzzy ART) is highly dependent on the preset vigilance parameter, where deviations in its value can lead to significant fluctuations in clustering results, severely limiting its practicality for non-expert users.","Existing approaches generally enhance vigilance parameter robustness through adaptive mechanisms such as particle swarm optimization and fuzzy logic rules.","However, they often introduce additional hyperparameters or complex frameworks that contradict the original simplicity of the algorithm.","To address this, we propose Iterative Refinement Adaptive Resonance Theory (IR-ART), which integrates three key phases into a unified iterative framework: (1) Cluster Stability Detection: A dynamic stability detection module that identifies unstable clusters by analyzing the change of sample size (number of samples in the cluster) in iteration.","(2) Unstable Cluster Deletion:","An evolutionary pruning module that eliminates low-quality clusters.","(3) Vigilance Region Expansion:","A vigilance region expansion mechanism that adaptively adjusts similarity thresholds.","Independent of the specific execution of clustering, these three phases sequentially focus on analyzing the implicit knowledge within the iterative process, adjusting weights and vigilance parameters, thereby laying a foundation for the next iteration.","Experimental evaluation on 15 datasets demonstrates that IR-ART improves tolerance to suboptimal vigilance parameter values while preserving the parameter simplicity of Fuzzy ART.","Case studies visually confirm the algorithm's self-optimization capability through iterative refinement, making it particularly suitable for non-expert users in resource-constrained scenarios."],"url":"http://arxiv.org/abs/2505.04440v1"}
{"created":"2025-05-07 14:07:01","title":"Do We Still Need to Work on Odometry for Autonomous Driving?","abstract":"Over the past decades, a tremendous amount of work has addressed the topic of ego-motion estimation of moving platforms based on various proprioceptive and exteroceptive sensors. At the cost of ever-increasing computational load and sensor complexity, odometry algorithms have reached impressive levels of accuracy with minimal drift in various conditions. In this paper, we question the need for more research on odometry for autonomous driving by assessing the accuracy of one of the simplest algorithms: the direct integration of wheel encoder data and yaw rate measurements from a gyroscope. We denote this algorithm as Odometer-Gyroscope (OG) odometry. This work shows that OG odometry can outperform current state-of-the-art radar-inertial SE(2) odometry for a fraction of the computational cost in most scenarios. For example, the OG odometry is on top of the Boreas leaderboard with a relative translation error of 0.20%, while the second-best method displays an error of 0.26%. Lidar-inertial approaches can provide more accurate estimates, but the computational load is three orders of magnitude higher than the OG odometry. To further the analysis, we have pushed the limits of the OG odometry by purposely violating its fundamental no-slip assumption using data collected during a heavy snowstorm with different driving behaviours. Our conclusion shows that a significant amount of slippage is required to result in non-satisfactory pose estimates from the OG odometry.","sentences":["Over the past decades, a tremendous amount of work has addressed the topic of ego-motion estimation of moving platforms based on various proprioceptive and exteroceptive sensors.","At the cost of ever-increasing computational load and sensor complexity, odometry algorithms have reached impressive levels of accuracy with minimal drift in various conditions.","In this paper, we question the need for more research on odometry for autonomous driving by assessing the accuracy of one of the simplest algorithms: the direct integration of wheel encoder data and yaw rate measurements from a gyroscope.","We denote this algorithm as Odometer-Gyroscope (OG) odometry.","This work shows that OG odometry can outperform current state-of-the-art radar-inertial SE(2) odometry for a fraction of the computational cost in most scenarios.","For example, the OG odometry is on top of the Boreas leaderboard with a relative translation error of 0.20%, while the second-best method displays an error of 0.26%.","Lidar-inertial approaches can provide more accurate estimates, but the computational load is three orders of magnitude higher than the OG odometry.","To further the analysis, we have pushed the limits of the OG odometry by purposely violating its fundamental no-slip assumption using data collected during a heavy snowstorm with different driving behaviours.","Our conclusion shows that a significant amount of slippage is required to result in non-satisfactory pose estimates from the OG odometry."],"url":"http://arxiv.org/abs/2505.04438v1"}
{"created":"2025-05-07 14:02:35","title":"FedBWO: Enhancing Communication Efficiency in Federated Learning","abstract":"Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a shared model is collaboratively trained by various clients using their local datasets while keeping the data private. Considering resource-constrained devices, FL clients often suffer from restricted transmission capacity. Aiming to enhance the system performance, the communication between clients and server needs to be diminished. Current FL strategies transmit a tremendous amount of data (model weights) within the FL process, which needs a high communication bandwidth. Considering resource constraints, increasing the number of clients and, consequently, the amount of data (model weights) can lead to a bottleneck. In this paper, we introduce the Federated Black Widow Optimization (FedBWO) technique to decrease the amount of transmitted data by transmitting only a performance score rather than the local model weights from clients. FedBWO employs the BWO algorithm to improve local model updates. The conducted experiments prove that FedBWO remarkably improves the performance of the global model and the communication efficiency of the overall system. According to the experimental outcomes, FedBWO enhances the global model accuracy by an average of 21% over FedAvg, and 12% over FedGWO. Furthermore, FedBWO dramatically decreases the communication cost compared to other methods.","sentences":["Federated Learning (FL) is a distributed Machine Learning (ML) setup, where a shared model is collaboratively trained by various clients using their local datasets while keeping the data private.","Considering resource-constrained devices, FL clients often suffer from restricted transmission capacity.","Aiming to enhance the system performance, the communication between clients and server needs to be diminished.","Current FL strategies transmit a tremendous amount of data (model weights) within the FL process, which needs a high communication bandwidth.","Considering resource constraints, increasing the number of clients and, consequently, the amount of data (model weights) can lead to a bottleneck.","In this paper, we introduce the Federated Black Widow Optimization (FedBWO) technique to decrease the amount of transmitted data by transmitting only a performance score rather than the local model weights from clients.","FedBWO employs the BWO algorithm to improve local model updates.","The conducted experiments prove that FedBWO remarkably improves the performance of the global model and the communication efficiency of the overall system.","According to the experimental outcomes, FedBWO enhances the global model accuracy by an average of 21% over FedAvg, and 12% over FedGWO.","Furthermore, FedBWO dramatically decreases the communication cost compared to other methods."],"url":"http://arxiv.org/abs/2505.04435v1"}
{"created":"2025-05-07 14:01:22","title":"Theoretical Guarantees for LT-TTD: A Unified Transformer-based Architecture for Two-Level Ranking Systems","abstract":"Modern recommendation and search systems typically employ multi-stage ranking architectures to efficiently handle billions of candidates. The conventional approach uses distinct L1 (candidate retrieval) and L2 (re-ranking) models with different optimization objectives, introducing critical limitations including irreversible error propagation and suboptimal ranking. This paper identifies and analyzes the fundamental limitations of this decoupled paradigm and proposes LT-TTD (Listwise Transformer with Two-Tower Distillation), a novel unified architecture that bridges retrieval and ranking phases. Our approach combines the computational efficiency of two-tower models with the expressivity of transformers in a unified listwise learning framework. We provide a comprehensive theoretical analysis of our architecture and establish formal guarantees regarding error propagation mitigation, ranking quality improvements, and optimization convergence. We derive theoretical bounds showing that LT-TTD reduces the upper limit on irretrievable relevant items by a factor that depends on the knowledge distillation strength, and prove that our multi-objective optimization framework achieves a provably better global optimum than disjoint training. Additionally, we analyze the computational complexity of our approach, demonstrating that the asymptotic complexity remains within practical bounds for real-world applications. We also introduce UPQE, a novel evaluation metric specifically designed for unified ranking architectures that holistically captures retrieval quality, ranking performance, and computational efficiency.","sentences":["Modern recommendation and search systems typically employ multi-stage ranking architectures to efficiently handle billions of candidates.","The conventional approach uses distinct L1 (candidate retrieval) and L2 (re-ranking) models with different optimization objectives, introducing critical limitations including irreversible error propagation and suboptimal ranking.","This paper identifies and analyzes the fundamental limitations of this decoupled paradigm and proposes LT-TTD (Listwise Transformer with Two-Tower Distillation), a novel unified architecture that bridges retrieval and ranking phases.","Our approach combines the computational efficiency of two-tower models with the expressivity of transformers in a unified listwise learning framework.","We provide a comprehensive theoretical analysis of our architecture and establish formal guarantees regarding error propagation mitigation, ranking quality improvements, and optimization convergence.","We derive theoretical bounds showing that LT-TTD reduces the upper limit on irretrievable relevant items by a factor that depends on the knowledge distillation strength, and prove that our multi-objective optimization framework achieves a provably better global optimum than disjoint training.","Additionally, we analyze the computational complexity of our approach, demonstrating that the asymptotic complexity remains within practical bounds for real-world applications.","We also introduce UPQE, a novel evaluation metric specifically designed for unified ranking architectures that holistically captures retrieval quality, ranking performance, and computational efficiency."],"url":"http://arxiv.org/abs/2505.04434v1"}
{"created":"2025-05-07 14:01:05","title":"Improving Inclusivity for Emotion Recognition Based on Face Tracking","abstract":"The limited expressiveness of virtual user representations in Mixed Reality and Virtual Reality can inhibit an integral part of communication: emotional expression. Emotion recognition based on face tracking is often used to compensate for this. However, emotional facial expressions are highly individual, which is why many approaches have difficulties recognizing unique variations of emotional expressions. We propose several strategies to improve face tracking systems for emotion recognition with and without user intervention for the Affective Interaction Workshop at CHI '25.","sentences":["The limited expressiveness of virtual user representations in Mixed Reality and Virtual Reality can inhibit an integral part of communication: emotional expression.","Emotion recognition based on face tracking is often used to compensate for this.","However, emotional facial expressions are highly individual, which is why many approaches have difficulties recognizing unique variations of emotional expressions.","We propose several strategies to improve face tracking systems for emotion recognition with and without user intervention for the Affective Interaction Workshop at CHI '25."],"url":"http://arxiv.org/abs/2505.04433v1"}
{"created":"2025-05-07 14:00:03","title":"An Asynchronous Distributed-Memory Parallel Algorithm for k-mer Counting","abstract":"This paper describes a new asynchronous algorithm and implementation for the problem of k-mer counting (KC), which concerns quantifying the frequency of length k substrings in a DNA sequence. This operation is common to many computational biology workloads and can take up to 77% of the total runtime of de novo genome assembly. The performance and scalability of the current state-of-the-art distributed-memory KC algorithm are hampered by multiple rounds of Many-To-Many collectives. Therefore, we develop an asynchronous algorithm (DAKC) that uses fine-grained, asynchronous messages to obviate most of this global communication while utilizing network bandwidth efficiently via custom message aggregation protocols. DAKC can perform strong scaling up to 256 nodes (512 sockets / 6K cores) and can count k-mers up to 9x faster than the state-of-the-art distributed-memory algorithm, and up to 100x faster than the shared-memory alternative. We also provide an analytical model to understand the hardware resource utilization of our asynchronous KC algorithm and provide insights on the performance.","sentences":["This paper describes a new asynchronous algorithm and implementation for the problem of k-mer counting (KC), which concerns quantifying the frequency of length k substrings in a DNA sequence.","This operation is common to many computational biology workloads and can take up to 77% of the total runtime of de novo genome assembly.","The performance and scalability of the current state-of-the-art distributed-memory KC algorithm are hampered by multiple rounds of Many-To-Many collectives.","Therefore, we develop an asynchronous algorithm (DAKC) that uses fine-grained, asynchronous messages to obviate most of this global communication while utilizing network bandwidth efficiently via custom message aggregation protocols.","DAKC can perform strong scaling up to 256 nodes (512 sockets / 6K cores) and can count k-mers up to 9x faster than the state-of-the-art distributed-memory algorithm, and up to 100x faster than the shared-memory alternative.","We also provide an analytical model to understand the hardware resource utilization of our asynchronous KC algorithm and provide insights on the performance."],"url":"http://arxiv.org/abs/2505.04431v1"}

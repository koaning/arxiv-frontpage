{"created":"2025-05-14 17:59:55","title":"UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing","abstract":"Audio-Visual Video Parsing (AVVP) entails the challenging task of localizing both uni-modal events (i.e., those occurring exclusively in either the visual or acoustic modality of a video) and multi-modal events (i.e., those occurring in both modalities concurrently). Moreover, the prohibitive cost of annotating training data with the class labels of all these events, along with their start and end times, imposes constraints on the scalability of AVVP techniques unless they can be trained in a weakly-supervised setting, where only modality-agnostic, video-level labels are available in the training data. To this end, recently proposed approaches seek to generate segment-level pseudo-labels to better guide model training. However, the absence of inter-segment dependencies when generating these pseudo-labels and the general bias towards predicting labels that are absent in a segment limit their performance. This work proposes a novel approach towards overcoming these weaknesses called Uncertainty-weighted Weakly-supervised Audio-visual Video Parsing (UWAV). Additionally, our innovative approach factors in the uncertainty associated with these estimated pseudo-labels and incorporates a feature mixup based training regularization for improved training. Empirical results show that UWAV outperforms state-of-the-art methods for the AVVP task on multiple metrics, across two different datasets, attesting to its effectiveness and generalizability.","sentences":["Audio-Visual Video Parsing (AVVP) entails the challenging task of localizing both uni-modal events (i.e., those occurring exclusively in either the visual or acoustic modality of a video) and multi-modal events (i.e., those occurring in both modalities concurrently).","Moreover, the prohibitive cost of annotating training data with the class labels of all these events, along with their start and end times, imposes constraints on the scalability of AVVP techniques unless they can be trained in a weakly-supervised setting, where only modality-agnostic, video-level labels are available in the training data.","To this end, recently proposed approaches seek to generate segment-level pseudo-labels to better guide model training.","However, the absence of inter-segment dependencies when generating these pseudo-labels and the general bias towards predicting labels that are absent in a segment limit their performance.","This work proposes a novel approach towards overcoming these weaknesses called Uncertainty-weighted Weakly-supervised Audio-visual Video Parsing (UWAV).","Additionally, our innovative approach factors in the uncertainty associated with these estimated pseudo-labels and incorporates a feature mixup based training regularization for improved training.","Empirical results show that UWAV outperforms state-of-the-art methods for the AVVP task on multiple metrics, across two different datasets, attesting to its effectiveness and generalizability."],"url":"http://arxiv.org/abs/2505.09615v1"}
{"created":"2025-05-14 17:59:35","title":"Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?","abstract":"Language model (LM) agents are increasingly used as autonomous decision-makers who need to actively gather information to guide their decisions. A crucial cognitive skill for such agents is the efficient exploration and understanding of the causal structure of the world -- key to robust, scientifically grounded reasoning. Yet, it remains unclear whether LMs possess this capability or exhibit systematic biases leading to erroneous conclusions. In this work, we examine LMs' ability to explore and infer causal relationships, using the well-established \"Blicket Test\" paradigm from developmental psychology. We find that LMs reliably infer the common, intuitive disjunctive causal relationships but systematically struggle with the unusual, yet equally (or sometimes even more) evidenced conjunctive ones. This \"disjunctive bias\" persists across model families, sizes, and prompting strategies, and performance further declines as task complexity increases. Interestingly, an analogous bias appears in human adults, suggesting that LMs may have inherited deep-seated reasoning heuristics from their training data. To this end, we quantify similarities between LMs and humans, finding that LMs exhibit adult-like inference profiles (but not children-like). Finally, we propose a test-time sampling method which explicitly samples and eliminates hypotheses about causal relationships from the LM. This scalable approach significantly reduces the disjunctive bias and moves LMs closer to the goal of scientific, causally rigorous reasoning.","sentences":["Language model (LM) agents are increasingly used as autonomous decision-makers who need to actively gather information to guide their decisions.","A crucial cognitive skill for such agents is the efficient exploration and understanding of the causal structure of the world -- key to robust, scientifically grounded reasoning.","Yet, it remains unclear whether LMs possess this capability or exhibit systematic biases leading to erroneous conclusions.","In this work, we examine LMs' ability to explore and infer causal relationships, using the well-established \"Blicket Test\" paradigm from developmental psychology.","We find that LMs reliably infer the common, intuitive disjunctive causal relationships but systematically struggle with the unusual, yet equally (or sometimes even more) evidenced conjunctive ones.","This \"disjunctive bias\" persists across model families, sizes, and prompting strategies, and performance further declines as task complexity increases.","Interestingly, an analogous bias appears in human adults, suggesting that LMs may have inherited deep-seated reasoning heuristics from their training data.","To this end, we quantify similarities between LMs and humans, finding that LMs exhibit adult-like inference profiles (but not children-like).","Finally, we propose a test-time sampling method which explicitly samples and eliminates hypotheses about causal relationships from the LM.","This scalable approach significantly reduces the disjunctive bias and moves LMs closer to the goal of scientific, causally rigorous reasoning."],"url":"http://arxiv.org/abs/2505.09614v1"}
{"created":"2025-05-14 17:58:40","title":"Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors","abstract":"The use of Large Language Models (LLMs) in hardware design has taken off in recent years, principally through its incorporation in tools that increase chip designer productivity. There has been considerable discussion about the use of LLMs in RTL specifications of chip designs, for which the two most popular languages are Verilog and VHDL. LLMs and their use in Verilog design has received significant attention due to the higher popularity of the language, but little attention so far has been given to VHDL despite its continued popularity in the industry. There has also been little discussion about the unique needs of organizations that engage in high-performance processor design, and techniques to deploy AI solutions in these settings. In this paper, we describe our journey in developing a Large Language Model (LLM) specifically for the purpose of explaining VHDL code, a task that has particular importance in an organization with decades of experience and assets in high-performance processor design. We show how we developed test sets specific to our needs and used them for evaluating models as we performed extended pretraining (EPT) of a base LLM. Expert evaluation of the code explanations produced by the EPT model increased to 69% compared to a base model rating of 43%. We further show how we developed an LLM-as-a-judge to gauge models similar to expert evaluators. This led us to deriving and evaluating a host of new models, including an instruction-tuned version of the EPT model with an expected expert evaluator rating of 71%. Our experiments also indicate that with the potential use of newer base models, this rating can be pushed to 85% and beyond. We conclude with a discussion on further improving the quality of hardware design LLMs using exciting new developments in the Generative AI world.","sentences":["The use of Large Language Models (LLMs) in hardware design has taken off in recent years, principally through its incorporation in tools that increase chip designer productivity.","There has been considerable discussion about the use of LLMs in RTL specifications of chip designs, for which the two most popular languages are Verilog and VHDL.","LLMs and their use in Verilog design has received significant attention due to the higher popularity of the language, but little attention so far has been given to VHDL despite its continued popularity in the industry.","There has also been little discussion about the unique needs of organizations that engage in high-performance processor design, and techniques to deploy AI solutions in these settings.","In this paper, we describe our journey in developing a Large Language Model (LLM) specifically for the purpose of explaining VHDL code, a task that has particular importance in an organization with decades of experience and assets in high-performance processor design.","We show how we developed test sets specific to our needs and used them for evaluating models as we performed extended pretraining (EPT) of a base LLM.","Expert evaluation of the code explanations produced by the EPT model increased to 69% compared to a base model rating of 43%.","We further show how we developed an LLM-as-a-judge to gauge models similar to expert evaluators.","This led us to deriving and evaluating a host of new models, including an instruction-tuned version of the EPT model with an expected expert evaluator rating of 71%.","Our experiments also indicate that with the potential use of newer base models, this rating can be pushed to 85% and beyond.","We conclude with a discussion on further improving the quality of hardware design LLMs using exciting new developments in the Generative AI world."],"url":"http://arxiv.org/abs/2505.09610v1"}
{"created":"2025-05-14 17:57:27","title":"LightLab: Controlling Light Sources in Images with Diffusion Models","abstract":"We present a simple, yet effective diffusion-based method for fine-grained, parametric control over light sources in an image. Existing relighting methods either rely on multiple input views to perform inverse rendering at inference time, or fail to provide explicit control over light changes. Our method fine-tunes a diffusion model on a small set of real raw photograph pairs, supplemented by synthetically rendered images at scale, to elicit its photorealistic prior for relighting. We leverage the linearity of light to synthesize image pairs depicting controlled light changes of either a target light source or ambient illumination. Using this data and an appropriate fine-tuning scheme, we train a model for precise illumination changes with explicit control over light intensity and color. Lastly, we show how our method can achieve compelling light editing results, and outperforms existing methods based on user preference.","sentences":["We present a simple, yet effective diffusion-based method for fine-grained, parametric control over light sources in an image.","Existing relighting methods either rely on multiple input views to perform inverse rendering at inference time, or fail to provide explicit control over light changes.","Our method fine-tunes a diffusion model on a small set of real raw photograph pairs, supplemented by synthetically rendered images at scale, to elicit its photorealistic prior for relighting.","We leverage the linearity of light to synthesize image pairs depicting controlled light changes of either a target light source or ambient illumination.","Using this data and an appropriate fine-tuning scheme, we train a model for precise illumination changes with explicit control over light intensity and color.","Lastly, we show how our method can achieve compelling light editing results, and outperforms existing methods based on user preference."],"url":"http://arxiv.org/abs/2505.09608v1"}
{"created":"2025-05-14 17:56:26","title":"The Niche Connectivity Paradox: Multichrome Contagions Overcome Vaccine Hesitancy more effectively than Monochromacy","abstract":"The rise of vaccine hesitancy has caused a resurgence of vaccine-preventable diseases such as measles and pertussis, alongside widespread skepticism and refusals of COVID-19 vaccinations. While categorizing individuals as either supportive of or opposed to vaccines provides a convenient dichotomy of vaccine attitudes, vaccine hesitancy is far more complex and dynamic. It involves wavering individuals whose attitudes fluctuate -- those who may exhibit pro-vaccine attitudes at one time and anti-vaccine attitudes at another. Here, we identify and analyze multichrome contagions as potential targets for intervention by leveraging a dataset of known pro-vax and anti-vax Twitter users ($n =135$ million) and a large COVID-19 Twitter dataset ($n = 3.5$ billion; including close analysis of $1,563,472$ unique individuals). We reconstruct an evolving multiplex sentiment landscape using top co-spreading issues, characterizing them as monochrome and multichrome contagions, based on their conceptual overlap with vaccination. We demonstrate switchers as deliberative: they are more moderate, engage with a wider range of topics, and occupy more central positions in their networks. Further examination of their information consumption shows that their discourse often engages with progressive issues such as climate change, which can serve as avenues for multichrome contagion interventions to promote pro-vaccine attitudes. Using data-driven intervention simulations, we demonstrate a paradox of niche connectivity, where multichrome contagions with fragmented, non-overlapping communities generate the highest levels of diffusion for pro-vaccine attitudes. Our work offers insights into harnessing synergistic hitchhiking effect of multichrome contagions to drive desired attitude and behavior changes in network-based interventions, particularly for overcoming vaccine hesitancy.","sentences":["The rise of vaccine hesitancy has caused a resurgence of vaccine-preventable diseases such as measles and pertussis, alongside widespread skepticism and refusals of COVID-19 vaccinations.","While categorizing individuals as either supportive of or opposed to vaccines provides a convenient dichotomy of vaccine attitudes, vaccine hesitancy is far more complex and dynamic.","It involves wavering individuals whose attitudes fluctuate -- those who may exhibit pro-vaccine attitudes at one time and anti-vaccine attitudes at another.","Here, we identify and analyze multichrome contagions as potential targets for intervention by leveraging a dataset of known pro-vax and anti-vax Twitter users ($n =135$ million) and a large COVID-19 Twitter dataset ($n = 3.5$ billion; including close analysis of $1,563,472$ unique individuals).","We reconstruct an evolving multiplex sentiment landscape using top co-spreading issues, characterizing them as monochrome and multichrome contagions, based on their conceptual overlap with vaccination.","We demonstrate switchers as deliberative: they are more moderate, engage with a wider range of topics, and occupy more central positions in their networks.","Further examination of their information consumption shows that their discourse often engages with progressive issues such as climate change, which can serve as avenues for multichrome contagion interventions to promote pro-vaccine attitudes.","Using data-driven intervention simulations, we demonstrate a paradox of niche connectivity, where multichrome contagions with fragmented, non-overlapping communities generate the highest levels of diffusion for pro-vaccine attitudes.","Our work offers insights into harnessing synergistic hitchhiking effect of multichrome contagions to drive desired attitude and behavior changes in network-based interventions, particularly for overcoming vaccine hesitancy."],"url":"http://arxiv.org/abs/2505.09605v1"}
{"created":"2025-05-14 17:55:10","title":"DataMIL: Selecting Data for Robot Imitation Learning with Datamodels","abstract":"Recently, the robotics community has amassed ever larger and more diverse datasets to train generalist robot policies. However, while these policies achieve strong mean performance across a variety of tasks, they often underperform on individual, specialized tasks and require further tuning on newly acquired task-specific data. Combining task-specific data with carefully curated subsets of large prior datasets via co-training can produce better specialized policies, but selecting data naively may actually harm downstream performance. To address this, we introduce DataMIL, a policy-driven data selection framework built on the datamodels paradigm that reasons about data selection in an end-to-end manner, using the policy itself to identify which data points will most improve performance. Unlike standard practices that filter data using human notions of quality (e.g., based on semantic or visual similarity), DataMIL directly optimizes data selection for task success, allowing us to select data that enhance the policy while dropping data that degrade it. To avoid performing expensive rollouts in the environment during selection, we use a novel surrogate loss function on task-specific data, allowing us to use DataMIL in the real world without degrading performance. We validate our approach on a suite of more than 60 simulation and real-world manipulation tasks - most notably showing successful data selection from the Open X-Embodiment datasets-demonstrating consistent gains in success rates and superior performance over multiple baselines. Our results underscore the importance of end-to-end, performance-aware data selection for unlocking the potential of large prior datasets in robotics. More information at https://robin-lab.cs.utexas.edu/datamodels4imitation/","sentences":["Recently, the robotics community has amassed ever larger and more diverse datasets to train generalist robot policies.","However, while these policies achieve strong mean performance across a variety of tasks, they often underperform on individual, specialized tasks and require further tuning on newly acquired task-specific data.","Combining task-specific data with carefully curated subsets of large prior datasets via co-training can produce better specialized policies, but selecting data naively may actually harm downstream performance.","To address this, we introduce DataMIL, a policy-driven data selection framework built on the datamodels paradigm that reasons about data selection in an end-to-end manner, using the policy itself to identify which data points will most improve performance.","Unlike standard practices that filter data using human notions of quality (e.g., based on semantic or visual similarity), DataMIL directly optimizes data selection for task success, allowing us to select data that enhance the policy while dropping data that degrade it.","To avoid performing expensive rollouts in the environment during selection, we use a novel surrogate loss function on task-specific data, allowing us to use DataMIL in the real world without degrading performance.","We validate our approach on a suite of more than 60 simulation and real-world manipulation tasks - most notably showing successful data selection from the Open X-Embodiment datasets-demonstrating consistent gains in success rates and superior performance over multiple baselines.","Our results underscore the importance of end-to-end, performance-aware data selection for unlocking the potential of large prior datasets in robotics.","More information at https://robin-lab.cs.utexas.edu/datamodels4imitation/"],"url":"http://arxiv.org/abs/2505.09603v1"}
{"created":"2025-05-14 17:52:10","title":"Adversarial Suffix Filtering: a Defense Pipeline for LLMs","abstract":"Large Language Models (LLMs) are increasingly embedded in autonomous systems and public-facing environments, yet they remain susceptible to jailbreak vulnerabilities that may undermine their security and trustworthiness. Adversarial suffixes are considered to be the current state-of-the-art jailbreak, consistently outperforming simpler methods and frequently succeeding even in black-box settings. Existing defenses rely on access to the internal architecture of models limiting diverse deployment, increase memory and computation footprints dramatically, or can be bypassed with simple prompt engineering methods. We introduce $\\textbf{Adversarial Suffix Filtering}$ (ASF), a lightweight novel model-agnostic defensive pipeline designed to protect LLMs against adversarial suffix attacks. ASF functions as an input preprocessor and sanitizer that detects and filters adversarially crafted suffixes in prompts, effectively neutralizing malicious injections. We demonstrate that ASF provides comprehensive defense capabilities across both black-box and white-box attack settings, reducing the attack efficacy of state-of-the-art adversarial suffix generation methods to below 4%, while only minimally affecting the target model's capabilities in non-adversarial scenarios.","sentences":["Large Language Models (LLMs) are increasingly embedded in autonomous systems and public-facing environments, yet they remain susceptible to jailbreak vulnerabilities that may undermine their security and trustworthiness.","Adversarial suffixes are considered to be the current state-of-the-art jailbreak, consistently outperforming simpler methods and frequently succeeding even in black-box settings.","Existing defenses rely on access to the internal architecture of models limiting diverse deployment, increase memory and computation footprints dramatically, or can be bypassed with simple prompt engineering methods.","We introduce $\\textbf{Adversarial Suffix Filtering}$","(ASF), a lightweight novel model-agnostic defensive pipeline designed to protect LLMs against adversarial suffix attacks.","ASF functions as an input preprocessor and sanitizer that detects and filters adversarially crafted suffixes in prompts, effectively neutralizing malicious injections.","We demonstrate that ASF provides comprehensive defense capabilities across both black-box and white-box attack settings, reducing the attack efficacy of state-of-the-art adversarial suffix generation methods to below 4%, while only minimally affecting the target model's capabilities in non-adversarial scenarios."],"url":"http://arxiv.org/abs/2505.09602v1"}
{"created":"2025-05-14 17:50:35","title":"Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware","abstract":"Scaling robot learning requires vast and diverse datasets. Yet the prevailing data collection paradigm-human teleoperation-remains costly and constrained by manual effort and physical robot access. We introduce Real2Render2Real (R2R2R), a novel approach for generating robot training data without relying on object dynamics simulation or teleoperation of robot hardware. The input is a smartphone-captured scan of one or more objects and a single video of a human demonstration. R2R2R renders thousands of high visual fidelity robot-agnostic demonstrations by reconstructing detailed 3D object geometry and appearance, and tracking 6-DoF object motion. R2R2R uses 3D Gaussian Splatting (3DGS) to enable flexible asset generation and trajectory synthesis for both rigid and articulated objects, converting these representations to meshes to maintain compatibility with scalable rendering engines like IsaacLab but with collision modeling off. Robot demonstration data generated by R2R2R integrates directly with models that operate on robot proprioceptive states and image observations, such as vision-language-action models (VLA) and imitation learning policies. Physical experiments suggest that models trained on R2R2R data from a single human demonstration can match the performance of models trained on 150 human teleoperation demonstrations. Project page: https://real2render2real.com","sentences":["Scaling robot learning requires vast and diverse datasets.","Yet the prevailing data collection paradigm-human teleoperation-remains costly and constrained by manual effort and physical robot access.","We introduce Real2Render2Real (R2R2R), a novel approach for generating robot training data without relying on object dynamics simulation or teleoperation of robot hardware.","The input is a smartphone-captured scan of one or more objects and a single video of a human demonstration.","R2R2R renders thousands of high visual fidelity robot-agnostic demonstrations by reconstructing detailed 3D object geometry and appearance, and tracking 6-DoF object motion.","R2R2R uses 3D Gaussian Splatting (3DGS) to enable flexible asset generation and trajectory synthesis for both rigid and articulated objects, converting these representations to meshes to maintain compatibility with scalable rendering engines like IsaacLab but with collision modeling off.","Robot demonstration data generated by R2R2R integrates directly with models that operate on robot proprioceptive states and image observations, such as vision-language-action models (VLA) and imitation learning policies.","Physical experiments suggest that models trained on R2R2R data from a single human demonstration can match the performance of models trained on 150 human teleoperation demonstrations.","Project page: https://real2render2real.com"],"url":"http://arxiv.org/abs/2505.09601v1"}
{"created":"2025-05-14 17:47:00","title":"How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference","abstract":"As large language models (LLMs) spread across industries, understanding their environmental footprint at the inference level is no longer optional; it is essential. However, most existing studies exclude proprietary models, overlook infrastructural variability and overhead, or focus solely on training, even as inference increasingly dominates AI's environmental impact. To bridge this gap, this paper introduces a novel infrastructure-aware benchmarking framework for quantifying the environmental footprint of LLM inference across 30 state-of-the-art models as deployed in commercial data centers. Our framework combines public API performance data with region-specific environmental multipliers and statistical inference of hardware configurations. We additionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank models by performance relative to environmental cost. Our results show that o3 and DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33 Wh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and that Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short GPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results in substantial annual environmental impacts. These include electricity use comparable to 35,000 U.S. homes, freshwater evaporation matching the annual drinking needs of 1.2 million people, and carbon emissions requiring a Chicago-sized forest to offset. These findings illustrate a growing paradox: although individual queries are efficient, their global scale drives disproportionate resource consumption. Our study provides a standardized, empirically grounded methodology for benchmarking the sustainability of LLM deployments, laying a foundation for future environmental accountability in AI development and sustainability standards.","sentences":["As large language models (LLMs) spread across industries, understanding their environmental footprint at the inference level is no longer optional; it is essential.","However, most existing studies exclude proprietary models, overlook infrastructural variability and overhead, or focus solely on training, even as inference increasingly dominates AI's environmental impact.","To bridge this gap, this paper introduces a novel infrastructure-aware benchmarking framework for quantifying the environmental footprint of LLM inference across 30 state-of-the-art models as deployed in commercial data centers.","Our framework combines public API performance data with region-specific environmental multipliers and statistical inference of hardware configurations.","We additionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank models by performance relative to environmental cost.","Our results show that o3 and DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33 Wh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and that Claude-3.7 Sonnet ranks highest in eco-efficiency.","While a single short GPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results in substantial annual environmental impacts.","These include electricity use comparable to 35,000 U.S. homes, freshwater evaporation matching the annual drinking needs of 1.2 million people, and carbon emissions requiring a Chicago-sized forest to offset.","These findings illustrate a growing paradox: although individual queries are efficient, their global scale drives disproportionate resource consumption.","Our study provides a standardized, empirically grounded methodology for benchmarking the sustainability of LLM deployments, laying a foundation for future environmental accountability in AI development and sustainability standards."],"url":"http://arxiv.org/abs/2505.09598v1"}
{"created":"2025-05-14 17:46:16","title":"MDTP -- An Adaptive Multi-Source Data Transfer Protocol","abstract":"Scientific data volume is growing in size, and as a direct result, the need for faster transfers is also increasing. The scientific community has sought to leverage parallel transfer methods using multi-threaded and multi-source download models to reduce download times. In multi-source transfers, a client downloads data from multiple replicated servers in parallel. Tools such as Aria2 and BitTorrent support such multi-source transfers and have shown improved transfer times.   In this work, we introduce Multi-Source Data Transfer Protocol, MDTP, which further improves multi-source transfer performance. MDTP logically divides a file request into smaller chunk requests and distributes the chunk requests across multiple servers. Chunk sizes are adapted based on each server's performance but selected in a way that ensures each round of requests completes around the same time. We formulate this chunk-size allocation problem as a variant of the bin-packing problem, where adaptive chunking efficiently fills the available capacity \"bins\" corresponding to each server.   Our evaluation shows that MDTP reduces transfer times by 10-22% compared to Aria2, the fastest alternative. Comparisons with other protocols, such as static chunking and BitTorrent, demonstrate even greater improvements. Additionally, we show that MDTP distributes load proportionally across all available replicas, not just the fastest ones, which improves throughput. Finally, we show MDTP maintains high throughput even when latency increases or bandwidth to the fastest server decreases.","sentences":["Scientific data volume is growing in size, and as a direct result, the need for faster transfers is also increasing.","The scientific community has sought to leverage parallel transfer methods using multi-threaded and multi-source download models to reduce download times.","In multi-source transfers, a client downloads data from multiple replicated servers in parallel.","Tools such as Aria2 and BitTorrent support such multi-source transfers and have shown improved transfer times.   ","In this work, we introduce Multi-Source Data Transfer Protocol, MDTP, which further improves multi-source transfer performance.","MDTP logically divides a file request into smaller chunk requests and distributes the chunk requests across multiple servers.","Chunk sizes are adapted based on each server's performance but selected in a way that ensures each round of requests completes around the same time.","We formulate this chunk-size allocation problem as a variant of the bin-packing problem, where adaptive chunking efficiently fills the available capacity \"bins\" corresponding to each server.   ","Our evaluation shows that MDTP reduces transfer times by 10-22% compared to Aria2, the fastest alternative.","Comparisons with other protocols, such as static chunking and BitTorrent, demonstrate even greater improvements.","Additionally, we show that MDTP distributes load proportionally across all available replicas, not just the fastest ones, which improves throughput.","Finally, we show MDTP maintains high throughput even when latency increases or bandwidth to the fastest server decreases."],"url":"http://arxiv.org/abs/2505.09597v1"}
{"created":"2025-05-14 17:43:40","title":"WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models","abstract":"Large Language Models (LLMs) are predominantly trained and aligned in ways that reinforce Western-centric epistemologies and socio-cultural norms, leading to cultural homogenization and limiting their ability to reflect global civilizational plurality. Existing benchmarking frameworks fail to adequately capture this bias, as they rely on rigid, closed-form assessments that overlook the complexity of cultural inclusivity. To address this, we introduce WorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity (GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our approach is grounded in the Multiplex Worldview proposed by Senturk et al., which distinguishes between Uniplex models, reinforcing cultural homogenization, and Multiplex models, which integrate diverse perspectives. WorldView-Bench measures Cultural Polarization, the exclusion of alternative perspectives, through free-form generative evaluation rather than conventional categorical benchmarks. We implement applied multiplexity through two intervention strategies: (1) Contextually-Implemented Multiplex LLMs, where system prompts embed multiplexity principles, and (2) Multi-Agent System (MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing distinct cultural perspectives collaboratively generate responses. Our results demonstrate a significant increase in Perspectives Distribution Score (PDS) entropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs, alongside a shift toward positive sentiment (67.7%) and enhanced cultural balance. These findings highlight the potential of multiplex-aware AI evaluation in mitigating cultural bias in LLMs, paving the way for more inclusive and ethically aligned AI systems.","sentences":["Large Language Models (LLMs) are predominantly trained and aligned in ways that reinforce Western-centric epistemologies and socio-cultural norms, leading to cultural homogenization and limiting their ability to reflect global civilizational plurality.","Existing benchmarking frameworks fail to adequately capture this bias, as they rely on rigid, closed-form assessments that overlook the complexity of cultural inclusivity.","To address this, we introduce WorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity (GCI) in LLMs by analyzing their ability to accommodate diverse worldviews.","Our approach is grounded in the Multiplex Worldview proposed by Senturk et al., which distinguishes between Uniplex models, reinforcing cultural homogenization, and Multiplex models, which integrate diverse perspectives.","WorldView-Bench measures Cultural Polarization, the exclusion of alternative perspectives, through free-form generative evaluation rather than conventional categorical benchmarks.","We implement applied multiplexity through two intervention strategies: (1) Contextually-Implemented Multiplex LLMs, where system prompts embed multiplexity principles, and (2) Multi-Agent System (MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing distinct cultural perspectives collaboratively generate responses.","Our results demonstrate a significant increase in Perspectives Distribution Score (PDS) entropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs, alongside a shift toward positive sentiment (67.7%) and enhanced cultural balance.","These findings highlight the potential of multiplex-aware AI evaluation in mitigating cultural bias in LLMs, paving the way for more inclusive and ethically aligned AI systems."],"url":"http://arxiv.org/abs/2505.09595v1"}
{"created":"2025-05-14 17:42:50","title":"Online Isolation Forest","abstract":"The anomaly detection literature is abundant with offline methods, which require repeated access to data in memory, and impose impractical assumptions when applied to a streaming context. Existing online anomaly detection methods also generally fail to address these constraints, resorting to periodic retraining to adapt to the online context. We propose Online-iForest, a novel method explicitly designed for streaming conditions that seamlessly tracks the data generating process as it evolves over time. Experimental validation on real-world datasets demonstrated that Online-iForest is on par with online alternatives and closely rivals state-of-the-art offline anomaly detection techniques that undergo periodic retraining. Notably, Online-iForest consistently outperforms all competitors in terms of efficiency, making it a promising solution in applications where fast identification of anomalies is of primary importance such as cybersecurity, fraud and fault detection.","sentences":["The anomaly detection literature is abundant with offline methods, which require repeated access to data in memory, and impose impractical assumptions when applied to a streaming context.","Existing online anomaly detection methods also generally fail to address these constraints, resorting to periodic retraining to adapt to the online context.","We propose Online-iForest, a novel method explicitly designed for streaming conditions that seamlessly tracks the data generating process as it evolves over time.","Experimental validation on real-world datasets demonstrated that Online-iForest is on par with online alternatives and closely rivals state-of-the-art offline anomaly detection techniques that undergo periodic retraining.","Notably, Online-iForest consistently outperforms all competitors in terms of efficiency, making it a promising solution in applications where fast identification of anomalies is of primary importance such as cybersecurity, fraud and fault detection."],"url":"http://arxiv.org/abs/2505.09593v1"}
{"created":"2025-05-14 17:40:22","title":"Variational Visual Question Answering","abstract":"Despite remarkable progress in multimodal models for Visual Question Answering (VQA), there remain major reliability concerns because the models can often be overconfident and miscalibrated, especially in out-of-distribution (OOD) settings. Plenty has been done to address such issues for unimodal models, but little work exists for multimodal cases. Here, we address unreliability in multimodal models by proposing a Variational VQA approach. Specifically, instead of fine-tuning vision-language models by using AdamW, we employ a recently proposed variational algorithm called IVON, which yields a posterior distribution over model parameters. Through extensive experiments, we show that our approach improves calibration and abstentions without sacrificing the accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce Expected Calibration Error by more than 50% compared to the AdamW baseline and raise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of distribution shifts, the performance gain is even higher, achieving 8% Coverage (@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we present variational learning as a viable option to enhance the reliability of multimodal models.","sentences":["Despite remarkable progress in multimodal models for Visual Question Answering (VQA), there remain major reliability concerns because the models can often be overconfident and miscalibrated, especially in out-of-distribution (OOD) settings.","Plenty has been done to address such issues for unimodal models, but little work exists for multimodal cases.","Here, we address unreliability in multimodal models by proposing a Variational VQA approach.","Specifically, instead of fine-tuning vision-language models by using AdamW, we employ a recently proposed variational algorithm called IVON, which yields a posterior distribution over model parameters.","Through extensive experiments, we show that our approach improves calibration and abstentions without sacrificing the accuracy of AdamW.","For instance, compared to AdamW fine-tuning, we reduce Expected Calibration Error by more than 50% compared to the AdamW baseline and raise Coverage by 4% vs. SOTA (for a fixed risk of 1%).","In the presence of distribution shifts, the performance gain is even higher, achieving 8% Coverage (@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD.","Overall, we present variational learning as a viable option to enhance the reliability of multimodal models."],"url":"http://arxiv.org/abs/2505.09591v1"}
{"created":"2025-05-14 17:39:34","title":"Distance-aware Self-adaptive Graph Convolution for Fine-grained Hierarchical Recommendation","abstract":"Graph Convolutional Networks (GCNs) are widely used to improve recommendation accuracy and performance by effectively learning the representations of user and item nodes. However, two major challenges remain: (1) the lack of further optimization in the graph representation structure and (2) insufficient attention given to the varying contributions of different convolutional layers.This paper proposes SAGCN, a distance-based adaptive hierarchical aggregation method that refines the aggregation process through differentiated representation metrics. SAGCN introduces a detailed approach to multilayer information aggregation and representation space optimization, enabling the model to learn hierarchical embedding weights based on the distance between hierarchical representations. This innovation allows for more precise cross-layer information aggregation, improves the model's ability to capture hierarchical embeddings, and optimizes the representation space structure. Additionally, the objective loss function is refined to better align with recommendation tasks.Extensive experiments conducted on four real-world datasets demonstrate significant improvements, including over a 5% increase on Yelp and a 5.58% increase in Recall@10 on the ML_1M dataset.","sentences":["Graph Convolutional Networks (GCNs) are widely used to improve recommendation accuracy and performance by effectively learning the representations of user and item nodes.","However, two major challenges remain: (1) the lack of further optimization in the graph representation structure and (2) insufficient attention given to the varying contributions of different convolutional layers.","This paper proposes SAGCN, a distance-based adaptive hierarchical aggregation method that refines the aggregation process through differentiated representation metrics.","SAGCN introduces a detailed approach to multilayer information aggregation and representation space optimization, enabling the model to learn hierarchical embedding weights based on the distance between hierarchical representations.","This innovation allows for more precise cross-layer information aggregation, improves the model's ability to capture hierarchical embeddings, and optimizes the representation space structure.","Additionally, the objective loss function is refined to better align with recommendation tasks.","Extensive experiments conducted on four real-world datasets demonstrate significant improvements, including over a 5% increase on Yelp and a 5.58% increase in Recall@10 on the ML_1M dataset."],"url":"http://arxiv.org/abs/2505.09590v1"}
{"created":"2025-05-14 17:37:15","title":"Rhomboid Tiling for Geometric Graph Deep Learning","abstract":"Graph Neural Networks (GNNs) have proven effective for learning from graph-structured data through their neighborhood-based message passing framework. Many hierarchical graph clustering pooling methods modify this framework by introducing clustering-based strategies, enabling the construction of more expressive and powerful models. However, all of these message passing framework heavily rely on the connectivity structure of graphs, limiting their ability to capture the rich geometric features inherent in geometric graphs. To address this, we propose Rhomboid Tiling (RT) clustering, a novel clustering method based on the rhomboid tiling structure, which performs clustering by leveraging the complex geometric information of the data and effectively extracts its higher-order geometric structures. Moreover, we design RTPool, a hierarchical graph clustering pooling model based on RT clustering for graph classification tasks. The proposed model demonstrates superior performance, outperforming 21 state-of-the-art competitors on all the 7 benchmark datasets.","sentences":["Graph Neural Networks (GNNs) have proven effective for learning from graph-structured data through their neighborhood-based message passing framework.","Many hierarchical graph clustering pooling methods modify this framework by introducing clustering-based strategies, enabling the construction of more expressive and powerful models.","However, all of these message passing framework heavily rely on the connectivity structure of graphs, limiting their ability to capture the rich geometric features inherent in geometric graphs.","To address this, we propose Rhomboid Tiling (RT) clustering, a novel clustering method based on the rhomboid tiling structure, which performs clustering by leveraging the complex geometric information of the data and effectively extracts its higher-order geometric structures.","Moreover, we design RTPool, a hierarchical graph clustering pooling model based on RT clustering for graph classification tasks.","The proposed model demonstrates superior performance, outperforming 21 state-of-the-art competitors on all the 7 benchmark datasets."],"url":"http://arxiv.org/abs/2505.09586v1"}
{"created":"2025-05-14 17:31:16","title":"Beyond Likes: How Normative Feedback Complements Engagement Signals on Social Media","abstract":"Many online platforms incorporate engagement signals--such as likes and upvotes--into their content ranking systems and interface design. These signals are designed to boost user engagement. However, they can unintentionally elevate content that is less inclusive and may not support normatively desirable behavior. This issue becomes especially concerning when toxic content correlates strongly with popularity indicators such as likes and upvotes. In this study, we propose structured prosocial feedback as a complementary signal to likes and upvotes--one that highlights content quality based on normative criteria to help address the limitations of conventional engagement signals. We begin by designing and implementing a machine learning feedback system powered by a large language model (LLM), which evaluates user comments based on principles of positive psychology, such as individual well-being, constructive social media use, and character strengths. We then conduct a pre-registered user study to examine how existing peer-based and the new expert-based feedback interact to shape users' selection of comments in a social media setting. Results show that peer feedback increases conformity to popularity cues, while expert feedback shifts preferences toward normatively higher-quality content. Moreover, incorporating expert feedback alongside peer evaluations improves alignment with expert assessments and contributes to a less toxic community environment. This illustrates the added value of normative cues--such as expert scores generated by LLMs using psychological rubrics--and underscores the potential benefits of incorporating such signals into platform feedback systems to foster healthier online environments.","sentences":["Many online platforms incorporate engagement signals--such as likes and upvotes--into their content ranking systems and interface design.","These signals are designed to boost user engagement.","However, they can unintentionally elevate content that is less inclusive and may not support normatively desirable behavior.","This issue becomes especially concerning when toxic content correlates strongly with popularity indicators such as likes and upvotes.","In this study, we propose structured prosocial feedback as a complementary signal to likes and upvotes--one that highlights content quality based on normative criteria to help address the limitations of conventional engagement signals.","We begin by designing and implementing a machine learning feedback system powered by a large language model (LLM), which evaluates user comments based on principles of positive psychology, such as individual well-being, constructive social media use, and character strengths.","We then conduct a pre-registered user study to examine how existing peer-based and the new expert-based feedback interact to shape users' selection of comments in a social media setting.","Results show that peer feedback increases conformity to popularity cues, while expert feedback shifts preferences toward normatively higher-quality content.","Moreover, incorporating expert feedback alongside peer evaluations improves alignment with expert assessments and contributes to a less toxic community environment.","This illustrates the added value of normative cues--such as expert scores generated by LLMs using psychological rubrics--and underscores the potential benefits of incorporating such signals into platform feedback systems to foster healthier online environments."],"url":"http://arxiv.org/abs/2505.09583v1"}
{"created":"2025-05-14 17:29:35","title":"VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation","abstract":"While vision-language models have advanced significantly, their application in language-conditioned robotic manipulation is still underexplored, especially for contact-rich tasks that extend beyond visually dominant pick-and-place scenarios. To bridge this gap, we introduce Vision-Tactile-Language-Action model, a novel framework that enables robust policy generation in contact-intensive scenarios by effectively integrating visual and tactile inputs through cross-modal language grounding. A low-cost, multi-modal dataset has been constructed in a simulation environment, containing vision-tactile-action-instruction pairs specifically designed for the fingertip insertion task. Furthermore, we introduce Direct Preference Optimization (DPO) to offer regression-like supervision for the VTLA model, effectively bridging the gap between classification-based next token prediction loss and continuous robotic tasks. Experimental results show that the VTLA model outperforms traditional imitation learning methods (e.g., diffusion policies) and existing multi-modal baselines (TLA/VLA), achieving over 90% success rates on unseen peg shapes. Finally, we conduct real-world peg-in-hole experiments to demonstrate the exceptional Sim2Real performance of the proposed VTLA model. For supplementary videos and results, please visit our project website: https://sites.google.com/view/vtla","sentences":["While vision-language models have advanced significantly, their application in language-conditioned robotic manipulation is still underexplored, especially for contact-rich tasks that extend beyond visually dominant pick-and-place scenarios.","To bridge this gap, we introduce Vision-Tactile-Language-Action model, a novel framework that enables robust policy generation in contact-intensive scenarios by effectively integrating visual and tactile inputs through cross-modal language grounding.","A low-cost, multi-modal dataset has been constructed in a simulation environment, containing vision-tactile-action-instruction pairs specifically designed for the fingertip insertion task.","Furthermore, we introduce Direct Preference Optimization (DPO) to offer regression-like supervision for the VTLA model, effectively bridging the gap between classification-based next token prediction loss and continuous robotic tasks.","Experimental results show that the VTLA model outperforms traditional imitation learning methods (e.g., diffusion policies) and existing multi-modal baselines (TLA/VLA), achieving over 90% success rates on unseen peg shapes.","Finally, we conduct real-world peg-in-hole experiments to demonstrate the exceptional Sim2Real performance of the proposed VTLA model.","For supplementary videos and results, please visit our project website: https://sites.google.com/view/vtla"],"url":"http://arxiv.org/abs/2505.09577v1"}
{"created":"2025-05-14 17:29:19","title":"Ethics and Persuasion in Reinforcement Learning from Human Feedback: A Procedural Rhetorical Approach","abstract":"Since 2022, versions of generative AI chatbots such as ChatGPT and Claude have been trained using a specialized technique called Reinforcement Learning from Human Feedback (RLHF) to fine-tune language model output using feedback from human annotators. As a result, the integration of RLHF has greatly enhanced the outputs of these large language models (LLMs) and made the interactions and responses appear more \"human-like\" than those of previous versions using only supervised learning. The increasing convergence of human and machine-written text has potentially severe ethical, sociotechnical, and pedagogical implications relating to transparency, trust, bias, and interpersonal relations. To highlight these implications, this paper presents a rhetorical analysis of some of the central procedures and processes currently being reshaped by RLHF-enhanced generative AI chatbots: upholding language conventions, information seeking practices, and expectations for social relationships. Rhetorical investigations of generative AI and LLMs have, to this point, focused largely on the persuasiveness of the content generated. Using Ian Bogost's concept of procedural rhetoric, this paper shifts the site of rhetorical investigation from content analysis to the underlying mechanisms of persuasion built into RLHF-enhanced LLMs. In doing so, this theoretical investigation opens a new direction for further inquiry in AI ethics that considers how procedures rerouted through AI-driven technologies might reinforce hegemonic language use, perpetuate biases, decontextualize learning, and encroach upon human relationships. It will therefore be of interest to educators, researchers, scholars, and the growing number of users of generative AI chatbots.","sentences":["Since 2022, versions of generative AI chatbots such as ChatGPT and Claude have been trained using a specialized technique called Reinforcement Learning from Human Feedback (RLHF) to fine-tune language model output using feedback from human annotators.","As a result, the integration of RLHF has greatly enhanced the outputs of these large language models (LLMs) and made the interactions and responses appear more \"human-like\" than those of previous versions using only supervised learning.","The increasing convergence of human and machine-written text has potentially severe ethical, sociotechnical, and pedagogical implications relating to transparency, trust, bias, and interpersonal relations.","To highlight these implications, this paper presents a rhetorical analysis of some of the central procedures and processes currently being reshaped by RLHF-enhanced generative AI chatbots: upholding language conventions, information seeking practices, and expectations for social relationships.","Rhetorical investigations of generative AI and LLMs have, to this point, focused largely on the persuasiveness of the content generated.","Using Ian Bogost's concept of procedural rhetoric, this paper shifts the site of rhetorical investigation from content analysis to the underlying mechanisms of persuasion built into RLHF-enhanced LLMs.","In doing so, this theoretical investigation opens a new direction for further inquiry in AI ethics that considers how procedures rerouted through AI-driven technologies might reinforce hegemonic language use, perpetuate biases, decontextualize learning, and encroach upon human relationships.","It will therefore be of interest to educators, researchers, scholars, and the growing number of users of generative AI chatbots."],"url":"http://arxiv.org/abs/2505.09576v1"}
{"created":"2025-05-14 17:15:11","title":"SAD Neural Networks: Divergent Gradient Flows and Asymptotic Optimality via o-minimal Structures","abstract":"We study gradient flows for loss landscapes of fully connected feed forward neural networks with commonly used continuously differentiable activation functions such as the logistic, hyperbolic tangent, softplus or GELU function. We prove that the gradient flow either converges to a critical point or diverges to infinity while the loss converges to an asymptotic critical value. Moreover, we prove the existence of a threshold $\\varepsilon>0$ such that the loss value of any gradient flow initialized at most $\\varepsilon$ above the optimal level converges to it. For polynomial target functions and sufficiently big architecture and data set, we prove that the optimal loss value is zero and can only be realized asymptotically. From this setting, we deduce our main result that any gradient flow with sufficiently good initialization diverges to infinity. Our proof heavily relies on the geometry of o-minimal structures. We confirm these theoretical findings with numerical experiments and extend our investigation to real-world scenarios, where we observe an analogous behavior.","sentences":["We study gradient flows for loss landscapes of fully connected feed forward neural networks with commonly used continuously differentiable activation functions such as the logistic, hyperbolic tangent, softplus or GELU function.","We prove that the gradient flow either converges to a critical point or diverges to infinity while the loss converges to an asymptotic critical value.","Moreover, we prove the existence of a threshold $\\varepsilon>0$ such that the loss value of any gradient flow initialized at most $\\varepsilon$ above the optimal level converges to it.","For polynomial target functions and sufficiently big architecture and data set, we prove that the optimal loss value is zero and can only be realized asymptotically.","From this setting, we deduce our main result that any gradient flow with sufficiently good initialization diverges to infinity.","Our proof heavily relies on the geometry of o-minimal structures.","We confirm these theoretical findings with numerical experiments and extend our investigation to real-world scenarios, where we observe an analogous behavior."],"url":"http://arxiv.org/abs/2505.09572v1"}
{"created":"2025-05-14 17:15:03","title":"Don't Forget your Inverse DDIM for Image Editing","abstract":"The field of text-to-image generation has undergone significant advancements with the introduction of diffusion models. Nevertheless, the challenge of editing real images persists, as most methods are either computationally intensive or produce poor reconstructions. This paper introduces SAGE (Self-Attention Guidance for image Editing) - a novel technique leveraging pre-trained diffusion models for image editing. SAGE builds upon the DDIM algorithm and incorporates a novel guidance mechanism utilizing the self-attention layers of the diffusion U-Net. This mechanism computes a reconstruction objective based on attention maps generated during the inverse DDIM process, enabling efficient reconstruction of unedited regions without the need to precisely reconstruct the entire input image. Thus, SAGE directly addresses the key challenges in image editing. The superiority of SAGE over other methods is demonstrated through quantitative and qualitative evaluations and confirmed by a statistically validated comprehensive user study, in which all 47 surveyed users preferred SAGE over competing methods. Additionally, SAGE ranks as the top-performing method in seven out of 10 quantitative analyses and secures second and third places in the remaining three.","sentences":["The field of text-to-image generation has undergone significant advancements with the introduction of diffusion models.","Nevertheless, the challenge of editing real images persists, as most methods are either computationally intensive or produce poor reconstructions.","This paper introduces SAGE (Self-Attention Guidance for image Editing) - a novel technique leveraging pre-trained diffusion models for image editing.","SAGE builds upon the DDIM algorithm and incorporates a novel guidance mechanism utilizing the self-attention layers of the diffusion U-Net.","This mechanism computes a reconstruction objective based on attention maps generated during the inverse DDIM process, enabling efficient reconstruction of unedited regions without the need to precisely reconstruct the entire input image.","Thus, SAGE directly addresses the key challenges in image editing.","The superiority of SAGE over other methods is demonstrated through quantitative and qualitative evaluations and confirmed by a statistically validated comprehensive user study, in which all 47 surveyed users preferred SAGE over competing methods.","Additionally, SAGE ranks as the top-performing method in seven out of 10 quantitative analyses and secures second and third places in the remaining three."],"url":"http://arxiv.org/abs/2505.09571v1"}
{"created":"2025-05-14 17:11:23","title":"MIGRATION-BENCH: Repository-Level Code Migration Benchmark from Java 8","abstract":"With the rapid advancement of powerful large language models (LLMs) in recent years, a wide range of software engineering tasks can now be addressed using LLMs, significantly enhancing productivity and scalability. Numerous benchmark datasets have been developed to evaluate the coding capabilities of these models, while they primarily focus on problem-solving and issue-resolution tasks. In contrast, we introduce a new coding benchmark MIGRATION-BENCH with a distinct focus: code migration. MIGRATION-BENCH aims to serve as a comprehensive benchmark for migration from Java 8 to the latest long-term support (LTS) versions (Java 17, 21), MIGRATION-BENCH includes a full dataset and its subset selected with $5,102$ and $300$ repositories respectively. Selected is a representative subset curated for complexity and difficulty, offering a versatile resource to support research in the field of code migration. Additionally, we provide a comprehensive evaluation framework to facilitate rigorous and standardized assessment of LLMs on this challenging task. We further propose SD-Feedback and demonstrate that LLMs can effectively tackle repository-level code migration to Java 17. For the selected subset with Claude-3.5-Sonnet-v2, SD-Feedback achieves 62.33% and 27.00% success rate (pass@1) for minimal and maximal migration respectively. The benchmark dataset and source code are available at: https://huggingface.co/collections/AmazonScience and https://github.com/amazon-science/self_debug respectively.","sentences":["With the rapid advancement of powerful large language models (LLMs) in recent years, a wide range of software engineering tasks can now be addressed using LLMs, significantly enhancing productivity and scalability.","Numerous benchmark datasets have been developed to evaluate the coding capabilities of these models, while they primarily focus on problem-solving and issue-resolution tasks.","In contrast, we introduce a new coding benchmark MIGRATION-BENCH with a distinct focus: code migration.","MIGRATION-BENCH aims to serve as a comprehensive benchmark for migration from Java 8 to the latest long-term support (LTS) versions (Java 17, 21), MIGRATION-BENCH includes a full dataset and its subset selected with $5,102$ and $300$ repositories respectively.","Selected is a representative subset curated for complexity and difficulty, offering a versatile resource to support research in the field of code migration.","Additionally, we provide a comprehensive evaluation framework to facilitate rigorous and standardized assessment of LLMs on this challenging task.","We further propose SD-Feedback and demonstrate that LLMs can effectively tackle repository-level code migration to Java 17.","For the selected subset with Claude-3.5-Sonnet-v2, SD-Feedback achieves 62.33% and 27.00% success rate (pass@1) for minimal and maximal migration respectively.","The benchmark dataset and source code are available at: https://huggingface.co/collections/AmazonScience and https://github.com/amazon-science/self_debug respectively."],"url":"http://arxiv.org/abs/2505.09569v1"}
{"created":"2025-05-14 17:11:07","title":"BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset","abstract":"Unifying image understanding and generation has gained growing attention in recent research on multimodal models. Although design choices for image understanding have been extensively studied, the optimal model architecture and training recipe for a unified framework with image generation remain underexplored. Motivated by the strong potential of autoregressive and diffusion models for high-quality generation and scalability, we conduct a comprehensive study of their use in unified multimodal settings, with emphasis on image representations, modeling objectives, and training strategies. Grounded in these investigations, we introduce a novel approach that employs a diffusion transformer to generate semantically rich CLIP image features, in contrast to conventional VAE-based representations. This design yields both higher training efficiency and improved generative quality. Furthermore, we demonstrate that a sequential pretraining strategy for unified models-first training on image understanding and subsequently on image generation-offers practical advantages by preserving image understanding capability while developing strong image generation ability. Finally, we carefully curate a high-quality instruction-tuning dataset BLIP3o-60k for image generation by prompting GPT-4o with a diverse set of captions covering various scenes, objects, human gestures, and more. Building on our innovative model design, training recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art unified multimodal models. BLIP3-o achieves superior performance across most of the popular benchmarks spanning both image understanding and generation tasks. To facilitate future research, we fully open-source our models, including code, model weights, training scripts, and pretraining and instruction tuning datasets.","sentences":["Unifying image understanding and generation has gained growing attention in recent research on multimodal models.","Although design choices for image understanding have been extensively studied, the optimal model architecture and training recipe for a unified framework with image generation remain underexplored.","Motivated by the strong potential of autoregressive and diffusion models for high-quality generation and scalability, we conduct a comprehensive study of their use in unified multimodal settings, with emphasis on image representations, modeling objectives, and training strategies.","Grounded in these investigations, we introduce a novel approach that employs a diffusion transformer to generate semantically rich CLIP image features, in contrast to conventional VAE-based representations.","This design yields both higher training efficiency and improved generative quality.","Furthermore, we demonstrate that a sequential pretraining strategy for unified models-first training on image understanding and subsequently on image generation-offers practical advantages by preserving image understanding capability while developing strong image generation ability.","Finally, we carefully curate a high-quality instruction-tuning dataset BLIP3o-60k for image generation by prompting GPT-4o with a diverse set of captions covering various scenes, objects, human gestures, and more.","Building on our innovative model design, training recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art unified multimodal models.","BLIP3-o achieves superior performance across most of the popular benchmarks spanning both image understanding and generation tasks.","To facilitate future research, we fully open-source our models, including code, model weights, training scripts, and pretraining and instruction tuning datasets."],"url":"http://arxiv.org/abs/2505.09568v1"}
{"created":"2025-05-14 17:07:30","title":"Using Foundation Models as Pseudo-Label Generators for Pre-Clinical 4D Cardiac CT Segmentation","abstract":"Cardiac image segmentation is an important step in many cardiac image analysis and modeling tasks such as motion tracking or simulations of cardiac mechanics. While deep learning has greatly advanced segmentation in clinical settings, there is limited work on pre-clinical imaging, notably in porcine models, which are often used due to their anatomical and physiological similarity to humans. However, differences between species create a domain shift that complicates direct model transfer from human to pig data.   Recently, foundation models trained on large human datasets have shown promise for robust medical image segmentation; yet their applicability to porcine data remains largely unexplored. In this work, we investigate whether foundation models can generate sufficiently accurate pseudo-labels for pig cardiac CT and propose a simple self-training approach to iteratively refine these labels. Our method requires no manually annotated pig data, relying instead on iterative updates to improve segmentation quality. We demonstrate that this self-training process not only enhances segmentation accuracy but also smooths out temporal inconsistencies across consecutive frames. Although our results are encouraging, there remains room for improvement, for example by incorporating more sophisticated self-training strategies and by exploring additional foundation models and other cardiac imaging technologies.","sentences":["Cardiac image segmentation is an important step in many cardiac image analysis and modeling tasks such as motion tracking or simulations of cardiac mechanics.","While deep learning has greatly advanced segmentation in clinical settings",", there is limited work on pre-clinical imaging, notably in porcine models, which are often used due to their anatomical and physiological similarity to humans.","However, differences between species create a domain shift that complicates direct model transfer from human to pig data.   ","Recently, foundation models trained on large human datasets have shown promise for robust medical image segmentation; yet their applicability to porcine data remains largely unexplored.","In this work, we investigate whether foundation models can generate sufficiently accurate pseudo-labels for pig cardiac CT and propose a simple self-training approach to iteratively refine these labels.","Our method requires no manually annotated pig data, relying instead on iterative updates to improve segmentation quality.","We demonstrate that this self-training process not only enhances segmentation accuracy but also smooths out temporal inconsistencies across consecutive frames.","Although our results are encouraging, there remains room for improvement, for example by incorporating more sophisticated self-training strategies and by exploring additional foundation models and other cardiac imaging technologies."],"url":"http://arxiv.org/abs/2505.09564v1"}
{"created":"2025-05-14 17:05:12","title":"Camera-Only 3D Panoptic Scene Completion for Autonomous Driving through Differentiable Object Shapes","abstract":"Autonomous vehicles need a complete map of their surroundings to plan and act. This has sparked research into the tasks of 3D occupancy prediction, 3D scene completion, and 3D panoptic scene completion, which predict a dense map of the ego vehicle's surroundings as a voxel grid. Scene completion extends occupancy prediction by predicting occluded regions of the voxel grid, and panoptic scene completion further extends this task by also distinguishing object instances within the same class; both aspects are crucial for path planning and decision-making. However, 3D panoptic scene completion is currently underexplored. This work introduces a novel framework for 3D panoptic scene completion that extends existing 3D semantic scene completion models. We propose an Object Module and Panoptic Module that can easily be integrated with 3D occupancy and scene completion methods presented in the literature. Our approach leverages the available annotations in occupancy benchmarks, allowing individual object shapes to be learned as a differentiable problem. The code is available at https://github.com/nicolamarinello/OffsetOcc .","sentences":["Autonomous vehicles need a complete map of their surroundings to plan and act.","This has sparked research into the tasks of 3D occupancy prediction, 3D scene completion, and 3D panoptic scene completion, which predict a dense map of the ego vehicle's surroundings as a voxel grid.","Scene completion extends occupancy prediction by predicting occluded regions of the voxel grid, and panoptic scene completion further extends this task by also distinguishing object instances within the same class; both aspects are crucial for path planning and decision-making.","However, 3D panoptic scene completion is currently underexplored.","This work introduces a novel framework for 3D panoptic scene completion that extends existing 3D semantic scene completion models.","We propose an Object Module and Panoptic Module that can easily be integrated with 3D occupancy and scene completion methods presented in the literature.","Our approach leverages the available annotations in occupancy benchmarks, allowing individual object shapes to be learned as a differentiable problem.","The code is available at https://github.com/nicolamarinello/OffsetOcc ."],"url":"http://arxiv.org/abs/2505.09562v1"}
{"created":"2025-05-14 17:00:47","title":"Learning Long-Context Diffusion Policies via Past-Token Prediction","abstract":"Reasoning over long sequences of observations and actions is essential for many robotic tasks. Yet, learning effective long-context policies from demonstrations remains challenging. As context length increases, training becomes increasingly expensive due to rising memory demands, and policy performance often degrades as a result of spurious correlations. Recent methods typically sidestep these issues by truncating context length, discarding historical information that may be critical for subsequent decisions. In this paper, we propose an alternative approach that explicitly regularizes the retention of past information. We first revisit the copycat problem in imitation learning and identify an opposite challenge in recent diffusion policies: rather than over-relying on prior actions, they often fail to capture essential dependencies between past and future actions. To address this, we introduce Past-Token Prediction (PTP), an auxiliary task in which the policy learns to predict past action tokens alongside future ones. This regularization significantly improves temporal modeling in the policy head, with minimal reliance on visual representations. Building on this observation, we further introduce a multistage training strategy: pre-train the visual encoder with short contexts, and fine-tune the policy head using cached long-context embeddings. This strategy preserves the benefits of PTP while greatly reducing memory and computational overhead. Finally, we extend PTP into a self-verification mechanism at test time, enabling the policy to score and select candidates consistent with past actions during inference. Experiments across four real-world and six simulated tasks demonstrate that our proposed method improves the performance of long-context diffusion policies by 3x and accelerates policy training by more than 10x.","sentences":["Reasoning over long sequences of observations and actions is essential for many robotic tasks.","Yet, learning effective long-context policies from demonstrations remains challenging.","As context length increases, training becomes increasingly expensive due to rising memory demands, and policy performance often degrades as a result of spurious correlations.","Recent methods typically sidestep these issues by truncating context length, discarding historical information that may be critical for subsequent decisions.","In this paper, we propose an alternative approach that explicitly regularizes the retention of past information.","We first revisit the copycat problem in imitation learning and identify an opposite challenge in recent diffusion policies: rather than over-relying on prior actions, they often fail to capture essential dependencies between past and future actions.","To address this, we introduce Past-Token Prediction (PTP), an auxiliary task in which the policy learns to predict past action tokens alongside future ones.","This regularization significantly improves temporal modeling in the policy head, with minimal reliance on visual representations.","Building on this observation, we further introduce a multistage training strategy: pre-train the visual encoder with short contexts, and fine-tune the policy head using cached long-context embeddings.","This strategy preserves the benefits of PTP while greatly reducing memory and computational overhead.","Finally, we extend PTP into a self-verification mechanism at test time, enabling the policy to score and select candidates consistent with past actions during inference.","Experiments across four real-world and six simulated tasks demonstrate that our proposed method improves the performance of long-context diffusion policies by 3x and accelerates policy training by more than 10x."],"url":"http://arxiv.org/abs/2505.09561v1"}
{"created":"2025-05-14 16:45:51","title":"Distilling Realizable Students from Unrealizable Teachers","abstract":"We study policy distillation under privileged information, where a student policy with only partial observations must learn from a teacher with full-state access. A key challenge is information asymmetry: the student cannot directly access the teacher's state space, leading to distributional shifts and policy degradation. Existing approaches either modify the teacher to produce realizable but sub-optimal demonstrations or rely on the student to explore missing information independently, both of which are inefficient. Our key insight is that the student should strategically interact with the teacher --querying only when necessary and resetting from recovery states --to stay on a recoverable path within its own observation space. We introduce two methods: (i) an imitation learning approach that adaptively determines when the student should query the teacher for corrections, and (ii) a reinforcement learning approach that selects where to initialize training for efficient exploration. We validate our methods in both simulated and real-world robotic tasks, demonstrating significant improvements over standard teacher-student baselines in training efficiency and final performance. The project website is available at : https://portal-cornell.github.io/CritiQ_ReTRy/","sentences":["We study policy distillation under privileged information, where a student policy with only partial observations must learn from a teacher with full-state access.","A key challenge is information asymmetry: the student cannot directly access the teacher's state space, leading to distributional shifts and policy degradation.","Existing approaches either modify the teacher to produce realizable but sub-optimal demonstrations or rely on the student to explore missing information independently, both of which are inefficient.","Our key insight is that the student should strategically interact with the teacher --querying only when necessary and resetting from recovery states --to stay on a recoverable path within its own observation space.","We introduce two methods: (i) an imitation learning approach that adaptively determines when the student should query the teacher for corrections, and (ii) a reinforcement learning approach that selects where to initialize training for efficient exploration.","We validate our methods in both simulated and real-world robotic tasks, demonstrating significant improvements over standard teacher-student baselines in training efficiency and final performance.","The project website is available at : https://portal-cornell.github.io/CritiQ_ReTRy/"],"url":"http://arxiv.org/abs/2505.09546v1"}
{"created":"2025-05-14 16:40:34","title":"The Silent Scientist: When Software Research Fails to Reach Its Audience","abstract":"If software research were a performance, it would be a thoughtful theater play -- full of rich content but confined to the traditional stage of academic publishing. Meanwhile, its potential audience is immersed in engaging on-demand experiences, leaving the theater half-empty, and the research findings lost in the wings. As long as this remains the case, discussions about research relevance and impact lack meaningful context.","sentences":["If software research were a performance, it would be a thoughtful theater play -- full of rich content but confined to the traditional stage of academic publishing.","Meanwhile, its potential audience is immersed in engaging on-demand experiences, leaving the theater half-empty, and the research findings lost in the wings.","As long as this remains the case, discussions about research relevance and impact lack meaningful context."],"url":"http://arxiv.org/abs/2505.09541v1"}
{"created":"2025-05-14 16:32:45","title":"GlobalMood: A cross-cultural benchmark for music emotion recognition","abstract":"Human annotations of mood in music are essential for music generation and recommender systems. However, existing datasets predominantly focus on Western songs with mood terms derived from English, which may limit generalizability across diverse linguistic and cultural backgrounds. To address this, we introduce `GlobalMood', a novel cross-cultural benchmark dataset comprising 1,180 songs sampled from 59 countries, with large-scale annotations collected from 2,519 individuals across five culturally and linguistically distinct locations: U.S., France, Mexico, S. Korea, and Egypt. Rather than imposing predefined mood categories, we implement a bottom-up, participant-driven approach to organically elicit culturally specific music-related mood terms. We then recruit another pool of human participants to collect 988,925 ratings for these culture-specific descriptors. Our analysis confirms the presence of a valence-arousal structure shared across cultures, yet also reveals significant divergences in how certain mood terms, despite being dictionary equivalents, are perceived cross-culturally. State-of-the-art multimodal models benefit substantially from fine-tuning on our cross-culturally balanced dataset, as evidenced by improved alignment with human evaluations - particularly in non-English contexts. More broadly, our findings inform the ongoing debate on the universality versus cultural specificity of emotional descriptors, and our methodology can contribute to other multimodal and cross-lingual research.","sentences":["Human annotations of mood in music are essential for music generation and recommender systems.","However, existing datasets predominantly focus on Western songs with mood terms derived from English, which may limit generalizability across diverse linguistic and cultural backgrounds.","To address this, we introduce `GlobalMood', a novel cross-cultural benchmark dataset comprising 1,180 songs sampled from 59 countries, with large-scale annotations collected from 2,519 individuals across five culturally and linguistically distinct locations: U.S., France, Mexico, S. Korea, and Egypt.","Rather than imposing predefined mood categories, we implement a bottom-up, participant-driven approach to organically elicit culturally specific music-related mood terms.","We then recruit another pool of human participants to collect 988,925 ratings for these culture-specific descriptors.","Our analysis confirms the presence of a valence-arousal structure shared across cultures, yet also reveals significant divergences in how certain mood terms, despite being dictionary equivalents, are perceived cross-culturally.","State-of-the-art multimodal models benefit substantially from fine-tuning on our cross-culturally balanced dataset, as evidenced by improved alignment with human evaluations - particularly in non-English contexts.","More broadly, our findings inform the ongoing debate on the universality versus cultural specificity of emotional descriptors, and our methodology can contribute to other multimodal and cross-lingual research."],"url":"http://arxiv.org/abs/2505.09539v1"}
{"created":"2025-05-14 16:28:34","title":"Optimizing the Decoding Probability and Coverage Ratio of Composite DNA","abstract":"This paper studies two problems that are motivated by the novel recent approach of composite DNA that takes advantage of the DNA synthesis property which generates a huge number of copies for every synthesized strand. Under this paradigm, every composite symbols does not store a single nucleotide but a mixture of the four DNA nucleotides. The first problem studies the expected number of strand reads in order to decode a composite strand or a group of composite strands. In the second problem, our goal is study how to carefully choose a fixed number of mixtures of the DNA nucleotides such that the decoding probability by the maximum likelihood decoder is maximized.","sentences":["This paper studies two problems that are motivated by the novel recent approach of composite DNA that takes advantage of the DNA synthesis property which generates a huge number of copies for every synthesized strand.","Under this paradigm, every composite symbols does not store a single nucleotide but a mixture of the four DNA nucleotides.","The first problem studies the expected number of strand reads in order to decode a composite strand or a group of composite strands.","In the second problem, our goal is study how to carefully choose a fixed number of mixtures of the DNA nucleotides such that the decoding probability by the maximum likelihood decoder is maximized."],"url":"http://arxiv.org/abs/2505.09533v1"}
{"created":"2025-05-14 16:24:22","title":"Contactless Cardiac Pulse Monitoring Using Event Cameras","abstract":"Time event cameras are a novel technology for recording scene information at extremely low latency and with low power consumption. Event cameras output a stream of events that encapsulate pixel-level light intensity changes within the scene, capturing information with a higher dynamic range and temporal resolution than traditional cameras. This study investigates the contact-free reconstruction of an individual's cardiac pulse signal from time event recording of their face using a supervised convolutional neural network (CNN) model. An end-to-end model is trained to extract the cardiac signal from a two-dimensional representation of the event stream, with model performance evaluated based on the accuracy of the calculated heart rate. The experimental results confirm that physiological cardiac information in the facial region is effectively preserved within the event stream, showcasing the potential of this novel sensor for remote heart rate monitoring. The model trained on event frames achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm) compared to the RMSE of 2.92 bpm achieved by the baseline model trained on standard camera frames. Furthermore, models trained on event frames generated at 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an RMSE of 2.54 and 2.13 bpm, respectively.","sentences":["Time event cameras are a novel technology for recording scene information at extremely low latency and with low power consumption.","Event cameras output a stream of events that encapsulate pixel-level light intensity changes within the scene, capturing information with a higher dynamic range and temporal resolution than traditional cameras.","This study investigates the contact-free reconstruction of an individual's cardiac pulse signal from time event recording of their face using a supervised convolutional neural network (CNN) model.","An end-to-end model is trained to extract the cardiac signal from a two-dimensional representation of the event stream, with model performance evaluated based on the accuracy of the calculated heart rate.","The experimental results confirm that physiological cardiac information in the facial region is effectively preserved within the event stream, showcasing the potential of this novel sensor for remote heart rate monitoring.","The model trained on event frames achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm) compared to the RMSE of 2.92 bpm achieved by the baseline model trained on standard camera frames.","Furthermore, models trained on event frames generated at 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an RMSE of 2.54 and 2.13 bpm, respectively."],"url":"http://arxiv.org/abs/2505.09529v1"}
{"created":"2025-05-14 16:23:26","title":"Conformal Bounds on Full-Reference Image Quality for Imaging Inverse Problems","abstract":"In imaging inverse problems, we would like to know how close the recovered image is to the true image in terms of full-reference image quality (FRIQ) metrics like PSNR, SSIM, LPIPS, etc. This is especially important in safety-critical applications like medical imaging, where knowing that, say, the SSIM was poor could potentially avoid a costly misdiagnosis. But since we don't know the true image, computing FRIQ is non-trivial. In this work, we combine conformal prediction with approximate posterior sampling to construct bounds on FRIQ that are guaranteed to hold up to a user-specified error probability. We demonstrate our approach on image denoising and accelerated magnetic resonance imaging (MRI) problems. Code is available at https://github.com/jwen307/quality_uq.","sentences":["In imaging inverse problems, we would like to know how close the recovered image is to the true image in terms of full-reference image quality (FRIQ) metrics like PSNR, SSIM, LPIPS, etc.","This is especially important in safety-critical applications like medical imaging, where knowing that, say, the SSIM was poor could potentially avoid a costly misdiagnosis.","But since we don't know the true image, computing FRIQ is non-trivial.","In this work, we combine conformal prediction with approximate posterior sampling to construct bounds on FRIQ that are guaranteed to hold up to a user-specified error probability.","We demonstrate our approach on image denoising and accelerated magnetic resonance imaging (MRI) problems.","Code is available at https://github.com/jwen307/quality_uq."],"url":"http://arxiv.org/abs/2505.09528v1"}
{"created":"2025-05-14 16:22:41","title":"Evaluation Metrics for Misinformation Warning Interventions: Challenges and Prospects","abstract":"Misinformation has become a widespread issue in the 21st century, impacting numerous areas of society and underscoring the need for effective intervention strategies. Among these strategies, user-centered interventions, such as warning systems, have shown promise in reducing the spread of misinformation. Many studies have used various metrics to evaluate the effectiveness of these warning interventions. However, no systematic review has thoroughly examined these metrics in all studies. This paper provides a comprehensive review of existing metrics for assessing the effectiveness of misinformation warnings, categorizing them into four main groups: behavioral impact, trust and credulity, usability, and cognitive and psychological effects. Through this review, we identify critical challenges in measuring the effectiveness of misinformation warnings, including inconsistent use of cognitive and attitudinal metrics, the lack of standardized metrics for affective and emotional impact, variations in user trust, and the need for more inclusive warning designs. We present an overview of these metrics and propose areas for future research.","sentences":["Misinformation has become a widespread issue in the 21st century, impacting numerous areas of society and underscoring the need for effective intervention strategies.","Among these strategies, user-centered interventions, such as warning systems, have shown promise in reducing the spread of misinformation.","Many studies have used various metrics to evaluate the effectiveness of these warning interventions.","However, no systematic review has thoroughly examined these metrics in all studies.","This paper provides a comprehensive review of existing metrics for assessing the effectiveness of misinformation warnings, categorizing them into four main groups: behavioral impact, trust and credulity, usability, and cognitive and psychological effects.","Through this review, we identify critical challenges in measuring the effectiveness of misinformation warnings, including inconsistent use of cognitive and attitudinal metrics, the lack of standardized metrics for affective and emotional impact, variations in user trust, and the need for more inclusive warning designs.","We present an overview of these metrics and propose areas for future research."],"url":"http://arxiv.org/abs/2505.09526v1"}
{"created":"2025-05-14 16:21:45","title":"An Asymptotically Optimal Approximation Algorithm for Multiobjective Submodular Maximization at Scale","abstract":"Maximizing a single submodular set function subject to a cardinality constraint is a well-studied and central topic in combinatorial optimization. However, finding a set that maximizes multiple functions at the same time is much less understood, even though it is a formulation which naturally occurs in robust maximization or problems with fairness considerations such as fair influence maximization or fair allocation.   In this work, we consider the problem of maximizing the minimum over many submodular functions, which is known as multiobjective submodular maximization. All known polynomial-time approximation algorithms either obtain a weak approximation guarantee or rely on the evaluation of the multilinear extension. The latter is expensive to evaluate and renders such algorithms impractical. We bridge this gap and introduce the first scalable and practical algorithm that obtains the best-known approximation guarantee. We furthermore introduce a novel application fair centrality maximization and show how it can be addressed via multiobjective submodular maximization. In our experimental evaluation, we show that our algorithm outperforms known algorithms in terms of objective value and running time.","sentences":["Maximizing a single submodular set function subject to a cardinality constraint is a well-studied and central topic in combinatorial optimization.","However, finding a set that maximizes multiple functions at the same time is much less understood, even though it is a formulation which naturally occurs in robust maximization or problems with fairness considerations such as fair influence maximization or fair allocation.   ","In this work, we consider the problem of maximizing the minimum over many submodular functions, which is known as multiobjective submodular maximization.","All known polynomial-time approximation algorithms either obtain a weak approximation guarantee or rely on the evaluation of the multilinear extension.","The latter is expensive to evaluate and renders such algorithms impractical.","We bridge this gap and introduce the first scalable and practical algorithm that obtains the best-known approximation guarantee.","We furthermore introduce a novel application fair centrality maximization and show how it can be addressed via multiobjective submodular maximization.","In our experimental evaluation, we show that our algorithm outperforms known algorithms in terms of objective value and running time."],"url":"http://arxiv.org/abs/2505.09525v1"}
{"created":"2025-05-14 16:16:36","title":"PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning","abstract":"Parameter-efficient fine-tuning (PEFT) methods have shown promise in adapting large language models, yet existing approaches exhibit counter-intuitive phenomena: integrating router into prompt tuning (PT) increases training efficiency yet does not improve performance universally; parameter reduction through matrix decomposition can improve performance in specific domains. Motivated by these observations and the modular nature of PT, we propose PT-MoE, a novel framework that integrates matrix decomposition with mixture-of-experts (MoE) routing for efficient PT. Results across 17 datasets demonstrate that PT-MoE achieves state-of-the-art performance in both question answering (QA) and mathematical problem solving tasks, improving F1 score by 1.49 points over PT and 2.13 points over LoRA in QA tasks, while enhancing mathematical accuracy by 10.75 points over PT and 0.44 points over LoRA, all while using 25% fewer parameters than LoRA. Our analysis reveals that while PT methods generally excel in QA tasks and LoRA-based methods in math datasets, the integration of matrix decomposition and MoE in PT-MoE yields complementary benefits: decomposition enables efficient parameter sharing across experts while MoE provides dynamic adaptation, collectively enabling PT-MoE to demonstrate cross-task consistency and generalization abilities. These findings, along with ablation studies on routing mechanisms and architectural components, provide insights for future PEFT methods.","sentences":["Parameter-efficient fine-tuning (PEFT) methods have shown promise in adapting large language models, yet existing approaches exhibit counter-intuitive phenomena: integrating router into prompt tuning (PT) increases training efficiency yet does not improve performance universally; parameter reduction through matrix decomposition can improve performance in specific domains.","Motivated by these observations and the modular nature of PT, we propose PT-MoE, a novel framework that integrates matrix decomposition with mixture-of-experts (MoE) routing for efficient PT.","Results across 17 datasets demonstrate that PT-MoE achieves state-of-the-art performance in both question answering (QA) and mathematical problem solving tasks, improving F1 score by 1.49 points over PT and 2.13 points over LoRA in QA tasks, while enhancing mathematical accuracy by 10.75 points over PT and 0.44 points over LoRA, all while using 25% fewer parameters than LoRA.","Our analysis reveals that while PT methods generally excel in QA tasks and LoRA-based methods in math datasets, the integration of matrix decomposition and MoE in PT-MoE yields complementary benefits: decomposition enables efficient parameter sharing across experts while MoE provides dynamic adaptation, collectively enabling PT-MoE to demonstrate cross-task consistency and generalization abilities.","These findings, along with ablation studies on routing mechanisms and architectural components, provide insights for future PEFT methods."],"url":"http://arxiv.org/abs/2505.09519v1"}
{"created":"2025-05-14 16:15:58","title":"\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs","abstract":"Partially observable Markov decision processes (POMDPs) model specific environments in sequential decision-making under uncertainty. Critically, optimal policies for POMDPs may not be robust against perturbations in the environment. Hidden-model POMDPs (HM-POMDPs) capture sets of different environment models, that is, POMDPs with a shared action and observation space. The intuition is that the true model is hidden among a set of potential models, and it is unknown which model will be the environment at execution time. A policy is robust for a given HM-POMDP if it achieves sufficient performance for each of its POMDPs. We compute such robust policies by combining two orthogonal techniques: (1) a deductive formal verification technique that supports tractable robust policy evaluation by computing a worst-case POMDP within the HM-POMDP and (2) subgradient ascent to optimize the candidate policy for a worst-case POMDP. The empirical evaluation shows that, compared to various baselines, our approach (1) produces policies that are more robust and generalize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of over a hundred thousand environments.","sentences":["Partially observable Markov decision processes (POMDPs) model specific environments in sequential decision-making under uncertainty.","Critically, optimal policies for POMDPs may not be robust against perturbations in the environment.","Hidden-model POMDPs (HM-POMDPs) capture sets of different environment models, that is, POMDPs with a shared action and observation space.","The intuition is that the true model is hidden among a set of potential models, and it is unknown which model will be the environment at execution time.","A policy is robust for a given HM-POMDP if it achieves sufficient performance for each of its POMDPs.","We compute such robust policies by combining two orthogonal techniques: (1) a deductive formal verification technique that supports tractable robust policy evaluation by computing a worst-case POMDP within the HM-POMDP and (2) subgradient ascent to optimize the candidate policy for a worst-case POMDP.","The empirical evaluation shows that, compared to various baselines, our approach (1) produces policies that are more robust and generalize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of over a hundred thousand environments."],"url":"http://arxiv.org/abs/2505.09518v1"}
{"created":"2025-05-14 16:07:17","title":"Risk-aware Markov Decision Processes Using Cumulative Prospect Theory","abstract":"Cumulative prospect theory (CPT) is the first theory for decision-making under uncertainty that combines full theoretical soundness and empirically realistic features [P.P. Wakker - Prospect theory: For risk and ambiguity, Page 2]. While CPT was originally considered in one-shot settings for risk-aware decision-making, we consider CPT in sequential decision-making. The most fundamental and well-studied models for sequential decision-making are Markov chains (MCs), and their generalization Markov decision processes (MDPs). The complexity theoretic study of MCs and MDPs with CPT is a fundamental problem that has not been addressed in the literature.   Our contributions are as follows: First, we present an alternative viewpoint for the CPT-value of MCs and MDPs. This allows us to establish a connection with multi-objective reachability analysis and conclude the strategy complexity result that memoryless randomized strategies are necessary and sufficient for optimality. Second, based on this connection, we provide an algorithm for computing the CPT-value in MDPs with infinite-horizon objectives. We show that the problem is in EXPTIME and fixed-parameter tractable. Moreover, we provide a polynomial-time algorithm for the special case of MCs.","sentences":["Cumulative prospect theory (CPT) is the first theory for decision-making under uncertainty that combines full theoretical soundness and empirically realistic features","[P.P. Wakker - Prospect theory: For risk and ambiguity, Page 2].","While CPT was originally considered in one-shot settings for risk-aware decision-making, we consider CPT in sequential decision-making.","The most fundamental and well-studied models for sequential decision-making are Markov chains (MCs), and their generalization Markov decision processes (MDPs).","The complexity theoretic study of MCs and MDPs with CPT is a fundamental problem that has not been addressed in the literature.   ","Our contributions are as follows:","First, we present an alternative viewpoint for the CPT-value of MCs and MDPs.","This allows us to establish a connection with multi-objective reachability analysis and conclude the strategy complexity result that memoryless randomized strategies are necessary and sufficient for optimality.","Second, based on this connection, we provide an algorithm for computing the CPT-value in MDPs with infinite-horizon objectives.","We show that the problem is in EXPTIME and fixed-parameter tractable.","Moreover, we provide a polynomial-time algorithm for the special case of MCs."],"url":"http://arxiv.org/abs/2505.09514v1"}
{"created":"2025-05-14 16:03:01","title":"Design of a Formation Control System to Assist Human Operators in Flying a Swarm of Robotic Blimps","abstract":"Formation control is essential for swarm robotics, enabling coordinated behavior in complex environments. In this paper, we introduce a novel formation control system for an indoor blimp swarm using a specialized leader-follower approach enhanced with a dynamic leader-switching mechanism. This strategy allows any blimp to take on the leader role, distributing maneuvering demands across the swarm and enhancing overall formation stability. Only the leader blimp is manually controlled by a human operator, while follower blimps use onboard monocular cameras and a laser altimeter for relative position and altitude estimation. A leader-switching scheme is proposed to assist the human operator to maintain stability of the swarm, especially when a sharp turn is performed. Experimental results confirm that the leader-switching mechanism effectively maintains stable formations and adapts to dynamic indoor environments while assisting human operator.","sentences":["Formation control is essential for swarm robotics, enabling coordinated behavior in complex environments.","In this paper, we introduce a novel formation control system for an indoor blimp swarm using a specialized leader-follower approach enhanced with a dynamic leader-switching mechanism.","This strategy allows any blimp to take on the leader role, distributing maneuvering demands across the swarm and enhancing overall formation stability.","Only the leader blimp is manually controlled by a human operator, while follower blimps use onboard monocular cameras and a laser altimeter for relative position and altitude estimation.","A leader-switching scheme is proposed to assist the human operator to maintain stability of the swarm, especially when a sharp turn is performed.","Experimental results confirm that the leader-switching mechanism effectively maintains stable formations and adapts to dynamic indoor environments while assisting human operator."],"url":"http://arxiv.org/abs/2505.09511v1"}
{"created":"2025-05-14 16:02:34","title":"Partnership through Play: Investigating How Long-Distance Couples Use Digital Games to Facilitate Intimacy","abstract":"Long-distance relationships (LDRs) have become more common in the last few decades, primarily among young adults pursuing educational or employment opportunities. A common way for couples in LDRs to spend time together is by playing multiplayer video games, which are often a shared hobby and therefore a preferred joint activity. However, games are relatively understudied in the context of relational maintenance for LDRs. In this work, we used a mixed-methods approach to collect data on the experiences of 13 couples in LDRs who frequently play games together. We investigated different values around various game mechanics and modalities and found significant differences in couple play styles, and also detail how couples appropriate game mechanics to express affection to each other virtually. We also created prototypes and design implications based on couples' needs surrounding the lack of physical sensation and memorabilia storage in most popular games.","sentences":["Long-distance relationships (LDRs) have become more common in the last few decades, primarily among young adults pursuing educational or employment opportunities.","A common way for couples in LDRs to spend time together is by playing multiplayer video games, which are often a shared hobby and therefore a preferred joint activity.","However, games are relatively understudied in the context of relational maintenance for LDRs.","In this work, we used a mixed-methods approach to collect data on the experiences of 13 couples in LDRs who frequently play games together.","We investigated different values around various game mechanics and modalities and found significant differences in couple play styles, and also detail how couples appropriate game mechanics to express affection to each other virtually.","We also created prototypes and design implications based on couples' needs surrounding the lack of physical sensation and memorabilia storage in most popular games."],"url":"http://arxiv.org/abs/2505.09509v1"}
{"created":"2025-05-14 15:53:14","title":"Towards Fair In-Context Learning with Tabular Foundation Models","abstract":"Tabular foundational models have exhibited strong in-context learning (ICL) capabilities on structured data, allowing them to make accurate predictions on test sets without parameter updates, using training examples as context. This emerging approach positions itself as a competitive alternative to traditional gradient-boosted tree methods. However, while biases in conventional machine learning models are well documented, it remains unclear how these biases manifest in tabular ICL. The paper investigates the fairness implications of tabular ICL and explores three preprocessing strategies--correlation removal, group-balanced demonstration selection, and uncertainty-based demonstration selection--to address bias. Comprehensive experiments indicate that uncertainty-based demonstration selection consistently enhances group fairness of in-context predictions. The source code for reproducing the results of this work can be found at https://github.com/patrikken/Fair-TabICL.","sentences":["Tabular foundational models have exhibited strong in-context learning (ICL) capabilities on structured data, allowing them to make accurate predictions on test sets without parameter updates, using training examples as context.","This emerging approach positions itself as a competitive alternative to traditional gradient-boosted tree methods.","However, while biases in conventional machine learning models are well documented, it remains unclear how these biases manifest in tabular ICL.","The paper investigates the fairness implications of tabular ICL and explores three preprocessing strategies--correlation removal, group-balanced demonstration selection, and uncertainty-based demonstration selection--to address bias.","Comprehensive experiments indicate that uncertainty-based demonstration selection consistently enhances group fairness of in-context predictions.","The source code for reproducing the results of this work can be found at https://github.com/patrikken/Fair-TabICL."],"url":"http://arxiv.org/abs/2505.09503v1"}
{"created":"2025-05-14 15:52:09","title":"Scaling Up: Revisiting Mining Android Sandboxes at Scale for Malware Classification","abstract":"The widespread use of smartphones in daily life has raised concerns about privacy and security among researchers and practitioners. Privacy issues are generally highly prevalent in mobile applications, particularly targeting the Android platform, the most popular mobile operating system. For this reason, several techniques have been proposed to identify malicious behavior in Android applications, including the Mining Android Sandbox approach (MAS approach), which aims to identify malicious behavior in repackaged Android applications (apps). However, previous empirical studies evaluated the MAS approach using a small dataset consisting of only 102 pairs of original and repackaged apps. This limitation raises questions about the external validity of their findings and whether the MAS approach can be generalized to larger datasets. To address these concerns, this paper presents the results of a replication study focused on evaluating the performance of the MAS approach regarding its capabilities of correctly classifying malware from different families. Unlike previous studies, our research employs a dataset that is an order of magnitude larger, comprising 4,076 pairs of apps covering a more diverse range of Android malware families. Surprisingly, our findings indicate a poor performance of the MAS approach for identifying malware, with the F1-score decreasing from 0.90 for the small dataset used in the previous studies to 0.54 in our more extensive dataset. Upon closer examination, we discovered that certain malware families partially account for the low accuracy of the MAS approach, which fails to classify a repackaged version of an app as malware correctly. Our findings highlight the limitations of the MAS approach, particularly when scaled, and underscore the importance of complementing it with other techniques to detect a broader range of malware effectively.","sentences":["The widespread use of smartphones in daily life has raised concerns about privacy and security among researchers and practitioners.","Privacy issues are generally highly prevalent in mobile applications, particularly targeting the Android platform, the most popular mobile operating system.","For this reason, several techniques have been proposed to identify malicious behavior in Android applications, including the Mining Android Sandbox approach (MAS approach), which aims to identify malicious behavior in repackaged Android applications (apps).","However, previous empirical studies evaluated the MAS approach using a small dataset consisting of only 102 pairs of original and repackaged apps.","This limitation raises questions about the external validity of their findings and whether the MAS approach can be generalized to larger datasets.","To address these concerns, this paper presents the results of a replication study focused on evaluating the performance of the MAS approach regarding its capabilities of correctly classifying malware from different families.","Unlike previous studies, our research employs a dataset that is an order of magnitude larger, comprising 4,076 pairs of apps covering a more diverse range of Android malware families.","Surprisingly, our findings indicate a poor performance of the MAS approach for identifying malware, with the F1-score decreasing from 0.90 for the small dataset used in the previous studies to 0.54 in our more extensive dataset.","Upon closer examination, we discovered that certain malware families partially account for the low accuracy of the MAS approach, which fails to classify a repackaged version of an app as malware correctly.","Our findings highlight the limitations of the MAS approach, particularly when scaled, and underscore the importance of complementing it with other techniques to detect a broader range of malware effectively."],"url":"http://arxiv.org/abs/2505.09501v1"}
{"created":"2025-05-14 15:50:45","title":"Layered Unlearning for Adversarial Relearning","abstract":"Our goal is to understand how post-training methods, such as fine-tuning, alignment, and unlearning, modify language model behavior and representations. We are particularly interested in the brittle nature of these modifications that makes them easy to bypass through prompt engineering or relearning. Recent results suggest that post-training induces shallow context-dependent ``circuits'' that suppress specific response patterns. This could be one explanation for the brittleness of post-training. To test this hypothesis, we design an unlearning algorithm, Layered Unlearning (LU), that creates distinct inhibitory mechanisms for a growing subset of the data. By unlearning the first $i$ folds while retaining the remaining $k - i$ at the $i$th of $k$ stages, LU limits the ability of relearning on a subset of data to recover the full dataset. We evaluate LU through a combination of synthetic and large language model (LLM) experiments. We find that LU improves robustness to adversarial relearning for several different unlearning methods. Our results contribute to the state-of-the-art of machine unlearning and provide insight into the effect of post-training updates.","sentences":["Our goal is to understand how post-training methods, such as fine-tuning, alignment, and unlearning, modify language model behavior and representations.","We are particularly interested in the brittle nature of these modifications that makes them easy to bypass through prompt engineering or relearning.","Recent results suggest that post-training induces shallow context-dependent ``circuits'' that suppress specific response patterns.","This could be one explanation for the brittleness of post-training.","To test this hypothesis, we design an unlearning algorithm, Layered Unlearning (LU), that creates distinct inhibitory mechanisms for a growing subset of the data.","By unlearning the first $i$ folds while retaining the remaining $k - i$ at the $i$th of $k$ stages, LU limits the ability of relearning on a subset of data to recover the full dataset.","We evaluate LU through a combination of synthetic and large language model (LLM) experiments.","We find that LU improves robustness to adversarial relearning for several different unlearning methods.","Our results contribute to the state-of-the-art of machine unlearning and provide insight into the effect of post-training updates."],"url":"http://arxiv.org/abs/2505.09500v1"}
{"created":"2025-05-14 15:45:17","title":"Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput","abstract":"In this paper, we introduce Flash-VL 2B, a novel approach to optimizing Vision-Language Models (VLMs) for real-time applications, targeting ultra-low latency and high throughput without sacrificing accuracy. Leveraging advanced architectural enhancements and efficient computational strategies, Flash-VL 2B is designed to maximize throughput by reducing processing time while maintaining competitive performance across multiple vision-language benchmarks. Our approach includes tailored architectural choices, token compression mechanisms, data curation, training schemes, and a novel image processing technique called implicit semantic stitching that effectively balances computational load and model performance. Through extensive evaluations on 11 standard VLM benchmarks, we demonstrate that Flash-VL 2B achieves state-of-the-art results in both speed and accuracy, making it a promising solution for deployment in resource-constrained environments and large-scale real-time applications.","sentences":["In this paper, we introduce Flash-VL 2B, a novel approach to optimizing Vision-Language Models (VLMs) for real-time applications, targeting ultra-low latency and high throughput without sacrificing accuracy.","Leveraging advanced architectural enhancements and efficient computational strategies, Flash-VL 2B is designed to maximize throughput by reducing processing time while maintaining competitive performance across multiple vision-language benchmarks.","Our approach includes tailored architectural choices, token compression mechanisms, data curation, training schemes, and a novel image processing technique called implicit semantic stitching that effectively balances computational load and model performance.","Through extensive evaluations on 11 standard VLM benchmarks, we demonstrate that Flash-VL 2B achieves state-of-the-art results in both speed and accuracy, making it a promising solution for deployment in resource-constrained environments and large-scale real-time applications."],"url":"http://arxiv.org/abs/2505.09498v1"}
{"created":"2025-05-14 15:40:40","title":"Radon Exposure Dataset","abstract":"Exposure to elevated radon levels in the home is one of the leading causes of lung cancer in the world. The following study describes the creation of a comprehensive, state-level dataset designed to enable the modeling and prediction of household radon concentrations at Zip Code Tabulation Area (ZCTA) and sub-kilometer scales. Details include the data collection and processing involved in compiling physical and demographic factors for Pennsylvania and Utah. Attempting to mitigate this risk requires identifying the underlying geological causes and the populations that might be at risk. This work focuses on identifying at-risk populations throughout Pennsylvania and Utah, where radon levels are some of the highest in the country. The resulting dataset harmonizes geological and demographic factors from various sources and spatial resolutions, including temperature, geochemistry, and soil characteristics. Demographic variables such as the household heating fuel used, the age of building, and the housing type provide further insight into which populations could be most susceptible in areas with potentially high radon levels. This dataset also serves as a foundational resource for two other studies conducted by the authors. The resolution of the data provides a novel approach to predicting potential radon exposure, and the data processing conducted for these states can be scaled up to larger spatial resolutions (e.g., the Contiguous United States [CONUS]) and allow for a broad reclassification of radon exposure potential in the United States.","sentences":["Exposure to elevated radon levels in the home is one of the leading causes of lung cancer in the world.","The following study describes the creation of a comprehensive, state-level dataset designed to enable the modeling and prediction of household radon concentrations at Zip Code Tabulation Area (ZCTA) and sub-kilometer scales.","Details include the data collection and processing involved in compiling physical and demographic factors for Pennsylvania and Utah.","Attempting to mitigate this risk requires identifying the underlying geological causes and the populations that might be at risk.","This work focuses on identifying at-risk populations throughout Pennsylvania and Utah, where radon levels are some of the highest in the country.","The resulting dataset harmonizes geological and demographic factors from various sources and spatial resolutions, including temperature, geochemistry, and soil characteristics.","Demographic variables such as the household heating fuel used, the age of building, and the housing type provide further insight into which populations could be most susceptible in areas with potentially high radon levels.","This dataset also serves as a foundational resource for two other studies conducted by the authors.","The resolution of the data provides a novel approach to predicting potential radon exposure, and the data processing conducted for these states can be scaled up to larger spatial resolutions (e.g., the Contiguous United States [CONUS]) and allow for a broad reclassification of radon exposure potential in the United States."],"url":"http://arxiv.org/abs/2505.09489v1"}
{"created":"2025-05-14 15:36:51","title":"Preserving Plasticity in Continual Learning with Adaptive Linearity Injection","abstract":"Loss of plasticity in deep neural networks is the gradual reduction in a model's capacity to incrementally learn and has been identified as a key obstacle to learning in non-stationary problem settings. Recent work has shown that deep linear networks tend to be resilient towards loss of plasticity. Motivated by this observation, we propose Adaptive Linearization (AdaLin), a general approach that dynamically adapts each neuron's activation function to mitigate plasticity loss. Unlike prior methods that rely on regularization or periodic resets, AdaLin equips every neuron with a learnable parameter and a gating mechanism that injects linearity into the activation function based on its gradient flow. This adaptive modulation ensures sufficient gradient signal and sustains continual learning without introducing additional hyperparameters or requiring explicit task boundaries. When used with conventional activation functions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can significantly improve performance on standard benchmarks, including Random Label and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split CIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such as class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in mitigating plasticity loss in off-policy reinforcement learning agents. We perform a systematic set of ablations that show that neuron-level adaptation is crucial for good performance and analyze a number of metrics in the network that might be correlated to loss of plasticity.","sentences":["Loss of plasticity in deep neural networks is the gradual reduction in a model's capacity to incrementally learn and has been identified as a key obstacle to learning in non-stationary problem settings.","Recent work has shown that deep linear networks tend to be resilient towards loss of plasticity.","Motivated by this observation, we propose Adaptive Linearization (AdaLin), a general approach that dynamically adapts each neuron's activation function to mitigate plasticity loss.","Unlike prior methods that rely on regularization or periodic resets, AdaLin equips every neuron with a learnable parameter and a gating mechanism that injects linearity into the activation function based on its gradient flow.","This adaptive modulation ensures sufficient gradient signal and sustains continual learning without introducing additional hyperparameters or requiring explicit task boundaries.","When used with conventional activation functions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can significantly improve performance on standard benchmarks, including Random Label and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split CIFAR-100.","Furthermore, its efficacy is shown in more complex scenarios, such as class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in mitigating plasticity loss in off-policy reinforcement learning agents.","We perform a systematic set of ablations that show that neuron-level adaptation is crucial for good performance and analyze a number of metrics in the network that might be correlated to loss of plasticity."],"url":"http://arxiv.org/abs/2505.09486v1"}
{"created":"2025-05-14 15:36:44","title":"Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing","abstract":"Face Anti-Spoofing (FAS) is essential for the security of facial recognition systems in diverse scenarios such as payment processing and surveillance. Current multimodal FAS methods often struggle with effective generalization, mainly due to modality-specific biases and domain shifts. To address these challenges, we introduce the \\textbf{M}ulti\\textbf{m}odal \\textbf{D}enoising and \\textbf{A}lignment (\\textbf{MMDA}) framework. By leveraging the zero-shot generalization capability of CLIP, the MMDA framework effectively suppresses noise in multimodal data through denoising and alignment mechanisms, thereby significantly enhancing the generalization performance of cross-modal alignment. The \\textbf{M}odality-\\textbf{D}omain Joint \\textbf{D}ifferential \\textbf{A}ttention (\\textbf{MD2A}) module in MMDA concurrently mitigates the impacts of domain and modality noise by refining the attention mechanism based on extracted common noise features. Furthermore, the \\textbf{R}epresentation \\textbf{S}pace \\textbf{S}oft (\\textbf{RS2}) Alignment strategy utilizes the pre-trained CLIP model to align multi-domain multimodal data into a generalized representation space in a flexible manner, preserving intricate representations and enhancing the model's adaptability to various unseen conditions. We also design a \\textbf{U}-shaped \\textbf{D}ual \\textbf{S}pace \\textbf{A}daptation (\\textbf{U-DSA}) module to enhance the adaptability of representations while maintaining generalization performance. These improvements not only enhance the framework's generalization capabilities but also boost its ability to represent complex representations. Our experimental results on four benchmark datasets under different evaluation protocols demonstrate that the MMDA framework outperforms existing state-of-the-art methods in terms of cross-domain generalization and multimodal detection accuracy. The code will be released soon.","sentences":["Face Anti-Spoofing (FAS) is essential for the security of facial recognition systems in diverse scenarios such as payment processing and surveillance.","Current multimodal FAS methods often struggle with effective generalization, mainly due to modality-specific biases and domain shifts.","To address these challenges, we introduce the \\textbf{M}ulti\\textbf{m}odal \\textbf{D}enoising and \\textbf{A}lignment (\\textbf{MMDA}) framework.","By leveraging the zero-shot generalization capability of CLIP, the MMDA framework effectively suppresses noise in multimodal data through denoising and alignment mechanisms, thereby significantly enhancing the generalization performance of cross-modal alignment.","The \\textbf{M}odality-\\textbf{D}omain Joint \\textbf{D}ifferential \\textbf{A}ttention (\\textbf{MD2A}) module in MMDA concurrently mitigates the impacts of domain and modality noise by refining the attention mechanism based on extracted common noise features.","Furthermore, the \\textbf{R}epresentation \\textbf{S}pace \\textbf{S}oft (\\textbf{RS2}) Alignment strategy utilizes the pre-trained CLIP model to align multi-domain multimodal data into a generalized representation space in a flexible manner, preserving intricate representations and enhancing the model's adaptability to various unseen conditions.","We also design a \\textbf{U}-shaped \\textbf{D}ual \\textbf{S}pace \\textbf{A}daptation (\\textbf{U-DSA}) module to enhance the adaptability of representations while maintaining generalization performance.","These improvements not only enhance the framework's generalization capabilities but also boost its ability to represent complex representations.","Our experimental results on four benchmark datasets under different evaluation protocols demonstrate that the MMDA framework outperforms existing state-of-the-art methods in terms of cross-domain generalization and multimodal detection accuracy.","The code will be released soon."],"url":"http://arxiv.org/abs/2505.09484v1"}
{"created":"2025-05-14 15:29:15","title":"Card Sorting Simulator: Augmenting Design of Logical Information Architectures with Large Language Models","abstract":"Card sorting is a common ideation technique that elicits information on users' mental organization of content and functionality by having them sort items into categories. For more robust card sorting research, digital card sorting tools could benefit from providing quick automated feedback. Our objective of this research is to advance toward an instrument that applies artificial intelligence (AI) to augment card sorting. For this purpose, we develop the Card Sorting Simulator, a prototype tool that leverages Large Language Models (LLMs) to generate informative categorizations of cards. To illuminate how aligned the simulation is with card sorting by actual participants, and to inform the instrument's design decisions, we conducted a generalizability-focused comparative study. We obtained 28 pre-existing card sorting studies from real practitioners, comprising 1,399 participants, along with diverse contents and origins. With this dataset, we conducted a comprehensive and nuanced analysis of the agreement between actual card sorting results (clusterings of cards) and synthetic clusterings across a multitude of LLMs and prompt designs. Mutual information scores indicate a good degree of agreement to real result clustering, although similarity matrices also demonstrate inconsistencies from mental models, which can be attributed to their top-down nature. Furthermore, the number of cards or complexity of their labels impact the accuracy of its simulation. These findings bolster the case for AI augmentation in card sorting research as a source of meaningful preliminary feedback and highlight the need for further study for the development and validation of intelligent user research tools.","sentences":["Card sorting is a common ideation technique that elicits information on users' mental organization of content and functionality by having them sort items into categories.","For more robust card sorting research, digital card sorting tools could benefit from providing quick automated feedback.","Our objective of this research is to advance toward an instrument that applies artificial intelligence (AI) to augment card sorting.","For this purpose, we develop the Card Sorting Simulator, a prototype tool that leverages Large Language Models (LLMs) to generate informative categorizations of cards.","To illuminate how aligned the simulation is with card sorting by actual participants, and to inform the instrument's design decisions, we conducted a generalizability-focused comparative study.","We obtained 28 pre-existing card sorting studies from real practitioners, comprising 1,399 participants, along with diverse contents and origins.","With this dataset, we conducted a comprehensive and nuanced analysis of the agreement between actual card sorting results (clusterings of cards) and synthetic clusterings across a multitude of LLMs and prompt designs.","Mutual information scores indicate a good degree of agreement to real result clustering, although similarity matrices also demonstrate inconsistencies from mental models, which can be attributed to their top-down nature.","Furthermore, the number of cards or complexity of their labels impact the accuracy of its simulation.","These findings bolster the case for AI augmentation in card sorting research as a source of meaningful preliminary feedback and highlight the need for further study for the development and validation of intelligent user research tools."],"url":"http://arxiv.org/abs/2505.09478v1"}
{"created":"2025-05-14 15:28:43","title":"Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities","abstract":"The integration of foundation models (FMs) into robotics has enabled robots to understand natural language and reason about the semantics in their environments. However, existing FM-enabled robots primary operate in closed-world settings, where the robot is given a full prior map or has a full view of its workspace. This paper addresses the deployment of FM-enabled robots in the field, where missions often require a robot to operate in large-scale and unstructured environments. To effectively accomplish these missions, robots must actively explore their environments, navigate obstacle-cluttered terrain, handle unexpected sensor inputs, and operate with compute constraints. We discuss recent deployments of SPINE, our LLM-enabled autonomy framework, in field robotic settings. To the best of our knowledge, we present the first demonstration of large-scale LLM-enabled robot planning in unstructured environments with several kilometers of missions. SPINE is agnostic to a particular LLM, which allows us to distill small language models capable of running onboard size, weight and power (SWaP) limited platforms. Via preliminary model distillation work, we then present the first language-driven UAV planner using on-device language models. We conclude our paper by proposing several promising directions for future research.","sentences":["The integration of foundation models (FMs) into robotics has enabled robots to understand natural language and reason about the semantics in their environments.","However, existing FM-enabled robots primary operate in closed-world settings, where the robot is given a full prior map or has a full view of its workspace.","This paper addresses the deployment of FM-enabled robots in the field, where missions often require a robot to operate in large-scale and unstructured environments.","To effectively accomplish these missions, robots must actively explore their environments, navigate obstacle-cluttered terrain, handle unexpected sensor inputs, and operate with compute constraints.","We discuss recent deployments of SPINE, our LLM-enabled autonomy framework, in field robotic settings.","To the best of our knowledge, we present the first demonstration of large-scale LLM-enabled robot planning in unstructured environments with several kilometers of missions.","SPINE is agnostic to a particular LLM, which allows us to distill small language models capable of running onboard size, weight and power (SWaP) limited platforms.","Via preliminary model distillation work, we then present the first language-driven UAV planner using on-device language models.","We conclude our paper by proposing several promising directions for future research."],"url":"http://arxiv.org/abs/2505.09477v1"}
{"created":"2025-05-14 15:25:50","title":"aUToPath: Unified Planning and Control for Autonomous Vehicles in Urban Environments Using Hybrid Lattice and Free-Space Search","abstract":"This paper presents aUToPath, a unified online framework for global path-planning and control to address the challenge of autonomous navigation in cluttered urban environments. A key component of our framework is a novel hybrid planner that combines pre-computed lattice maps with dynamic free-space sampling to efficiently generate optimal driveable corridors in cluttered scenarios. Our system also features sequential convex programming (SCP)-based model predictive control (MPC) to refine the corridors into smooth, dynamically consistent trajectories. A single optimization problem is used to both generate a trajectory and its corresponding control commands; this addresses limitations of decoupled approaches by guaranteeing a safe and feasible path. Simulation results of the novel planner on randomly generated obstacle-rich scenarios demonstrate the success rate of a free-space Adaptively Informed Trees* (AIT*)-based planner, and runtimes comparable to a lattice-based planner. Real-world experiments of the full system on a Chevrolet Bolt EUV further validate performance in dense obstacle fields, demonstrating no violations of traffic, kinematic, or vehicle constraints, and a 100% success rate across eight trials.","sentences":["This paper presents aUToPath, a unified online framework for global path-planning and control to address the challenge of autonomous navigation in cluttered urban environments.","A key component of our framework is a novel hybrid planner that combines pre-computed lattice maps with dynamic free-space sampling to efficiently generate optimal driveable corridors in cluttered scenarios.","Our system also features sequential convex programming (SCP)-based model predictive control (MPC) to refine the corridors into smooth, dynamically consistent trajectories.","A single optimization problem is used to both generate a trajectory and its corresponding control commands; this addresses limitations of decoupled approaches by guaranteeing a safe and feasible path.","Simulation results of the novel planner on randomly generated obstacle-rich scenarios demonstrate the success rate of a free-space Adaptively Informed Trees* (AIT*)-based planner, and runtimes comparable to a lattice-based planner.","Real-world experiments of the full system on a Chevrolet Bolt EUV further validate performance in dense obstacle fields, demonstrating no violations of traffic, kinematic, or vehicle constraints, and a 100% success rate across eight trials."],"url":"http://arxiv.org/abs/2505.09475v1"}
{"created":"2025-05-14 15:22:42","title":"Function-Correcting $b$-symbol Codes for Locally $(\u03bb, \u03c1,b)$-Functions","abstract":"The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family. In this paper, we explore locally ($\\lambda,\\rho$)-functions and develop function-correcting codes using these functions for $b$-symbol read channels. We establish the recurrence relation between the optimal redundancy of $(f,t)$ -function-correcting codes for the $(b+1)$-read and $b$-read channels. We establish an upper bound on the redundancy of general locally ($\\lambda,\\rho$, $b$)-function-correcting codes by linking it to the minimum achievable length of $b$-symbol error-correcting codes and traditional Hamming-metric codes, given a fixed number of codewords and a specified minimum distance. Specifically, we present explicit upper bounds for the classes of ($4,2t,b$)-local functions and ($2^b,2t,b$)-local functions. Additionally, for the case where $b=1$, we show that a ($3,2t,1$)-local function achieves the optimal redundancy of $3t$ under certain conditions. Moreover, we explicitly investigate locality and redundancy for the weight distribution function.","sentences":["The family of functions plays a central role in the design and effectiveness of function-correcting codes.","By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family.","In this paper, we explore locally ($\\lambda,\\rho$)-functions and develop function-correcting codes using these functions for $b$-symbol read channels.","We establish the recurrence relation between the optimal redundancy of $(f,t)$ -function-correcting codes for the $(b+1)$-read and $b$-read channels.","We establish an upper bound on the redundancy of general locally ($\\lambda,\\rho$, $b$)-function-correcting codes by linking it to the minimum achievable length of $b$-symbol error-correcting codes and traditional Hamming-metric codes, given a fixed number of codewords and a specified minimum distance.","Specifically, we present explicit upper bounds for the classes of ($4,2t,b$)-local functions and ($2^b,2t,b$)-local functions.","Additionally, for the case where $b=1$, we show that a ($3,2t,1$)-local function achieves the optimal redundancy of $3t$ under certain conditions.","Moreover, we explicitly investigate locality and redundancy for the weight distribution function."],"url":"http://arxiv.org/abs/2505.09473v1"}
{"created":"2025-05-14 15:22:38","title":"Streaming Multi-agent Pathfinding","abstract":"The task of the multi-agent pathfinding (MAPF) problem is to navigate a team of agents from their start point to the goal points. However, this setup is unsuitable in the assembly line scenario, which is periodic with a long working hour. To address this issue, the study formalizes the streaming MAPF (S-MAPF) problem, which assumes that the agents in the same agent stream have a periodic start time and share the same action sequence. The proposed solution, Agent Stream Conflict-Based Search (ASCBS), is designed to tackle this problem by incorporating a cyclic vertex/edge constraint to handle conflicts. Additionally, this work explores the potential usage of the disjoint splitting strategy within ASCBS. Experimental results indicate that ASCBS surpasses traditional MAPF solvers in terms of runtime for scenarios with prolonged working hours.","sentences":["The task of the multi-agent pathfinding (MAPF) problem is to navigate a team of agents from their start point to the goal points.","However, this setup is unsuitable in the assembly line scenario, which is periodic with a long working hour.","To address this issue, the study formalizes the streaming MAPF (S-MAPF) problem, which assumes that the agents in the same agent stream have a periodic start time and share the same action sequence.","The proposed solution, Agent Stream Conflict-Based Search (ASCBS), is designed to tackle this problem by incorporating a cyclic vertex/edge constraint to handle conflicts.","Additionally, this work explores the potential usage of the disjoint splitting strategy within ASCBS.","Experimental results indicate that ASCBS surpasses traditional MAPF solvers in terms of runtime for scenarios with prolonged working hours."],"url":"http://arxiv.org/abs/2505.09472v1"}
{"created":"2025-05-14 15:17:34","title":"A 2D Semantic-Aware Position Encoding for Vision Transformers","abstract":"Vision transformers have demonstrated significant advantages in computer vision tasks due to their ability to capture long-range dependencies and contextual relationships through self-attention. However, existing position encoding techniques, which are largely borrowed from natural language processing, fail to effectively capture semantic-aware positional relationships between image patches. Traditional approaches like absolute position encoding and relative position encoding primarily focus on 1D linear position relationship, often neglecting the semantic similarity between distant yet contextually related patches. These limitations hinder model generalization, translation equivariance, and the ability to effectively handle repetitive or structured patterns in images. In this paper, we propose 2-Dimensional Semantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding method with semantic awareness that dynamically adapts position representations by leveraging local content instead of fixed linear position relationship or spatial coordinates. Our method enhances the model's ability to generalize across varying image resolutions and scales, improves translation equivariance, and better aggregates features for visually similar but spatially distant patches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the gap between position encoding and perceptual similarity, thereby improving performance on computer vision tasks.","sentences":["Vision transformers have demonstrated significant advantages in computer vision tasks due to their ability to capture long-range dependencies and contextual relationships through self-attention.","However, existing position encoding techniques, which are largely borrowed from natural language processing, fail to effectively capture semantic-aware positional relationships between image patches.","Traditional approaches like absolute position encoding and relative position encoding primarily focus on 1D linear position relationship, often neglecting the semantic similarity between distant yet contextually related patches.","These limitations hinder model generalization, translation equivariance, and the ability to effectively handle repetitive or structured patterns in images.","In this paper, we propose 2-Dimensional Semantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding method with semantic awareness that dynamically adapts position representations by leveraging local content instead of fixed linear position relationship or spatial coordinates.","Our method enhances the model's ability to generalize across varying image resolutions and scales, improves translation equivariance, and better aggregates features for visually similar but spatially distant patches.","By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the gap between position encoding and perceptual similarity, thereby improving performance on computer vision tasks."],"url":"http://arxiv.org/abs/2505.09466v1"}
{"created":"2025-05-14 15:13:59","title":"ARM SVE Unleashed: Performance and Insights Across HPC Applications on Nvidia Grace","abstract":"Vector architectures are essential for boosting computing throughput. ARM provides SVE as the next-generation length-agnostic vector extension beyond traditional fixed-length SIMD. This work provides a first study of the maturity and readiness of exploiting ARM and SVE in HPC. Using selected performance hardware events on the ARM Grace processor and analytical models, we derive new metrics to quantify the effectiveness of exploiting SVE vectorization to reduce executed instructions and improve performance speedup. We further propose an adapted roofline model that combines vector length and data elements to identify potential performance bottlenecks. Finally, we propose a decision tree for classifying the SVE-boosted performance in applications.","sentences":["Vector architectures are essential for boosting computing throughput.","ARM provides SVE as the next-generation length-agnostic vector extension beyond traditional fixed-length SIMD.","This work provides a first study of the maturity and readiness of exploiting ARM and SVE in HPC.","Using selected performance hardware events on the ARM Grace processor and analytical models, we derive new metrics to quantify the effectiveness of exploiting SVE vectorization to reduce executed instructions and improve performance speedup.","We further propose an adapted roofline model that combines vector length and data elements to identify potential performance bottlenecks.","Finally, we propose a decision tree for classifying the SVE-boosted performance in applications."],"url":"http://arxiv.org/abs/2505.09462v1"}
{"created":"2025-05-14 15:08:28","title":"Variational Rank Reduction Autoencoder","abstract":"Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a regularization on the latent space by applying a truncated SVD. While this regularization makes Autoencoders more powerful, using them for generative purposes is counter-intuitive due to their deterministic nature. On the other hand, Variational Autoencoders (VAEs) are well known for their generative abilities by learning a probabilistic latent space. In this paper, we present Variational Rank Reduction Autoencoders (VRRAEs), a model that leverages the advantages of both RRAEs and VAEs. Our claims and results show that when carefully sampling the latent space of RRAEs and further regularizing with the Kullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs and VAEs. Additionally, we show that the regularization induced by the SVD not only makes VRRAEs better generators than VAEs, but also reduces the possibility of posterior collapse. Our results include a synthetic dataset of a small size that showcases the robustness of VRRAEs against collapse, and three real-world datasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to outperform both VAEs and RRAEs on many random generation and interpolation tasks based on the FID score.","sentences":["Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a regularization on the latent space by applying a truncated SVD.","While this regularization makes Autoencoders more powerful, using them for generative purposes is counter-intuitive due to their deterministic nature.","On the other hand, Variational Autoencoders (VAEs) are well known for their generative abilities by learning a probabilistic latent space.","In this paper, we present Variational Rank Reduction Autoencoders (VRRAEs), a model that leverages the advantages of both RRAEs and VAEs.","Our claims and results show that when carefully sampling the latent space of RRAEs and further regularizing with the Kullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs and VAEs.","Additionally, we show that the regularization induced by the SVD not only makes VRRAEs better generators than VAEs, but also reduces the possibility of posterior collapse.","Our results include a synthetic dataset of a small size that showcases the robustness of VRRAEs against collapse, and three real-world datasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to outperform both VAEs and RRAEs on many random generation and interpolation tasks based on the FID score."],"url":"http://arxiv.org/abs/2505.09458v1"}
{"created":"2025-05-14 15:05:36","title":"Beyond Pixels: Leveraging the Language of Soccer to Improve Spatio-Temporal Action Detection in Broadcast Videos","abstract":"State-of-the-art spatio-temporal action detection (STAD) methods show promising results for extracting soccer events from broadcast videos. However, when operated in the high-recall, low-precision regime required for exhaustive event coverage in soccer analytics, their lack of contextual understanding becomes apparent: many false positives could be resolved by considering a broader sequence of actions and game-state information. In this work, we address this limitation by reasoning at the game level and improving STAD through the addition of a denoising sequence transduction task. Sequences of noisy, context-free player-centric predictions are processed alongside clean game state information using a Transformer-based encoder-decoder model. By modeling extended temporal context and reasoning jointly over team-level dynamics, our method leverages the \"language of soccer\" - its tactical regularities and inter-player dependencies - to generate \"denoised\" sequences of actions. This approach improves both precision and recall in low-confidence regimes, enabling more reliable event extraction from broadcast video and complementing existing pixel-based methods.","sentences":["State-of-the-art spatio-temporal action detection (STAD) methods show promising results for extracting soccer events from broadcast videos.","However, when operated in the high-recall, low-precision regime required for exhaustive event coverage in soccer analytics, their lack of contextual understanding becomes apparent: many false positives could be resolved by considering a broader sequence of actions and game-state information.","In this work, we address this limitation by reasoning at the game level and improving STAD through the addition of a denoising sequence transduction task.","Sequences of noisy, context-free player-centric predictions are processed alongside clean game state information using a Transformer-based encoder-decoder model.","By modeling extended temporal context and reasoning jointly over team-level dynamics, our method leverages the \"language of soccer\" - its tactical regularities and inter-player dependencies - to generate \"denoised\" sequences of actions.","This approach improves both precision and recall in low-confidence regimes, enabling more reliable event extraction from broadcast video and complementing existing pixel-based methods."],"url":"http://arxiv.org/abs/2505.09455v1"}
{"created":"2025-05-14 15:03:16","title":"SEGA-DCIM: Design Space Exploration-Guided Automatic Digital CIM Compiler with Multiple Precision Support","abstract":"Digital computing-in-memory (DCIM) has been a popular solution for addressing the memory wall problem in recent years. However, the DCIM design still heavily relies on manual efforts, and the optimization of DCIM is often based on human experience. These disadvantages limit the time to market while increasing the design difficulty of DCIMs. This work proposes a design space exploration-guided automatic DCIM compiler (SEGA-DCIM) with multiple precision support, including integer and floating-point data precision operations. SEGA-DCIM can automatically generate netlists and layouts of DCIM designs by leveraging a template-based method. With a multi-objective genetic algorithm (MOGA)-based design space explorer, SEGA-DCIM can easily select appropriate DCIM designs for a specific application considering the trade-offs among area, power, and delay. As demonstrated by the experimental results, SEGA-DCIM offers solutions with wide design space, including integer and floating-point precision designs, while maintaining competitive performance compared to state-of-the-art (SOTA) DCIMs.","sentences":["Digital computing-in-memory (DCIM) has been a popular solution for addressing the memory wall problem in recent years.","However, the DCIM design still heavily relies on manual efforts, and the optimization of DCIM is often based on human experience.","These disadvantages limit the time to market while increasing the design difficulty of DCIMs.","This work proposes a design space exploration-guided automatic DCIM compiler (SEGA-DCIM) with multiple precision support, including integer and floating-point data precision operations.","SEGA-DCIM can automatically generate netlists and layouts of DCIM designs by leveraging a template-based method.","With a multi-objective genetic algorithm (MOGA)-based design space explorer, SEGA-DCIM can easily select appropriate DCIM designs for a specific application considering the trade-offs among area, power, and delay.","As demonstrated by the experimental results, SEGA-DCIM offers solutions with wide design space, including integer and floating-point precision designs, while maintaining competitive performance compared to state-of-the-art (SOTA) DCIMs."],"url":"http://arxiv.org/abs/2505.09451v1"}
{"created":"2025-05-14 15:01:59","title":"MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy","abstract":"Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally invasive diagnostic procedure. However, an aspiration needle tracker addressing rapid reciprocating motion is still missing. MrTrack, an aspiration needle tracker with a mamba-based register mechanism, is proposed. MrTrack leverages a Mamba-based register extractor to sequentially distill global context from each historical search map, storing these temporal cues in a register bank. The Mamba-based register retriever then retrieves temporal prompts from the register bank to provide external cues when current vision features are temporarily unusable due to rapid reciprocating motion and imaging degradation. A self-supervised register diversify loss is proposed to encourage feature diversity and dimension independence within the learned register, mitigating feature collapse. Comprehensive experiments conducted on both motorized and manual aspiration datasets demonstrate that MrTrack not only outperforms state-of-the-art trackers in accuracy and robustness but also achieves superior inference efficiency.","sentences":["Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally invasive diagnostic procedure.","However, an aspiration needle tracker addressing rapid reciprocating motion is still missing.","MrTrack, an aspiration needle tracker with a mamba-based register mechanism, is proposed.","MrTrack leverages a Mamba-based register extractor to sequentially distill global context from each historical search map, storing these temporal cues in a register bank.","The Mamba-based register retriever then retrieves temporal prompts from the register bank to provide external cues when current vision features are temporarily unusable due to rapid reciprocating motion and imaging degradation.","A self-supervised register diversify loss is proposed to encourage feature diversity and dimension independence within the learned register, mitigating feature collapse.","Comprehensive experiments conducted on both motorized and manual aspiration datasets demonstrate that MrTrack not only outperforms state-of-the-art trackers in accuracy and robustness but also achieves superior inference efficiency."],"url":"http://arxiv.org/abs/2505.09450v1"}
{"created":"2025-05-14 14:47:56","title":"Dimensioning and Optimization of Reliability Coverage in Local 6G Networks","abstract":"Enabling vertical use cases for the sixth generation (6G) wireless networks, such as automated manufacturing, immersive extended reality (XR), and self-driving fleets, will require network designs that meet reliability and latency targets in well-defined service areas. In order to establish a quantifiable design objective, we introduce the novel concept of reliability coverage, defined as the percentage area covered by communication services operating under well-defined reliability and performance targets. Reliability coverage allows us to unify the different network design tasks occurring at different time scales, namely resource orchestration and allocation, resulting in a single framework for dimensioning and optimization in local 6G networks. The two time scales, when considered together, yield remarkably consistent results and allow us to observe how stringent reliability/latency requirements translate into the increased wireless network resource demands.","sentences":["Enabling vertical use cases for the sixth generation (6G) wireless networks, such as automated manufacturing, immersive extended reality (XR), and self-driving fleets, will require network designs that meet reliability and latency targets in well-defined service areas.","In order to establish a quantifiable design objective, we introduce the novel concept of reliability coverage, defined as the percentage area covered by communication services operating under well-defined reliability and performance targets.","Reliability coverage allows us to unify the different network design tasks occurring at different time scales, namely resource orchestration and allocation, resulting in a single framework for dimensioning and optimization in local 6G networks.","The two time scales, when considered together, yield remarkably consistent results and allow us to observe how stringent reliability/latency requirements translate into the increased wireless network resource demands."],"url":"http://arxiv.org/abs/2505.09440v1"}
{"created":"2025-05-14 14:44:30","title":"CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios","abstract":"Large Language Models (LLMs) hold immense potential for revolutionizing Customer Experience Management (CXM), particularly in contact center operations. However, evaluating their practical utility in complex operational environments is hindered by data scarcity (due to privacy concerns) and the limitations of current benchmarks. Existing benchmarks often lack realism, failing to incorporate deep knowledge base (KB) integration, real-world noise, or critical operational tasks beyond conversational fluency. To bridge this gap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset specifically designed for evaluating AI in operational CXM contexts. Given the diversity in possible contact center features, we have developed a scalable LLM-powered pipeline that simulates the brand's CXM entities that form the foundation of our datasets-such as knowledge articles including product specifications, issue taxonomies, and contact center conversations. The entities closely represent real-world distribution because of controlled noise injection (informed by domain experts) and rigorous automated validation. Building on this, we release CXMArena, which provides dedicated benchmarks targeting five important operational tasks: Knowledge Base Refinement, Intent Prediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with Integrated Tools. Our baseline experiments underscore the benchmark's difficulty: even state of the art embedding and generation models achieve only 68% accuracy on article search, while standard embedding methods yield a low F1 score of 0.3 for knowledge base refinement, highlighting significant challenges for current models necessitating complex pipelines and solutions over conventional techniques.","sentences":["Large Language Models (LLMs) hold immense potential for revolutionizing Customer Experience Management (CXM), particularly in contact center operations.","However, evaluating their practical utility in complex operational environments is hindered by data scarcity (due to privacy concerns) and the limitations of current benchmarks.","Existing benchmarks often lack realism, failing to incorporate deep knowledge base (KB) integration, real-world noise, or critical operational tasks beyond conversational fluency.","To bridge this gap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset specifically designed for evaluating AI in operational CXM contexts.","Given the diversity in possible contact center features, we have developed a scalable LLM-powered pipeline that simulates the brand's CXM entities that form the foundation of our datasets-such as knowledge articles including product specifications, issue taxonomies, and contact center conversations.","The entities closely represent real-world distribution because of controlled noise injection (informed by domain experts) and rigorous automated validation.","Building on this, we release CXMArena, which provides dedicated benchmarks targeting five important operational tasks: Knowledge Base Refinement, Intent Prediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with Integrated Tools.","Our baseline experiments underscore the benchmark's difficulty: even state of the art embedding and generation models achieve only 68% accuracy on article search, while standard embedding methods yield a low F1 score of 0.3 for knowledge base refinement, highlighting significant challenges for current models necessitating complex pipelines and solutions over conventional techniques."],"url":"http://arxiv.org/abs/2505.09436v1"}
{"created":"2025-05-14 14:43:31","title":"Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records","abstract":"Pre-training on image-text colonoscopy records offers substantial potential for improving endoscopic image analysis, but faces challenges including non-informative background images, complex medical terminology, and ambiguous multi-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised framework that enhances Contrastive Language-Image Pre-training (CLIP) for this domain. Endo-CLIP's three-stage framework--cleansing, attunement, and unification--addresses these challenges by (1) removing background frames, (2) leveraging large language models to extract clinical attributes for fine-grained contrastive learning, and (3) employing patient-level cross-attention to resolve multi-polyp ambiguities. Extensive experiments demonstrate that Endo-CLIP significantly outperforms state-of-the-art pre-training methods in zero-shot and few-shot polyp detection and classification, paving the way for more accurate and clinically relevant endoscopic analysis.","sentences":["Pre-training on image-text colonoscopy records offers substantial potential for improving endoscopic image analysis, but faces challenges including non-informative background images, complex medical terminology, and ambiguous multi-lesion descriptions.","We introduce Endo-CLIP, a novel self-supervised framework that enhances Contrastive Language-Image Pre-training (CLIP) for this domain.","Endo-CLIP's three-stage framework--cleansing, attunement, and unification--addresses these challenges by (1) removing background frames, (2) leveraging large language models to extract clinical attributes for fine-grained contrastive learning, and (3) employing patient-level cross-attention to resolve multi-polyp ambiguities.","Extensive experiments demonstrate that Endo-CLIP significantly outperforms state-of-the-art pre-training methods in zero-shot and few-shot polyp detection and classification, paving the way for more accurate and clinically relevant endoscopic analysis."],"url":"http://arxiv.org/abs/2505.09435v1"}
{"created":"2025-05-14 14:42:07","title":"Decentralized Nonlinear Model Predictive Control-Based Flock Navigation with Real-Time Obstacle Avoidance in Unknown Obstructed Environments","abstract":"This work extends our prior work on the distributed nonlinear model predictive control (NMPC) for navigating a robot fleet following a certain flocking behavior in unknown obstructed environments with a more realistic local obstacle avoidance strategy. More specifically, we integrate the local obstacle avoidance constraint using point clouds into the NMPC framework. Here, each agent relies on data from its local sensor to perceive and respond to nearby obstacles. A point cloud processing technique is presented for both two-dimensional and three-dimensional point clouds to minimize the computational burden during the optimization. The process consists of directional filtering and down-sampling that significantly reduce the number of data points. The algorithm's performance is validated through realistic 3D simulations in Gazebo, and its practical feasibility is further explored via hardware-in-the-loop (HIL) simulations on embedded platforms.","sentences":["This work extends our prior work on the distributed nonlinear model predictive control (NMPC) for navigating a robot fleet following a certain flocking behavior in unknown obstructed environments with a more realistic local obstacle avoidance strategy.","More specifically, we integrate the local obstacle avoidance constraint using point clouds into the NMPC framework.","Here, each agent relies on data from its local sensor to perceive and respond to nearby obstacles.","A point cloud processing technique is presented for both two-dimensional and three-dimensional point clouds to minimize the computational burden during the optimization.","The process consists of directional filtering and down-sampling that significantly reduce the number of data points.","The algorithm's performance is validated through realistic 3D simulations in Gazebo, and its practical feasibility is further explored via hardware-in-the-loop (HIL) simulations on embedded platforms."],"url":"http://arxiv.org/abs/2505.09434v1"}
{"created":"2025-05-14 14:38:40","title":"Efficient LiDAR Reflectance Compression via Scanning Serialization","abstract":"Reflectance attributes in LiDAR point clouds provide essential information for downstream tasks but remain underexplored in neural compression methods. To address this, we introduce SerLiC, a serialization-based neural compression framework to fully exploit the intrinsic characteristics of LiDAR reflectance. SerLiC first transforms 3D LiDAR point clouds into 1D sequences via scan-order serialization, offering a device-centric perspective for reflectance analysis. Each point is then tokenized into a contextual representation comprising its sensor scanning index, radial distance, and prior reflectance, for effective dependencies exploration. For efficient sequential modeling, Mamba is incorporated with a dual parallelization scheme, enabling simultaneous autoregressive dependency capture and fast processing. Extensive experiments demonstrate that SerLiC attains over 2x volume reduction against the original reflectance data, outperforming the state-of-the-art method by up to 22% reduction of compressed bits while using only 2% of its parameters. Moreover, a lightweight version of SerLiC achieves > 10 fps (frames per second) with just 111K parameters, which is attractive for real-world applications.","sentences":["Reflectance attributes in LiDAR point clouds provide essential information for downstream tasks but remain underexplored in neural compression methods.","To address this, we introduce SerLiC, a serialization-based neural compression framework to fully exploit the intrinsic characteristics of LiDAR reflectance.","SerLiC","first transforms 3D LiDAR point clouds into 1D sequences via scan-order serialization, offering a device-centric perspective for reflectance analysis.","Each point is then tokenized into a contextual representation comprising its sensor scanning index, radial distance, and prior reflectance, for effective dependencies exploration.","For efficient sequential modeling, Mamba is incorporated with a dual parallelization scheme, enabling simultaneous autoregressive dependency capture and fast processing.","Extensive experiments demonstrate that SerLiC attains over 2x volume reduction against the original reflectance data, outperforming the state-of-the-art method by up to 22% reduction of compressed bits while using only 2% of its parameters.","Moreover, a lightweight version of SerLiC achieves > 10 fps (frames per second) with just 111K parameters, which is attractive for real-world applications."],"url":"http://arxiv.org/abs/2505.09433v1"}
{"created":"2025-05-14 14:37:32","title":"Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenche-Young Losses","abstract":"Surrogate regret bounds bridge the gap between the convergence rates of surrogate and target losses, with linear bounds favorable for their lossless regret transfer. While convex smooth surrogate losses are appealing in particular due to the efficient estimation and optimization, the existence of a trade-off between the smoothness and linear regret bound has been believed in the community. That being said, the better optimization and estimation properties of convex smooth surrogate losses may inevitably deteriorate after undergoing the regret transfer onto a target loss. We overcome this dilemma for arbitrary discrete target losses by constructing a convex smooth surrogate loss, which entails a linear surrogate regret bound composed with a tailored prediction link. The construction is based on Fenchel-Young losses generated by the convolutional negentropy, which are equivalent to the infimal convolution of a generalized negentropy and the target Bayes risk. Consequently, the infimal convolution enables us to derive a smooth loss while maintaining the surrogate regret bound linear. We additionally benefit from the infimal convolution to have a consistent estimator of the underlying class probability. Our results are overall a novel demonstration of how convex analysis penetrates into optimization and statistical efficiency in risk minimization.","sentences":["Surrogate regret bounds bridge the gap between the convergence rates of surrogate and target losses, with linear bounds favorable for their lossless regret transfer.","While convex smooth surrogate losses are appealing in particular due to the efficient estimation and optimization, the existence of a trade-off between the smoothness and linear regret bound has been believed in the community.","That being said, the better optimization and estimation properties of convex smooth surrogate losses may inevitably deteriorate after undergoing the regret transfer onto a target loss.","We overcome this dilemma for arbitrary discrete target losses by constructing a convex smooth surrogate loss, which entails a linear surrogate regret bound composed with a tailored prediction link.","The construction is based on Fenchel-Young losses generated by the convolutional negentropy, which are equivalent to the infimal convolution of a generalized negentropy and the target Bayes risk.","Consequently, the infimal convolution enables us to derive a smooth loss while maintaining the surrogate regret bound linear.","We additionally benefit from the infimal convolution to have a consistent estimator of the underlying class probability.","Our results are overall a novel demonstration of how convex analysis penetrates into optimization and statistical efficiency in risk minimization."],"url":"http://arxiv.org/abs/2505.09432v1"}
{"created":"2025-05-14 14:34:40","title":"Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU","abstract":"We present a method for training multi-task vision-language robotic diffusion policies that reduces training time and memory usage by an order of magnitude. This improvement arises from a previously underexplored distinction between action diffusion and the image diffusion techniques that inspired it: image generation targets are high-dimensional, while robot actions lie in a much lower-dimensional space. Meanwhile, the vision-language conditions for action generation remain high-dimensional. Our approach, Mini-Diffuser, exploits this asymmetry by introducing Level-2 minibatching, which pairs multiple noised action samples with each vision-language condition, instead of the conventional one-to-one sampling strategy. To support this batching scheme, we introduce architectural adaptations to the diffusion transformer that prevent information leakage across samples while maintaining full conditioning access. In RLBench simulations, Mini-Diffuser achieves 95\\% of the performance of state-of-the-art multi-task diffusion policies, while using only 5\\% of the training time and 7\\% of the memory. Real-world experiments further validate that Mini-Diffuser preserves the key strengths of diffusion-based policies, including the ability to model multimodal action distributions and produce behavior conditioned on diverse perceptual inputs. Code available at github.com/utomm/mini-diffuse-actor.","sentences":["We present a method for training multi-task vision-language robotic diffusion policies that reduces training time and memory usage by an order of magnitude.","This improvement arises from a previously underexplored distinction between action diffusion and the image diffusion techniques that inspired it: image generation targets are high-dimensional, while robot actions lie in a much lower-dimensional space.","Meanwhile, the vision-language conditions for action generation remain high-dimensional.","Our approach, Mini-Diffuser, exploits this asymmetry by introducing Level-2 minibatching, which pairs multiple noised action samples with each vision-language condition, instead of the conventional one-to-one sampling strategy.","To support this batching scheme, we introduce architectural adaptations to the diffusion transformer that prevent information leakage across samples while maintaining full conditioning access.","In RLBench simulations, Mini-Diffuser achieves 95\\% of the performance of state-of-the-art multi-task diffusion policies, while using only 5\\% of the training time and 7\\% of the memory.","Real-world experiments further validate that Mini-Diffuser preserves the key strengths of diffusion-based policies, including the ability to model multimodal action distributions and produce behavior conditioned on diverse perceptual inputs.","Code available at github.com/utomm/mini-diffuse-actor."],"url":"http://arxiv.org/abs/2505.09430v1"}
{"created":"2025-05-14 14:33:16","title":"Linear Search with Probabilistic Detection and Variable Speeds","abstract":"We present results on new variants of the famous linear search (or cow-path) problem that involves an agent searching for a target with unknown position on the infinite line. We consider the variant where the agent can move either at speed $1$ or at a slower speed $v \\in [0, 1)$. When traveling at the slower speed $v$, the agent is guaranteed to detect the target upon passing through its location. When traveling at speed $1$, however, the agent, upon passing through the target's location, detects it with probability $p \\in [0, 1]$. We present algorithms and provide upper bounds for the competitive ratios for three cases separately: when $p=0$, $v=0$, and when $p,v \\in (0,1)$. We also prove that the provided algorithm for the $p=0$ case is optimal.","sentences":["We present results on new variants of the famous linear search (or cow-path) problem that involves an agent searching for a target with unknown position on the infinite line.","We consider the variant where the agent can move either at speed $1$ or at a slower speed $v \\in [0, 1)$.","When traveling at the slower speed $v$, the agent is guaranteed to detect the target upon passing through its location.","When traveling at speed $1$, however, the agent, upon passing through the target's location, detects it with probability $p \\in [0, 1]$. We present algorithms and provide upper bounds for the competitive ratios for three cases separately: when $p=0$, $v=0$, and when $p,v \\in (0,1)$. We also prove that the provided algorithm for the $p=0$ case is optimal."],"url":"http://arxiv.org/abs/2505.09429v1"}
{"created":"2025-05-14 14:28:24","title":"SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation","abstract":"Large Language Models (LLMs) show growing promise in autonomous driving by reasoning over complex traffic scenarios to generate path plans. However, their tendencies toward overconfidence, and hallucinations raise critical safety concerns. We introduce SafePath, a modular framework that augments LLM-based path planning with formal safety guarantees using conformal prediction. SafePath operates in three stages. In the first stage, we use an LLM that generates a set of diverse candidate paths, exploring possible trajectories based on agent behaviors and environmental cues. In the second stage, SafePath filters out high-risk trajectories while guaranteeing that at least one safe option is included with a user-defined probability, through a multiple-choice question-answering formulation that integrates conformal prediction. In the final stage, our approach selects the path with the lowest expected collision risk when uncertainty is low or delegates control to a human when uncertainty is high. We theoretically prove that SafePath guarantees a safe trajectory with a user-defined probability, and we show how its human delegation rate can be tuned to balance autonomy and safety. Extensive experiments on nuScenes and Highway-env show that SafePath reduces planning uncertainty by 77\\% and collision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven path planning more safer.","sentences":["Large Language Models (LLMs) show growing promise in autonomous driving by reasoning over complex traffic scenarios to generate path plans.","However, their tendencies toward overconfidence, and hallucinations raise critical safety concerns.","We introduce SafePath, a modular framework that augments LLM-based path planning with formal safety guarantees using conformal prediction.","SafePath operates in three stages.","In the first stage, we use an LLM that generates a set of diverse candidate paths, exploring possible trajectories based on agent behaviors and environmental cues.","In the second stage, SafePath filters out high-risk trajectories while guaranteeing that at least one safe option is included with a user-defined probability, through a multiple-choice question-answering formulation that integrates conformal prediction.","In the final stage, our approach selects the path with the lowest expected collision risk when uncertainty is low or delegates control to a human when uncertainty is high.","We theoretically prove that SafePath guarantees a safe trajectory with a user-defined probability, and we show how its human delegation rate can be tuned to balance autonomy and safety.","Extensive experiments on nuScenes and Highway-env show that SafePath reduces planning uncertainty by 77\\% and collision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven path planning more safer."],"url":"http://arxiv.org/abs/2505.09427v1"}
{"created":"2025-05-14 14:25:32","title":"Exploring Pose-Guided Imitation Learning for Robotic Precise Insertion","abstract":"Recent studies have proved that imitation learning shows strong potential in the field of robotic manipulation. However, existing methods still struggle with precision manipulation task and rely on inefficient image/point cloud observations. In this paper, we explore to introduce SE(3) object pose into imitation learning and propose the pose-guided efficient imitation learning methods for robotic precise insertion task. First, we propose a precise insertion diffusion policy which utilizes the relative SE(3) pose as the observation-action pair. The policy models the source object SE(3) pose trajectory relative to the target object. Second, we explore to introduce the RGBD data to the pose-guided diffusion policy. Specifically, we design a goal-conditioned RGBD encoder to capture the discrepancy between the current state and the goal state. In addition, a pose-guided residual gated fusion method is proposed, which takes pose features as the backbone, and the RGBD features selectively compensate for pose feature deficiencies through an adaptive gating mechanism. Our methods are evaluated on 6 robotic precise insertion tasks, demonstrating competitive performance with only 7-10 demonstrations. Experiments demonstrate that the proposed methods can successfully complete precision insertion tasks with a clearance of about 0.01 mm. Experimental results highlight its superior efficiency and generalization capability compared to existing baselines. Code will be available at https://github.com/sunhan1997/PoseInsert.","sentences":["Recent studies have proved that imitation learning shows strong potential in the field of robotic manipulation.","However, existing methods still struggle with precision manipulation task and rely on inefficient image/point cloud observations.","In this paper, we explore to introduce SE(3) object pose into imitation learning and propose the pose-guided efficient imitation learning methods for robotic precise insertion task.","First, we propose a precise insertion diffusion policy which utilizes the relative SE(3) pose as the observation-action pair.","The policy models the source object SE(3) pose trajectory relative to the target object.","Second, we explore to introduce the RGBD data to the pose-guided diffusion policy.","Specifically, we design a goal-conditioned RGBD encoder to capture the discrepancy between the current state and the goal state.","In addition, a pose-guided residual gated fusion method is proposed, which takes pose features as the backbone, and the RGBD features selectively compensate for pose feature deficiencies through an adaptive gating mechanism.","Our methods are evaluated on 6 robotic precise insertion tasks, demonstrating competitive performance with only 7-10 demonstrations.","Experiments demonstrate that the proposed methods can successfully complete precision insertion tasks with a clearance of about 0.01 mm.","Experimental results highlight its superior efficiency and generalization capability compared to existing baselines.","Code will be available at https://github.com/sunhan1997/PoseInsert."],"url":"http://arxiv.org/abs/2505.09424v1"}
{"created":"2025-05-14 14:23:33","title":"MoRAL: Motion-aware Multi-Frame 4D Radar and LiDAR Fusion for Robust 3D Object Detection","abstract":"Reliable autonomous driving systems require accurate detection of traffic participants. To this end, multi-modal fusion has emerged as an effective strategy. In particular, 4D radar and LiDAR fusion methods based on multi-frame radar point clouds have demonstrated the effectiveness in bridging the point density gap. However, they often neglect radar point clouds' inter-frame misalignment caused by object movement during accumulation and do not fully exploit the object dynamic information from 4D radar. In this paper, we propose MoRAL, a motion-aware multi-frame 4D radar and LiDAR fusion framework for robust 3D object detection. First, a Motion-aware Radar Encoder (MRE) is designed to compensate for inter-frame radar misalignment from moving objects. Later, a Motion Attention Gated Fusion (MAGF) module integrate radar motion features to guide LiDAR features to focus on dynamic foreground objects. Extensive evaluations on the View-of-Delft (VoD) dataset demonstrate that MoRAL outperforms existing methods, achieving the highest mAP of 73.30% in the entire area and 88.68% in the driving corridor. Notably, our method also achieves the best AP of 69.67% for pedestrians in the entire area and 96.25% for cyclists in the driving corridor.","sentences":["Reliable autonomous driving systems require accurate detection of traffic participants.","To this end, multi-modal fusion has emerged as an effective strategy.","In particular, 4D radar and LiDAR fusion methods based on multi-frame radar point clouds have demonstrated the effectiveness in bridging the point density gap.","However, they often neglect radar point clouds' inter-frame misalignment caused by object movement during accumulation and do not fully exploit the object dynamic information from 4D radar.","In this paper, we propose MoRAL, a motion-aware multi-frame 4D radar and LiDAR fusion framework for robust 3D object detection.","First, a Motion-aware Radar Encoder (MRE) is designed to compensate for inter-frame radar misalignment from moving objects.","Later, a Motion Attention Gated Fusion (MAGF) module integrate radar motion features to guide LiDAR features to focus on dynamic foreground objects.","Extensive evaluations on the View-of-Delft (VoD) dataset demonstrate that MoRAL outperforms existing methods, achieving the highest mAP of 73.30% in the entire area and 88.68% in the driving corridor.","Notably, our method also achieves the best AP of 69.67% for pedestrians in the entire area and 96.25% for cyclists in the driving corridor."],"url":"http://arxiv.org/abs/2505.09422v1"}
{"created":"2025-05-14 14:14:04","title":"Non-expansive Fuzzy ALC","abstract":"Fuzzy description logics serve the representation of vague knowledge, typically letting concepts take truth degrees in the unit interval. Expressiveness, logical properties, and complexity vary strongly with the choice of propositional base. The Lukasiewicz propositional base is generally perceived to have preferable logical properties but often entails high complexity or even undecidability. Contrastingly, the less expressive Zadeh propositional base comes with low complexity but entails essentially no change in logical behaviour compared to the classical case. To strike a balance between these poles, we propose non-expansive fuzzy ALC, in which the Zadeh base is extended with Lukasiewicz connectives where one side is restricted to be a rational constant, that is, with constant shift operators. This allows, for instance, modelling dampened inheritance of properties along roles. We present an unlabelled tableau method for non-expansive fuzzy ALC, which allows reasoning over general TBoxes in EXPTIME like in two-valued ALC.","sentences":["Fuzzy description logics serve the representation of vague knowledge, typically letting concepts take truth degrees in the unit interval.","Expressiveness, logical properties, and complexity vary strongly with the choice of propositional base.","The Lukasiewicz propositional base is generally perceived to have preferable logical properties but often entails high complexity or even undecidability.","Contrastingly, the less expressive Zadeh propositional base comes with low complexity but entails essentially no change in logical behaviour compared to the classical case.","To strike a balance between these poles, we propose non-expansive fuzzy ALC, in which the Zadeh base is extended with Lukasiewicz connectives where one side is restricted to be a rational constant, that is, with constant shift operators.","This allows, for instance, modelling dampened inheritance of properties along roles.","We present an unlabelled tableau method for non-expansive fuzzy ALC, which allows reasoning over general TBoxes in EXPTIME like in two-valued ALC."],"url":"http://arxiv.org/abs/2505.09416v1"}
{"created":"2025-05-14 14:10:43","title":"FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models","abstract":"Face anti-spoofing (FAS) is crucial for protecting facial recognition systems from presentation attacks. Previous methods approached this task as a classification problem, lacking interpretability and reasoning behind the predicted results. Recently, multimodal large language models (MLLMs) have shown strong capabilities in perception, reasoning, and decision-making in visual tasks. However, there is currently no universal and comprehensive MLLM and dataset specifically designed for FAS task. To address this gap, we propose FaceShield, a MLLM for FAS, along with the corresponding pre-training and supervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K. FaceShield is capable of determining the authenticity of faces, identifying types of spoofing attacks, providing reasoning for its judgments, and detecting attack areas. Specifically, we employ spoof-aware vision perception (SAVP) that incorporates both the original image and auxiliary information based on prior knowledge. We then use an prompt-guided vision token masking (PVTM) strategy to random mask vision tokens, thereby improving the model's generalization ability. We conducted extensive experiments on three benchmark datasets, demonstrating that FaceShield significantly outperforms previous deep learning models and general MLLMs on four FAS tasks, i.e., coarse-grained classification, fine-grained classification, reasoning, and attack localization. Our instruction datasets, protocols, and codes will be released soon.","sentences":["Face anti-spoofing (FAS) is crucial for protecting facial recognition systems from presentation attacks.","Previous methods approached this task as a classification problem, lacking interpretability and reasoning behind the predicted results.","Recently, multimodal large language models (MLLMs) have shown strong capabilities in perception, reasoning, and decision-making in visual tasks.","However, there is currently no universal and comprehensive MLLM and dataset specifically designed for FAS task.","To address this gap, we propose FaceShield, a MLLM for FAS, along with the corresponding pre-training and supervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K. FaceShield is capable of determining the authenticity of faces, identifying types of spoofing attacks, providing reasoning for its judgments, and detecting attack areas.","Specifically, we employ spoof-aware vision perception (SAVP) that incorporates both the original image and auxiliary information based on prior knowledge.","We then use an prompt-guided vision token masking (PVTM) strategy to random mask vision tokens, thereby improving the model's generalization ability.","We conducted extensive experiments on three benchmark datasets, demonstrating that FaceShield significantly outperforms previous deep learning models and general MLLMs on four FAS tasks, i.e., coarse-grained classification, fine-grained classification, reasoning, and attack localization.","Our instruction datasets, protocols, and codes will be released soon."],"url":"http://arxiv.org/abs/2505.09415v1"}
{"created":"2025-05-14 14:10:22","title":"FACTors: A New Dataset for Studying the Fact-checking Ecosystem","abstract":"Our fight against false information is spearheaded by fact-checkers. They investigate the veracity of claims and document their findings as fact-checking reports. With the rapid increase in the amount of false information circulating online, the use of automation in fact-checking processes aims to strengthen this ecosystem by enhancing scalability. Datasets containing fact-checked claims play a key role in developing such automated solutions. However, to the best of our knowledge, there is no fact-checking dataset at the ecosystem level, covering claims from a sufficiently long period of time and sourced from a wide range of actors reflecting the entire ecosystem that admittedly follows widely-accepted codes and principles of fact-checking. We present a new dataset FACTors, the first to fill this gap by presenting ecosystem-level data on fact-checking. It contains 118,112 claims from 117,993 fact-checking reports in English (co-)authored by 1,953 individuals and published during the period of 1995-2025 by 39 fact-checking organisations that are active signatories of the IFCN (International Fact-Checking Network) and/or EFCSN (European Fact-Checking Standards Network). It contains 7,327 overlapping claims investigated by multiple fact-checking organisations, corresponding to 2,977 unique claims. It allows to conduct new ecosystem-level studies of the fact-checkers (organisations and individuals). To demonstrate the usefulness of FACTors, we present three example applications, including a first-of-its-kind statistical analysis of the fact-checking ecosystem, examining the political inclinations of the fact-checking organisations, and attempting to assign a credibility score to each organisation based on the findings of the statistical analysis and political leanings. Our methods for constructing FACTors are generic and can be used to maintain a live dataset that can be updated dynamically.","sentences":["Our fight against false information is spearheaded by fact-checkers.","They investigate the veracity of claims and document their findings as fact-checking reports.","With the rapid increase in the amount of false information circulating online, the use of automation in fact-checking processes aims to strengthen this ecosystem by enhancing scalability.","Datasets containing fact-checked claims play a key role in developing such automated solutions.","However, to the best of our knowledge, there is no fact-checking dataset at the ecosystem level, covering claims from a sufficiently long period of time and sourced from a wide range of actors reflecting the entire ecosystem that admittedly follows widely-accepted codes and principles of fact-checking.","We present a new dataset FACTors, the first to fill this gap by presenting ecosystem-level data on fact-checking.","It contains 118,112 claims from 117,993 fact-checking reports in English (co-)authored by 1,953 individuals and published during the period of 1995-2025 by 39 fact-checking organisations that are active signatories of the IFCN (International Fact-Checking Network) and/or","EFCSN (European Fact-Checking Standards Network).","It contains 7,327 overlapping claims investigated by multiple fact-checking organisations, corresponding to 2,977 unique claims.","It allows to conduct new ecosystem-level studies of the fact-checkers (organisations and individuals).","To demonstrate the usefulness of FACTors, we present three example applications, including a first-of-its-kind statistical analysis of the fact-checking ecosystem, examining the political inclinations of the fact-checking organisations, and attempting to assign a credibility score to each organisation based on the findings of the statistical analysis and political leanings.","Our methods for constructing FACTors are generic and can be used to maintain a live dataset that can be updated dynamically."],"url":"http://arxiv.org/abs/2505.09414v1"}
{"created":"2025-05-14 14:10:09","title":"Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians","abstract":"Current learning-based methods predict NeRF or 3D Gaussians from point clouds to achieve photo-realistic rendering but still depend on categorical priors, dense point clouds, or additional refinements. Hence, we introduce a novel point cloud rendering method by predicting 2D Gaussians from point clouds. Our method incorporates two identical modules with an entire-patch architecture enabling the network to be generalized to multiple datasets. The module normalizes and initializes the Gaussians utilizing the point cloud information including normals, colors and distances. Then, splitting decoders are employed to refine the initial Gaussians by duplicating them and predicting more accurate results, making our methodology effectively accommodate sparse point clouds as well. Once trained, our approach exhibits direct generalization to point clouds across different categories. The predicted Gaussians are employed directly for rendering without additional refinement on the rendered images, retaining the benefits of 2D Gaussians. We conduct extensive experiments on various datasets, and the results demonstrate the superiority and generalization of our method, which achieves SOTA performance. The code is available at https://github.com/murcherful/GauPCRender}{https://github.com/murcherful/GauPCRender.","sentences":["Current learning-based methods predict NeRF or 3D Gaussians from point clouds to achieve photo-realistic rendering but still depend on categorical priors, dense point clouds, or additional refinements.","Hence, we introduce a novel point cloud rendering method by predicting 2D Gaussians from point clouds.","Our method incorporates two identical modules with an entire-patch architecture enabling the network to be generalized to multiple datasets.","The module normalizes and initializes the Gaussians utilizing the point cloud information including normals, colors and distances.","Then, splitting decoders are employed to refine the initial Gaussians by duplicating them and predicting more accurate results, making our methodology effectively accommodate sparse point clouds as well.","Once trained, our approach exhibits direct generalization to point clouds across different categories.","The predicted Gaussians are employed directly for rendering without additional refinement on the rendered images, retaining the benefits of 2D Gaussians.","We conduct extensive experiments on various datasets, and the results demonstrate the superiority and generalization of our method, which achieves SOTA performance.","The code is available at https://github.com/murcherful/GauPCRender}{https://github.com/murcherful/GauPCRender."],"url":"http://arxiv.org/abs/2505.09413v1"}
{"created":"2025-05-14 14:07:27","title":"Counterfactual Strategies for Markov Decision Processes","abstract":"Counterfactuals are widely used in AI to explain how minimal changes to a model's input can lead to a different output. However, established methods for computing counterfactuals typically focus on one-step decision-making, and are not directly applicable to sequential decision-making tasks. This paper fills this gap by introducing counterfactual strategies for Markov Decision Processes (MDPs). During MDP execution, a strategy decides which of the enabled actions (with known probabilistic effects) to execute next. Given an initial strategy that reaches an undesired outcome with a probability above some limit, we identify minimal changes to the initial strategy to reduce that probability below the limit. We encode such counterfactual strategies as solutions to non-linear optimization problems, and further extend our encoding to synthesize diverse counterfactual strategies. We evaluate our approach on four real-world datasets and demonstrate its practical viability in sophisticated sequential decision-making tasks.","sentences":["Counterfactuals are widely used in AI to explain how minimal changes to a model's input can lead to a different output.","However, established methods for computing counterfactuals typically focus on one-step decision-making, and are not directly applicable to sequential decision-making tasks.","This paper fills this gap by introducing counterfactual strategies for Markov Decision Processes (MDPs).","During MDP execution, a strategy decides which of the enabled actions (with known probabilistic effects) to execute next.","Given an initial strategy that reaches an undesired outcome with a probability above some limit, we identify minimal changes to the initial strategy to reduce that probability below the limit.","We encode such counterfactual strategies as solutions to non-linear optimization problems, and further extend our encoding to synthesize diverse counterfactual strategies.","We evaluate our approach on four real-world datasets and demonstrate its practical viability in sophisticated sequential decision-making tasks."],"url":"http://arxiv.org/abs/2505.09412v1"}
